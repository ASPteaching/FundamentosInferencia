# Pruebas $\mathrm{X}^{2}$

1. El modelo multinomial
2. Aplicaciones del modelo multinomial
3. Formalización del contraste
4. Condiciones de validez
5. Análisis de Tablas de contingencia
6. Pruebas de independencia
7. Violación de las condiciones del contraste
8. Pruebas de homogeneidad

## El modelo multinomial.

Es un modelo discreto multivariante. Puede verse como una generalización del modelo binomial que permite más de dos posibles resultados. Ya hemos hablado de él en el capítulo dedicado a las distribuciones discretas.

Una situación típica es el número de veces que se dan cada uno de los posibles resultados $\mathrm{A}_{1}, \ldots$, $\mathrm{A}_{\mathrm{k}}$ en N extracciones independientes manteniéndose constante la probabilidad de cada resultado. Los parámetros del modelo se corresponden con las diferentes probabilidades: $\mathrm{p}_{1}=\mathrm{P}\left(\mathrm{A}_{1}\right), \cdots \cdots, \mathrm{p}_{\mathrm{k}}=\mathrm{P}\left(\mathrm{A}_{\mathrm{k}}\right)$ y con el valor N .

Por ejemplo:
Para saber si un dado es regular realizamos 120 lanzamientos y anotamos los resultados obtenidos:

| Resultado | 1 | 2 | 3 | 4 | 5 | 6 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| Frecuencia | 15 | 22 | 18 | 14 | 25 | 26 |

El modelo teórico sugiere que la probabilidad de cada cara es la misma

$$
\mathrm{P}(1)=\mathrm{P}(2)=\mathrm{P}(3)=\mathrm{P}(4)=\mathrm{P}(5)=\mathrm{P}(6)=1 / 6 \text {, es decir } \mathrm{p}_{\mathrm{i}}=1 / 6 \quad \mathrm{i}=1, \ldots, 6
$$

Los valores realmente observados son: $O_{1}=15, \ldots, O_{6}=26$.

### Aplicaciones del modelo multinomial.

Generalmente la inferencia basada en el modelo multinomial está enfocada a comprobar si dado un modelo teórico los resultados muestrales obtenidos son compatibles con el modelo.

Posibles aplicaciones:

- Bondad de ajuste a distribuciones teóricas.
- Pruebas de independencia en Tablas de contingencia.
- Pruebas de homogeneidad para variables cualitativas.


### Formalización del contraste.

La hipótesis nula del contraste es que el modelo multinomial teórico es correcto :

$$
\begin{gathered}
\mathrm{H}_{0}: \mathrm{P}\left(\mathrm{~A}_{1}\right)=\mathrm{p}_{1}, \mathrm{P}\left(\mathrm{~A}_{2}\right)=\mathrm{p}_{2}, \ldots, \mathrm{P}\left(\mathrm{~A}_{\mathrm{K}}\right)=\mathrm{p}_{\mathrm{k}} \\
\mathrm{H}_{1}: \text { Para alguna i } \mathrm{P}\left(\mathrm{~A}_{\mathrm{i}}\right) \neq \mathrm{p}_{\mathrm{i}}
\end{gathered}
$$

Obtención de las probabilidades $\mathrm{p}_{\mathrm{i}}$ :

- Las que directamente indique $\mathrm{H}_{0}$ si es el caso.
- $\mathrm{Si}_{0}$ indica la distribución de la variable, estimar los parámetros y a través de ellos las probabilidades.
- En el caso de pruebas de independencia y homogeneidad en tablas de contingencia se verá más adelante.

Los valores esperados para cada clase bajo $\mathrm{H}_{0}$ son $e_{i}=\mathrm{N} \cdot \mathrm{p}_{\mathrm{i}}$., donde N es la suma de los valores observados para cada clase ( $\mathrm{N}=o_{1}+o_{2}+\ldots+o_{k}$ )

El estadístico para contrastar la hipótesis es el siguiente:

$$
\chi_{\exp }^{2}=\sum_{i=1}^{k} \frac{\left(o_{i}-e_{i}\right)^{2}}{e_{i}}
$$

La distribución asintótica del estadístico anterior bajo la hipótesis nula es una $\chi^{2}$ con $\mathrm{k}-\mathrm{s}-\mathrm{r}$ grados de libertad, donde s es el número de parámetros que ha sido necesario estimar a partir de la muestra para determinar las probabilidades teóricas, y r es el número de restricciones impuestas a los valores esperados. Este último valor es generalmente 1 debido a la restricción $e_{1}+e_{2}+\ldots+e_{k}=N$.

Rechazamos la hipótesis nula si

$$
\chi_{\exp }^{2} \geq \chi_{\alpha}^{2}
$$

donde el último término es el valor crítico asociado a una distribución $\chi^{2}$ con $\mathrm{k}-\mathrm{s}-\mathrm{r}$ grados de libertad tal que deja a su derecha una probabilidad igual a $\alpha$.

Si $\mathrm{k}=2$ es equivalente al contraste para una proporción.
Puede aplicarse a variables continuas definiendo las clases a través de intervalos.

<!-- | ![](https://cdn.mathpix.com/cropped/8fb6aebc-d028-4d10-9d17-acf468c1b322-05.jpg?height=764&width=315&top_left_y=94&top_left_x=486) |  -->

Se puede comprobar el comprobar el funcionamiento funcionamiento de la prueba Jide la prueba Jicuadrado para para verificar la de bondad de entre ajuste entre unas frecuencias observadas y unas y proporciones teóricas. toricas. |
| :--- | :--- |

### Condiciones de validez.

Es un contraste asintótico que requiere para su validez que las frecuencias esperadas ( $\mathrm{N} \cdot \mathrm{p}_{\mathrm{i}}$ ) sean suficientemente grandes, en general se pide que sean superiores a $\mathbf{5}$. Caso de no verificarse esta premisa será necesario ampliar la muestra para incrementar las frecuencias esperadas, o en su defecto agrupar clases para lograr el mismo objetivo.

El siguiente Applet nos permite verificar la correcta aproximación del contraste a través de unas simulaciones de lanzamientos de un dado con frecuencias teóricas de cada cara seleccionadas por nosotros. La simulación se realiza según la frecuencia teórica, por tanto el resultado correcto del contraste debe ser aceptar la hipótesis nula (la distribución de frecuencias teóricas). Los posibles errores deberían corresponder con los previstos según el nivel de significación.

## Análisis de Tablas de contingencia.

Una tabla de contingencia bidimensional es una clasificación de observaciones muestrales según dos características cualitativas, cada una de ellas con un número determinado de posibles resultados. Una de las características determina las filas de la tabla y la otra las columnas.

Característica B
| Característica A |  | $\mathrm{B}_{1}$ | $\mathrm{B}_{2}$ | $\dots$ | $\mathrm{B}_{m}$ | Total |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
|  | $\mathrm{A}_{1}$ | $n_{11}$ | $n_{12}$ | $\dots$ | $n_{1 m}$ | $n_{1}$. |
|  | $\mathrm{A}_{2}$ | $n_{21}$ | $n_{22}$ | $\dots$ | $n_{2 m}$ | $n_{2}$. |
|  | $\dots$ | $\dots$ | $\dots$ | $\dots$ | $\dots$ | $\dots$ |
|  | $\mathrm{A}_{k}$ | $n_{k 1}$ | $n_{k 2}$ | $\dots$ | $n_{k m}$ | $n_{k}$. |
|  | Total | $n \cdot 1$ | $n \cdot 2$ | $\dots$ | $n_{\cdot m}$ | $N$ |


Si la muestra corresponde a una única población y los individuos se clasifican según dos variables cualitativas medidas sobre cada uno de ellos con k y m posibles resultados para cada variable, el objetivo del análisis de la tabla será determinar si existe relación entre las variables, se tratará de una prueba de Independencia.

Si por el contrario, cada fila corresponde a una muestra de una población diferente y sobre cada individuo se mide una variable cualitativa, el objetivo será determinar si las diferentes poblaciones son homogéneas respecto la característica estudiada, se trata de una prueba de Homogeneidad entre las poblaciones.

La diferencia fundamental entre ambos enfoques es que en la tabla para la prueba de homogeneidad los totales de las filas no son aleatorios sino que son valores fijos.

### Pruebas de independencia.

El objetivo es verificar si existe una dependencia entre las variables cualitativas que definen filas y columnas, es decir si para todo $\mathrm{i}=1, \ldots, \mathrm{k}$ y $\mathrm{j}=1, . ., \mathrm{m}$ se verifica que la probabilidad del resultado correspondiente a la combinación $\mathrm{A}_{\mathrm{i}} \cap \mathrm{B}_{\mathrm{j}}$ es el producto de las probabilidades marginales correspondientes. $\mathrm{P}\left(\mathrm{A}_{\mathrm{i}}\right)$ es la probabilidad del resultado i para la variable fila y $\mathrm{P}\left(\mathrm{B}_{\mathrm{j}}\right)$ la del resultado j para la variable columna.

$$
\mathrm{P}\left(\mathrm{~A}_{\mathrm{i}} \cap \mathrm{~B}_{\mathrm{j}}\right)=\mathrm{P}\left(\mathrm{~A}_{\mathrm{i}}\right) \cdot \mathrm{P}\left(\mathrm{~B}_{\mathrm{j}}\right)
$$

Utilizaremos generalmente la notación más simplificada:

$$
\begin{gathered}
\mathrm{P}\left(\mathrm{~A}_{\mathrm{i}} \cap \mathrm{~B}_{\mathrm{j}}\right)=\mathrm{p}_{\mathrm{ij}} \\
\mathrm{P}\left(\mathrm{~A}_{\mathrm{j}}\right)=\mathrm{p}_{\mathrm{i}} \cdot \\
\mathrm{P}\left(\mathrm{~B}_{\mathrm{j}}\right)=\mathrm{p} \cdot \mathrm{j}
\end{gathered}
$$

Los valores de $\mathrm{p}_{\mathrm{i}} \cdot \mathrm{y} \mathrm{p} \cdot \mathrm{j}$ serán estimados, a partir de los valores observados en la tabla de contingencia, por
$n_{i} \cdot / N$ y $n_{\cdot j} / N$ respectivamente.
Hipótesis nula de independencia: para toda combinación de resultados de las variables fila y columna (i,j)

$$
\mathrm{H}_{0}: \mathrm{p}_{\mathrm{ij}}=\mathrm{p}_{\mathrm{i}} \cdot \mathrm{p} \cdot \mathrm{j} \quad \text { para todo } \quad \mathrm{i}=1, \ldots, \mathrm{k} \quad \mathrm{j}=1, . ., \mathrm{m}
$$

La hipótesis alternativa, que implica dependencia, se puede formular diciendo que alguna de las igualdades de la hipótesis nula es falsa.

Los valores observados son $n_{i j}$. Los valores esperados bajo la hipótesis nula de independencia se calculan de la manera siguiente

$$
e_{i j}=N \cdot \mathrm{p}_{\mathrm{ij}}=N \cdot \mathrm{p}_{\mathrm{i} \cdot} \cdot \mathrm{p}_{\cdot \mathrm{j}}=N \cdot\left(n_{i \cdot} / N\right) \cdot\left(n_{\cdot j} / N\right)=\left(n_{i \cdot} \cdot n_{\cdot j}\right) / N
$$

El estadístico de contraste se calcula de la forma habitual

$$
\chi_{\exp }^{2}=\sum_{i=1}^{k} \sum_{j=1}^{m} \frac{\left(n_{i j}-e_{i j}\right)^{2}}{e_{i j}}
$$

La distribución asintótica bajo la hipótesis nula es una $\chi^{2}$ con $(\mathrm{k}-1) \cdot(\mathrm{m}-1)$ grados de libertad. Los grados de libertad pueden entenderse de forma intuitiva entendiendo que el número de parámetros que se estiman son (k-1) y (m-1) al quedar fijada la probabilidad de la última clase de cada característica una vez estimadas las restantes. Por tanto aplicando la fórmula para los grados de libertad se obtiene

$$
\begin{aligned}
& \text { grados de libertad }=\text { número de clases }- \text { número de parámetros estimados }-1 \\
& \qquad \operatorname{grados~de~libertad~}=k \cdot m-(k-1)-(m-1)-1=(k-1) \cdot(m-1)
\end{aligned}
$$

El criterio de decisión es el mismo que en el caso general:
Rechazamos la hipótesis nula si

$$
\chi_{\exp }^{2} \geq \chi_{\alpha}^{2}
$$

donde el último término es el valor crítico asociado a una distribución $\chi^{2}$ con $(\mathrm{k}-1) \cdot(\mathrm{m}-1)$ grados de libertad tal que deja a su derecha una probabilidad igual a $\alpha$.

La condición de validez es que las frecuencias esperadas $e_{i j}$ sean mayores que 5 .

### Violación de las condiciones del contraste.

- Solución óptima: ampliar la muestra.
- Solución alternativa: agrupar filas o columnas.
- Sin embargo, agrupar filas o columnas significa perder algún resultado experimental que puede ser justamente el importante para la significación del contraste y se reducen los grados de libertad.

En tablas $2 \times 2$ existe una corrección por continuidad (Corrección de Yates).

$$
\chi_{\exp }^{2}=N \frac{\left(\left|n_{11} n_{22}-n_{12} n_{21}\right|-\frac{N}{2}\right)^{2}}{n_{1} \cdot n_{2} \cdot n_{1} n_{2}}
$$

Si las frecuencias esperadas son demasiado pequeñas, también es posible utilizar el test exacto de Fisher al ser equivalente a la comparación de dos proporciones.

## Pruebas de homogeneidad.

El objetivo es comprobar si en k poblaciones $\left(\mathrm{A}_{1}, \ldots, \mathrm{~A}_{\mathrm{k}}\right)$, es idéntica la distribución de probabilidad de una variable cualitativa con m posibles resultados $\left(\mathrm{B}_{1}, \ldots, \mathrm{~B}_{\mathrm{m}}\right)$. Es decir si se verifica

$$
\mathrm{P}\left(\mathrm{~B}_{\mathrm{j}} / \mathrm{A}_{1}\right)=\mathrm{P}\left(\mathrm{~B}_{\mathrm{j}} / \mathrm{A}_{2}\right)=\cdots=\mathrm{P}\left(\mathrm{~B}_{\mathrm{j}} / \mathrm{A}_{\mathrm{k}}\right)=\mathrm{P}\left(\mathrm{~B}_{\mathrm{j}}\right) \quad \text { para todo } \mathrm{j}=1, \ldots, \mathrm{~m}
$$

La diferencia con el caso de independencia es que los totales de las filas $n_{i}$. son valores fijos y no aleatorios, y corresponden al número de individuos seleccionados en la muestra pertenecientes a la población i. La estimación de los valores $\mathrm{P}\left(\mathrm{B}_{\mathrm{j}}\right)$ bajo la hipótesis de homogeneidad se obtiene a partir de la tabla de contingencia a través de $n_{\cdot j} / N$.

Hipótesis nula de homogeneidad: dadas dos poblaciones cualesquiera i y i' se verifica

$$
\mathrm{H}_{0}: \mathrm{p}_{\mathrm{ij}}=\mathrm{p}_{\mathrm{i}}{ }^{\prime} \mathrm{j} \quad \text { para todo } \mathrm{j}=1, \ldots, \mathrm{~m}
$$

donde $\mathrm{p}_{\mathrm{ij}}$ es la probabilidad del resultado j en la población i.
La hipótesis alternativa (alguna igualdad no es cierta) implica no homogeneidad de las poblaciones.
Los valores observados son $n_{i j}$. Los valores esperados bajo la hipótesis nula de homogeneidad se calculan de la manera siguiente

$$
e_{i j}=n_{i} \cdot P\left(\mathrm{~B}_{\mathrm{j}}\right)=n_{i \cdot}\left(n_{\cdot j} / N\right)=\left(n_{i \cdot} \cdot n_{\cdot j}\right) / N
$$

Resultado idéntico al obtenido en el caso del contraste de independencia.
El estadístico de contraste se calcula de forma análoga

$$
\chi_{\exp }^{2}=\sum_{i=1}^{k} \sum_{j=1}^{m} \frac{\left(n_{i j}-e_{i j}\right)^{2}}{e_{i j}}
$$

La distribución asintótica bajo la hipótesis nula es una $\chi^{2}$ con $(\mathrm{k}-1) \cdot(\mathrm{m}-1)$ grados de libertad. Los grados de libertad pueden entenderse de forma intuitiva entendiendo que el número de parámetros que se estiman son (m-1) al quedar fijada la probabilidad de la última clase $\mathrm{B}_{\mathrm{j}}$ una vez estimadas las restantes, y al considerar que existen k restricciones a los valores esperados debido a que tenemos fijados los totales de cada población. Por tanto aplicando la fórmula para los grados de libertad se obtiene
grados de libertad $=$ número de clases - número de parámetros estimados - número de restricciones

$$
\operatorname{grados~de~libertad~}=(\mathrm{k} \cdot \mathrm{~m})-(\mathrm{m}-1)-\mathrm{k}=(\mathrm{k}-1) \cdot(\mathrm{m}-1)
$$

El criterio de decisión es el mismo que en el contraste de independencia.

La condición de validez es que las frecuencias esperadas $e_{i j}$ sean mayores que 5 .

## La distribución Multinomial

Este modelo se puede ver como una generalización del Binomial en el que, en lugar de tener dos posibles resultados, tenemos $r$ resultados posibles.

Supongamos que el resultado de una determinada experiencia puede ser $r$ valores distintos: $A_{1}, A_{2}, \ldots$, $A_{r}$ cada uno de ellos con probabilidad $p_{1}, p_{2}, \ldots, p_{r}$, respectivamente.

$$
P\left(A_{1}\right)=p_{1} ; \quad P\left(A_{2}\right)=p_{2} ; \quad \ldots . \quad P\left(A_{r}\right)=p_{r} ; \quad \text { con } \sum_{i=1}^{r} P\left(A_{i}\right)=1 ;
$$

Si repetimos la experiencia $n$ veces en condiciones independientes, podemos preguntarnos la probabilidad de que el suceso $A_{1}$ aparezca $k_{1}$ veces, el suceso $A_{2}, k_{2}$ veces y así sucesivamente:

$$
P\left[\left(A_{1}=k_{1}\right) \cap\left(A_{1}=k_{2}\right) \cap \cdots \cap\left(A_{r}=k_{r}\right)\right]
$$

Al modelo estadístico que nos da dicha probabilidad se le denomina Multinomial, y su función de densidad viene dada por:

$$
\begin{gathered}
f\left(k_{1}, k_{2}, \ldots, k_{r}\right)=P\left[\left(A_{1}=k_{1}\right) \cap\left(A_{1}=k_{2}\right) \cap \cdots \cap\left(A_{r}=k_{r}\right)\right]=\frac{n!}{k_{1}!k!\cdots k_{r}!} p_{1}^{k_{1}} p_{2}^{k_{2}} \cdots p_{r}^{k_{r}} \\
\operatorname{con} \sum_{i=1}^{r} P\left(A_{i}\right)=1 \quad \mathbf{y} \quad \sum_{i=1}^{r} k_{i}=n ;
\end{gathered}
$$

como se ve, el modelo Multinomial queda definido por los parámetros $\left(n, p_{1}, p_{2}, \ldots, p_{r}\right)$. La fórmula anterior puede deducirse de forma análoga al caso Binomial. En realidad, si tomamos $r=2$ tenemos exactamente el modelo Binomial.

Se debe destacar que este modelo es un ejemplo de distribución multivariante, es decir, de distribución conjunta de varias ( $r$ ) variables aleatorias. En efecto, si definimos la variable aleatoria $X_{1}$ como número de veces que se produce el suceso $A_{1}$ de un total de n experiencias, y así sucesivamente, tenemos un conjunto de $r$ variables aleatorias discretas cuya función de densidad conjunta (valorada a la vez) viene definida por la anterior fórmula. Nótese que si consideramos cada una de estas variables $X_{i}(i=1,2, \ldots, r)$ por separado, su distribución es la Binomial de parámetros $n$ y $p_{i}$.

## La distribución Binomial

Al igual que el modelo de Bernouilli, hace referencia a experiencias con resultados dicotómicos (el resultado sólo puede ser $A$ o $A^{c}$ ). Sin embargo en este modelo estamos interesados en la repetición de $n$ veces una experiencia de este tipo en condiciones independientes.

Tomemos el ejemplo del contaje del número de caras en el lanzamiento $n$ veces de una moneda regular.
Para concretar, vamos a suponer que disponemos de una moneda regular ( $P[$ cara $]=P[$ cruz $]=1 / 2$ ) que lanzamos cuatro veces. Es evidente que, en estas condiciones, la variable $X$ : número de caras en cuatro lanzamientos independientes de una moneda regular es una variable aleatoria discreta que sólo puede tomar cinco posibles valores:

$$
x=0,1,2,3,4
$$

Pasemos ahora a calcular la probabilidad de cada valor (en terminología estadística, vamos a calcular la función de densidad de la variable $X$ ).

Es evidente que la $P[X=0]$ es igual a la probabilidad de salgan cuatro cruces seguidas:

$$
P[X=0]=P[c r u z, c r u z, c r u z, c r u z]=\mathrm{P}[c r u z]^{4}=(1 / 2)^{4}=0,0625
$$

ya que la moneda es regular y, por tanto, $P[$ cara $]=P[$ cruz $]=1 / 2$.
La $P[X=3]$ corresponde al suceso de que salgan tres caras ( $c$ en adelante) y una cruz ( + en adelante). Sin embargo, en este caso tenemos hasta cuatro posibles maneras de obtener dicho resultado, según el orden en que aparezcan las tres caras y la cruz:

| +ccc | $\mathrm{c}+\mathrm{cc}$ | $\mathrm{cc}+\mathrm{c}$ | $\mathrm{ccc}+$ |
| :--- | :--- | :--- | :--- |

También debería resultar evidente que la probabilidad de cada uno de estos sucesos es la misma:

$$
P[+c c c]=P[c+c c]=P[c c+c]=P[c c c+]=(1 / 2)^{4}=(1 / 2)^{4}=0,0625,
$$

de manera que, finalmente, la probabilidad de que salgan tres caras y una cruz es la suma de las probabilidades de los 4 casos anteriores:

$$
P[X=3]=4(1 / 2)^{4}=0,25
$$

Y así podríamos ir calculando el resto de casos. Podemos ver que, en este ejemplo, todos los casos tienen la misma probabilidad $(0,0625)$ y que el número total de casos posibles es 16 . En términos de combinatoria dicho número se obtendría como variaciones con repetición de dos valores (cara o cruz) tomados de cuatro en cuatro (el número de lanzamientos de la moneda):

$$
V R_{2}^{4}=2^{4}=16
$$

En la siguiente tabla se muestran los dieciséis posibles resultados:

<!-- ![](https://cdn.mathpix.com/cropped/8fb6aebc-d028-4d10-9d17-acf468c1b322-14.jpg?height=62&width=746&top_left_y=2741&top_left_x=657) -->

| k = número de caras | Casos |
| :--- | :--- |
| 0 | ++++ |
| 1 | +++C |
|  | ++C+ |
|  | +C++ |
|  | C+++ |
| 2 | ++CC |
|  | $+\mathrm{c}+\mathrm{c}$ |
|  | +CC+ |
|  | C++C |
|  | C+C+ |
|  | CC++ |
| 3 | CCC+ |
|  | CC+C |
|  | C+CC |
|  | +CCC |
| 4 | CCCC |

Si hacemos uso de nuestros conocimientos de combinatoria, comprobamos que el número de casos para cada posible valor $k(k=0,1,2,3,4)$ puede calcularse como permutaciones con repetición de cuatro elementos tomado de $k$ y $4-k$ :

$$
R P_{4}^{k, 4-k}=\frac{4!}{k!(4-k)!}=\binom{4}{k}
$$

y obtenemos finalmente el número combinatorio 4 sobre $k$. En efecto, para el caso $k=3$, tendríamos:

$$
\binom{4}{3}=\frac{4!}{3!1!}=4
$$

que son los cuatro posibles casos que nos dan tres caras y una cruz.
Finalmente, recordando que todos los casos tienen la misma probabilidad, se construye la siguiente tabla:

| $k=$ número de caras | Número de casos | $P[X=k]$ |
| :---: | :---: | :---: |
| 0 | 1 | 0,0625 |
| 1 | 4 | 0,2500 |
|  |  |  |

La distribución Binomial

| 2 | 6 | 0,3750 |
| :---: | :---: | :---: |
| 3 | 4 | 0,2500 |
| 4 | 1 | 0,0625 |
| Total | 16 | 1 |

