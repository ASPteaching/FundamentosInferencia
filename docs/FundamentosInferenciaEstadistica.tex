% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\documentclass[
]{article}
\usepackage{xcolor}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\setcounter{secnumdepth}{5}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\newsavebox\pandoc@box
\newcommand*\pandocbounded[1]{% scales image to fit in text height/width
  \sbox\pandoc@box{#1}%
  \Gscale@div\@tempa{\textheight}{\dimexpr\ht\pandoc@box+\dp\pandoc@box\relax}%
  \Gscale@div\@tempb{\linewidth}{\wd\pandoc@box}%
  \ifdim\@tempb\p@<\@tempa\p@\let\@tempa\@tempb\fi% select the smaller of both
  \ifdim\@tempa\p@<\p@\scalebox{\@tempa}{\usebox\pandoc@box}%
  \else\usebox{\pandoc@box}%
  \fi%
}
% Set default figure placement to htbp
\def\fps@figure{htbp}
\makeatother
\ifLuaTeX
  \usepackage{luacolor}
  \usepackage[soul]{lua-ul}
\else
  \usepackage{soul}
\fi
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage{bookmark}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={Fundamentos de Inferencia Estadistica},
  pdfauthor={Alex Sanchez Pla y Santiago Pérez Hoyos},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Fundamentos de Inferencia Estadistica}
\author{Alex Sanchez Pla y Santiago Pérez Hoyos}
\date{2026-01-05}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\section*{Presentación}\label{presentaciuxf3n}
\addcontentsline{toc}{section}{Presentación}

\subsection*{Objetivo}\label{objetivo}
\addcontentsline{toc}{subsection}{Objetivo}

El objetivo de estas notas es presentar un material que sirva de soporte para la asignatura de ``Inferencia Estadística'' del \href{https://www.uoc.edu/es/estudios/masters/master-universitario-bioinformatica-bioestadistica}{Máster interuniversitario de Bioiestadística y Bioinformática} impartido conjuntamente por la \href{https://www.uoc.edu}{Universitat Oberta de Catalunya (UOC)} y la \href{https://www.ub.edu}{Universidad de Barcelona (UB)}.

Esta asignatura adolece de las características habituales de las asignaturas de posgrado, y especialmente de un posgrado de estadística (y bioinformática), que muestran algunas de las cosas que no debe de ser esta asignatura:

\begin{itemize}
\tightlist
\item
  No puede ser un primer curso de estadística, porque se supone que los estudiantes del máster ya lo han cursado en sus grados. Por no decir que, a quien viene a especializarse en estadística se le puede suponer una base mínima.
\item
  Tampoco debe ser como los segundos cursos de estadística de algunos grados, que tratan temas como la regresión, el diseño de experimentos o el análisis multivariante, porque esto ya se trata en diversas asignaturas del máster.
\end{itemize}

¿Que debemos pues esperar que sea este curso?

\begin{itemize}
\tightlist
\item
  Puestos a pedir, este curso debería servir para repasar y consolidar los conceptos básicos que la mayoría de estudiantes traerán consigo.
\item
  Además, y sobretodo, debe proporcionar una visión general, lo más completa posible dentro de las limitaciones de tiempo, del campo de la inferencia estadística
\item
  Y, naturalmente, esto significa proporcionar aquellos conceptos sobre los que se apoyaran muchas de las restantes asignaturas como ``Regresión modelos y métodos'', ``Diseño de Experimentos'', ``Análisis Multivariante'', ``Análisis de la Supervivencia'' o ``Análisis de datos ómicos''.
\end{itemize}

\subsection*{Prerequisitos y organización del material}\label{prerequisitos-y-organizaciuxf3n-del-material}
\addcontentsline{toc}{subsection}{Prerequisitos y organización del material}

Uno de los problemas ``eternos'' en el estudio de la estadística ha sido siempre la falta de acuerdo, entre la comunidad de docentes, de cual debería ser el nivel matemático a que se impartan los cursos.

En los cursos de pre-grado ha habido un cierto consenso, y con los años el nivel de formalismo ha disminuido, incluso en estudios de tipo ``STEM'', tendiendo a centrarse en la aplicación de los conceptos, por ejemplo usando R, más que en un tratamiento formal (``matemático'') de los mismos.

Aunque esto puede ser práctico para aquellos estudios en los que la estadística és una asignatura de un grado, es también obvio que dicha aproximación no permite profundizar en muchos de los puntos que se tratan.

Es por ello que en este curso seguiremos la indicación habitual en cursos similares de asumir que el estudiante:

\begin{itemize}
\tightlist
\item
  Se siente comodo con el lenguaje algebráico, desarrollo de expresiones, sumatorios etc.
\item
  Está familiarizado con el cálculo diferencial en una o varias variables, aunque esta familiaridad no será imprescindible para seguir la mayoría de los contenidos del curso.
\item
  Conoce el lenguaje estadístico R, que en muchas ocasiones nos ofrecerá una solución directa a los problemas de cálculo.
\end{itemize}

\section*{Agradecimiento y fuentes utilizadas}\label{agradecimiento-y-fuentes-utilizadas}
\addcontentsline{toc}{section}{Agradecimiento y fuentes utilizadas}

Salvo que uno desee escribir un libro sobre algo muy extraño, siempre habran otros libros o manuales similares al que se está planteando.

La respuesta a la pregunta, ``Y entonces, ¿porque hacer un nuevo matrerial?'' suele ser más una excusa que una explicación sólida.

Una posible razón puede ser \emph{para ajustarlo al máximo al perfil del curso para al que se destinan dichos materiales}, condición que otros textos, pensados para cursos y audiencias distintas, pueden no satisfacer. En este caso adoptaremos esta explicación y el tiempo decidirá si el objetivo se alcanza.

Dicho esto, debemos agradecer a las distintas fuentes utilizadas, el que hayan puesto a disposición sus materiales para poder reutilizarlos. Entre estos destacamos:

\subsection*{El proyecto Statmedia}\label{el-proyecto-statmedia}
\addcontentsline{toc}{subsection}{El proyecto Statmedia}

Statmedia es un grupo de innovación docente de la Universidad de Barcelona, cuyo objetivo es desarrollar nuevas herramientas que ayuden en la enseñanza de la estadística aplicada, mejorando así el rendimiento académico de los alumnos y su motivación hacia la estadística.

Partiendo de la idea que el aprendizaje debe basarse en casos prácticos para motivar y fomentar la participación de los estudiantes. Se desarrolló primer proyecto, Statmedia I, un texto multimedia de estadística que además de los contenidos, relativamente ampliados, para un curso de introducción a la estadística, incorporaba:

\begin{itemize}
\tightlist
\item
  Una serie de casos para motivar e ilustrar los conceptos introducidos.
\item
  Un conjunto de gadgets interactivos con los que interactuar y experimentar y
\item
  Ejercicios de respuesta múltiple para verificar los conceptos trabajados.
\end{itemize}

Aunque el proyecto Statmedia ha seguido evolucionando en múltiples direcciones, Statmedia I, como tantos otros, no sobrevivió al desarrollo tecnológico, y la evolución (o decadencia) del lenguaje Java lo llevó a dejar de ser funcional.

Para estos apuntes hemos recuperado, y en ocasiones adaptado o modificado, algunos de los contenidos de Statmedia I, que habían estado escritos con gran pulcritud. Esto se ha hecho siguiendo las indicaciones de la licencia (CC-Share-alike) que permite adaptar contenidos atribuyendolo a sus autores y citando la fuente.

Los gadgets originales ya no son funcionales pero muchos de ellos han sido re-escritos en R como aplicaciones Shiny (disponibles en: \url{https://grbio.upc.edu/en/software/teaching_apps}) y se enlazaran desde los puntos necesarios del texto.

Dejando aparte (además) de la licencia, vaya nuestro agradecimiento explícito al equipo de profesores del Departamento de Estadística de la Universidad de Barcelona, redactor de la versión inicial del proyecto, que es la que hemos utilizado: Antonio Arcas Pons, Miquel Calvo Llorca, Antonio Miñarro Alonso, Sergi Civit Vives y Angel Vilarroya del Campo.

Dos de los autores nos han dejado prematuramente, Angel Vilarroya a una temprana edad, hace casi 20 años y Miguel Calvo, próximo a su jubilación, muy recientemente. Vaya desde aquí nuestro más sincero recuerdo. \emph{Sin vosotros, nada de esto existiría, y aunque esto perdure os echaremos siempre en falta}.

\href{https://www.emis.de/journals/BEIO/files/BEIOv25n1_HE_A.Arcas+A.Minarro+M.Calvo.pdf}{Antoni Arcas, Antonio Miñarro and Miguel Calvo (2008) Statmedia projects in Statistical Education}

\subsection*{Otros materiales utilizados}\label{otros-materiales-utilizados}
\addcontentsline{toc}{subsection}{Otros materiales utilizados}

Entremezclado con el uso de los materiales del proyecto Statmedia se encuentran materiales tomados del curso de Introducción a la Estadística Matemàtica, creados originalmente para una asignatura de Inferencia Estadística, impartida en la diplomatura de Estadística de la Universidad de Barcelona en el periodo anterior al proyecto Bolonia. Algo más formales que los del proyecto Statmedia, ambos se complementan bien para crear unos materiales a nivel de Máster de bioestadística, como se pretende hacer aquí.

\begin{itemize}
\tightlist
\item
  \href{https://github.com/ASPteaching/ApuntsEstadisticaMatematica}{Alex Sanchez y Francesc Carmona (2002). Apunts d'Estadística Matemàtica} Licencia CC0 1.0 Universal
\end{itemize}

\subsection*{Materiales complementarios}\label{materiales-complementarios}
\addcontentsline{toc}{subsection}{Materiales complementarios}

Los documentos que se citan a continuación contienen materiales similares a los que aquí se presentan, para cursos parecidos al que ha generado los presentes.

Aunque todavía no se han utilizado para mejorar la versión actual, contamos en incorporar algunas de sus ideas y/o enfoques en versiones futuras.

\begin{itemize}
\item
  \href{https://verso.mat.uam.es/~joser.berrendero/libro-est/}{Berrendero, José. Fundamentos de Estadística}
\item
  \href{https://bookdown.org/egarpor/inference/}{Molina Peralta, I. and García-Portugués, E. (2024). \emph{A First Course on Statistical Inference}. Version 2.4.1. ISBN 978-84-09-29680-4}. Licencia CC BY-NC-ND 4.0
\item
  \href{https://bookdown.org/pkaldunn/DistTheory}{Peter K. Dunn (2024) \emph{The theory of distributions}.} Licencia CC BY-NC-ND 4.0
\end{itemize}

\subsubsection*{Complementos matemáticos}\label{complementos-matemuxe1ticos}
\addcontentsline{toc}{subsubsection}{Complementos matemáticos}

Los prerequisitos para este curso corresponden básicamente a una matemáticas -bien aprendidas- del bachilerato. Algunas fuentes adiconales pueden ser:

\begin{itemize}
\item
  \href{http://cimanet.uoc.edu/cursMates0/IniciacionMatematicas/pdf/PID_00273914.pdf}{Iniciación a las matemáticas para la ingeniería. M. Besalú y Joana Villalonga}

  \begin{itemize}
  \tightlist
  \item
    \href{https://www.youtube.com/playlist?list=PLv8FweHfYYMo6Lr2zt6H4znq5KuBacq28}{Colección de (100) videos de soporte a las matemáticas para la ingeniería}
  \end{itemize}
\end{itemize}

\newpage

\section{Probabilidad y Experimentos aleatorios}\label{probabilidad-y-experimentos-aleatorios}

\subsection{Introducción}\label{introducciuxf3n}

\subsubsection{Fenómenos deterministas y fenómenos aleatorios}\label{fenuxf3menos-deterministas-y-fenuxf3menos-aleatorios}

Supongamos que disponemos de un dado regular con todas las caras
pintadas de blanco y con un número, que irá de 1 a \(6 \sin\) repetir
ninguno, en cada una de las seis caras.

Definamos los dos experimentos siguientes: Experimento 1: Tirar el dado
y anotar el color de la cara resultante. Experimento 2: Tirar el dado y
anotar el número de la cara resultante. ¿Qué diferencia fundamental
observamos entre ambos experimentos? Muy simple! En el experimento 1, el
resultado es obvio: saldrá una cara de color blanco. Es decir, es
posible predecir el resultado. Se trata de un experimento o fenómeno
determinista.

En cambio, en el experimento 2 no podemos predecir cuál será el valor
resultante. El resultado puede ser : \(1,2,3,4,5\) o 6 . Se trata de un
experimento o fenómeno aleatorio.

El conjunto de resultados se anotará con el símbolo: \(\Omega\). En este
caso, \(\Omega=\{1,2,3,4,5,6\}\). En los fenómenos aleatorios, al hacer
muchas veces la experiencia, la frecuencia relativa de cualquier
elemento del conjunto de resultados debe aproximarse siempre hacia un
mismo valor.

\subsubsection{Sucesos}\label{sucesos}

Supongamos que se ejecuta un experimento aleatorio. Se nos puede ocurrir
emitir un enunciado que, una vez realizada la experiencia, pueda decirse
si se ha verificado o no se ha verificado. A dichos enunciados los
denominamos sucesos.

Por otro lado, los sucesos van asociados a subconjuntos del conjunto de
resultados. Cada suceso se corresponderá exactamente con uno, y sólo con
un, subconjunto del conjunto de resultados.

Veamos un ejemplo: Experimento: Tirar un dado regular. Conjunto de
resultados : \(\Omega=\{1,2,3,4,5,6\}\) Enunciado: Obtener múltiplo de 3.
Subconjunto al que se asocia el enunciado: \(A=\{3,6\}\) Nos referiremos
habitualmente al suceso A.

\paragraph{Sucesos y conjuntos}\label{sucesos-y-conjuntos}

Al conjunto de resultados \(\Omega\), se le denomina suceso seguro. Al
conjunto Ø ( conjunto sin elementos), se le denomina suceso imposible.
Al complementario del conjunto
\(\mathrm{A}\left(\mathrm{A}^{\mathrm{c}}\right)\), se le denomina suceso
contrario o complementario de \(A\). A partir de dos sucesos A y B,
podemos formar los sucesos siguientes:

\begin{itemize}
\tightlist
\item
  A intersección B, que anotaremos como:
\end{itemize}

\[
A \cap B
\]

\begin{itemize}
\tightlist
\item
  A unión B, que anotaremos como:
\end{itemize}

\[
A \cup B
\]

A intersección B, significa que se verifican a la vez A y B. A unión B,
significa que se verifica \(A\) o \(B\) ( se pueden verificar a la vez).

\subsection{Función de probabilidad}\label{funciuxf3n-de-probabilidad}

Lógicamente, una vez tenemos un suceso, nos preocupa saber si hay muchas
o pocas posibilidades de que al realizar la experiencia se haya
verificado.

Por lo tanto, sería interesante el tener alguna función que midiera el
grado de confianza a depositar en que se verifique el suceso.

A esta función la denominaremos función de probabilidad. La función de
probabilidad será, pues, una aplicación entre el conjunto de resultados
y el conjunto de números reales, que asignará a cada suceso la
probabilidad de que se verifique.

La notación: \(\mathrm{P}(\mathrm{A})\) significará: probabilidad de que
se verifique el suceso A . Pero claro, de funciones de probabilidad
asociadas a priori a una experiencia aleatoria podrían haber muchas.

Lo que se hace para decir qué es y qué no es una función de probabilidad
es construir una serie de propiedades (denominadas axiomas) que se
exigirán a una función para poder ser catalogada como función de
probabilidad.

Y, ¿cuáles son estos axiomas? Pues los siguientes: Sea S el conjunto de
sucesos.

\begin{itemize}
\item
  Axioma 1: Para cualquier suceso A, la probabilidad debe ser
  mayor o igual que 0.
\item
  Axioma 2: La probabilidad del \emph{suceso seguro} debe ser 1: \(\mathrm{P}(\Omega)=1\)
\item
  Axioma 3: Para sucesos \(\mathrm{A}_{\mathrm{i}}\), de modo que cada par de sucesos no
  tengan ningún resultado común, se verifica que:
\end{itemize}

\[
P\left(\bigcup_{i=1}^{\infty} A_{i}\right)=\sum_{i=1}^{\infty} P\left(A_{i}\right)
\]

De este modo, pueden haber muchas funciones de probabilidad que se
podrían asociar con la experiencia.

El problema pasa entonces al investigador para decidir cual o cuales son
las funciones de probabilidad más razonables asociadas con la
experiencia que está manejando.

\subsubsection{¿Diferentes funciones de probabilidad para una misma experiencia aleatoria?}\label{diferentes-funciones-de-probabilidad-para-una-misma-experiencia-aleatoria}

Supongamos la experiencia de tirar un dado regular. A todo el mundo se
le ocurriría pensar que la función de probabilidad se obtiene de contar
el número de resultados que contiene el suceso dividido por 6 , que es
el número total de resultados posibles. Así pues, la probabilidad de
obtener un múltiplo de 3 sería igual a \(2 / 6\), la probabilidad de
obtener el número 2 sería \(1 / 6\) i la probabilidad de obtener un número
par sería 3/6. Es decir, parece inmediato construir la función de
probabilidad que, además, parece única. A nadie se le ocurre decir, por
ejemplo, que la probabilidad de obtener un número par es \(5 / 6\) !

En este caso, todo ha sido muy fácil. Hemos visto que existe una única
función de probabilidad que encaje de forma lógica con la experiencia y,
además, ha sido muy sencillo encontrarla.

Pero esto, por desgracia, no siempre es así. En muchísimas ocasiones
resulta muy complejo el decidir cuál es la función de probabilidad.

En el tema de variables aleatorias y de función de distribución se
explica el problema de la modelización de muchas situaciones reales.

\subsection{¿Cómo se calculan las probabilidades?}\label{cuxf3mo-se-calculan-las-probabilidades}

No siempre es fácil conocer los valores de la función de probabilidad de
todos los sucesos. Sin embargo, muchas veces se pueden conocer las
probabilidades de algunos de estos sucesos. Con la ayuda de ciertas
propiedades que se deducen de manera inmediata a partir de la axiomática
es posible calcular las probabilidades de más sucesos.

Por otro lado, en caso de que el número de resultados sea finito y de
que todos los resultados tengan las mismas posibilidades de verificarse,
la probabilidad de un suceso cualquiera se puede calcular a partir de la
regla de Laplace:

Si A es un suceso :

\[
\text { Probabilidad }(A)=\frac{\text { Número de casos favorables }}{\text { Número de casos posibles }}
\]

donde: Número de casos favorables \(=\) Número de resultados contenidos en
\(\mathrm{A}(\) cardinal de A\()\) Número de casos posibles \(=\) Número total
de resultados posibles (cardinal del conjunto total de resultados)

En este caso, el contar número de resultados, ya sean favorables o
posibles, debe hacerse por medio de la combinatoria.

Veamos con unos ejemplos muy sencillos y visuales cómo se obtienen y qué
representan los casos posibles y los casos favorables.

También es posible obtener de manera aproximada la probabilidad de un
suceso si se puede repetir muchas veces la experiencia: la probabilidad
del suceso sería el valor al que tendería la frecuencia relativa del
suceso. Podéis consultar más detalles acerca de esta aproximación.

En este caso, la cuestión estriba en poder hacer muchas veces la
experiencia en condiciones independientes.

\subsection{Sucesos elementales y sucesos observables}\label{sucesos-elementales-y-sucesos-observables}

En el contexto de la probabilidad, es fundamental diferenciar entre los \textbf{sucesos elementales} y los \textbf{sucesos observables}.

Los sucesos elementales son los resultados individuales que pueden ocurrir al realizar un experimento aleatorio, es decir, cada uno de los elementos que conforman el conjunto de resultados \(\Omega\). En nuestro ejemplo del dado, los sucesos elementales son los números \(1, 2, 3, 4, 5\) y \(6\).

Sin embargo, no todos los sucesos elementales son necesariamente observables. Un suceso observable es un subconjunto de estos sucesos elementales que permite formular afirmaciones verificables sobre el resultado del experimento.

\textbf{Ejemplo}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Podemos imaginar un dado en el que pintamos de blanco las caras pares y de negro las impares. En este caso los sucesos elementales serían los habituales 1, 2, 3,\ldots6.
  Sin embargo tan solo ``Par'' (``blanco'') o impar (``negro'') se pueden observar.
\item
  Si repintamos el dado de forma que las caras 1 y 2 esten blancas, las 3 y 4, azules y las 5 y 6 rojas podremos observar el suceso ``Sale 1 o 2 (=Sale blanco)'' o ``sale blanco o azul'', pero no el suceso ``sale par'' dado que cada color contiene un número par y uno impar
\end{enumerate}

Para formalizar estos conceptos, definimos el \textbf{espacio de probabilizable} como el par de conjuntos formados por: \((\Omega, \mathcal{A})\)

\begin{itemize}
\tightlist
\item
  \(\Omega\) es el conjunto de todos los resultados posibles (el conjunto de resultados o sucesos elementales).
\item
  \(\mathcal{A}\) es el conjunto de todos los sucesos observables, que vienen definidos por el \emph{nivel de observación} del experimento.
\end{itemize}

\subsection{Propiedades inmediatas de la probabilidad}\label{propiedades-inmediatas-de-la-probabilidad}

Veremos a continuación una serie de propiedades que se deducen de manera
inmediata de la axiomática de la probabilidad.

\subsubsection{Succeso imposible}\label{succeso-imposible}

El suceso imposible se identifica con el conjunto vacío, puesto que no hay ningún resultado asociado a él. La probabilidad del suceso imposible es:

\[
P(\varnothing)=0
\]

\subsubsection{Suceso implicado}\label{suceso-implicado}

Decimos que un suceso, B, esta implicado por otro suceso A, si siempre que se presenta A, también lo hace B. Por ejemplo, si al tirar un dado se obtiene un dos (suceso A), ello implica que ha salido un número par (suceso B). En terminos de conjuntos, A es un suceso que está contenido en B (todos los resultados de A
también pertenecen a B ), por lo que:

\[
\mathrm{P}(\mathrm{A}) \leq \mathrm{P}(\mathrm{B})
\]

\subsubsection{Complementario de un suceso}\label{complementario-de-un-suceso}

Sea \(A^{\mathrm{c}}\) el suceso formado por todos los elementos de
\(\Omega\) que no pertenecen a A (Suceso complementario de A). La
probabilidad de dicho suceso es igual a:

\[
\mathrm{P}\left(\mathrm{A}^{\mathrm{c}}\right)=1-\mathrm{P}(\mathrm{A})
\]

\subsubsection{Ocurrencia de algun suceso}\label{ocurrencia-de-algun-suceso}

La probabilidad de la unión de dos sucesos A y B es igual a:

\[
P(A \cup B)=P(A)+P(B)-P(A \cap B)
\]

\subsubsection{Probabilidad de que ocurra algun suceso}\label{probabilidad-de-que-ocurra-algun-suceso}

Si tenemos una colección de \(k\) sucesos, la probabilidad de la unión de
dichos sucesos será:

\[
P\left(\bigcup_{i=1}^{k} A_{i}\right)=\sum_{i=1}^{k} P\left(A_{i}\right)-\sum_{i<j} P\left(A_{i} \cap A_{j}\right)+\sum P\left(A_{i} \cap A_{j} \cap A_{k}\right)+\ldots+(-1)^{k+1} \cdot P\left(A_{1} \cap . . \cap A_{k}\right)
\]

\subsubsection{Probabilidad de que ocurran dos (o más) sucesos a la vez}\label{probabilidad-de-que-ocurran-dos-o-muxe1s-sucesos-a-la-vez}

No existe una expresión cerrada única para la probabilidad de que ocurran dos o más sucesos a la vez, pues esto depende de si los sucesos que consideramos son dependientes o independientes, conceptos éstos, que introduciremos en la próxima sección.

Lo que si que existe es una cota para dicha probabilidad, es decir, podemos decir que valor alcanza dicha probabilidad, \emph{como mínimo}.

\[
P\left(\bigcap_{i=1}^{n} A_{i}\right) \geq 1-\sum_{i=1}^{n} P\left(\bar{A}_{i}\right)
\]

\subsection{Espacios de probabilidad}\label{espacios-de-probabilidad}

Para concluir esta introducción introduciremos los \textbf{espacio de probabilidad} que, extienden los \textbf{espacios probabilizables} definidos en la sección anterior

La terna \((\Omega, \mathcal{A}, P)\) donde:

\begin{itemize}
\tightlist
\item
  \(Omega\) es el conjunto de todos los resultados posibles (el conjunto de resultados o sucesos elementales),
\item
  \(\mathcal{A}\) es el conjunto de todos los sucesos observables, que vienen definidos por el \emph{nivel de observación} del experimento y
\item
  \(P\) es una función de probabilidad, que asigna a cada suceso observable \(A \in \mathcal{A}\) un número real \(P(A)\) que representa la probabilidad de que ocurra dicho suceso
\end{itemize}

se conoce como \textbf{espacio de probabilidad}.

Es importante destacar que \textbf{la probabilidad se calcula exclusivamente para los sucesos observables}, lo que garantiza que la medida sea coherente y verificada a través de experimentos.

Los espacios de probabilidad proporcionan una estructura fundamental para analizar y medir las incertidumbres asociadas a los fenómenos aleatorios, facilitando el estudio de sus propiedades, la construcción, sobre ellos de diversos conceptos fundamentales como el de variables aleatorias, y, en general, la aplicación de teorías de la probabilidad a diversas áreas de conocimiento.

\subsection{Probabilidad condicionada}\label{probabilidad-condicionada}

Imaginemos que en la experiencia de tirar un dado regular supiéramos de
antemano que se ha obtenido un número par. Es decir, que se ha
verificado el suceso: \(\{B = \mbox{número par}\}\)``.

Pregunta: ¿Cuál es ahora la probabilidad de que se verifique el suceso
mayor o igual a cuatro? Lógicamente, el resultado sería : \(2 / 3\). Por
lo tanto, la probabilidad del suceso \(\mathrm{A}=\) mayor o igual a
cuatro se ha modificado. Evidentemente, ha pasado de ser \(1 / 2\) (
cuando no tenemos ninguna información previa) a ser \(2 / 3\) (cuando
sabemos que se ha verificado el suceso B). ¿Cómo podemos anotar esta
última probabilidad \((2 / 3)\) ? Muy sencillo. Anotaremos
\(\mathrm{P}(\mathrm{A} / \mathrm{B})\), que se lee como probabilidad de A
condicionada a B . Así, en este ejemplo,

\[
\begin{gathered}
\mathrm{P}(\mathrm{A} / \mathrm{B})=2 / 3 \\
\mathrm{P}(\mathrm{A})=1 / 2
\end{gathered}
\]

En términos generales, estamos en condiciones de poder definir la
probabilidad condicionada, y lo hacemos como:

\[
P(A / B)=\frac{P(A \cap B)}{P(B)}
\]

El explorador interactivo que se encuentra a continuación (disponible en la versión en HTML del docuemnto) permite visualizar de una manera práctica el ejemplo
anterior.

Siguiendo con la notación utilizada, el suceso A será lo que
denominamos suceso de obtención, mientras que el suceso B será lo que
denominamos suceso \emph{condicionante}. La pantalla nos proporcionará los casos
posibles para el condicionante elegido y los casos favorables,
calculando mediante la regla de Laplace la probabilidad del suceso.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Elegid suceso a estudiar. Desplazad, si procede, las barras de selección.
\item
  Elegir suceso condicionante. Desplazad, si procede, las barras de selección..
\item
  Comprobad los sucesos posibles y los favorables y las probabilidades resultantes.
\end{enumerate}

\begin{quote}
\emph{Simulador interactivo disponible solo en la versión HTML del libro.}
\end{quote}

\subsubsection{La probabilidad condicionada es una medida de probabilidad}\label{la-probabilidad-condicionada-es-una-medida-de-probabilidad}

Ejemplos como el anterior nos muestran que, efectivamente, la probabilidad condicionada se comporta como una función de probabilidad. Esto equivale, como ya hemos visto, a afirma que verifica los tres axiomas por los que se define la probabilidad:

Axioma 1:

\[
\mathrm{P}(\mathrm{A} / \mathrm{B}) \geq 0
\]

Axioma 2:

\[
P(\Omega / B)=1
\]

Axioma 3:

\[
P\left(\bigcup_{i=1}^{\infty} A_{i} / B\right)=\sum_{i=1}^{\infty} P\left(A_{i} / B\right)
\]

para sucesos \(\mathrm{A}_{\mathrm{i}}\) con intersección vacía dos a dos.

\subsubsection{Sucesos dependientes y sucesos independientes}\label{sucesos-dependientes-y-sucesos-independientes}

Sean A y B dos sucesos con probabilidad mayor que 0 . Evidentemente, si

\[
\mathrm{P}(\mathrm{A} / \mathrm{B})=\mathrm{P}(\mathrm{A})
\]

B no ha modificado la probabilidad de que suceda A. En este caso diremos
que son sucesos independientes.

En caso contrario diremos que son sucesos dependientes. En el ejemplo
del apartado anterior, se observa que los sucesos son dependientes
puesto que las probabilidades anteriores no coinciden.

Se verifica que independencia de los sucesos A y B es equivalente a
decir que la probabilidad de la intersección es igual a producto de
probabilidades de los dos sucesos.

Se verifica también que si A y B son independientes: a) El
complementario del suceso A y el suceso B son independientes. b) El
complementario del suceso A y el complementario del suceso B son
independientes. c) El complementario del suceso B y el suceso A son
independientes.

\subsubsection{Incompatibilidad e independencia}\label{incompatibilidad-e-independencia}

Dos sucesos con intersección vacía se denominan sucesos incompatibles.
Esto, ¿qué implica? Pues, que si se verifica uno seguro que no se
verifica el otro, ya que no tienen resultados en común. Por lo tanto es
el caso extremo de dependencia. Obtenemos en este caso que:

\[
\mathrm{P}(\mathrm{A} / \mathrm{B})=0
\]

y, en consecuencia, si \(\mathrm{P}(\mathrm{A})\) y
\(\mathrm{P}(\mathrm{B})\) son diferentes de cero, la probabilidad
condicionada anterior es diferente de \(\mathrm{P}(\mathrm{A})\), y así se
deduce la dependencia.

La única posibilidad de que se dé incompatibilidad e independencia a la
vez, es que alguno de los dos sucesos tenga probabilidad igual a cero.

\subsection{Dos Teoremas importantes}\label{dos-teoremas-importantes}

\subsubsection{Teorema de las probabilidades totales}\label{teorema-de-las-probabilidades-totales}

Sea \(\Omega\) el conjunto total formado por una partición (colección de
sucesos con intersección vacía dos a dos):

\[
\Omega=H_{1} \cup \ldots \ldots \cup H_{n}
\]

La probabilidad de cualquier otro suceso A , se puede obtener a partir
de las probabilidades de los sucesos de la partición y de las
probabilidades de A condicionado a los sucesos de la partición, de la
manera siguiente:

\[
P(A)=\sum_{i=1}^{n} P\left(A / H_{i}\right) \cdot P\left(H_{i}\right)
\]

Esto es lo que se conoce como teorema de las probabilidades totales.

\subsubsection{Teorema de Bayes}\label{teorema-de-bayes}

Es una consecuencia del teorema de las probabilidades totales. Sea
\(\Omega\) el conjunto total formado por una partición (colección de
sucesos con intersección vacía dos a dos).

\[
\Omega=H_{1} \cup \ldots \ldots \cup H_{n}
\]

Ahora el interés se centrará en la obtención de la probabilidad de
cualquier suceso de la partición condicionada a un suceso A cualquiera.

El resultado será:

\[
P\left(\mathrm{H}_{\mathrm{i}} / \mathrm{A}\right)=\frac{\mathrm{P}\left(\mathrm{A} / \mathrm{H}_{\mathrm{i}}\right) \cdot \mathrm{P}\left(\mathrm{H}_{\mathrm{i}}\right)}{\sum_{i=1}^{n} \mathrm{P}\left(\mathrm{A} / \mathrm{H}_{\mathrm{i}}\right) \cdot \mathrm{P}\left(\mathrm{H}_{\mathrm{i}}\right)}
\]

Esto es conocido como teorema o regla de Bayes.

\subsection{Introducción a los experimentos múltiples}\label{introducciuxf3n-a-los-experimentos-muxfaltiples}

Supongamos que tiramos a la vez un dado y una moneda. Tenemos una
experiencia múltiple, puesto que la experiencia que se realiza es la
composición de dos experiencias (experiencia \(1=\) tirar un dado regular;
experiencia 2 = tirar una moneda regular). ¿Cuál es en este caso el
conjunto de resultados? Si \(\Omega_{1}\) es el conjunto de resultados
asociado con la experiencia tirar un dado y \(\Omega_{2}\) es el conjunto
de resultados asociado con la experiencia tirar una moneda, el conjunto
de resultados asociado a la experiencia múltiple será
\(\Omega_{1} \times \Omega_{2}\).

Es decir, \(\Omega_{1}=\{1,2,3,4,5,6\}\) \(\Omega_{2}=\{\) cara, cruz \(\}\)
\(\Omega_{1} \times \Omega_{2}=\{(1\), cara \(),(2\), cara \(),(3\), cara
\(),(4\), cara \(),(5\), cara \(),(6\), cara \(),(1\), cruz ), ( 2 , cruz ), (
3, cruz ), (4, cruz \(),(5\), cruz \(),(6\), cruz \()\}\)

Si \(\mathrm{P}_{1}\) y \(\mathrm{P}_{2}\) son, respectivamente, las
funciones de probabilidad asociadas a las experiencias 1 y 2 , ¿es
posible calcular probabilidades de la experiencia múltiple a partir de
\(\mathrm{P}_{1}\) y \(\mathrm{P}_{2}\) ?

Efectivamente! Pero hemos de distinguir dos situaciones:

\begin{itemize}
\tightlist
\item
  Experiencias independientes: cuando el resultado de una no influya
  en la otra.
\item
  Experiencias dependientes: cuando el resultado de una influya en la
  otra.
\end{itemize}

En nuestro caso se trata de experiencias independientes, puesto que el
resultado que se obtenga al tirar el dado no influye sobre el resultado
que se obtenga al lanzar la moneda y al revés. ¿Como se calculan, pues,
las probabilidades de la experiencia múltiple? Sea un suceso de la
experiencia múltiple: A x B.

\begin{itemize}
\tightlist
\item
  Caso de experiencias independientes:
\end{itemize}

\[
\mathrm{P}(\mathrm{A} \times \mathrm{B})=\mathrm{P}_{1}(\mathrm{~A}) \times \mathrm{P}_{2}(\mathrm{~B})
\]

\begin{itemize}
\tightlist
\item
  Caso de experiencias dependientes:
\end{itemize}

\[
\mathrm{P}(\mathrm{A} \times \mathrm{B})=\mathrm{P}_{1}(\mathrm{~A}) \times \mathrm{P}_{2}(\mathrm{~B} / \mathrm{A})
\]

Entendemos que existe una \(\mathrm{P}_{2}\) para cada suceso A .

Esto que hemos explicado se puede, lógicamente, generalizar a una
experiencia múltiple formada por \(n\) experiencias.

\subsection{Combinatoria}\label{combinatoria}

Veamos algunas fórmulas simples que se utilizan en combinatoria y que
nos pueden ayudar a calcular el número de casos posibles o el número de
casos favorables.

\subsubsection{Permutaciones}\label{permutaciones}

Sea un conjunto de \(n\) elementos. A las ordenaciones que se pueden hacer
con estos \(n\) elementos \(\sin\) repetir ningún elemento y utilizándolos
todos se las denomina permutaciones. El número de permutaciones que se
pueden realizar coincide con el factorial de \(n\), y su cálculo es:

\[
n!=n \cdot(n-1) \cdot(n-2) \ldots \ldots .2 \cdot 1
\]

Ejemplo:

¿De cuántas maneras distintas podemos alinear a seis personas
en una fila?

Respuesta

De \(6!=6 \cdot 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1=720\) maneras
(permutaciones de 6 elementos).

\subsubsection{Variaciones}\label{variaciones}

Sea un conjunto de \(n\) elementos. Supongamos que deseamos ordenar \(r\)
elementos de entre los \(n\). A cada una de estas ordenaciones la
denominamos variación. El número de variaciones que se pueden hacer de
los \(n\) elementos tomados de \(r\) en \(r\) es:

\[
V_{n}^{r}=n \cdot(n-1) \ldots \ldots(n-r+1)
\]

Ejemplo

En una carrera de velocidad compiten diez atletas. ¿De cuántas maneras
distintas podría estar formado el podio? (el podio lo forman el primer,
el segundo y el tercer clasificado)

Respuesta

Cada podio posible es una variación de diez elementos tomado de tres en
tres. Por tanto, el número posible de podios es:

\[
\mathrm{V}_{10}^{3}=10.9 .8=720
\]

\subsubsection{Variaciones con repetición}\label{variaciones-con-repeticiuxf3n}

Sea un conjunto de \(n\) elementos. Supongamos que se trata de ordenar \(r\)
elementos que pueden estar repetidos. Cada ordenación es una variación
con repetición. El número de variaciones con repetición para un conjunto
de \(n\) tomados de \(r\) en \(r\) es :

\[
\mathrm{RV}_{\mathrm{n}}^{\mathrm{r}}=\mathrm{n}^{\mathrm{r}}
\]

\ul{Ejemplo}

En una urna tenemos cinco bolas numeradas del 1 al 5 . Se extraen tres
bolas sucesivamente con reposición (devolviendo cada vez la bola a la
urna). ¿Cuántos resultados distintos es posible obtener?

Respuesta: Se trata de variaciones con repetición de un conjunto de
cinco bolas tomadas de tres en tres. En total tendremos:

\[
\mathrm{RV}_{5}^{3}=5^{3}=125
\]

\subsubsection{Combinaciones}\label{combinaciones}

Cuando se trata de contar el número de subconjuntos de \(x\) elementos en un conjunto de \(n\) elementos tenemos lo que se denomina combinaciones de
x elementos en un conjunto de n . El cálculo del contaje se hace
mediante el número combinatorio, de la manera siguiente:

\[
\mathrm{C}_{\mathrm{n}}^{\mathrm{x}}=\binom{n}{\mathrm{x}}=\frac{\mathrm{n!}}{\mathrm{x}!.(\mathrm{n}-\mathrm{x})!}
\]

Ejemplo

¿De cuántas maneras podemos elegir, en la urna anterior (recordemos que
había cinco bolas), tres bolas en una única extracción?

Respuesta

Serán combinaciones de cinco elementos tomados de tres en tres, por
tanto, tendremos:

\[
\mathrm{C}_{5}^{3}=\binom{5}{3}=\frac{5!}{3!(5-3)!}=10
\]

\subsubsection{Permutaciones con repetición}\label{permutaciones-con-repeticiuxf3n}

Sea un conjunto de \(n\) elementos, de entre los cuales tenemos \(a\)
elementos indistinguibles entre sí, \(b\) elementos indistinguibles entre
sí, \(c\) elementos indistinguibles entre sí, etc. Cada ordenación de
estos elementos se denominará permutación con repetición. El número de
permutaciones con repetición es:

\[
R P{ }_{n}^{a, b, c, \ldots}=\frac{n!}{a!b!c!\ldots}
\]

Ejemplo

¿Cuantas palabras con sentido o sin él pueden formarse con las letras
PATATA?

Respuesta: Tenemos tres veces la letra A, dos veces la T y una vez la P.
Por tanto, serán:

\[
\mathrm{RP}_{6}^{3,2,1}=\frac{6!}{3!2!!}=60
\]

\subsection{Frecuencia relativa y probabilidad}\label{frecuencia-relativa-y-probabilidad}

La definición moderna de probabilidad basada en la axiomática de
Kolmogorov (presentada anteriormente) es relativamente reciente.
Históricamente hubo otros intentos previos de definir el escurridizo
concepto de probabilidad, descartados por diferentes razones. Sin
embargo conviene destacar aquí algunas ideas que aparecen en la antigua
definición basada en la frecuencia relativa, ya que permiten intuir
algunas profundas propiedades de la probabilidad.

Recordemos antes que si en un experimento que se ha repetido \(n\) veces
un determinado suceso A se ha observado en \(k\) de estas repeticiones, la
frecuencia relativa \(\mathrm{f}_{\mathrm{r}}\) del suceso A es:

\[
\mathrm{f}_{\mathrm{r}}=k / n
\]

El interés por la frecuencia relativa y su relación con el concepto de
probabilidad aparece a lo largo de los siglos XVIII a XX al observar el
comportamiento de numerosas repeticiones de experimentos reales.

A título de ejemplo de un experimento de este tipo, supongamos que se
dispone de una moneda ideal perfectamente equilibrada. Aplicando
directamente la regla de Laplace resulta claro que el suceso
\(\mathrm{A}=\) obtener cara tiene probabilidad:

\[
\mathrm{p}(\mathrm{A})=1 / 2=0,5.
\]

\subsubsection{Ilustración por simulación}\label{ilustraciuxf3n-por-simulaciuxf3n}

Mediante el enlace siguiente se accede a una simulación por ordenador de la \emph{ley de los grandes números} en la que se basa precisamente la idea de asimilar ``a la larga'' (es decir a medida que crece el número de repeticiones) frecuencia relativa y probabilidad.

\href{https://www.grbio.eu/statmedia/Statmedia_1/}{Enlace a la simulación}

En la simulación podéis definir:

\begin{itemize}
\tightlist
\item
  La verdadera probabilidad'' de que al tirar la moneda salga cara,
\item
  EL número de tiradas.
\end{itemize}

Como podréis comprobar, sea cual sea la probabilidad (una moneda justa es un 0.5) a la larga la frecuencia relativa converge hacia el valor que habéis fijado.

Eso sí, observad lo que sucede si fijais probabilidades cercanas a 0.5 o muy alejadas de ell.

¿La idea de lo que sucede a la larga es la misma? ¿En que encontráis diferencias?

Aunque no deje de llamar la atención el carácter errático del comportamiento de \(\mathrm{f}_{\mathrm{r}}\) entre los valores 0 y 1, estaréis seguramente de acuerdo que a mayor
número de lanzamientos \(n\), más improbable es que \(f_{r}\) se aleje
mucho de \(p(A)\).

La teoría moderna de la probabilidad enlaza formalmente estas ideas con
el estudio de las leyes de los grandes números, que se discutiran con más detalle en el capítulo dedicado a las ``Grandes muestras''.

\subsection{Caso de Estudio: Eficacia de una prueba diagnóstica}\label{caso-de-estudio-eficacia-de-una-prueba-diagnuxf3stica}

Para decidir la presencia(E) o ausencia (A) de sordera profunda a la edad de seis meses, se está ensayando una batería de tests.

Considerando el caso en que la prueba pueda dar positivo \((+)\) o negativo \((-)\), hay que tener en cuenta que en individuos con dicha sordera la prueba dará a veces positivo y a veces negativo, e igual ocurrirá con individuos que no presentan la sordera.

En este contexto todas las probabilidades pueden ser interpretadas en terminos de resultados positivos o neghativos, correctamente o no y cada una ha recibe un nombre que la ha popularizado dentro de la literatura médica:

Así tenemos:

\begin{itemize}
\item
  \(\mathrm{P}(+/ \mathrm{E})\)

  \begin{itemize}
  \tightlist
  \item
    Probabilidad de test positivo en individuos que padecen la sordera.
  \item
    Este valor se conoce como \emph{sensibilidad del test}.
  \end{itemize}
\item
  \(\mathrm{P}(+/ \mathrm{A})=\)

  \begin{itemize}
  \tightlist
  \item
    Probabilidad de test positivo en individuos que no padecen la sordera.
  \item
    Este valor se conoce como \emph{probabilidad de falso-positivo}.
  \end{itemize}
\item
  \(\mathrm{P}(-/ \mathrm{E})=\)

  \begin{itemize}
  \tightlist
  \item
    Probabilidad de test negativo en individuos que padecen la sordera
  \item
    Este valor se conoce como \emph{probabilidad de falso-negativo}.
  \end{itemize}
\item
  \(P(-/ A)=\)

  \begin{itemize}
  \tightlist
  \item
    Probabilidad de test negativo en individuos que no padecen sordera.
  \item
    Este valor se conoce como
    \emph{especificidad del test}.
  \end{itemize}
\item
  Finalmente a la probabilidad, \(\mathrm{P}(\mathrm{E})\), de presentar la enfermedad se le conoce como \emph{prevalencia} de la enfermedad.
\end{itemize}

Lógicamente, en un ``buen test'' nos interesa que la sensibilidad y la especificidad sean elevadas, mientras que los falsos-positivos y falsos-negativos sean valores bajos.

Además no debemos olvidar que, el interés de aplicar el test, consiste en que sirva de elemento predictivo para diagnosticar la sordera.

Por lo tanto, interesa que las probabilidades:

\begin{itemize}
\item
  \(\mathrm{P}(\mathrm{E} /+)=\) Probabilidad de padecer sordera si el test da positivo
\item
  \(\mathrm{P}(\mathrm{A} /-)=\) Probabilidad de no padecer sordera si el test da negativo
\end{itemize}

sean realmente altas.

A las probabilidades
anteriores se las conoce como: \emph{valores predictivos} del test, en concreto:

\begin{itemize}
\item
  \(\mathrm{P}(\mathrm{E} /+)=\) es el \emph{valor predictivo positivo} y
\item
  \(\mathrm{P}(\mathrm{A} /-)=\) es el \emph{valor predictivo negativo}
\end{itemize}

\subsubsection{Aplicación del Teorema de Bayes}\label{aplicaciuxf3n-del-teorema-de-bayes}

Estamos en una situación en que, a partir de conocimiento de unas probabilidades, nos interesa calcular otras, para lo que utilizaremos el teorema de Bayes.

Habitualmente, a partir de estudios epidemiológicos y muestras experimentales, se estiman:

\begin{itemize}
\item
  La prevalencia
\item
  La sensibilidad del test
\item
  La especificidad del test
\item
  La probabilidad de falso positivo
\item
  La probabilidad de falso negativo
\end{itemize}

¿Cómo se obtiene entonces el valor predictivo del test?

Veamos como aplicar el teorema de Bayes a este problema:

Si dividimos a la población global (en este caso, el conjunto de todos los bebés de seis meses) entre los que padecen sordera y los que no la padecen, aplicando el teorema de Bayes resulta que:

\[
\mathrm{P}(\mathrm{E} /+)=(\mathrm{P}(+/ \mathrm{E}) \times \mathrm{P}(\mathrm{E})) /(\mathrm{P}(+/ \mathrm{E}) \times \mathrm{P}(\mathrm{E})+\mathrm{P}(+/ \mathrm{A}) \times \mathrm{P}(\mathrm{~A}))
\]
y

\[
\mathrm{P}(\mathrm{~A} /-)=(\mathrm{P}(-/ \mathrm{A}) \times \mathrm{P}(\mathrm{~A})) /(\mathrm{P}(-/ \mathrm{A}) \times \mathrm{P}(\mathrm{~A})+\mathrm{P}(-/ \mathrm{E}) \times \mathrm{P}(\mathrm{E}))
\]

\subsubsection{Ejemplo numérico}\label{ejemplo-numuxe9rico}

Supongamos que en el ejemplo de la sordera, se sabe que:

\begin{itemize}
\item
  Prevalencia \(=0,003\), Es decir, que un tres por mil padece sordera profunda a esta edad.
\item
  Sensibilidad \(=0,98\)
\item
  Especificidad \(=0,95\)
\item
  Probabilidad de falso positivo \(=0,05\)
\item
  Probabilidad de falso negativo \(=0,02\)
\end{itemize}

¿Cuál es el valor predictivo del test?

\[
\begin{aligned}
& \mathrm{P}(\mathrm{E} /+)=(0,98 \times 0,003) /(0,98 \times 0,003+0,05 \times 0,997)=0,00294 / 0,05279=0,055692 \\
& \mathrm{P}(\mathrm{~A} /-)=(0,95 \times 0,997) /(0,95 \times 0,997+0,02 \times 0,003)=0,94715 / 0,94721=0,999936
\end{aligned}
\]

En conclusión,
Podemos afirmar que se trata de un test muy válido para decidir que no hay sordera en caso de que el resultado del test sea negativo.

Sin embargo, el valor tan bajo de \(\mathrm{P}(\mathrm{E} /+)\) no permite poder considerar al test como un predictor válido para diagnosticar la sordera.

Obsérvese que:

\begin{itemize}
\item
  Probabilidad de falso positivo \(=1-\) especificidad
\item
  Probabilidad de falso negativo \(=1-\) sensibilidad
\end{itemize}

\newpage

\section{Variables aleatorias y Distribuciones de probabilidad}\label{variables-aleatorias-y-distribuciones-de-probabilidad}

En el capítulo anterior hemos introducido el concepto de probabilidad y
como calcular probabilidades asociadas a sucesos observables, formados
por uno o mas sucesos elementales, resultado de un experimento
aleatorio.

En muchas ocasiones nos interesa representar los resultados de un
experimento aleatorio mediante un valor numérico que lo caracterice. Por
ejemplo si tiramos tres monedas y contamos el número de caras, nos será
indiferente cuando salgan dos caras, en que monedas ha salido una cara y
en cual ha salido una cruz.

En la práctica, esto significa que en dichas ocasiones, aunque haya un
experimento aleatorio detras de los valores que observamos, tan sólo nos
interesan los resultados que expresamos a traves de valores numéricos.

Las variables aleatorias son la forma que hemos desarrollado para
\emph{trasladar la estructura proporcionada por los espacios de probabilidad
el espacio muestral, el conjunto de sucesos elementales, al conjunto de
los números, en concreto a la recta real, haciéndolo de tal forma que
podamos seguir calculando probabilidades de sucesos observables}.

En este capítulo veremos que las variables aleatorias permiten pues
\emph{transportar} la probabilidad del espacio de probabilidad original a la
recta real. Para ello, introduciremos una función que es la que se ocupa
de ello, la \emph{función de distribución de probabilidad}.

\subsection{El espacio muestral y sus elementos}\label{el-espacio-muestral-y-sus-elementos}

Cuando llevamos a cabo un experimento aleatorio, el conjunto \(\Omega\) de
resultados posibles forman el denominado espacio muestral. Sus elementos
\(\omega\) (resultados o sucesos elementales) deben ser conocidos por el
investigador que realiza la experiencia, aun cuando no podamos
determinar a priori el resultado particular de una realización concreta.

Supondremos que también conocemos la manera de asignar una probabilidad
sobre el conjunto de enunciados o \emph{sucesos observables} que se pueden
construir a partir de \(\Omega\). Es decir, supondremos la existencia de
un espacio de probabilidad construido a partir de los resultados de
\(\Omega\).

Generalmente, la estructura del espacio muestral no permite, o por lo
menos no facilita, su tratamiento matemático. Pensemos en la inmensa
variedad en la naturaleza de resultados posibles de diferentes
experimentos. Además es bastante frecuente que no nos interesen los
resultados en sí, sino una característica que, de alguna manera, resuma
el resultado del experimento.

\subsection{Representación numérica de los sucesos elementales. Variables aleatorias}\label{representaciuxf3n-numuxe9rica-de-los-sucesos-elementales.-variables-aleatorias}

La forma de resumen que adoptaremos es la asignación a cada suceso
elemental de un valor numérico, en particular, de un número real.

En la práctica la asignación de un valor numérico a cada elemento del
espacio muestral se hace siguiendo una regla o enunciado, según el
interés concreto del experimentador. Evidentemente, podemos construir
diversas maneras de asignar valores numéricos a los mismos resultados de
un experimento.

Hablando en términos coloquiales, podemos decir que cada regla de
asignación corresponde a una determinada variable que se puede medir
sobre los sucesos elementales.

Nótese que es posible construir múltiples variables sobre un mismo
espacio de probabilidad. En términos algo más formales, las reglas de
asignación se pueden interpretar como una aplicación de \(\Omega\) en el
conjunto de números reales. \[
\begin{aligned}
X: \Omega & \rightarrow \mathbb{R} \\
\omega & \rightarrow X(\omega)
\end{aligned}
\]

\(X\) representa la variable o regla de asignación concreta. El conjunto
de valores numéricos que puede tomar una variable, y que depende de la
naturaleza de la misma variable, recibe el nombre de recorrido de la
variable.

A partir de este momento, los sucesos elementales quedan substituidos
por sus valores numéricos de acuerdo a una determinada variable y
permiten un mayor tratamiento matemático en el marco de la teoría de la
probabilidad.

El apelativo aleatoria que reciben las variables hace referencia al
hecho de que los posibles valores que toman dependen de los resultados
de un fenómeno aleatorio que se presentan con una determinada
probabilidad.

Como un complemento al tema, al final del capítulo, presentamos la
definición formal de variable aleatoria, donde se introducen las
restricciones a las reglas de asignación numérica que posibilitan el
tratamiento matemático de las variables.

\subsection{Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución}\label{caracterizaciuxf3n-de-una-variable-aleatoria-a-travuxe9s-de-la-probabilidad.-funciuxf3n-de-distribuciuxf3n}

Una vez que tenemos definida una variable aleatoria, ésta queda
totalmente caracterizada en el momento en que somos capaces de
determinar la probabilidad de que la variable tome valores en cualquier
intervalo de la recta real. Dado que los posibles valores que puede
tomar la variable, es decir, su recorrido, pueden ser muy grandes
(infinitos de hecho), el problema de caracterizar una variable aleatoria
se resuelve introduciendo una función especial, \emph{la función de
distribución}.

\textbf{Definición}

La función de distribución de una variable aleatoria \(X\) es la
aplicación que, a cada punto de la recta real, le asigna la probabilidad
del suceso formado por los resultados del experimento que tienen
asignado un valor de la variable aleatoria menor o igual a dicho punto.

\[
\begin{array}{rll}
F: & \mathbb{R} & \rightarrow[0,1] \\
& x & \rightarrow F(x)=P(X \leq x)=P\{\omega \in \Omega \mid X(\omega) \leq x\}
\end{array}
\] También podemos decir que es la probabilidad inducida en el intervalo
de la recta \((-\infty, x]\)

Hay que hacer notar que siempre será posible determinar dicha
probabilidad gracias a los requerimientos exigidos en la definición
formal de variable aleatoria. Por tanto, toda variable aleatoria tiene
asociada una función de distribución. Nos referimos a esta función
cuando decimos que conocemos la distribución de la variable aleatoria.

\subsection{Propiedades de la función de distribución}\label{propiedades-de-la-funciuxf3n-de-distribuciuxf3n}

La forma en que hemos definido las funciones de distribución determina que
dichas funciones deban de tener las siguientes propiedades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(0 \leq F(x) \leq 1. \quad\)
  Efectivamente, se trata de una probabilidad, por lo que toma valores entre 0 y 1
\item
  \(\lim _{x \rightarrow+\infty} F(x)=1. \quad\)
  A medida que un valor se hace más y más grande, la probabilidad de encontrar valores anteriores a él crece y, en el límite, valdrá uno (el valor máximo para una probabilidad).
\item
  \(\lim _{x \rightarrow-\infty} F(x)=0. \quad\)
  A medida que un valor se hace más y más negativo, la probabilidad de encontrar valores anteriores a él disminuye, y en el límite es cero (el valor mínimo para una probabilidad).
\item
  \(x_{1}<x_{2} \Rightarrow F\left(x_{1}\right) \leq F\left(x_{2}\right). \quad\)
  Por construcción, es una función monótona, es decir, si un valor es inferior a otro, la probabilidad de encontrar valores inferiores al menor de los dos será menor o igual que la de encontrarlos inferiores al mayor de los dos.
\item
  \(\lim _{x \rightarrow a^{+}} F(x)=F(a) \quad \forall a \in \mathbb{R}. \quad\)
  Por la forma en que se ha definido, la función de distribución es \emph{contínua por la derecha}.
\end{enumerate}

Toda función que verifique las propiedades anteriores es una función de
distribución y toda función de distribución caracteriza una determinada
variable aleatoria sobre algún espacio de probabilidad.

Las propiedades anteriores determinan la forma de la función de distribución. En concreto, según la variable sea contínua o discreta, conceptos definidos a continuación en el capítulo, la forma de la función será: :

Primer tipo (Variables contínuas)

\includegraphics[width=0.9\linewidth]{images/cdfContinua}

Segundo tipo (variables discretas)

\includegraphics[width=0.9\linewidth]{images/cdfDiscreta}

\subsection{Clasificación de las variables aleatorias}\label{clasificaciuxf3n-de-las-variables-aleatorias}

Para su estudio, las variables aleatorias se clasifican en variables
discretas o variables contínuas.

\subsubsection{Variables aleatorias discretas}\label{variables-aleatorias-discretas}

\textbf{Definición: Variable aleatoria discreta}

Diremos que una variable aleatoria es discreta si su recorrido, es decir, el conjunto de valores que puede tomar, es finito
o infinito numerable.

Generalmente, este tipo de variables van asociadas
a experimentos en los cuales se cuenta el número de veces que se ha
presentado un suceso o donde el resultado es una puntuación concreta.

Los puntos del recorrido se corresponden con saltos en la gráfica de la
función de distribución, que correspondería al segundo tipo de gráfica
visto anteriormente.

\subsubsection{Variables aleatorias continuas}\label{variables-aleatorias-continuas}

\textbf{Definición: Variable aleatoria contínua}

Diremos que una variable aleatoria es continua si su función de distribución es una función
continua.

También puede definirse, de forma análoga a las variables discretas como aquellas cuyo recorrido, es decir, el conjunto de valores que puede tomar, es un intervalo o subconjunto no numerable de los números reales. En otras palabras, aquellas que pueden tomar cualquier valor dentro de un rango continuo, sin saltos entre los valores posibles.

Se corresponde con el primer tipo de gráfica visto.

Generalmente, se corresponden con variables asociadas a experimentos en
los cuales la variable medida puede tomar cualquier valor en un
intervalo; mediciones biométricas, por ejemplo.

Un caso particular dentro de las variables aleatorias continuas y al
cual pertenecen todos los ejemplos usualmente utilizados, son las
denominadas variables aleatorias absolutamente continuas.

\textbf{Definición: Distribución absolutamente contínua}

Diremos que una variable aleatoria \(X\) continua tiene una distribución
absolutamente continua si existe una función real \(f\), positiva e integrable en el conjunto de números reales, tal que la función de
distribución \(F\) de \(X\) se puede expresar como

\[
F(x)=\int_{-\infty}^{x} f(t) d t
\]

Una variable aleatoria con distribución absolutamente continua, por
extensión, se la clasifica como variable aleatoria absolutamente
continua.

\textbf{Definición: función de densidad de probabilidad}

A la función \(f\) se la denomina función de densidad de probabilidad de
la variable \(X\).

Hay que hacer notar que no toda variable continua es absolutamente
continua, pero los ejemplos son complicados, algunos utilizan para su
construcción el conjunto de Cantor, y quedan fuera del nivel y del
objetivo de este curso.

Igualmente indicaremos que los tipos de variables comentados
anteriormente forman únicamente una parte de todos los posibles tipos de
variables, sin embargo contienen prácticamente todas las variables
aleatorias que encontramos usualmente.

Tal como se estudiará más adelante, existen algunas familias de
funciones de distribución, tanto dentro del grupo de las discretas como
de las continuas, que por su importancia reciben un nombre propio y se
estudiarán en los capítulos siguientes.

En ocasiones encontramos variables de tipo mixto, es decir que se
comportan como discretas o contínuas para distintos grupos de valores.

\subsection{Variable aleatoria discretas}\label{variable-aleatoria-discretas}

Tal como se ha definido, una variable aleatoria \(X\) discreta toma valores en un conjunrto finito o numerables.

Indicaremos el recorrido de la variable \(X\) como:
\(\left\{x_{1}, x_{2}, \ldots, x_{\mathrm{k}}, \ldots\right\}\).

El ejemplo más sencillo de variable aleatoria discreta lo constituyen
las variables indicadoras. Sea \(A\) un suceso observable, se llama
indicador de \(A\) a la variable aleatoria definida por

\[
\begin{aligned}
I_{A}: \Omega & \rightarrow \mathbb{R} \\
\omega & \rightarrow I_{A}(\omega)=\left\{\begin{array}{lll}
1 & \text { si } \omega \in A \\
0 & \text { si } & A
\end{array}\right.
\end{aligned}
\]

\paragraph{Ejercicio propuesto}\label{ejercicio-propuesto}

Construir, a partir de las variables indicadoras de \(A\) y \(B\), las
siguientes variables indicadoras

\[
I_{A \cap B} ; I_{A \cup B} ; I_{A} c ; I_{\Omega}
\]

\subparagraph{Solución}\label{soluciuxf3n}

\[
\begin{gathered}
I_{A \cap B}=I_{A} \cdot I_{B} \\
I_{A \cup B}=I_{A}+I_{B}-I_{A \cap B} \\
I_{A} c=1-I_{A} \\
\Omega=1
\end{gathered}
\]

\subsubsection{Caracterización de las v.a. discretas}\label{caracterizaciuxf3n-de-las-v.a.-discretas}

Una variable aleatoria discreta puede caracterizarse a través de la
función que asocia cada elemento del recorrido su probabilidad.
Dicha función recibe varios nombres según los autores:
- función de probabilidad
- ley de probabilidad,
- función de densidad de la variable aleatoria
discreta.
- función de masa de probabilidad.

Aunque es habitual encontrar, en muchos libros el término \emph{función de densidad} para variables (absolutamente) contínuas y el término \emph{función de masa de probabilidad} para variables discretas, también lo es referirse a ambas como ``función de densidad''.

La función de probabilidad de una variable discreta se puede representar de la manera siguiente:

\[
\begin{array}{rll}
f: & \mathbb{R} & \rightarrow[0,1] \\
& x & \rightarrow f(x)=P(X=x)=P\{\omega \in \Omega \mid X(\omega)=x\}
\end{array}
\]

Obsérvese que, a diferencia de la función de distribución que toma valores para cualquier valor real, la función definida anteriormente es nula en todo punto que no
pertenezca al recorrido.

En cambio, siguiendo con la análogía, y dado que se trata de una probabilidad, la
función de densidad discreta está acotada \(0 \leq f(x) \leq 1\).

Toda
función de densidad discreta puede expresarse de manera explícita a
través de una tabla que asocie directamente puntos del recorrido con sus
probabilidades.

\textbf{Ejemplo: Función de densidad de una variable indicadora}

Consideremos la variable indicadora del suceso \(A\) :

\[
\begin{aligned}
I_{A}: \Omega & \rightarrow \mathbb{R} \\
\omega & \rightarrow I_{A}(\omega)=\left\{\begin{array}{lll}
1 & \text { si } & \omega \in A \\
0 & \text { si } & A
\end{array}\right.
\end{aligned}
\]

La función de densidad de esta variable sería la siguiente:

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
\(x\) & 0 & 1 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(f(x)=P(X=x)\) & \(1-P(A)=P\left(A^{\mathrm{c}}\right)\) & \(P(A)\) \\
\end{longtable}

El recorrido está formado por dos valores: 1 y 0 , con las mismas
probabilidades que las del suceso \(A\) y su complementario,
respectivamente.

En muchos casos será posible expresar la función de probabilidadmediante una fórmula
matemática que define una regla de asignación de probabilidades para los
valores del recorrido.

\textbf{Ejemplo: Un modelo matemático para la función de probabilidad}

\[
P(X=x)=0,2 \cdot 0,8^{x-1}, \quad x=1,2, \ldots
\]

es la función de densidad de una variable aleatoria discreta con
recorrido numerable.

\subsubsection{Propiedades de la función de densidad discreta}\label{propiedades-de-la-funciuxf3n-de-densidad-discreta}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
\end{enumerate}

\[
0 \leq f(x) \leq 1
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \(\sum_{i=1}^{n} f\left(x_{i}\right)=1\), si el recorrido es finito.
\item
  \(\sum_{i=1}^{\infty} f\left(x_{i}\right)=1\), si el recorrido es
  numerable.
\end{enumerate}

\subsubsection{\texorpdfstring{Relaciones entre la función de distribución y la función de densidad discreta. Probabilidad de intervalos.}{Relaciones entre la función de distribución y la función de densidad discreta.   Probabilidad de intervalos.}}\label{relaciones-entre-la-funciuxf3n-de-distribuciuxf3n-y-la-funciuxf3n-de-densidad-discreta.-probabilidad-de-intervalos.}

Existe una relación muy importante entre las funciones de distribución
\(F(x)\) y de densidad \(f(x)\) de una variable aleatoria discreta. La
función de distribución en un punto se obtiene acumulando el valor de la
función de densidad para todos los valores del recorrido menores o
iguales al punto en cuestión.

\[
F(x)=\sum_{x_{i} \leq x} f\left(x_{i}\right) \quad \text { para todo } \mathrm{x}_{\mathrm{i}} \text { perteneciente al recorrido de la variable. }
\]

En efecto, supongamos que el recorrido de una variable discreta \(X\) es
\(\left\{x_{1}, x_{2}, \ldots, x_{k}, \ldots\right\}\) y que deseamos
conocer el valor de la función de distribución en un punto \(x\) tal que
\(x_{i} \leq x<x_{i+1}\), entonces es inmediato que

\[
F(x)=P(X \leq x)=P\left(X=x_{1}\right)+P\left(X=x_{2}\right)+\ldots+P\left(X=x_{i}\right)=f\left(x_{1}\right)+f\left(x_{2}\right)+f\left(x_{3}\right)+\ldots+f\left(x_{i}\right)
\]

Por ejemplo, para una variable indicadora de un suceso \(A\), tenemos la
relación siguiente:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Valor de \(\boldsymbol{x}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{f}(\boldsymbol{x})\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\boldsymbol{F}(\boldsymbol{x})\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\((-\infty, 0)\) & & 0 \\
0 & \(P\left(A^{c}\right)\) & \(P\left(A^{\mathrm{c}}\right)\) \\
\((0,1)\) & & \(P\left(A^{\mathrm{c}}\right)\) \\
1 & \(P(A)\) & \(P\left(A^{\mathrm{c}}\right)+P(A)=1\) \\
\((1,+\infty)\) & & 1 \\
\end{longtable}

A partir de las funciones de densidad y de distribución es posible
expresar las probabilidades para cualquier posible intervalo de valores
de la variable. Por ejemplo:

\begin{longtable}[]{@{}l@{}}
\toprule\noalign{}
Intervalo \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(P(X \leq a)=F(a)\) \\
\(P(X<a)=F(a)-f(a)\) \\
\(P(X>a)=1-F(a)=1-P(X \leq a)\) \\
\(P(X \geq a)=1-F(a)+f(a)=1-P(X>a)\) \\
\(P(a<X \leq b)=F(b)-F(a)\) \\
\(P(a<X<b)=F(b)-f(b)-F(a)\) \\
\(P(a \leq X \leq b)=F(b)-F(a)+f(a)\) \\
\(P(a \leq X<b)=F(b)-f(b)-F(a)+f(a)\) \\
\end{longtable}

\subsection{Variables aleatorias continuas}\label{variables-aleatorias-continuas-1}

Una variable aleatoria \(X\) diremos que es continua si su función de
distribución es una función continua. En la práctica, se corresponden
con variables asociadas con experimentos en los cuales la variable
medida puede tomar cualquier valor en un intervalo: mediciones
biométricas, intervalos de tiempo, áreas, etc.

\textbf{Ejemplo: Variables aleatorias continuas}

\begin{itemize}
\tightlist
\item
  Resultado de un generador de números aleatorios entre 0 y 1. Es el
  ejemplo más sencillo que podemos considerar, es un caso particular
  de una familia de variables aleatorias que tienen una distribución
  uniforme en un intervalo \([a, b]\). Se corresponde con la elección al
  azar de cualquier valor entre \(a\) y \(b\).
\item
  Estatura de una persona elegida al azar en una población. El valor
  que se obtenga será una medición en cualquier unidad de longitud ( m
  , cm , etc.) dentro de unos límites condicionados por la naturaleza
  de la variable. El resultado es impredecible con antelación, pero
  existen intervalos de valores más probables que otros debido a la
  distribución de alturas en la población. Más adelante veremos que,
  generalmente, variables biométricas como la altura se adaptan un
  modelo de distribución denominado distribución Normal y representado
  por una campana de Gauss.
\end{itemize}

Dentro de las variables aleatorias continuas tenemos las variables
aleatorias absolutamente continuas.

Diremos que una variable aleatoria \(X\) continua tiene una distribución
absolutamente continua si existe una función real \(f\), positiva e
integrable en el conjunto de números reales, tal que la función de
distribución \(F\) de \(X\) se puede expresar como

\[
F(x)=\int_{-\infty}^{x} f(t) d t
\]

Una variable aleatoria con distribución absolutamente continua, por
extensión, se clasifica como variable aleatoria absolutamente continua.

En cuanto a nuestro manual, todas las variables aleatorias continuas con
las que trabajemos pertenecen al grupo de las variables absolutamente
continuas, en particular, los ejemplos y casos expuestos.

\subsubsection{Función de densidad continua}\label{funciuxf3n-de-densidad-continua}

La función que caracteriza las variables continuas es aquella función
\(f\) positiva e integrable en los reales, tal que acumulada desde
\(-\infty\) hasta un punto \(x\), nos proporciona el valor de la función de
distribución en \(x, F(\mathrm{x})\). Recibe el nombre de función de
densidad de la variable aleatoria continua.

\[
F(x)=\int_{-\infty}^{x} f(t) d t
\]

Las funciones de densidad discreta y continua tienen, por tanto, un
significado análogo, ambas son las funciones que acumuladas (en forma de
sumatorio en el caso discreto o en forma de integral en el caso
continuo) dan como resultado la función de distribución.

La diferencia entre ambas, sin embargo, es notable.

\begin{itemize}
\tightlist
\item
  La función de densidad discreta toma valores positivos únicamente en
  los puntos del recorrido y se interpreta como la probabilidad de la
  que la variable tome ese valor \(f(x)=P(X=x)\).
\item
  La función de densidad continua toma valores en el conjunto de
  números reales y no se interpreta como una probabilidad. No está
  acotada por 1, puede tomar cualquier valor positivo. Es más, en una
  variable continua se cumple que probabilidades definidas sobre
  puntos concretos siempre son nulas.
\end{itemize}

\[
P(X=x)=0 \text { para todo } x \text { real. }
\]

¿Cómo se interpreta, entonces, la función de densidad continua? Las
probabilidades son las áreas bajo la función de densidad. El área bajo
la función de densidad entre dos puntos a y b se interpreta como la
probabilidad de que la variable aleatoria tome valores comprendidos
entre \(a\) y \(b\).

Por tanto, siempre se cumple lo siguiente:

\[
\int_{-\infty}^{+\infty} f(x) d x=1
\]

La función de densidad se expresa a través de una función matemática. La
forma específica de la función matemática generalmente pasa por
considerar a la variable aleatoria como miembro de una determinada
familia de distribuciones, un determinado modelo de probabilidad. Estas
familias generalmente dependen de uno o más parámetros y serán objeto de
un estudio específico en un capítulo posterior. La atribución a una
determinada familia depende de la naturaleza de la variable en cuestión.

Podemos ver, únicamente con ánimo ilustrativo, la expresión analítica y
la gráfica para los ejemplos comentados con anterioridad:

\begin{itemize}
\tightlist
\item
  Resultado de un generador de números aleatorios entre
  \(\boldsymbol{a}\) y \(\boldsymbol{b}\). Modelo Uniforme.
  \(f(x)=\left\{\begin{array}{cc}\frac{1}{b-a} & x \in[a, b] \\ 0 & x \notin[a, b]\end{array}\right\}\)
\item
  Estatura de una persona elegida al azar en una población. Modelo
  Normal.
\end{itemize}

\[
f(x)=\frac{1}{\sqrt{2 \pi}} e^{\frac{-(x-170)^{2}}{2}}-\infty<x<\infty
\]

\subsubsection{Relaciones entre la función de distribución y la función de densidad.}\label{relaciones-entre-la-funciuxf3n-de-distribuciuxf3n-y-la-funciuxf3n-de-densidad.}

Para una variable continua, la relación entre las funciones de
distribución y de densidad viene dada directamente a través de la
definición. La función de distribución en un punto se obtiene integrando
el valor de la función de densidad desde menos infinito hasta el punto
en cuestión. Por ejemplo:

\[
F(x)=\int_{-\infty}^{x} f(t) d t
\]

\paragraph{Probabilidad de intervalos}\label{probabilidad-de-intervalos}

A partir de las funciones de densidad y de distribución, y teniendo en
cuenta que \(P(X=x)=0\) para todo \(x\) real, es posible expresar las
probabilidades para cualquier posible intervalo de valores de la
variable. Por ejemplo:

\begin{longtable}[]{@{}c@{}}
\toprule\noalign{}
Intervalo \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(P(X \leq a)=P(X<a)=F(a)=\int_{-\infty}^{a} f(x) d x\) \\
\(P(X \geq a)=P(X>a)=1-F(a)=\int_{a}^{+\infty} f(x) d x\) \\
\(P(a<X \leq b)=P(a<X<b)=P(a \leq X \leq b)=P(a \leq X<b)\) \\
\(=F(b)-F(a)=\int^{b} f(x) d x\) \\
\end{longtable}

Fijémonos que la probabilidad de los intervalos se corresponde con el
área bajo la función de densidad dentro del intervalo considerado.

\includegraphics[width=0.8\linewidth]{images/probsDNormal}

\subsection{Caracterización de una variable aleatoria a través de parámetros}\label{caracterizaciuxf3n-de-una-variable-aleatoria-a-travuxe9s-de-paruxe1metros}

Hasta el momento hemos visto que toda variable aleatoria viene
caracterizada a través de unas determinadas funciones matemáticas, las
funciones de distribución y de densidad. Una vez caracterizada, y por
tanto conocida, la distribución de una variable aleatoria, podemos
obtener cualquier probabilidad asociada.

En ocasiones podemos acotar más el problema y reducir el estudio de una
variable aleatoria a determinar una serie de características numéricas
asociadas con la distribución de la variable. Dichas características
tienen como propiedad fundamental el hecho de resumir gran parte de las
propiedades de la variable aleatoria y juegan un papel muy destacado en
las técnicas estadísticas que desarrollaremos a lo largo del curso.

Por ejemplo, supuesta la pertenencia de una variable aleatoria a una
determinada familia de distribuciones de probabilidad, bien sea discreta
o continua, los diferentes miembros de la familia diferirán en el valor
de esas características numéricas. En este caso, denominaremos a tales
características los parámetros de la distribución.

Existe un buen número de tales características, pero nos centraremos en
las dos más importantes: la esperanza y la varianza. La primera nos
informa sobre la localización de los valores de la variable y la
segunda, sobre el grado de dispersión de estos valores.

\subsection{Esperanza de una variable aleatoria discreta}\label{esperanza-de-una-variable-aleatoria-discreta}

La esperanza matemática de una variable aleatoria es una característica
numérica que proporciona una idea de la localización de la variable
aleatoria sobre la recta real. Decimos que es un parámetro de
centralización o de localización.

Su interpretación intuitiva o significado se corresponde con el valor
medio teórico de los posibles valores que pueda tomar la variable
aleatoria, o también con el centro de gravedad de los valores de la
variable supuesto que cada valor tuviera una masa proporcional a la
función de densidad en ellos.

La definición matemática de la esperanza en el caso de las variables
aleatorias discretas se corresponde directamente con las
interpretaciones proporcionadas en el párrafo anterior. Efectivamente,
supuesta una variable aleatoria discreta \(X\) con recorrido
\(\left\{x_{1}, x_{2}, \ldots, x_{k}, \ldots\right\}\) y con función de
densidad \(f(x)\), se define la esperanza matemática de \(X\) como el valor

\[
E(X)=\sum_{x_{i} \in X(\Omega)} x_{i} f\left(x_{i}\right)
\]

donde el sumatorio se efectúa para todo valor que pertenece al recorrido
de \(X\). En caso de que el recorrido sea infinito la esperanza existe si
la serie resultante es absolutamente convergente, condición que no
siempre se cumple.

La definición se corresponde con un promedio ponderado según su
probabilidad de los valores del recorrido y, por tanto, se corresponde
con la idea de un valor medio teórico.

\subsection{Esperanza de una variable aleatoria continua}\label{esperanza-de-una-variable-aleatoria-continua}

La idea intuitiva que más nos puede ayudar en la definición de la
esperanza matemática de una variable aleatoria continua es la idea del
centro de gravedad de los valores de la variable, donde cada valor tiene
una masa proporcional a la función de densidad en ellos.

Dada una variable aleatoria absolutamente continua \(X\) con función de
densidad \(f(x)\), se define la esperanza matemática de \(X\) como el valor

\[
E(X)=\int_{-\infty}^{+\infty} x f(x) d x
\]

suponiendo que la integral exista.

\subsection{Propiedades de la esperanza matemática}\label{propiedades-de-la-esperanza-matemuxe1tica}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Esperanza de una función de una variable aleatoria
\end{enumerate}

\begin{itemize}
\tightlist
\item
  Variable discreta
\end{itemize}

\[
E(h(X))=\sum_{x_{i} \in X(\Omega)} h\left(x_{i}\right) f\left(x_{i}\right)
\]

\begin{itemize}
\tightlist
\item
  Variable continua
\end{itemize}

\[
E(h(X))=\int_{-\infty}^{+\infty} h(x) f(x) d x
\]

\subsubsection{Linealidad de la esperanza matemática}\label{linealidad-de-la-esperanza-matemuxe1tica}

\begin{itemize}
\item
  \(E(X+Y)=E(X)+E(Y)\)
\item
  \(E(k \cdot X)=k \cdot E(X)\) para todo número real \(k\).
\item
  \(E(k)=k\) para todo número real \(k\).
\item
  \(E(a \cdot X+b)=a \cdot E(X)+b\) para todo par de números reales \(a\) y
  \(b\).
\end{itemize}

\subsubsection{Esperanza del producto}\label{esperanza-del-producto}

\begin{itemize}
\tightlist
\item
  \(E(X \cdot Y)=E(X) \cdot E(Y)\) únicamente en el caso de que \(X\) e
  \(Y\) sean variables aleatorias independientes.
\end{itemize}

\subsection{Varianza de una variable aleatoria}\label{varianza-de-una-variable-aleatoria}

La varianza de una variable aleatoria es una característica numérica que
proporciona una idea de la dispersión de la variable aleatoria respecto
de su esperanza. Decimos que es un parámetro de dispersión.

La definición es la siguiente:

\[
\operatorname{Var}(X)=E\left((X-E(X))^{2}\right)
\]

Es, por tanto, el promedio teórico de las desviaciones cuadráticas de
los diferentes valores que puede tomar la variable respecto de su valor
medio teórico o esperanza.

En el caso de las variables discretas, la expresión se convierte en:

\[
\operatorname{Var}(X)=\sum_{x_{i} \in X(\Omega)}\left(x_{i}-E(X)\right)^{2} f\left(x_{i}\right)
\]

mientras que para las variables continuas tenemos:

\[
\operatorname{Var}(X)=\int_{-\infty}^{+\infty}(x-E(X))^{2} f(x) d x
\]

En ambos casos existe una expresión equivalente alternativa y
generalmente de cálculo más fácil:

\[
\operatorname{Var}(X)=E\left(X^{2}\right)-(E(X))^{2}
\]

Una de las características de la varianza es que viene expresada en
unidades cuadráticas respecto de las unidades originales de la variable.
Un parámetro de dispersión derivado de la varianza y que tiene las
mismas unidades de la variable aleatoria es la desviación típica, que se
define como la raíz cuadrada de la varianza.

\[
\sigma_{X}=\sqrt{\operatorname{Var}(X)}=\sqrt{E\left((X-E(X))^{2}\right)}
\]

\subsubsection{Propiedades de la varianza}\label{propiedades-de-la-varianza}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\operatorname{Var}(X) \geq 0\)
\item
  \(\operatorname{Var}(k \cdot X)=k^{2} \cdot \operatorname{Var}(X)\)
  para todo numero real \(k\).
\item
  \(\operatorname{Var}(k)=0\) para todo numero real \(k\).
\item
  \(\operatorname{Var}(a \cdot X+b)=a^{2} \cdot \operatorname{Var}(X)\)
  para todo par de números reales \(a\) i \(b\).
\item
  \(\operatorname{Var}(X+Y)=\operatorname{Var}(X)+\operatorname{Var}(Y)\)
  únicamente en el caso que \(X\) y \(Y\) sean independientes.
\end{enumerate}

\subsection{\texorpdfstring{Momentos (de orden \(k\)) de una variable aleatoria}{Momentos (de orden k) de una variable aleatoria}}\label{momentos-de-orden-k-de-una-variable-aleatoria}

\begin{itemize}
\tightlist
\item
  Dada una variable aleatoria \(X\), definimos el momento de orden \(k\)
  como:
\end{itemize}

\[
m_{k}=E\left(X^{k}\right)
\]

suponiendo que tal esperanza exista. Podemos ver que la esperanza es el
momento de orden \(1, E(X)=m_{1}\).

\begin{itemize}
\tightlist
\item
  Definimos el momento central de orden \(k\) como:
\end{itemize}

\[
\mu_{k}=E\left((X-E(X))^{k}\right)
\]

Con la denominación anterior, la varianza es el momento central de orden
\(2, \operatorname{Var}(X)=\mu_{2}\).

\begin{itemize}
\tightlist
\item
  Es posible también definir momentos mixtos de dos variables
  aleatorias. Dadas dos variables aleatorias \(X\) e \(Y\) definimos el
  momento mixto de orden \((r, k)\) como
\end{itemize}

\[
m_{r k}=E\left(X^{r} \cdot Y^{k}\right)
\]

y el momento mixto central de orden \((r, k)\) como

\[
\left.\mu_{r k}=E(X-E(X))^{r} \cdot(Y-E(Y))^{k}\right)
\]

\begin{itemize}
\tightlist
\item
  El momento mixto central más importante es el \(\mu_{11}\), denominado
  la covarianza de \(X\) e \(Y\), y con una interpretación en el sentido
  de cuantificar el grado de dependencia entre dos variables
  aleatorias, puesto que si \(X\) e \(Y\) son independientes se verifica
  que \(\mu_{11}=0\), mientras que si \(\mu_{11} \neq 0\) entonces las
  variables son dependientes.
\end{itemize}

\subsection{Definición formal de variable aleatoria}\label{definiciuxf3n-formal-de-variable-aleatoria}

Tal como hemos comentado, la definición formal de variable aleatoria
impone una restricción matemática en la formulación vista hasta el
momento.

Definiremos una variable aleatoria como una aplicación de \(\Omega\) en el
conjunto de números reales

\[
\begin{aligned}
X: \Omega & \rightarrow \mathbb{R} \\
\omega & \rightarrow X(\omega)
\end{aligned}
\] que verifique la propiedad siguiente

\[
\forall x \in \mathbb{R} \quad \text { el conjunto } \mathrm{A}=\{a \mid \mathrm{X}(a) \leq \mathrm{x}\} \text { es un suceso observable }
\]

es decir, para todo número real \(x\), el conjunto de resultados
elementales tales que la variable aleatoria toma sobre ellos valores
inferiores o iguales a \(x\) ha de ser un suceso sobre el cual podamos
definir una probabilidad.

Dicha propiedad recibe el nombre de medibilidad y por tanto podríamos
decir que una variable aleatoria es una función medible de \(\Omega\) en
los reales.

Esta condición nos asegura que podremos calcular sin problemas,
probabilidades sobre intervalos de la recta real a partir de las
probabilidades de los sucesos correspondientes.

\[
P(X \leq x)=P\{\omega \mid X(\omega) \leq x\}
\]

La expresión anterior se leería de la manera siguiente: La probabilidad
de que la variable aleatoria tome valores inferiores o iguales a \(x\) es
igual a la probabilidad del suceso formado por el conjunto de resultados
elementales sobre los que el valor de la variable es menor o igual que
\(x\).

La probabilidad obtenida de esta manera se denomina probabilidad
inducida. Se puede comprobar que, a partir de la condición requerida, se
pueden obtener probabilidades sobre cualquier tipo de intervalo de la
recta real. Por ejemplo:

\[
P(a<X \leq b)=P(X \leq b)-P(X \leq a)
\]

La condición exigida para ser variable aleatoria discreta ahora puede
ser expresada como:

\[
\forall k=1,2, \ldots \text { el conjunto } \mathrm{A}=\left\{\omega \mid \mathrm{X}(\omega)=\mathrm{x}_{\mathrm{k}}\right\}=\mathrm{X}^{-1}\left(\left\{\mathrm{x}_{\mathrm{k}}\right\}\right) \text { es un suceso observable }
\]

Toda variable aleatoria definida sobre un espacio de probabilidad finito
es necesariamente discreta. La suma y el producto de variables
aleatorias discretas, definido por:

\[
(X+Y)(w)=X(w)+Y(w) \text { y }(X \cdot Y)(w)=X(w) \cdot Y(w)
\]

es también una variable aleatoria discreta.

\subsection{Caso práctico: Lanzamiento de dos dados}\label{caso-pruxe1ctico-lanzamiento-de-dos-dados}

\subsubsection{Espacio muestral}\label{espacio-muestral}

Supongamos que estamos realizando un experimento consistente en el lanzamiento simultáneo de dos dados y en la observación del resultado
obtenido.

El conjunto de resultados posibles forma el espacio muestral \(\Omega\) asociado a dicho experimento. Sus elementos serán como los que se
muestran a continuación:

\pandocbounded{\includegraphics[keepaspectratio]{images/clipboard-1434716414.png}}

En total, el espacio muestral estaría formado por 36 resultados posibles
que, en principio y suponiendo los dados regulares, son todos ellos
equiprobables con probabilidad \(1 / 36\).

Nótese que consideramos diferentes resultados del tipo: un uno en el
primer dado y un dos en el segundo o un dos en el primer dado y un uno
en el segundo.

Una vez fijados los enunciados anteriores, es fácil asignar
probabilidades a diferentes sucesos observables, por ejemplo:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
Suceso & Probabilidad \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Que aparezcan dos cifras iguales & \(6 \cdot 1 / 36=1 / 6\) \\
Que la suma sea 10 & \(3 \cdot 1 / 36=1 / 12\) \\
\end{longtable}

No entramos en detalles de la obtención de las probabilidades dado que
se ha estudiado suficientemente en el tema anterior.

\subsubsection{Representación numérica}\label{representaciuxf3n-numuxe9rica}

Continuando con el experimento anterior, podemos representar los
resultados obtenidos al lanzar dos dados por valores numéricos. ¿Cómo
hacerlo? Definiendo una regla de asignación numérica para cada
resultado.

Una posible regla sería, por ejemplo, asignar a cada resultado la suma
de puntos de las caras. Este enunciado nos define una variable que
representa cada suceso elemental por un valor numérico.

\pandocbounded{\includegraphics[keepaspectratio]{images/clipboard-2572516778.png}}

Los 36 posibles resultados del experimento se transforman en 11 posibles
valores numéricos para la variable: \(2,3,4,5,6,7,8,9,10,11\) y 12 .

Este conjunto de valores forman el \emph{recorrido de la variable suma de
puntos de las caras}. A partir de las probabilidades definidas sobre los
sucesos observables es fácil extender las probabilidades a los
diferentes resultados de la variable.

Por ejemplo, la probabilidad de que la variable tome el valor 10 es
equivalente a la probabilidad del suceso observable que la suma sea 10 ,
calculada anteriormente e igual a \(1 / 12\).

La variable considerada hasta el momento es sólo una de las múltiples
variables que podríamos definir sobre el mismo experimento. Por ejemplo,
podemos estar interesados no en la suma de puntos sino en el punto más
bajo de cada tirada, de forma que podríamos construir una nueva variable
a partir del enunciado o regla de asignación asignar a cada resultado el
menor de los puntos de las dos caras. Tenemos una nueva variable sobre
el mismo espacio anterior.

\pandocbounded{\includegraphics[keepaspectratio]{images/clipboard-3898377838.png}}

El recorrido, en este caso, está formado por los valores: \(1,2,3,4,5\) y
6 . Las dos variables estudiadas y otras muchas que se podrían definir
sobre este experimento son ejemplos absolutamente equivalentes desde el
punto de vista formal.

\subsubsection{Algunas probabilidades}\label{algunas-probabilidades}

En el ejemplo de los dados vamos a centrarnos en la variable aleatoria

\[
X=\text { Suma de puntos de las caras }
\]

\pandocbounded{\includegraphics[keepaspectratio]{images/clipboard-1018442669.png}}

El recorrido de la variable está formado por los números
\(\{2,3,4,5,6,7,8,9,10,11\) i 12\(\}\). Vamos a calcular algunas
probabilidades:

\begin{itemize}
\tightlist
\item
  \(P(X \leq 1)=P\{\varnothing\}=0\) (Ningún resultado tiene asignado un
  valor menor o igual a 1)
\item
  \(P(X \leq 2)=P\{(1,1)\}=1/36\) (Sólo hay un caso al que se le asigne
  un valor inferior o igual a 2).
\item
  \(P(X \leq 3.5)=P\{(1,1), (1,2), (2,1)\}=3/36\) (Tres resultados
  elementales tienen asignado un valor menor o igual a 3.5)
\end{itemize}

Ahora podéis intentar calcular por vosotros mismos algunas
probabilidades: (a) \(P(X \leq 6)\) (b) \(P(X \leq 8,2)\); (c)
\(P(X \leq 12)\); (d) \(P(X \leq 20)\) i (e) \(P(2,2<X \leq 7)\)

\subsubsection{Función de distribución}\label{funciuxf3n-de-distribuciuxf3n}

Para calcular la función de distribución de la variable X \(=\) Suma de
puntos de las caras :

\pandocbounded{\includegraphics[keepaspectratio]{images/clipboard-2353777197.png}}

necesitamos conocer el recorrido de la variable, que es:
\(\{2,3,4,5,6,7,8,9,10,11, 12\}\) y, utilizando este recorrido como pauta,
determinar \emph{para todo punto} \(x\) \emph{de la recta real} la probabilidad
\(P(X \leq x)\).

En nuestro ejemplo:

\[
F(x)=P(X \leq x)= \begin{cases}0 & x<2 \\ 1 / 36 & 2 \leq x<3 \\ 3 / 36 & 3 \leq x<4 \\ 6 / 36 & 4 \leq x<5 \\ 10 / 36 & 5 \leq x<6 \\ 15 / 36 & 6 \leq x<7 \\ 21 / 36 & 7 \leq x<8 \\ 26 / 36 & 8 \leq x<9 \\ 30 / 36 & 9 \leq x<10 \\ 33 / 36 & 10 \leq x<11 \\ 35 / 36 & 11 \leq x<12 \\ 36 / 36=1 & x \geq 12\end{cases}
\]

Acabamos de construir la función de distribución de la variable suma de
la puntuación al lanzar dos dados.

Vamos a ver su representación gráfica:

\includegraphics[width=0.9\linewidth]{images/clipboard-1894572766}

Ejercicio : Haced lo mismo para la variable aleatoria el menor de los
puntos de las dos caras al lanzar dos dados.

\subsubsection{Clasificación de las variables}\label{clasificaciuxf3n-de-las-variables}

En el experimento que estamos considerando, lanzar simultáneamente dos
dados, cualquiera de las dos variables aleatorias que hemos considerado
hasta el momento:

\[ X=\text {Suma los puntos de las dos caras } \]

\[
Y=\text { El menor de los puntos de las dos caras }
\]

se clasifican dentro del tipo de variables aleatorias discretas, puesto
que en ambos casos el recorrido es finito:
\(\{2,3,4,5,6,7,8,9,10,11, 12\}\) para la variable \(X\) y
\(\{1,2,3,4,5, 6\}\) para la variable \(Y\).

También son discretas aquellas variables aleatorias con recorrido
infinito numerable.

Ejercicio: ¿Sabríais construir una variable aleatoria discreta con
recorrido infinito numerable basada en el experimento que consiste en el
lanzamiento de dos dados?

\subsubsection{Función de densidad discreta}\label{funciuxf3n-de-densidad-discreta}

Para calcular la función de densidad de la variable

\[
X=\text { suma de puntos de las caras }
\]

\pandocbounded{\includegraphics[keepaspectratio]{images/clipboard-2707476680.png}}

necesitamos conocer el recorrido de la variable, es decir:
\(\{2,3,4,5,6,7,8,9,10,11, 12\}\) y, a partir del recorrido, determinar
para todo punto del recorrido la probabilidad \(P(X=x)\).

En nuestro ejemplo

\[
f(x)=P(X=x)= \begin{cases}1 / 36 & x=2 \\ 2 / 36 & x=3 \\ 3 / 36 & x=4 \\ 4 / 36 & x=5 \\ 5 / 36 & x=6 \\ 6 / 36 & x=7 \\ 5 / 36 & x=8 \\ 4 / 36 & x=9 \\ 3 / 36 & x=10 \\ 2 / 36 & x=11 \\ 1 / 36 & x=12\end{cases}
\]

Acabamos de construir la función de densidad de la variable suma de la
puntuación al lanzar dos dados.

Vamos a ver su representación gráfica:

\includegraphics[width=0.8\linewidth]{images/fmp2Dados}

Hemos optado por la representación con barras en lugar de puntos para
permitir una visualización de la función óptima.

Ejercicio: Haced lo mismo para la variable aleatoria el menor de los
puntos de las dos caras al lanzar dos dados.

\subsubsection{Probabilidad de intervalos}\label{probabilidad-de-intervalos-1}

Vamos a centrarnos en la variable

\[
X=\text { Suma de puntos de las caras }
\]

Las funciones de distribución y de densidad son, respectivamente,

\[
F(x)=P(X \leq x)=\left\{\begin{array}{ll}
0 & x<2 \\
1 / 36 & 2 \leq x<3 \\
3 / 36 & 3 \leq x<4 \\
6 / 36 & 4 \leq x<5 \\
10 / 36 & 5 \leq x<6 \\
15 / 36 & 6 \leq x<7 \\
21 / 36 & 7 \leq x<8 \\
26 / 36 & 8 \leq x<9 \\
30 / 36 & 9 \leq x<10 \\
33 / 36 & 10 \leq x<11 \\
35 / 36 & 11 \leq x<12 \\
36 / 36=1 & x \geq 12
\end{array} \quad f(x)=P(X=x)= \begin{cases}1 / 36 & x=2 \\
2 / 36 & x=3 \\
3 / 36 & x=4 \\
4 / 36 & x=5 \\
5 / 36 & x=6 \\
6 / 36 & x=7 \\
5 / 36 & x=8 \\
4 / 36 & x=9 \\
3 / 36 & x=10 \\
2 / 36 & x=11 \\
1 / 36 & x=12\end{cases}\right.
\]

Puede observarse cómo los valores de la función de distribución se
obtienen acumulando los valores de la función de densidad
correspondientes.

Vamos a calcular algunas probabilidades utilizando las funciones
anteriores. Compárese con los resultados obtenidos con anterioridad
basados directamente en los resultados elementales.

\begin{itemize}
\tightlist
\item
  \(P(X \leq 1)=F(1)=0\)
\item
  \(P(X \leq 3,5)=F(3,5)=3 / 36=f(2)+f(3)\)
\item
  \(P(X<6)=F(6)-f(6)=15 / 36-5 / 36=10 / 36=f(2)+f(3)+f(4)+f(5)\)
\item
  \(P(2,2<X \leq 7)=F(7)-F(2,2)=21 / 36-1 / 36=20 / 36=f(3)+f(4)+f(5)+f(6)+f(7)\)
\item
  \(P(2<X<7)=F(7)-f(7)-F(2)=21 / 36-6 / 36-1 / 36=14 / 36=f(3)+f(4)+f(5)+f(6)\)
\end{itemize}

\subsubsection{Esperanza}\label{esperanza}

Supongamos que estamos interesados en determinar cual sería el valor
medio teórico de la variable

\[
X=\text { Suma de puntos de las caras }
\]

La función de densidad es:

\[
f(x)=P(X=x)= \begin{cases}1 / 36 & x=2 \\ 2 / 36 & x=3 \\ 3 / 36 & x=4 \\ 4 / 36 & x=5 \\ 5 / 36 & x=6 \\ 6 / 36 & x=7 \\ 5 / 36 & x=8 \\ 4 / 36 & x=9 \\ 3 / 36 & x=10 \\ 2 / 36 & x=11 \\ 1 / 36 & x=12\end{cases}
\]

La misma función de densidad nos da información sobre el recorrido de la
variable. Calcular el valor medio teórico de la variable quiere decir
calcular la esperanza. A partir de la fórmula de la esperanza para
variables discretas, tenemos

\[
\begin{aligned}
E(X) &=2 \cdot 1 / 36+3 \cdot 2 / 36+4 \cdot 3 / 36+5 \cdot 4 / 36+6 \cdot 5 / 36+\\
& + 7 \cdot 6 / 36+8 \cdot 5 / 36+9 \cdot 4 / 36+\\
&+ 10 \cdot 3 / 36+ 
11 \cdot 2 / 36+12 \cdot 1 / 36=\\
& =7
\end{aligned}
\]

Por tanto, 7 es la esperanza de la variable \(X=\) Suma de puntos de las
caras. Fijaos que la esperanza para la variable Puntuación de un dado
sería

\[
1 \cdot 1 / 6+2 \cdot 1 / 6+3 \cdot 1 / 6+4 \cdot 1 / 6+5 \cdot 1 / 6+6 \cdot 1 / 6=3,5
\]

y que se puede considerar la variable Suma de puntos de las dos caras
como la suma de dos variables que representen la puntuación de cada
dado. La esperanza de la suma es, efectivamente, la suma de las
esperanzas de cada variable sumada.

En la aplicación siguiente, podéis calcular la esperanza de la variable
Puntuación de un dado y modificar las probabilidades de las diferentes
caras, de este modo se modifica la esperanza.

Ejercicio: ¿Podríais hacer lo mismo para la variable \(X=\) El menor de
los puntos de las dos caras al lanzar dos dados?

\subsubsection{Esperanza de un juego}\label{esperanza-de-un-juego}

Imaginemos que alguien os propone el juego siguiente: lanzad dos dados,
si la suma obtenida es menor o igual a 6 ganáis 100 euros, sin embargo,
si la suma obtenida es mayor que 6 tenéis que pagar 100 euros. ¿Nos
conviene jugar a este juego?

Veamos, podemos considerar el resultado del juego como una variable
aleatoria discreta que toma dos valores: +100 si ganamos y -100 si
perdemos. Nos interesa conocer las probabilidades de los diferentes
resultados. Consideremos la variable \(X=\) Suma de puntos de las caras,
cuya función de densidad conocemos:

\[
f(x)=P(X=x)= \begin{cases}1 / 36 & x=2 \\ 2 / 36 & x=3 \\ 3 / 36 & x=4 \\ 4 / 36 & x=5 \\ 5 / 36 & x=6 \\ 6 / 36 & x=7 \\ 5 / 36 & x=8 \\ 4 / 36 & x=9 \\ 3 / 36 & x=10 \\ 2 / 36 & x=11 \\ 1 / 36 & x=12\end{cases}
\]

A partir de aquí es fácil ver que la función de densidad de la variable
\(Y=\) Resultado del juego será la siguiente:

\[
f(100)=15 / 36 ; f(-100)=21 / 36
\]

Por tanto, la esperanza del juego, que puede ser interpretada como la
ganancia media por jugada, será

\[
E(Y)=100 \cdot 15 / 36-100 \cdot 21 / 36=-100 / 6 \approx-16,667
\]

Es decir, la ganancia media por jugada es negativa, por tanto no es
favorable dicho juego para el jugador, es un juego no equitativo.

\subsubsection{Esperanza con recorrido infinito}\label{esperanza-con-recorrido-infinito}

Vamos a tratar de calcular la esperanza de la siguiente variable
aleatoria: \(X=\) Número de lanzamientos que hemos de hacer para conseguir
que aparezca un doble seis La variable que acabamos de definir es una
variable discreta con recorrido infinito numerable. El recorrido sería
el siguiente:

\[
\{1,2,3,4, \ldots\}
\]

Vamos a ver como calculamos la función de densidad: \(P(X=1)=\)
Probabilidad de que aparezca un doble seis en el primer lanzamiento
\(=1 / 36\) \(P(X=2)=\) Probabilidad de que el doble seis no aparezca en el
primer lanzamiento y sí en el segundo =
\(35 / 36 \cdot 1 / 36=35 / 36^{2}\) \(P(X=3)=\) Probabilidad de que el
doble seis no aparezca ni en el primer ni en el segundo lanzamientos y
sí en el tercero \(=35 / 36 \cdot 35 / 361 / 36=35^{2} / 36^{3}\)

En general, \(P(X=k)=35^{k-1} / 36^{k}\) Para simplificar, vamos a llamar
\(p=1 / 36\) y \(q=1-p=35 / 36\), con esta nomenclatura
\(P(X=\mathrm{k})=q^{k-1} p\). Por tanto, la esperanza será:

\[
\begin{aligned}
E(X)& =\sum_{i=1}^{\infty} i q^{i-1} p=p \sum_{i=1}^{\infty} i q^{i-1}=p \frac{d}{d q} \sum_{i=1}^{\infty} q^{i}= \\ 
&= p \frac{d}{d q}\left(\frac{q}{1-q}\right)=p \frac{1}{(1-q)^{2}}=\\
& = \frac{1}{p}
\end{aligned}
\]

En nuestro ejemplo el número medio de tiradas antes de salir un doble
seis será 36 .

\subsubsection{Esperanza infinita}\label{esperanza-infinita}

Ahora calcularemos la esperanza del juego siguiente: lanzamos un dado
hasta que aparece un número par, el jugador gana \(2^{n}\) unidades
monetarias si aparece un número par por primera vez en la tirada nésima.

El recorrido de la variable aleatoria \(X=\) Ganancia del juego, está
formado por todos los números de la forma \(2^{n}\) con \(n=1,2,3, \ldots\)
La probabilidad de cada valor del recorrido es la probabilidad de que
aparezca un número par por primera vez en la tirada nésima, es decir
\((1 / 2)^{n-1} \cdot(1 / 2)=(1 / 2)^{n}\). Por tanto, la esperanza del
juego es la siguiente:

\[
E(X)=\sum_{n=1}^{\infty} 2^{n}(1 / 2)^{n}=\sum_{n=1}^{\infty} 1=\infty
\]

Como vemos, la variable aleatoria \(X\) no tiene esperanza finita. El
enunciado presentado es una versión del problema presentado alrededor de
1730 por el matemático Daniel Bernouilli a la Academia de San
Petersburgo y conocido como la paradoja de San Petersburgo, dado que la
esperanza del juego es aparentemente infinita.

\subsubsection{Varianza}\label{varianza}

Si ahora queremos calcular la varianza de la variable

\[
X=\text { Suma de puntos de las caras }
\]

con función de densidad:

\[
f(x)=P(X=x)= \begin{cases}1 / 36 & x=2 \\ 2 / 36 & x=3 \\ 3 / 36 & x=4 \\ 4 / 36 & x=5 \\ 5 / 36 & x=6 \\ 6 / 36 & x=7 \\ 5 / 36 & x=8 \\ 4 / 36 & x=9 \\ 3 / 36 & x=10 \\ 2 / 36 & x=11 \\ 1 / 36 & x=12\end{cases}
\]

Podemos aplicar la fórmula

\[
\operatorname{Var}(X)=E\left(X^{2}\right)-(E(X))^{2}
\]

La esperanza ya la tenemos calculada con anterioridad

\[
\begin{aligned}
E(X) & =2 \cdot 1 / 36+3 \cdot 2 / 36+4 \cdot 3 / 36+5 \cdot 4 / 36+\\
& +6 \cdot 5 / 36+7 \cdot 6 / 36+8 \cdot 5 / 36+9 \cdot 4 / 36+\\
& +10 \cdot 3 / 36+ 11 \cdot 2 / 36+12 \cdot 1 / 36=\\
& =7
\end{aligned}
\]

Necesitamos calcular la esperanza de la variable al cuadrado, que en
este caso resulta:

\[
\begin{aligned}
E\left(X^{2}\right)& =2^{2} \cdot 1 / 36+3^{2} \cdot 2 / 36+4^{2} \cdot 3 / 36+5^{2} \cdot 4 / 36+6^{2} \cdot 5 / 36+\\
& + 7^{2} \cdot 6 / 36+8^{2} \cdot 5 / 36+9^{2} \cdot 4 / 36+  10^{2} \cdot 3 / 36+\\
& + 11^{2} \cdot 2 / 36+12^{2} \cdot 1 / 36=329 / 6 \\
&\approx 54,833
\end{aligned}
\]

Con lo que la varianza resulta ser

\[
\operatorname{Var}(X)=329 / 6-7^{2}=35 / 6 \approx 5,833
\]

Nuevamente, para la variable Puntuación de un dado, la varianza se
obtendría de la manera siguiente:

\[
\begin{aligned}
E(X)& =1 \cdot 1 / 6+2 \cdot 1 / 6+3 \cdot 1 / 6+4 \cdot 1 / 6+5 \cdot 1 / 6+6 \cdot 1 / 6= \\& =3,5\\
E \left(X^{2}\right)&=1^{2} \cdot 1 / 6+2^{2} \cdot 1 / 6+3^{2} \cdot 1 / 6+4^{2} \cdot 1 / 6+\\
& + 5^{2} \cdot 1 / 6+6^{2} \cdot 1 / 6=91 / 6\\ &  \approx 15,167 \\
\operatorname{Var}(X)&=91 / 6-3,5^{2}=35 / 12 \approx 2,9167
\end{aligned}
\]

y se cumple que la varianza de la variable Suma de puntos de las dos
caras es la suma de las varianzas de las puntuaciones de cada dado por separado. Recordemos que esto sólo sucede si las variables sumadas son independientes, como así ocurre con las puntuaciones de cada dado por separado.

\newpage

\section{Distribuciones Notables}\label{distribuciones-notables}

\subsection{Distribuciones discretas}\label{distribuciones-discretas}

\subsubsection{La distribución de Bernouilli}\label{la-distribuciuxf3n-de-bernouilli}

Es el modelo discreto más sencillo en que podamos pensar. Hace referencia a situaciones en las que el resultado de un experimento sólo puede ser: se ha dado el suceso \(A\) ó no se ha dado el suceso \(A\). Por ejemplo, en el lanzamiento de una moneda sólo puede darse el suceso sale cara o su complementario no sale cara (sale cruz).

Por lo tanto, definimos la variable aleatoria \(X\) de la siguiente manera:

\begin{itemize}
\tightlist
\item
  \(X=1\) si se ha dado \(A\).
\item
  \(X=0\) si no se ha dado \(A\), es decir, se ha dado el complementario \(A^{c}\).
\end{itemize}

Si además, conocemos la probabilidad de que suceda \(A\) :

\[
P[A]=p
\]

y, por tanto,

\[
P\left[A^{c}\right]=1-p
\]

ya podemos definir la distribución de la variable aleatoria \(X\).
En estas condiciones diremos que \(X\) sigue una distribución de Bernouilli de parámetro \(p\), que abreviaremos así \(X \sim \operatorname{Bernouilli}(p)\), y su función de densidad se define así:

\[
f(k)=P[X=k]=\left\{\begin{array}{cc}
p & \text { si } k=1(\text { se ha dado } A) \\
1-p & \text { si } k=0\left(\text { se ha dado } A^{c}\right)
\end{array}\right\}
\]

Gráficamente:

\includegraphics[width=0.8\linewidth]{images/fmpBernouilli}

Mientras que la función de distribución será:

\[
F(k)=P[X \leq k]=\left\{\begin{array}{lc}
0 & \text { si } \mathbf{k}<0 \\
\mathbf{p} & \text { si } 0 \leq \mathbf{k}<1 \\
1 & \text { si } \mathbf{p} \geq 1
\end{array}\right\}
\]

Gráficamente:

\includegraphics[width=0.8\linewidth]{images/cdfBernouilli}

\paragraph{Propiedades del modelo de Bernouilli}\label{propiedades-del-modelo-de-bernouilli}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  La esperanza vale \(E(X)=p\).
\item
  La varianza vale \(V(X)=p(1-p)\).
\end{enumerate}

\subsubsection{La distribución Binomial}\label{la-distribuciuxf3n-binomial}

Al igual que el modelo de Bernouilli, hace referencia a experiencias con resultados dicotómicos (el resultado sólo puede ser \(A\) o \(A^{\mathcal{C}}\) ). Sin embargo en este modelo estamos interesados en la repetición de \(n\) veces una experiencia de este tipo en condiciones independientes.

Tomemos el ejemplo del contaje del número de caras en el lanzamiento \(n\) veces de una moneda regular.
Para concretar, vamos a suponer que disponemos de una moneda regular \((P[\) cara \(]=P[c r u z]=1 / 2)\) que lanzamos cuatro veces. Es evidente que, en estas condiciones, la variable X: número de caras en cuatro lanzamientos independientes de una moneda regular es una variable aleatoria discreta que sólo puede tomar cinco posibles valores:

\[
x=0,1,2,3,4
\]

Pasemos ahora a calcular la probabilidad de cada valor (en terminología estadística, vamos a calcular la función de densidad de la variable \(X\) ).

Es evidente que la \(P[X=0]\) es igual a la probabilidad de salgan cuatro cruces seguidas:

\[
P[X=0]=P[c r u z, c r u z, c r u z, c r u z]=\mathrm{P}[c r u z]^{4}=(1 / 2)^{4}=0,0625
\]

ya que la moneda es regular y, por tanto, \(P[\) cara \(]=P[\) cruz \(]=1 / 2\).
La \(P[X=3]\) corresponde al suceso de que salgan tres caras ( \(c\) en adelante) y una cruz ( + en adelante). Sin embargo, en este caso tenemos hasta cuatro posibles maneras de obtener dicho resultado, según el orden en que aparezcan las tres caras y la cruz:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\centering\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
+ccc
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathrm{c}+\mathrm{cc}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathrm{cc}+\mathrm{c}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathrm{ccc}+\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\end{longtable}

También debería resultar evidente que la probabilidad de cada uno de estos sucesos es la misma:

\[
P[+\mathrm{ccc}]=P[\mathrm{c}+\mathrm{cc}]=P[\mathrm{cc}+\mathrm{c}]=P[\mathrm{ccc}+]=(1 / 2)^{4}=(1 / 2)^{4}=0,0625
\]

de manera que, finalmente, la probabilidad de que salgan tres caras y una cruz es la suma de las probabilidades de los 4 casos anteriores:

\[
P[X=3]=4(1 / 2)^{4}=0,25
\]

Y así podríamos ir calculando el resto de casos. Podemos ver que, en este ejemplo, todos los casos tienen la misma probabilidad \((0,0625)\) y que el número total de casos posibles es 16 . En términos de combinatoria dicho número se obtendría como variaciones con repetición de dos valores (cara o cruz) tomados de cuatro en cuatro (el número de lanzamientos de la moneda):

\[
V R_{2}{ }^{4}=2^{4}=16
\]

En la siguiente tabla se muestran los dieciséis posibles resultados:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(k=\) número de caras & Casos \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & +++++ \\
1 & +++c \\
& \(++\mathrm{c}+\) \\
& \(+\mathrm{c}++\) \\
& \(\mathrm{c}+++\) \\
& ++cc \\
& \(+\mathrm{c}+\mathrm{c}\) \\
& \(\mathrm{c}++\mathrm{c}+\) \\
& \(\mathrm{c}+\mathrm{c}+\) \\
& cc++ \\
& \(\mathrm{ccc}+\) \\
& \(\mathrm{c}+\mathrm{cc}\) \\
\end{longtable}

Si hacemos uso de nuestros conocimientos de combinatoria, comprobamos que el número de casos para cada posible valor \(k(k=0,1,2,3,4)\) puede calcularse como permutaciones con repetición de cuatro elementos tomado de \(k\) y \(4-k\) :

\[
R P_{4}^{k, 4-k}=\frac{4!}{k!(4-k)!}=\binom{4}{k}
\]

y obtenemos finalmente el número combinatorio 4 sobre \(k\). En efecto, para el caso \(k=3\), tendríamos:

\[
\binom{4}{3}=\frac{4!}{3!1!}=4
\]

que son los cuatro posibles casos que nos dan tres caras y una cruz.
Finalmente, recordando que todos los casos tienen la misma probabilidad, se construye la siguiente tabla:

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
\(k=\) número de caras & Número de casos & \(P[X=k]\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1 & 0,0625 \\
1 & 4 & 0,2500 \\
& & \\
\end{longtable}

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
2 & 6 & 0,3750 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
3 & 4 & 0,2500 \\
4 & 1 & 0,0625 \\
Total & 16 & 1 \\
\end{longtable}

\paragraph{Los parámetros de la distribución Binomial}\label{los-paruxe1metros-de-la-distribuciuxf3n-binomial}

La última tabla de la página anterior es, justamente, la función de densidad de nuestra variable \(X\).

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
Función de densidad de \(X\) & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(k\) & \(P[X=k]\) \\
0 & 0,0625 \\
1 & 0,2500 \\
2 & 0,3750 \\
3 & 0,2500 \\
4 & 0,0625 \\
En otro caso & 0 \\
\end{longtable}

Como hemos visto, para obtener los resultados anteriores, hemos tenido que definir dos valores:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(n\) : el número de lanzamientos (repeticiones de la experiencia aleatoria en condiciones independientes), en nuestro caso \(n=4\).
\item
  \(p\) : la probabilidad de que salga cara \((P[c])\), en nuestro caso \(p=1 / 2\).
\end{enumerate}

Se dice, por tanto, que la distribución Binomial depende de dos parámetros: \(n\) y \(p\). En nuestro ejemplo, diremos que \(X\) sigue una distribución Binomial de parámetros \(n=4\) i \(p=1 / 2\). De forma abreviada:

\[
X \sim B(n=4 ; p=1 / 2)
\]

En el ejemplo que hemos visto, suponíamos que la moneda era regular y, por tanto,

\[
P[c]=P[+]=1 / 2
\]

Si tenemos una moneda trucada con las siguientes probabilidades:

\[
P[c]=2 / 3 \quad \text { i } \quad P[+]=1 / 3
\]

diremos que en este caso la variable \(X\) : número de caras en cuatro lanzamientos independientes de nuestra moneda trucada sigue una distribución Binomial de parámetros:

\[
X \sim B(n=4 ; p=2 / 3)
\]

El problema se nos complica levemente ya que ahora no todos los posibles resultados tienen la misma probabilidad. Veamos dos ejemplos:

\begin{itemize}
\tightlist
\item
  La probabilidad de obtener cuatro caras es:
\end{itemize}

\[
P[c c c c]=(2 / 3)^{4}=0,1975
\]

\begin{itemize}
\tightlist
\item
  La probabilidad de que el primer lanzamiento sea cara y el resto sean cruces valdrá:
\end{itemize}

\[
P\left[c^{+++}\right]=(2 / 3)^{\prime}(1 / 3)^{3}=0,0247
\]

Sin embargo sí se cumplirá que la probabilidad de que todos los caso que resulten en el mismo número de caras y cruces tendrán la misma probabilidad. Por ejemplo, para los cuatro casos en los que el número total de caras es 1 y el de cruces 3 :

\[
P[c+++]=P[+c++]=P[++c+]=P[+++c]=(2 / 3)^{\prime}(1 / 3)^{3}=0,0247
\]

Y, por tanto, la probabilidad de obtener una sola cara en el lanzamiento de nuestra moneda trucada será:

\[
P[X=1]=4^{\prime} 0,0247=0,0988
\]

O, generalizando, si \(P[A]=p\) y \(P\left[A^{c}\right]=1-p\) tenemos que

\[
P[X=k]=c(n, k) p^{k}(1-\mathrm{p})^{n-k} \quad \text { si } k=0,1, \ldots, n
\]

donde \(c(n, k)\) representa el número de posibles resultados en los que obtenemos \(k\) caras y \(n-k\) cruces en \(n\) lanzamientos. Tal como hemos visto, dicho número se puede calcular como permutaciones con repetición de \(n\) unidades tomadas de \(k\) y \(n-k\).

Todo lo anterior nos lleva a formular el model binoial a traves de la siguiente función de densidad:

\[
f(k)=P[X=k]=\left\{\begin{array}{ll}
\binom{\mathbf{n}}{\mathbf{k}} p^{k}(1-p)^{n-k} & \text { si } \quad k=0, \ldots, n \\
0 & \text { en caso contrario }
\end{array}\right\}
\]

con lo que la función de distribución se calcularía:

\[
F(k)=P[X \leq k]=\left\{\begin{array}{cc}
0 & \text { si } k<0 \\
\sum_{i=0}^{k}\binom{\mathbf{i}}{\mathbf{n}} p^{i}(\mathbf{1}-p)^{n-i} \\
\mathbf{1} & \text { si } k \geq n
\end{array}\right\}
\]

\paragraph{Propiedades del modelo Binomial}\label{propiedades-del-modelo-binomial}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La esperanza vale \(E(X)=n p\).
\item
  La varianza es \(V(X)=n p(1-p)\).
\item
  Es una generalización del modelo de Bernouilli. En efecto, la Binomial con \(n=1\) (una sola realización) coincide con la distribución de Bernouilli.
\item
  La suma de dos variables aleatorias binomiales independientes con igual parámetro \(p\) también sigue una distribución Binomial:
\end{enumerate}

\[
X_{1} \sim B\left(n=n_{1} ; p=p_{0}\right) \quad \text { i } \quad X_{2} \sim B\left(n=n_{2} ; p=p_{0}\right)
\]

Si definimos \(Z=X_{1}+X_{2}\) entonces,

\[
Z \sim B\left(n=n_{1}+n_{2} ; p=p_{0}\right)
\]

\subsubsection{La distribución de Poisson}\label{la-distribuciuxf3n-de-poisson}

Se trata de un modelo discreto, pero en el que el conjunto de valores con probabilidad no nula no es finito, sino numerable. Se dice que una variable aleatoria \(X\) sigue la distribución de Poisson si su función de densidad viene dada por:

\[
f(k)=P[X=k]=\left\{\begin{array}{ll}
e^{-\lambda \frac{\lambda^{k}}{k!}} & \text { si } k=0,12, \ldots \\
0 & \text { en caso contrario }
\end{array}\right\}
\]

Como vemos, este modelo se caracteriza por un sólo parámetro \(\lambda\), que debe ser positivo.
Esta distribución suele utilizarse para contajes del tipo número de individuos por unidad de tiempo, de espacio, etc.

\paragraph{Propiedades del modelo de Poisson}\label{propiedades-del-modelo-de-poisson}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Esperanza: \(E(X)=\lambda\).
\item
  Varianza: \(V(X)=\lambda\).
\end{enumerate}

En esta distribución la esperanza y la varianza coinciden.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  La suma de dos variables aleatorias independientes con distribución de Poisson resulta en una nueva variable aleatoria, también con distribución de Poisson, de parámetro igual a la suma de parámetros:
\end{enumerate}

\[
X_{1} \sim P\left(\lambda=\lambda_{1}\right) \quad \text { y } \quad X_{2} \sim P\left(\lambda=\lambda_{2}\right)
\]

y definimos \(Z=X_{1}+X_{2}\), entonces,

\[
Z \sim P\left(\lambda=\lambda_{1}+\lambda_{2}\right)
\]

Este resultado se extiende inmediatamente al caso de \(n\) variables aleatorias independientes con distribución de Poisson. En este caso, la variable suma de todas ellas sigue una distribución de Poisson de parámetro igual a la suma de los parámetros.

\subsubsection{La distribución Uniforme discreta}\label{la-distribuciuxf3n-uniforme-discreta}

Tenemos esta distribución cuando el resultado de una experiencia aleatoria puede ser un conjunto finito de \(n\) posibles resultados, todos ellos igualmente probables.

Un ejemplo puede ser la variable \(X\), puntuación en el lanzamiento de un dado regular. Esta variable toma seis valores posibles, todos con la misma probabilidad \(p=1 / 6\). La función de densidad de esta variable será:

\[
f(k)=P[X=k]=1 / 6 \quad k=1,2,3,4,5,6
\]

\includegraphics[width=0.8\linewidth]{images/pmfUnifDiscreta}

\includegraphics[width=0.8\linewidth]{images/cdfUnifDiscreta}

En general, si la variable \(X\) puede tomar \(n(k=1,2, \ldots, n)\) valores, todos con igual probabilidad, su función de densidad será:

\[
f(k)=P[X=k]=1 / n \quad k=1,2, \ldots, n
\]

\paragraph{Propiedades del modelo Uniforme discreto}\label{propiedades-del-modelo-uniforme-discreto}

Sea \(n\) el número de valores equiprobables posibles:

\paragraph{Esperanza:}\label{esperanza-1}

\[
E(X)=\frac{n+1}{2}
\]

\paragraph{Varianza:}\label{varianza-1}

\[
V(X)=\frac{(n+1)[2(2 n+1)-3(n+1)]}{12}
\]

\subsubsection{La distribución Hipergeométrica}\label{la-distribuciuxf3n-hipergeomuxe9trica}

Este modelo presenta similitudes con el Binomial, pero sin la suposición de independencia de éste último. Veámoslo:

\begin{itemize}
\tightlist
\item
  Partimos de un conjunto formado por \(N\) individuos divididos en dos categorías mutuamente excluyentes: \(A\) y \(A^{c}\); de manera que \(N_{1}\) individuos pertenecen a la categoría \(A\) y \(N_{2}\) individuos, a la categoría \(A^{c}\). Por tanto, se cumple que
\end{itemize}

\[
N=N_{1}+N_{2}
\]

\begin{itemize}
\tightlist
\item
  Si del conjunto anterior extraemos \(n\) individuos sin reemplazamiento \((n \leq N)\), la variable \(X\) que representa el número k de individuos que pertenecen a la categoría A (de los n extraídos) tiene por función de densidad:
\end{itemize}

\[
f(k)=P[X=k]=\frac{\binom{\mathbf{N}_{1}}{\mathbf{k}}\binom{\mathrm{N}_{2}}{\mathbf{n}-\mathbf{k}}}{\binom{\mathbf{N}}{\mathbf{n}}}
\]

si \(\operatorname{max}\left\{0, \mathrm{n}-N_{2}\right\} \leq \mathrm{k} \leq \min \left\{N_{1}, n\right\}\)

La dependencia se debe al hecho de que \(N\) es finito y las extracciones se efectúan sin reemplazamiento. El caso de extracciones con reemplazamiento sería equivalente al de \(N\) infinito y se resolvería mediante el modelo Binomial.

\paragraph{Propiedades del modelo hipergeométrico}\label{propiedades-del-modelo-hipergeomuxe9trico}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Esperanza: \(\mathrm{E}(\mathrm{X})=\mathrm{n} \mathrm{N}_{1} / \mathrm{N}_{2}\).
\item
  Varianza: \(V(X)=\left(n N_{1} N_{2}(N-n)\right) /\left(N_{2}(N-1)\right)\)
\end{enumerate}

\subsubsection{La distribución Geométrica o de Pascal}\label{la-distribuciuxf3n-geomuxe9trica-o-de-pascal}

Definamos una experiencia aleatoria cuyo resultado sólo puede ser el suceso \(A\) o su complementario \(A^{c}\), y que se repite secuencialmente hasta que aparece el suceso \(A\) por primera vez.

Definamos la variable aleatoria \(X\) como el número de veces que repetimos la experiencia en condiciones independientes hasta que se dé A por primera vez. Bajo estas condiciones, decimos que la variable \(X\) sigue una distribución geométrica o de Pascal de parámetro \(p=P(A)\).

La función de densidad puede deducirse fácilmente de la definición:

\[
f(k)=P[X=k]=(1-p)^{k} p \quad k=0,1,2, \ldots
\]

En el programa siguiente podéis ver su forma y obtener los valores de la función de densidad y de la de distribución:

Algunas puntualizaciones de la definición de \(X\) :

\begin{itemize}
\tightlist
\item
  Notése que, en esta definición, condiciones independientes significa que \(p\), la probabilidad de \(A\), y \(1-p\), la de su complementario \(A^{c}\), no varían a lo largo de las sucesivas repeticiones de la experiencia.
\item
  Tal y como la hemos definido, \(X\) se refiere al número de lanzamientos hasta que se produce \(A\), pero sin contabilizar el último caso en que se da \(A\). Por dicha razón \(X\) puede tomar los valores \(k=\) \(0,1,2, \ldots\) con probabilidad no nula.
\end{itemize}

Un ejemplo de este modelo podría ser la experiencia consistente en lanzar sucesivamente un dado regular hasta que aparezca el número 6 . Si definimos la variable aleatoria \(X\) como el número de lanzamientos de un dado regular hasta que aparezca un 6 , queda claro que \(X\) sigue una distribución geométrica de parámetro \(p=1 / 6\).

\paragraph{Propiedades del modelo Geométrico o de Pascal}\label{propiedades-del-modelo-geomuxe9trico-o-de-pascal}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Esperanza: \(E(X)=(1-p) / p\)
\item
  Varianza: \(V(X)=(1-p) / p^{2}\)
\end{enumerate}

\paragraph{Preguntas:}\label{preguntas}

\begin{itemize}
\item
  ¿A que suceso nos referimos cuando decimos \(X=0\) ? Respuesta.

  \begin{itemize}
  \tightlist
  \item
    Cuando decimos que \(X=0\) nos referimos al caso en que el 6 aparece en el primer lanzamiento. La probabilidad de que esto suceda, suponiendo un dado regular, es de \(1 / 6\) :
  \end{itemize}
\end{itemize}

\[
P[X=0]=1 / 6
\]

\begin{itemize}
\item
  ¿Cuál es la probabilidad de que el primer 6 aparezca en el cuarto lanzamiento? Respuesta.

  \begin{itemize}
  \tightlist
  \item
    La probabilidad de que el primer 6 aparezca en el cuarto lanzamiento corresponde a:
  \end{itemize}
\end{itemize}

\[
P[X=3]=(5 / 6)^{3 \cdot} 1 / 6=0,0965
\]

Fijémonos en que, si definimos \(A\) como el suceso sale un 6, la probabilidad anterior corresponde a la del suceso: \(\left\{A^{c} A^{c} A^{c} A\right\}\) (en este orden).

\subsubsection{La distribución Binomial negativa}\label{la-distribuciuxf3n-binomial-negativa}

Puede definirse como una generalización del modelo Geométrico o de Pascal. Así, dado un suceso \(A\) y su complementario \(A^{c}\), cuando \(X\) representa el número de veces que se da \(\mathrm{A}^{\mathrm{c}}\) (ausencias, fallos, etc.) hasta que se produce r veces el suceso A , en una serie de repeticiones de la experiencia aleatoria en condiciones independientes, decimos que \(X\) sigue la distribución Binomial negativa. Nótese que, cuando \(r=1\), tenemos exactamente el modelo geométrico.

Este modelo queda definido por dos parámetros \(p\) (la probabilidad de \(A: p=P(A)\) ) y \(r\) (el número de veces que debe producirse \(A\) para que detengamos la experiencia).

La función de densidad viene dada por:

\[
f(k)=P[X=k]=\binom{\mathbf{k}+\mathbf{r}-\mathbf{1}}{\mathbf{r}-\mathbf{1}} \mathbf{p}^{\mathbf{r}} \mathbf{q}^{\mathbf{k}} \quad \mathbf{k}=\mathbf{0}, \mathbf{1}, \mathbf{2}, \ldots
\]

donde \(q\) representa el complementario de \(p: q=1-p\).

\paragraph{Propiedades del modelo Binomial negativo}\label{propiedades-del-modelo-binomial-negativo}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Esperanza: \(E(X)=r^{\prime} q / p\)
\item
  Varianza: \(V(X)=r^{\prime} q / p^{2}\)
\item
  Se cumplen las siguientes propiedades respecto la función de densidad:
\end{enumerate}

\[
f(0)=p^{r} \quad \text { y } \quad f(k+1)=\frac{(1-p)(k+r)}{k+1} f(k)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\item
  Este modelo se ajusta bien a contajes (números de individuos por unidad de superficie) cuando se produce una distribución contagiosa (los individuos tienden a agruparse).
\item
  La distribución Binomial negativa puede definirse con mayor generalidad si tomamos \(r\) como un número real positivo cualquiera (no necesariamente entero). Pero, en dicho caso, se pierde el carácter intuitivo del modelo y se complican ligeramente los cálculos. Por dichas razones, se ha excluido dicha posibilidad en esta presentación.
\end{enumerate}

\subsubsection{Tabla resumen de las distribuciones discretas principales}\label{tabla-resumen-de-las-distribuciones-discretas-principales}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Distribución
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Parámetros
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Función de densidad
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Esperanza
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Varianza
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bernouilli & \(0 \leq p \leq 1\) & \(p^{k}(1-p)^{1-k}\) \(k=0,1\) & \(p\) & \(p(1-p)\) \\
Binomial & \(0 \leq p \leq 1\) \(n=1,2, \ldots\) & \(\binom{\mathbf{n}}{\mathbf{k}} p^{k}(1-p)^{n-k}\) \(k=0,1, \ldots, n\) & \(n p\) & \(n p(1-p)\) \\
Poisson & \(\lambda>0\) & \(e^{-\lambda} \frac{\lambda^{k}}{k!}\) \(k=012, \ldots\) & \(\lambda\) & \(\lambda\) \\
Multinomial & \(0 \leq p_{1}, \ldots\) \(p_{r} \leq 1\) \(\left(p_{1}+\ldots+\right.\) \(\left.p_{\mathrm{r}}=1\right)\) \(n=1,2\) & \(\frac{n!}{k_{1}!k_{2}!\cdots k_{r}!} p_{1}^{k_{1}} p_{2}^{k_{2}} \cdots p_{r}^{k_{r}}\) \(\sum_{i=1}^{r} k_{i}=n\) & \(\left(\begin{array}{c}n p_{1} \\ n p_{2} \\ \vdots \\ n p_{r}\end{array}\right)\) & \(\boldsymbol{\sigma}_{i i}=n p_{i}\left(1-p_{i}\right)\) \(\boldsymbol{\sigma}_{i j}=n p_{i} p_{j} \quad i \neq j\) \\
Uniforme discreta & \(n=1,2, \ldots\) & \(\frac{1}{n}\) \(k=1,2, \ldots . n\) & \(\frac{n+1}{2}\) & \(\frac{(n+1)[2(2 n+1)-3(n+1)}{12}\) \\
Hipergeométrica & \(\left\{\begin{array}{c}N=N_{1}+ \\ N_{2} \\ p=N_{1} / N\end{array}\right.\) & \(\frac{\binom{\mathrm{N}_{1}}{\mathrm{k}}\binom{\mathrm{N}_{2}}{\mathrm{n}-\mathrm{k}}}{\binom{\mathrm{N}}{\mathrm{n}}}\) \(\operatorname{max}\left\{0, \mathrm{n}-N_{2}\right\} \leq \mathrm{k} \leq \min \left\{N_{1}, n\right\}\) & \(n p\) & \(n p(1-p) \frac{N-n}{N-1}\) \\
Pascal & \(0 \leq p \leq 1\) & \(p(1-p)^{k}\) \(k=0,1,2, \ldots\) & \(\frac{1-p}{p}\) & \(\frac{1-p}{p^{2}}\) \\
Binomial negativa & \(0 \leq p \leq 1\) \(r>0\) & & \(\frac{r(1-p)}{p}\) & \(\frac{r(1-p)}{p^{2}}\) \\
\end{longtable}

\subsection{Distribuciones Continuas}\label{distribuciones-continuas}

\subsubsection{La distribución Uniforme}\label{la-distribuciuxf3n-uniforme}

La distribución Uniforme es el modelo (absolutamente) continuo más simple. Corresponde al caso de una variable aleatoria que sólo puede tomar valores comprendidos entre dos extremos \(a\) y \(b\), de manera que todos los intervalos de una misma longitud (dentro de \((a, b)\) ) tienen la misma probabilidad. También puede expresarse como el modelo probabilístico correspondiente a tomar un número al azar dentro de un intervalo \((a, b)\).

De la anterior definición se desprende que la función de densidad debe tomar el mismo valor para todos los puntos dentro del intervalo \((a, b)\) (y cero fuera del intervalo). Es decir,

\[
f_{X}(x)=\left\{\begin{array}{ll}
\frac{1}{b-a} & \text { si } x \in(a, b) \\
0 & \text { si } x \notin(a, b)
\end{array}\right\}
\]

Gráficamente:

\includegraphics[width=0.8\linewidth]{images/pdfUnifContinua}

La función de distribución se obtiene integrando la función de densidad y viene dada por:

\[
F_{X}(x)=P(X \leq x)=\left\{\begin{array}{ll}
0 & \text { si } x \leq a \\
\frac{x-a}{b-a} & \text { si } x \in(a, b) \\
1 & \text { si } x \geq b
\end{array}\right\}
\]

Gráficamente:

Función de distribución del modelo uniforme

\includegraphics[width=0.8\linewidth]{images/cdfUnifContinua}

\paragraph{Propiedades del modelo Uniforme}\label{propiedades-del-modelo-uniforme}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Su esperanza vale \((b+a) / 2\)
\item
  Su varianza es \((b-a)^{2} / 12\)
\end{enumerate}

\paragraph{Una aplicación del modelo Uniforme: el muestreo de Montecarlo}\label{una-aplicaciuxf3n-del-modelo-uniforme-el-muestreo-de-montecarlo}

En ciertos casos es útil simular el muestreo de una variable aleatoria con una distribución dada. El muestreo de Montecarlo es un procedimiento general para obtener muestras aleatorias de cualquier tipo de variable (discreta o continua) si su función de distribución es conocida o se puede calcular.

Supongamos que queremos generar una muestra procedente de una variable aleatoria \(X\) con función de distribución \(F(x)\). El proceso comprende los siguientes pasos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Obtener un valor aleatorio \(y\) entre cero y uno. Es decir, obtener una muestra de una distribución Uniforme entre cero y uno. La mayoría de lenguajes de programación incorporan un generador de este tipo.
\item
  Considerar el valor obtenido como el valor de la función de distribución a generar: \(y=F(x)\).
\item
  El valor \(x=F^{-1}(y)\) (la inversa de la función de distribución en el punto \(y\) ) es un valor procedente de la distribución de la que deseábamos generar la muestra.
\item
  Si queremos obtener una muestra con \(n\) individuos debemos repetir los pasos anteriores \(n\) veces.
\end{enumerate}

\paragraph{Generación de una muestra procedente de una distribución Binomial}\label{generaciuxf3n-de-una-muestra-procedente-de-una-distribuciuxf3n-binomial}

Supongamos que queremos simular el experimento de contar el número de caras obtenidas en 5 lanzamientos de una moneda trucada con probabilidad de cara igual a 0,75 . Es decir, queremos obtener una muestra de una distribución Binomial con \(n=5\) y \(p=0,75\).

Siguiendo los pasos anteriores deberemos obtener un número al azar entre 0 y 1 (un valor procedente de una distribución Uniforme entre 0 y 1) y si este valor es menor o igual a 0,75 diremos que ha salido cara y, si es superior a 0,75 , cruz. Utiliza el siguiente programa para simular cinco lanzamientos con nuestra moneda trucada:

\subsubsection{La distribución Exponencial}\label{la-distribuciuxf3n-exponencial}

Este modelo suele utilizarse para variables que describen el tiempo hasta que se produce un determinado suceso.

Su función de densidad es de la forma:

\[
f(x)=\left\{\begin{array}{lll}
\frac{1}{\alpha} \exp \left(-\frac{x}{\alpha}\right) & \text { si } & x>0 \\
0 & \text { si } & x \leq 0
\end{array}\right\}
\]

Como vemos este modelo depende de un único parámetro \(\alpha\) que debe ser positivo: \(\alpha>0\). A continuación se muestra un programa que nos permite ver cómo cambia la forma de la función de densidad según el parámetro \(\alpha\).

La función de distribución se obtiene integrando la de densidad y es de la forma:

\[
F(x)=\left\{\begin{array}{lll}
1-\exp \left(-\frac{x}{\alpha}\right) & \text { si } & x>0 \\
0 & \text { si } & x \leq 0
\end{array}\right\}
\]

Podemos utilizar el programa siguiente para calcular dicha función de distribución:

\paragraph{Propiedades del modelo Exponencial}\label{propiedades-del-modelo-exponencial}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Su esperanza es \(\alpha\).
\item
  Su varianza es \(\alpha^{2}\).
\item
  Una propiedad importante es la denominada \emph{carencia de memoria}, que podemos definir así: si la variable \(X\) mide el tiempo de vida y sigue una distribución Exponencial, significará que la probabilidad de que siga con vida dentro de 20 años es la misma para un individuo que a fecha de hoy tiene 25 años que para otro que tenga 60 años.
\item
  Cuando el número de sucesos por unidad de tiempo sigue una distribución de Poisson de parámetro \(\lambda\) (proceso de Poisson), el tiempo entre dos sucesos consecutivos sigue una distribución Exponencial de parámetro \(\alpha=1 / \lambda\).
\end{enumerate}

\subsubsection{La distribución Normal}\label{la-distribuciuxf3n-normal}

Se trata, sin duda, del modelo continuo más importante en estadística, tanto por su aplicación directa, veremos que muchas variables de interés general pueden describirse por dicho modelo, como por sus propiedades, que han permitido el desarrollo de numerosas técnicas de inferencia estadística. En realidad, el nombre de Normal proviene del hecho de que durante un tiempo se creyó, por parte de médicos y biólogos, que todas las variables naturales de interés seguían este modelo.

Su función de densidad viene dada por la fórmula:

\[
f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left\{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right\} \quad \text { donde }-\infty<x<+\infty
\]

que, como vemos, depende de dos parámetros \(\mu\) (que puede ser cualquier valor real) y \(\sigma\) (que ha de ser positiva). Por esta razón, a partir de ahora indicaremos de forma abreviada que una variable \(X\) sigue el modelo Normal así: \(X \sim N(\mu, \sigma)\). Por ejemplo, si nos referimos a una distribución Normal con \(\mu=0\) y \(\sigma\) \(=1\) lo abreviaremos \(N(0,1)\).

A continuación vemos gráfica de esta función de densidad (podeis probar a cambiar los parámetros):

Como puedes ver, la función de densidad del modelo Normal tiene forma de campana, la que habitualmente se denomina campana de Gauss. De hecho, a este modelo, también se le conoce con el nombre de distribución gaussiana.

\paragraph{Propiedades del modelo Normal}\label{propiedades-del-modelo-normal}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Su esperanza es \(\mu\).
\item
  Su varianza es \(\sigma^{2} \mathrm{y}\), por tanto, su desviación típica es \(\sigma\).
\item
  Es simétrica respecto a su media \(\mu\), como puede apreciarse en la representación anterior.
\item
  Media, moda y mediana coinciden \((\mu)\).
\item
  Cualquier transformación lineal de una variable con distribución Normal seguirá también el modelo Normal. Si \(X \sim N(\mu, \sigma)\) y definimos \(Y=a X+b(\operatorname{con} a \neq 0)\), entonces \(Y \sim N(a \mu+b,|a| \sigma)\). Es decir, la esperanza de \(Y\) será \(a \mu+b\) y su desviación típica, \(|a| \sigma\).
\item
  Cualquier combinación lineal de variables normales independientes sigue también una distribución Normal. Es decir, dadas \(n\) variables aleatorias independientes con distribución \(X_{i} \sim\) \(N\left(\mu_{i}, \sigma_{i}\right)\) para \(i=1,2, \ldots, n\) la combinación lineal: \(Y=a_{n} X_{n}+a_{n-1} X_{n-1}+\ldots+a_{1} X_{1}+\mathrm{a}_{0}\) sigue también el modelo Normal:
\end{enumerate}

\[
Y \approx N\left(a_{0}+\sum_{i=1}^{n} a_{i} \boldsymbol{\mu}_{i}, \sqrt{\sum_{i=1}^{n} a_{i}^{2} \boldsymbol{\sigma}^{2}}\right)
\]

\#\#\#La función de distribución del modelo Normal

La función de distribución del modelo Normal se debería calcular, como en el resto de distribuciones continuas, integrando la función de densidad:

\[
F(x)=P[X \leq x]=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi} \sigma} \exp \left\{-\frac{(t-\mu)^{2}}{2 \sigma^{2}}\right\} \mathrm{dt}
\]

Pero nos encontramos con el problema de que no existe ninguna primitiva conocida para esta función, es decir, no sabemos resolver la anterior integral. Sin embargo, si somos incapaces de calcular la función distribución no podremos efectuar ningún cálculo con este modelo. ¿Cómo solucionamos el problema?

Una primera solución podría consistir en aproximar la integral a través de técnicas de cálculo numérico. Sin embargo, dado que el conjunto de valores que pueden tomar los parámetros \(\mu\) y \(\sigma\) son infinitos, deberíamos repetir el proceso para cada valor diferente de algún parámetro. Afortunadamente, podemos ahorrarnos el esfuerzo aprovechando la propiedad de que cualquier transformación lineal de una variable Normal sigue también el modelo Normal. Por tanto, replantearemos cualquier problema en términos de una Normal concreta, que suele ser la \(\mathrm{N}(0,1)\), de la siguiente manera:

Si \(X \sim N(\mu, \sigma)\) y entonces definimos \(Z=(\mathrm{X}-\mu) / \sigma\) se cumplirá que \(Z \sim N(0,1)\)

\[
\begin{gathered}
\text { y, por tanto: } \\
F_{X}(x)=P[X \leq x]=P\left[\frac{X-\boldsymbol{\mu}}{\boldsymbol{\sigma}} \leq \frac{x-\boldsymbol{\mu}}{\boldsymbol{\sigma}}\right]=P\left[Z \leq \frac{x-\boldsymbol{\mu}}{\boldsymbol{\sigma}}\right]=F_{Z}\left(\frac{x-\boldsymbol{\mu}}{\boldsymbol{\sigma}}\right)
\end{gathered}
\]

A la distribución \(N(0,1)\), es decir, la que tiene por media cero y por desviación típica uno, se le denomina Normal reducida o tipificada. En cambio, al proceso de transformación del cálculo de la función de distribución de una Normal cualquiera a través de la Normal tipificada, se le denomina tipificación.

Debemos remarcar que el proceso de tipificación no resuelve el problema de la inexistencia de la función primitiva correspondiente. Sin embargo, sí es posible, mediante técnicas de cálculo numérico, obtener la integral numérica correspondiente y elaborar unas tablas que podemos consultar. Naturalmente, la tipificación permite que con una sola tabla, la de la \(N(0,1)\), tengamos suficiente.

Hoy en día, cada vez se utilizan menos tablas como la mencionada anteriormente, ya que los ordenadores, junto con los abundantes programas estadísticos existentes nos resuelven este problema. Sin embargo, la imposibilidad de integrar analíticamente la función de densidad persiste y, aunque nosotros no seamos conscientes, los programas informáticos realizan el proceso de tipificación para simplificar el problema.

\subsubsection{La distribución Gamma}\label{la-distribuciuxf3n-gamma}

Este modelo es una generalización del modelo Exponencial ya que, en ocasiones, se utiliza para modelar variables que describen el tiempo hasta que se produce p veces un determinado suceso.

Su función de densidad es de la forma:

\[
f(x)=\left\{\begin{array}{lll}
\frac{1}{\alpha^{p} \Gamma(p)} e^{-\frac{x}{\alpha}} x^{p-1} & \text { si } & x>0 \\
0 & \text { si } & x \leq 0
\end{array}\right\}
\]

Como vemos, este modelo depende de dos parámetros positivos: \(\alpha\) y p.~

La función \(\Gamma(p)\) es la denominada función Gamma de Euler que representa la siguiente integral:

\[
\Gamma(p)=\int_{0}^{\infty} x^{p-1} e^{-x} d x
\]

que verifica \(\Gamma(p+1)=p \Gamma(p)\), con lo que, si \(p\) es un número entero positivo, \(\Gamma(p+1)=p!\). Es decir, si evaluamos la función gamma en números positivos se obtiene el factorial del valor anterior en el que se ha realizado la evaluación. Por ejemplo:
\[
\Gamma(5) = 4! =4\times 3 \times 2 =24
\]

\paragraph{Propiedades de la distribución Gamma}\label{propiedades-de-la-distribuciuxf3n-gamma}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Su esperanza es \(p \alpha\).
\item
  Su varianza es \(p \alpha^{2}\)
\item
  La distribución Gamma \((\alpha, p=1)\) es una distribución Exponencial de parámetro \(\alpha\). Es decir, el modelo Exponencial es un caso particular de la Gamma \(\operatorname{con} p=1\).
\item
  Dadas dos variables aleatorias con distribución Gamma y parámetro \(\alpha\) común
\end{enumerate}

\[
X \sim G\left(\alpha, p_{1}\right) \text { y } Y \sim G\left(\alpha, p_{2}\right)
\]

se cumplirá que la suma también sigue una distribución Gamma

\[
X+Y \sim G\left(\alpha, p_{1}+p_{2}\right)
\]

Una consecuencia inmediata de esta propiedad es que, si tenemos \(k\) variables aleatorias con distribución Exponencial de parámetro \(\alpha\) (común) e independientes, la suma de todas ellas seguirá una distribución \(G(\alpha, k)\).

\subsubsection{La distribución de Cauchy}\label{la-distribuciuxf3n-de-cauchy}

Se trata de un modelo continuo cuya función de densidad es:

\[
f(x)=\frac{1}{\pi\left(1+x^{2}\right)} \quad \text { para } \quad-\infty<x<\infty
\]

Cuya integral nos proporciona la función de distribución:

\[
F(x)=\int_{-\infty}^{x} \frac{1}{\pi\left(1+t^{2}\right)} d t=\frac{1}{\pi}[\arctan (t)]_{t=-\infty}^{t=x}=\frac{1}{2}+\frac{\arctan (x)}{\pi}
\]

El siguiente programa permite visualizar la forma de la función de densidad de este modelo y el valor de la función de distribución:

\paragraph{Propiedades de la distribución de Cauchy}\label{propiedades-de-la-distribuciuxf3n-de-cauchy}

Se trata de un ejemplo de variable aleatoria que carece de esperanza (y, por tanto, también de varianza o cualquier otro momento), ya que la integral impropia correspondiente no es convergente:

\[
E(X)=\int_{-\infty}^{\infty} \frac{x}{\pi\left(1+x^{2}\right)} d x=\frac{1}{2 \pi} \int_{-\infty}^{\infty} \frac{2 x}{1+x^{2}} d x=\frac{1}{2 \pi}\left[\lim _{x \rightarrow \infty} \ln \left(x^{2}\right)-\lim _{x \rightarrow-\infty} \ln \left(x^{2}\right)\right]=\frac{1}{2 \pi}[\infty-\infty]
\]

y nos queda una indeterminación. Por tanto, la esperanza de una distribución de Cauchy no existe. Cabe señalar que la función de densidad es simétrica respecto al valor cero (que sería la mediana y la moda), pero al no existir la integral anterior, la esperanza no existe.

\subsubsection{La distribución de Weibull}\label{la-distribuciuxf3n-de-weibull}

Se trata de un modelo continuo asociado a variables del tipo tiempo de vida, tiempo hasta que un mecanismo falla, etc. La función de densidad de este modelo viene dada por:

\[
f(x)=\left\{\begin{array}{ll}
\frac{\beta}{\alpha}\left(\frac{x}{\alpha}\right)^{\beta-1} e^{-\left(\frac{x}{\alpha}\right)^{\beta}} & \text { si } x \geq 0 \\
0 & \text { si } x<0
\end{array}\right\}
\]

que, como vemos, depende de dos parámetros: \(\alpha>0\) y \(\beta>0\), donde \(\alpha\) es un parámetro de escala y \(\beta\) es un parámetro de forma (lo que proporciona una gran flexibilidad a este modelo).

La función de distribución se obtiene por la integración de la función de densidad y vale:

\[
F(x)=1-e^{-\left(\frac{x}{\alpha}\right)^{\beta}}
\]

El siguiente programa permite visualizar la forma de la función de densidad de este modelo y el valor de la función de distribución:

\paragraph{Propiedades de la distribución Weibull}\label{propiedades-de-la-distribuciuxf3n-weibull}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Si tomamos \(\beta=1\) tenemos una distribución Exponencial.
\item
  Su esperanza vale:
\end{enumerate}

\[
E(X)=\alpha \Gamma\left(\frac{1}{\boldsymbol{\beta}}+\mathbf{1}\right)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Su varianza vale:
\end{enumerate}

\[
V(X)=\alpha^{2}\left\{\Gamma\left(\frac{2}{\beta}+1\right)-\left[\Gamma\left(\frac{1}{\beta}+1\right)\right]^{2}\right\}
\]

donde \(\Gamma(x)\) representa la función Gamma de Euler definida anteriormente.

\subsubsection{Tabla resumen de las principales distribuciones continuas}\label{tabla-resumen-de-las-principales-distribuciones-continuas}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Distribución
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Parámetros
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Función de densidad
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Esperanza
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Varianza
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniforme & \(a, b\) & \(\frac{1}{b-a}\) \(a<x<b\) & \(\frac{a+b}{2}\) & \(\frac{(b-a)^{2}}{12}\) \\
Exponencial & \(\alpha>0\) & \(\frac{1}{\alpha} \exp \left(-\frac{x}{\alpha}\right)\) \(x>0\) & \(\alpha\) & \(\alpha^{2}\) \\
Normal & \(-\infty<\mu<\infty\) \(\sigma>0\) & \(\frac{1}{\sqrt{2 \pi} \sigma} \exp \left\{-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right\}\) \(-\infty<x<+\infty\) & \(\mu\) & \(\sigma^{2}\) \\
\end{longtable}

Cauchy \textbar{} - \textbar{} \(\frac{1}{\pi\left(1+x^{2}\right)}\) \(-\infty<\mathbf{x}<\infty\) \textbar{} -- \textbar{} -- \textbar{}\\
Weibull \textbar{} \(\alpha>0\) \(\beta>0\) \textbar{} \(\frac{\boldsymbol{\beta}}{\boldsymbol{\alpha}}\left(\frac{x}{\boldsymbol{\alpha}}\right)^{\beta-1} e^{-\left(\frac{x}{\alpha}\right)^{\beta}}\) \(x \geq 0\) \textbar{} \(\alpha \Gamma\left(\frac{1}{\beta}+1\right)\) \textbar{} \(\alpha^{2}\left\{\Gamma\left(\frac{2}{\beta}+1\right)-\left[\Gamma\left(\frac{1}{\beta}+1\right)\right]^{2}\right\}\) \textbar{}

\subsection{Distribuciones con R (y Python)}\label{distribuciones-con-r-y-python}

El lenguaje estadístico R es muy potente en cuanto al cálculo con distribuciones de probabilidad.

Dado que el trabajo con distribucines de probabilidad usando R está muy estandarizado y explicado en múltiples fuentes no repetiremos aquí estas explicaciones.

Tan solo os referimos a dos buenas fuentes de información que podéis utilizar para aprender como hacer los cálculos con R y también una aplicación que os permite visualizar casi cualquier distribución conocida.

\textbf{R Tutorials}

Explicación detallada y de nivel básico del manejo de las principales distribuciones con R

\url{https://www.r-tutor.com/elementary-statistics/probability-distributions}

\textbf{The distribution Zoo}

Permite visualizar de forma interactiva distintas distribuciones y proporciona información diversa sobre sus propiedades e incluso su aplicación.

\url{https://ben18785.shinyapps.io/distribution-zoo/}

\textbf{Distribution explorer}

Más completo que los anteriores. No se basa en R sino en python.

\url{https://distribution-explorer.github.io/index.html}

\subsection{La familia exponencial de distribuciones}\label{la-familia-exponencial-de-distribuciones}

En el estudio de las propiedades de los estimadores, vemos que algunas distribuciones se comportan mejor que otras. Muchas veces, este buen comportamiento refleja una estructura común que proviene de pertenecer a una misma familia de distribuciones llamada familia exponencial.

\textbf{Definición}: Sea \(f_{\theta}\) una familia de probabilidades que depende de un parámetro unidimensional \(\left\{f_{\theta}(x), \theta \in \Theta \subseteq \mathbb{R}\right\}\) tal que el soporte \(S(\theta)=\left\{x \mid f_{\theta}(x)>0\right\}\) no depende de \(\theta\). Si existen funciones de los parámetros \(Q(\theta)\) y \(C(\theta)\) y funciones de las muestras, \(T(x)\) y \(h(x)\), tales que la función de densidad puede escribirse como:

\[f_{\theta}(x)=C(\theta) h(x) \exp\{Q(\theta) \cdot T(x)\}\]

diremos que \(f_{\theta}(x)\) \emph{pertenece a la familia exponencial de distribuciones}.

La familia exponencial no representa un nuevo tipo de distribuciones, sino la constatación de que muchas distribuciones comunes, que pueden reformularse para ajustarse a la expresión anterior, pertenecen a esta familia.

Veamos algunos ejemplos de que esto es efectivamente así.

\subsubsection{Ejemplos de distribuciones de esta familia}\label{ejemplos-de-distribuciones-de-esta-familia}

\paragraph{Distribución de Poisson}\label{distribuciuxf3n-de-poisson}

La ley de Poisson pertenece a la familia exponencial uniparamétrica.

Efectivamente,

\[f_{\lambda}(x)=e^{-\lambda} \frac{\lambda^{x}}{x!}=\exp\{-\lambda+x \log \lambda-\log(x!)\}\]

y si hacemos

\[Q(\lambda)=\log(\lambda) \quad T(x)=x \quad D(\lambda)=-\lambda \quad S(x)=-\log(x!)\]

se hace evidente que \(f_{\lambda}\) pertenece a la familia exponencial.

\paragraph{Distribución normal uniparamétrica}\label{distribuciuxf3n-normal-uniparamuxe9trica}

La ley normal depende de dos parámetros \(\mu\) y \(\sigma\). Fijado uno de ellos, nos queda una distribución que depende de un solo parámetro, y de aquí la denominación ``normal uniparamétrica''.

Si, con el subíndice ``0'', indicamos el parámetro fijado, tenemos:

\[
\begin{aligned}
&f_{\sigma}=\left\{N\left(\mu_0, \sigma\right), \sigma>0\right\} \text{ Normal uniparamétrica, de parámetro } \sigma^2, \\
&f_{\mu}=\left\{N\left(\mu, \sigma_0\right), \mu \in \mathbb{R}\right\} \text{ normal uniparamétrica, de parámetro } \mu.
\end{aligned}
\]

Si queremos considerar ambos parámetros a la vez, debemos extender la definición al caso de parámetros \(k\)-dimensionales. En estos materiales no trataremos esta extensión.

\subparagraph{\texorpdfstring{Caso 1: Fijando la media \(\mu_0\)}{Caso 1: Fijando la media \textbackslash mu\_0}}\label{caso-1-fijando-la-media-mu_0}

Consideramos la distribución normal \(N(\mu_0, \sigma^2)\), donde fijamos \(\mu = \mu_0\) y \(\sigma^2\) es el parámetro libre.

La función de densidad de probabilidad es

\[f_{\sigma}(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left\{-\frac{(x - \mu_0)^2}{2\sigma^2}\right\}\]

Vamos a reescribir esta función en forma de la familia exponencial. Primero, reorganizamos los términos de la densidad:

\[f_{\sigma}(x) = \frac{1}{\sqrt{2\pi}} \cdot \sigma^{-1} \exp\left\{-\frac{1}{2\sigma^2}(x - \mu_0)^2\right\}\]

Ahora identificamos las funciones que se corresponden con la forma de la familia exponencial \(f_{\theta}(x) = C(\theta) h(x) \exp\{Q(\theta) T(x)\}\):

\begin{itemize}
\tightlist
\item
  \(Q(\sigma) = -\frac{1}{2\sigma^2}\)
\item
  \(T(x) = (x - \mu_0)^2\)
\item
  \(C(\sigma) = \frac{1}{\sqrt{2\pi}\sigma}\)
\item
  \(h(x) = 1\)
\end{itemize}

Esto confirma que la distribución normal, con \(\mu_0\) fijo, pertenece a la familia exponencial.

\subparagraph{\texorpdfstring{Caso 2: Fijando la varianza \(\sigma_0^2\)}{Caso 2: Fijando la varianza \textbackslash sigma\_0\^{}2}}\label{caso-2-fijando-la-varianza-sigma_02}

Ahora consideramos la distribución \(N(\mu, \sigma_0^2)\), donde la varianza está fijada y el parámetro libre es \(\mu\).

La función de densidad es

\[f_{\mu}(x) = \frac{1}{\sqrt{2\pi\sigma_0^2}} \exp\left\{-\frac{(x - \mu)^2}{2\sigma_0^2}\right\}\]

Vamos a reescribir esta función de la misma manera:

\[f_{\mu}(x) = \frac{1}{\sqrt{2\pi\sigma_0^2}} \exp\left\{-\frac{1}{2\sigma_0^2}(x^2 - 2\mu x + \mu^2)\right\}\]

Identificamos las funciones correspondientes:

\begin{itemize}
\tightlist
\item
  \(Q(\mu) = \frac{\mu}{\sigma_0^2}\)
\item
  \(T(x) = x\)
\item
  \(D(\mu) = -\frac{\mu^2}{2\sigma_0^2}\)
\item
  \(S(x) = -\frac{x^2}{2\sigma_0^2}\)
\end{itemize}

Esto prueba que la distribución normal con \(\sigma_0\) fijo pertenece a la familia exponencial.

\subsubsection{Distribución Binomial}\label{distribuciuxf3n-binomial}

La distribución binomial es un ejemplo interesante, puesto que, a priori, no parece tener la estructura propia de la distribución exponencial, cosa que si pasa con la distribución de Poisson o con la Normales uniparamétricas que acabamos de ver.

Sin embargo, tras aplicar algunas transformaciones se puede ver como, también esta distribución pertenece a la familia exponencial

La función de masa de probabilidad para la distribución binomial es

\[f(x; n, p) = \binom{n}{x} p^x (1 - p)^{n - x}, \quad x = 0, 1, \dots, n\]

Reescribimos esta función en términos exponenciales:

\[f(x; n, p) = \binom{n}{x} \exp\{x \log(p) + (n - x) \log(1 - p)\}\]

Agrupamos los términos dependientes de \(x\):

\[f(x; n, p) = \binom{n}{x} \exp\left\{x \log\left(\frac{p}{1 - p}\right) + n \log(1 - p)\right\}\]

Identificamos las funciones correspondientes a la familia exponencial:

\begin{itemize}
\tightlist
\item
  \(Q(p) = \log\left(\frac{p}{1 - p}\right)\)
\item
  \(T(x) = x\)
\item
  \(D(p) = n \log(1 - p)\)
\item
  \(S(x) = \log \binom{n}{x}\)
\end{itemize}

Por lo tanto, la distribución binomial pertenece a la familia exponencial.

\subsubsection{Importancia y utilidad de la familia exponencial}\label{importancia-y-utilidad-de-la-familia-exponencial}

Muchas de las distribuciones usadas para modelar gran cantidad de situaciones prácticas pertenecen a esta familia.

Esto significa que es posible estudiar sus propiedades en conjunto. Es decir, si establecemos que una propiedad se verifica en una distribución que pertenece a la familia exponencial, automáticamente sabemos que todos los miembros de la familia verifican esa propiedad.

A continuación, se describen tres ventajas importantes de trabajar con esta familia:

\subsubsection{Los modelos lineales generalizados (GLMs)}\label{los-modelos-lineales-generalizados-glms}

Una de las aplicaciones más importantes de la familia exponencial es su uso en los \textbf{Modelos Lineales Generalizados (GLMs)}.

Estos modelos nos permiten extender la regresión lineal clásica a diferentes tipos de datos, como los resultados binarios (por ejemplo, éxito o fracaso), mediante la \emph{regresión logística}, recuentos de eventos (como el número de llamadas recibidas en una hora) mediante la \emph{regresión de Poisson}, y muchos otros.

Gracias a la estructura de la familia exponencial, podemos conectar la media de la variable que estamos modelando con las variables explicativas de forma flexible, lo que hace posible aplicar GLMs en una amplia variedad de situaciones.

\subsubsection{Estimación en la familia exponencial}\label{estimaciuxf3n-en-la-familia-exponencial}

Otra ventaja importante es que, al trabajar con distribuciones de la familia exponencial, los métodos que usamos para hacer inferencias estadísticas suelen tener \textbf{buenas propiedades}.

Esto, que se explicará con más detalle en capítulos siguientes, implica que los estimadores que obtenemos con estos modelos suelen ser precisos y reflejar correctamente la información que contienen los datos.

Naturalmente esto se puede ver al revés: Si podemos trabajar con distribuciones de la familia exponencial, solemos tener, de entrada, una serie de ventajas, como el buen comportamiento de los etimadores, por lo que siempre es una buena opción intentar utilizarlas en nuestros modelos.

\newpage

\section{Distribuciones de probabilidad multidimensionales}\label{distribuciones-de-probabilidad-multidimensionales}

En este capítulo se extiende el concepto de variable aleatoria a un conjunto de variables que pueden interpretarse asociadas a un conjunto de medidas distintas y que pueden estar, o no relacionadas.

Tras introducir los conceptos de distribuciones multidimensionales, condicionales y marginales, se pasa a considerar el caso más habitual en inferencia estadística en el que las componentes de los vectrores son independientes entre ellas.

Este es, de hecho, el punto de partida de muchos modelos y métodos en estadística.

\subsection{Distribuciones conjuntas de probabilidades}\label{distribuciones-conjuntas-de-probabilidades}

\begin{itemize}
\item
  A menudo nos interesa estudiar múltiples características de un fenómeno aleatorio:

  \begin{itemize}
  \tightlist
  \item
    La altura, el peso y el sexo de un individuo.
  \item
    La expresión coordinada de los genes que participan en una determinada via metabólica.
  \item
    El número de nucleótidos A, C, G, T en una región del genoma de tamaño \(n\).
  \end{itemize}
\item
  Estas características numéricas que, de forma análoga al caso univariante, podemos suponer asociadas a los resultados de experimentos aleatorios se denominan \emph{variables aleatorias multidimensionales} o, atendiendo a sus componentes, \textbf{vectores aleatorios}.
\end{itemize}

Las distribuciones de probabilidad que, siguiendo con la analogía, asociaremos a los vectores aleatorios se denominan \textbf{distribuciones de probabilidades conjuntas} o \textbf{multivariantes}.

Antes de desarrollar el tema es importante remarcar que consideraremos dos escenarios:

\begin{itemize}
\item
  El primero, el ``natural'' es considerar que si trabajamos con distintas variables asociadas a un mismo fenómeno, es razonable suponer que varien de alguna forma coordinada. De ahí la expresión \emph{distribución conjnta}.
\item
  En ocasiones, sin embargo, dispondremos de vectores aleatorios que varian independientemente los unos de los otros. En este caso su distribución conjunta será de un tipo especial que se conoce \emph{independencia}.
\end{itemize}

\subsubsection{Variable aleatoria bivariante}\label{variable-aleatoria-bivariante}

Empezaremos por el caso más sencillo que, sin embargo permite estudiar la mayoría de los conceptos quenos interesas: Las distribuciones conjuntas de dos variables aleatorias.

Una \textbf{variable aleatoria bivariante} es una aplicación que, a cada resultado de un experimento, le asocia dos números:

\[
(X, Y): \Omega \to \mathbb{R}^2
\]

\[
w \mapsto (X(w), Y(w))
\]

De modo que, para todo par de valores numéricos, \((x, y) \in \mathbb{R}^2\), se tiene

\[
\{w \in \Omega \mid X(w) \leq x,\quad Y(w) \leq y\} \in \mathcal{A}
\]
donde \(\mathcal{A}\) representa el conjunto de \emph{sucesos observables} definido en el capítulo 1.

Lo que viene a significar esta definición es que una variable aleatoria bidimensional es un conjunto de medidas (números reales) a los que, por el ehecho de poderse asociar con sucesos observables a traves de los intérvalos \(X(w) \leq x,\quad Y(w) \leq y\) se les puede asociar (calcular) una probabilidad.

Fijémonos también que, como en el caso univariante, la función que \emph{transporta} la probabilidad, del espació de probabilidad al conjunto de los reales, será la función de distribución, que se define a continuación.

\subsubsection{Función de distribución bivariante}\label{funciuxf3n-de-distribuciuxf3n-bivariante}

La función de distribución conjunta de \(X\) y \(Y\), \(F\), es una generalización inmediata del caso univariado y se define como:

\[
F(x, y) = P\{w \in \Omega \mid X(w) \leq x, Y(w) \leq y\} = P[X \leq x, Y \leq y]
\]

Como en el caso univariante, esta es la función que define la forma en que podemos calcular probabilidades sobre los valores de las variables, en este caso de dimensión 2.

\subsubsection{Ejemplo: Distribución conjunta del estado de infección y activación de células}\label{ejemplo-distribuciuxf3n-conjunta-del-estado-de-infecciuxf3n-y-activaciuxf3n-de-cuxe9lulas}

Supongamos que estamos observando dos características de células en un experimento de inmunología. Las variables que describen las células son:

\begin{itemize}
\tightlist
\item
  \(X\): La célula está infectada (\(X = 1\)) o no infectada (\(X = 0\)).
\item
  \(Y\): La célula está activada (\(Y = 1\)) o no activada (\(Y = 0\)).
\end{itemize}

La siguiente tabla muestra la probabilidad conjunta de observar cada combinación de infección y activación en una célula:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.2973}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3649}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3378}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(X \backslash Y\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(Y = 0\) (No activada)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(Y = 1\) (Activada)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(X = 0\) (No infectada) & 0.4 & 0.2 \\
\(X = 1\) (Infectada) & 0.1 & 0.3 \\
\end{longtable}

\paragraph{1. Función de distribución conjunta}\label{funciuxf3n-de-distribuciuxf3n-conjunta}

La función de distribución conjunta \(F(x, y)\) para esta situación se calcula como:

\[
F(x, y) = P(X \leq x, Y \leq y)
\]

Los valores para los pares posibles de \(x\) y \(y\) son:

\begin{itemize}
\tightlist
\item
  \(F(0, 0) = P(X = 0, Y = 0) = 0.4\)
\item
  \(F(0, 1) = P(X = 0, Y \leq 1) = P(X = 0, Y = 0) + P(X = 0, Y = 1) = 0.4 + 0.2 = 0.6\)
\item
  \(F(1, 0) = P(X \leq 1, Y = 0) = P(X = 0, Y = 0) + P(X = 1, Y = 0) = 0.4 + 0.1 = 0.5\)
\item
  \(F(1, 1) = P(X \leq 1, Y \leq 1) = 1\)
\end{itemize}

\paragraph{2. Cálculo de la probabilidad de eventos específicos}\label{cuxe1lculo-de-la-probabilidad-de-eventos-especuxedficos}

Por ejemplo, la probabilidad de que una célula esté infectada pero no activada es:

\[
P(X = 1, Y = 0) = 0.1
\]

\subsubsection{Implementación en R}\label{implementaciuxf3n-en-r}

Podemos visualizar esta distribución conjunta con un gráfico en R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(ggplot2)}

\CommentTok{\# Crear los datos de la distribución conjunta}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{X =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{Y =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{))}
\NormalTok{data}\SpecialCharTok{$}\NormalTok{Prob }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.4}\NormalTok{, }\FloatTok{0.2}\NormalTok{, }\FloatTok{0.1}\NormalTok{, }\FloatTok{0.3}\NormalTok{)}

\CommentTok{\# Crear el gráfico}
\NormalTok{p }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(data, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x =} \FunctionTok{factor}\NormalTok{(X, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"No infectada"}\NormalTok{, }\StringTok{"Infectada"}\NormalTok{)),}
                      \AttributeTok{y =} \FunctionTok{factor}\NormalTok{(Y, }\AttributeTok{labels =} \FunctionTok{c}\NormalTok{(}\StringTok{"No activada"}\NormalTok{, }\StringTok{"Activada"}\NormalTok{)))) }\SpecialCharTok{+}
  \FunctionTok{geom\_tile}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill =}\NormalTok{ Prob), }\AttributeTok{color =} \StringTok{"white"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_gradient}\NormalTok{(}\AttributeTok{low =} \StringTok{"white"}\NormalTok{, }\AttributeTok{high =} \StringTok{"blue"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{label =} \FunctionTok{round}\NormalTok{(Prob, }\DecValTok{2}\NormalTok{)), }\AttributeTok{size =} \DecValTok{5}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{x =} \StringTok{"Estado de infección (X)"}\NormalTok{, }\AttributeTok{y =} \StringTok{"Estado de activación (Y)"}\NormalTok{, }
       \AttributeTok{title =} \StringTok{"Distribución Conjunta de Infección y Activación Celular"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}

\CommentTok{\# Guardar el gráfico en el subdirectorio imagenes}
\FunctionTok{ggsave}\NormalTok{(}\StringTok{"images/distribucion\_conjunta.png"}\NormalTok{, }\AttributeTok{plot =}\NormalTok{ p, }\AttributeTok{width =} \DecValTok{6}\NormalTok{, }\AttributeTok{height =} \DecValTok{4}\NormalTok{, }\AttributeTok{dpi =} \DecValTok{300}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/distribucion\_conjunta.png"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=0.8\linewidth]{images/distribucion_conjunta}

\subsection{Variable aleatorias bivariantes discretas}\label{variable-aleatorias-bivariantes-discretas}

Una vez introducidos los conceptos de forma general pasamos a estudiar el problema en el caso discreto, que es muy intuitivo y, a la vez permite introducir todos los conceptos relevantes.

Un \textbf{vector aleatorio discreto}, \((X, Y)\) es aquel cuyo recorrido o conjunto de valores posibles es finito o numerable.

En este caso, toda probabilidad

\[
P\{(X, Y) \in B\}, \quad \text{donde } B \text{ es un conjunto de posibles valores de } X, Y,
\]

se puede calcular a partir de la \textbf{función de masa de probabilidad discreta bivariante}.

\subsubsection{Función de masa de probabilidad discreta (fmp)}\label{funciuxf3n-de-masa-de-probabilidad-discreta-fmp}

La funcion de masa de probabilidad de los vectores aleatorios generaliza la función del mismo nombre en el caso univariante, es decir, es una función:

\[
f: \mathbb{R}^2 \to [0, 1]
\]

Que asigna la probabilidad a cada punto del plano: para todo \((x, y) \in \mathbb{R}^{2}\):

\[
f(x, y) = P\{w \in \Omega \mid X(w) = x, Y(w) = y\} = P[X = x, Y = y]
\]

\subsubsection{Propiedades de la fmp bivariante}\label{propiedades-de-la-fmp-bivariante}

\begin{itemize}
\tightlist
\item
  La masa total de probabilidad sobre el plano es 1:
\end{itemize}

\[
\sum_{(x_i, y_j) \in \mathbb{R}^{2}} f(x_i, y_j) = 1
\]

\begin{itemize}
\tightlist
\item
  Para todo subconjunto \(B \subseteq \mathbb{R}^2\), se verifica:
\end{itemize}

\[
F(x, y) = P[X \leq x, Y \leq y] = \sum_{x_i \leq x, y_j \leq y} f(x_i, y_j)
\]

Es decir, como en el caso univariante \emph{la función de distribución se puede calcular a partir de la función de masa de probabilidad}.

\paragraph{Intuición frente a construcción}\label{intuiciuxf3n-frente-a-construcciuxf3n}

La presentación de los conceptos anteriores suele generar cierto desasosiego entre los estudiantes que afrontan estos conceptos por primera (o siguientes) vez.

El motivo de este desasosiego es que el papel de la función de distribución no suele ser tan intuitivo como el de la función de masa de probabilidad.

Es decir, es más intuitivo pensar en como calcular lña probabilidad que la variable tome un valor concreto (\(P[X=x]\)) , que la probabilidad de que no alcance cierto valor (\(P[X\leq x]\)).

Sin embargo, la función que realmente permite transportar la probabilidad no es la función de masa de probabilidad (fmp) sino la función de distribución (fdd). De ahí el contraste entre intuición (fmp) y construcción (fdd)

\subsubsection{Ejemplo de distribución bivariante discreta}\label{ejemplo-de-distribuciuxf3n-bivariante-discreta}

Supongamos que un estudio mide el número de células infectadas y el número de linfocitos activados en un campo microscópico. Dado el tamaño del campo y el grado de infección los valores observados de cada variables son:

\begin{itemize}
\tightlist
\item
  \(X\): Número de células infectadas (\(X \in \{0, 1, 2, 3, 4, 5\}\))).
\item
  \(Y\): Número de linfocitos activados (\(Y \in \{0, 1, 2, 3\}\))).
\end{itemize}

La distribución conjunta se refleja en la siguiente tabla de probabilidades conjuntas:

\begin{longtable}[]{@{}ccccc@{}}
\toprule\noalign{}
\(P[X=x]\) & \(P[Y = 0]\) & \(P[Y = 1]\) & \(P[Y = 2]\) & \(P[Y = 3]\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0.12 & 0.06 & 0.02 & 0.00 \\
1 & 0.10 & 0.10 & 0.04 & 0.01 \\
2 & 0.06 & 0.12 & 0.08 & 0.02 \\
3 & 0.03 & 0.12 & 0.10 & 0.05 \\
4 & 0.01 & 0.08 & 0.12 & 0.06 \\
5 & 0.00 & 0.03 & 0.10 & 0.07 \\
\end{longtable}

Puede comprobarse como la suma de todos los valores de la tabla es 1, y calcular probabilidades de sucesos como

\textbf{Probabilidad de que hayan dos células infectadas y un linfocito:}

Para calcular la probabilidad de que haya exactamente 2 células infectadas y 1 linfocito activado, se puede usar el valor directamente de la tabla.

\[
P(X = 2, Y = 1) = 0.12
\]

\textbf{Probabilidad de que hayan menos de tres celulas infectadas y menos de dos linfocitos:}

Esta probabilidad es la suma de todas las combinaciones de \(X\) y \(Y\)) que cumplen con la condición de \(X < 3\)) y \(Y < 2\)). Es decir, sumamos las probabilidades de los casos

\((X = 0, Y = 0)\)), \((X = 0, Y = 1)\)), \((X = 1, Y = 0)\)), \((X = 1, Y = 1)\)), \((X = 2, Y = 0)\)), y \((X = 2, Y = 1)\)).

\[
P(X < 3, Y < 2) = P(X = 0, Y = 0) + P(X = 0, Y = 1) + P(X = 1, Y = 0) + P(X = 1, Y = 1) + P(X = 2, Y = 0) + P(X = 2, Y = 1)
\]

\[
P(X < 3, Y < 2) = 0.12 + 0.06 + 0.10 + 0.10 + 0.06 + 0.12 = 0.56
\]

Recordemos que, al tratarse de variables discretas, no es lo mismo \(P[X < x]\) que \(P[X \leq x]\), por lo que si la pregunta fuera ``Probabilidad de que hayan al menos tres celulas infectadas y al menos dos linfocitos'' deberíamos calcular:

\[
P(X \leq 3, Y \leq 2) 
\]
Esta última expresión se corresponde con la función de distribución evaluada en \((3,2)\).

\paragraph{Código R para el cálculo de la pmf}\label{cuxf3digo-r-para-el-cuxe1lculo-de-la-pmf}

Podemos hacer los cálculos usando R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob\_table }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.12}\NormalTok{, }\FloatTok{0.06}\NormalTok{, }\FloatTok{0.02}\NormalTok{, }\FloatTok{0.00}\NormalTok{,}
                       \FloatTok{0.10}\NormalTok{, }\FloatTok{0.10}\NormalTok{, }\FloatTok{0.04}\NormalTok{, }\FloatTok{0.01}\NormalTok{,}
                       \FloatTok{0.06}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{0.08}\NormalTok{, }\FloatTok{0.02}\NormalTok{,}
                       \FloatTok{0.03}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{0.10}\NormalTok{, }\FloatTok{0.05}\NormalTok{,}
                       \FloatTok{0.01}\NormalTok{, }\FloatTok{0.08}\NormalTok{, }\FloatTok{0.12}\NormalTok{, }\FloatTok{0.06}\NormalTok{,}
                       \FloatTok{0.00}\NormalTok{, }\FloatTok{0.03}\NormalTok{, }\FloatTok{0.10}\NormalTok{, }\FloatTok{0.07}\NormalTok{), }
                     \AttributeTok{nrow =} \DecValTok{6}\NormalTok{, }\AttributeTok{byrow =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# Asignar nombres a las filas y columnas}
\FunctionTok{rownames}\NormalTok{(prob\_table) }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{5}
\FunctionTok{colnames}\NormalTok{(prob\_table) }\OtherTok{\textless{}{-}} \DecValTok{0}\SpecialCharTok{:}\DecValTok{3}

\CommentTok{\# Mostrar la tabla}

\NormalTok{prob\_table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      0    1    2    3
## 0 0.12 0.06 0.02 0.00
## 1 0.10 0.10 0.04 0.01
## 2 0.06 0.12 0.08 0.02
## 3 0.03 0.12 0.10 0.05
## 4 0.01 0.08 0.12 0.06
## 5 0.00 0.03 0.10 0.07
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calcular la probabilidad de (X = 2, Y = 1)}
\NormalTok{prob\_X2\_Y1 }\OtherTok{\textless{}{-}}\NormalTok{ prob\_table[}\StringTok{"2"}\NormalTok{, }\StringTok{"1"}\NormalTok{]}
\FunctionTok{cat}\NormalTok{(}\StringTok{"P(X = 2, Y = 1) ="}\NormalTok{, prob\_X2\_Y1, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## P(X = 2, Y = 1) = 0.12
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calcular la probabilidad de (X \textless{} 3, Y \textless{} 2)}
\NormalTok{prob\_X\_lt\_3\_Y\_lt\_2 }\OtherTok{\textless{}{-}} \FunctionTok{sum}\NormalTok{(prob\_table[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{])}
\FunctionTok{cat}\NormalTok{(}\StringTok{"P(X \textless{} 3, Y \textless{} 2) ="}\NormalTok{, prob\_X\_lt\_3\_Y\_lt\_2, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## P(X < 3, Y < 2) = 0.56
\end{verbatim}

\paragraph{Código R para visualizar la distribución conjunta}\label{cuxf3digo-r-para-visualizar-la-distribuciuxf3n-conjunta}

Para visualizar la distribución conjunta, podemos usar el código siguiente;

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Es preciso instalar y cargar el paquete scatterplot3d si no lo tienes instalado}
\CommentTok{\# install.packages("scatterplot3d")}
\FunctionTok{library}\NormalTok{(scatterplot3d)}

\CommentTok{\# Crear una matriz con los datos de la tabla de probabilidades}
\NormalTok{X\_vals }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{rownames}\NormalTok{(prob\_table))}
\NormalTok{Y\_vals }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{colnames}\NormalTok{(prob\_table))}

\CommentTok{\# Crear un grid de valores X e Y}
\NormalTok{X\_grid }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(X\_vals, }\AttributeTok{each =} \FunctionTok{length}\NormalTok{(Y\_vals))}
\NormalTok{Y\_grid }\OtherTok{\textless{}{-}} \FunctionTok{rep}\NormalTok{(Y\_vals, }\AttributeTok{times =} \FunctionTok{length}\NormalTok{(X\_vals))}

\CommentTok{\# Extraer las probabilidades como un vector}
\NormalTok{Z\_vals }\OtherTok{\textless{}{-}} \FunctionTok{as.vector}\NormalTok{(prob\_table)}

\CommentTok{\# Enviar el gráfico 3D de barras simuladas a pdf}
\FunctionTok{png}\NormalTok{(}\StringTok{"images/pmfTrinomial.png"}\NormalTok{)}
\FunctionTok{scatterplot3d}\NormalTok{(X\_grid, Y\_grid, Z\_vals,}
                     \AttributeTok{type =} \StringTok{"h"}\NormalTok{, }\AttributeTok{color =} \StringTok{"lightblue"}\NormalTok{, }
                     \AttributeTok{pch =} \DecValTok{16}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{5}\NormalTok{, }
                     \AttributeTok{cex.symbols =} \DecValTok{1}\NormalTok{,}
                     \AttributeTok{angle=}\DecValTok{60}\NormalTok{,}
                     \AttributeTok{xlab =} \StringTok{"Celulas Infectadas (X)"}\NormalTok{, }
                     \AttributeTok{ylab =} \StringTok{"Linfocitos Activados (Y)"}\NormalTok{, }
                     \AttributeTok{zlab =} \StringTok{"Probabilidad"}\NormalTok{,}
                     \AttributeTok{main =} \StringTok{"Distribución Conjunta de }\SpecialCharTok{\textbackslash{}n}\StringTok{ Celulas Infectadas y Linfocitos Activados"}\NormalTok{)}
\FunctionTok{dev.off}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## pdf 
##   2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Añadir texto con los valores de las probabilidades en la parte superior de las barras}
\CommentTok{\# s3d$text(X\_grid, Y\_grid, Z\_vals, labels = round(Z\_vals, 2), pos = 3, col = "black")}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/pmfTrinomial.png"}\NormalTok{, }\AttributeTok{rel\_path =} \ConstantTok{TRUE}\NormalTok{ )}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=0.9\linewidth]{images/pmfTrinomial}

\subsection{La distribución multinomial}\label{la-distribuciuxf3n-multinomial}

Antes de seguir con el estudio de las distribuciones discretas presentamos un caso importante de distribucion multivariante discreta, la \textbf{distribución multinomial}.

\subsubsection{Generación de las observaciones}\label{generaciuxf3n-de-las-observaciones}

Supongamos un experimentoaleatorio que puede producir \(k\) resultados posibles \(A_1, A_2, \dots, A_k\) con probabilidades \(p_1, p_2, \dots, p_k\), tales que \(p_1 + p_2 + \dots + p_k = 1\).

Repetimos el experimento \(n\) veces y llamamos \(X_1, X_2, \dots, X_k\) al número de veces que se presenta \(A_1, A_2, \dots, A_k\).

La distribución conjunta de \(X_1, X_2, \dots, X_k\) recibe el nombre de \textbf{multinomial}.

\subsubsection{Funcion de masa de probabilidad de la distribución multinomial}\label{funcion-de-masa-de-probabilidad-de-la-distribuciuxf3n-multinomial}

El vector \(\mathbf{X} = (X_1, \dots, X_k)\) tiene distribución multinomial de parámetros \(n\) y \(\mathbf{p} = (p_1, \dots, p_k),\) denotado por \(\mathbf{X} \sim \mathrm{M}(n, \mathbf{p})\), con \(n\) entero positivo, \(p_i \geq 0\) y \(\sum_{i=1}^{k} p_i = 1\).

Su función de densidad conjunta es:

\[
f(\mathbf{x}) = P[\mathbf{X} = \mathbf{x}] = \frac{n!}{x_1!x_2!\cdots x_k!} p_1^{x_1} p_2^{x_2} \dots p_k^{x_k}
\]

donde \(x_i\) son enteros no negativos tales que \(\sum_{i=1}^{k} x_i = n\).

\subsubsection{Relación con la distribución binomial}\label{relaciuxf3n-con-la-distribuciuxf3n-binomial}

Esta distribución puede verse como una generalización de la distribución binomial en el que, en lugar de tener dos posibles resultados, tenemos \(r\) resultados posibles.

\subsubsection{Un caso particular: La distribución trinomial}\label{un-caso-particular-la-distribuciuxf3n-trinomial}

Veamos un ejemplo propio del análisis de secuencias en el que se aplica esta distribución:

Si consideramos el alineamiento de dos secuencias \(x, y\) de tamaño \(n\), podemos observar:

\begin{itemize}
\tightlist
\item
  \$A\_1 \$: \(x_i\) alineado con \$y\_i \$, con \$P(A\_1) = p\_1 \$
\item
  \$A\_2 \$: \(x_i\) alineado con ``-'', con \$P(A\_2) = p\_2 \$
\item
  \$A\_3 \$: ``-'' alineado con \$y\_i \$, con \$P(A\_3) = 1 - p\_1 - p\_2 \$
\end{itemize}

La variable \$(X\_1, X\_2) \$, que cuenta el número de veces que se observa \(A_1, A_2\) (con \$X\_3 = n - X\_1 - X\_2 \$), sigue una distribución trinomial de parámetros \(n\), \$p\_1 \$, \$p\_2 \$.

Obsérvese que, dado que el total de observaciones \(n\) está prefijado, aunque haya tres categorías, \(A_1\), \(A_2\), \(A_3\) el número de observaciones de \(A_3\) es el total menos la suma de las observaciones de \(A_1+A_2\). O dicho de otra forma el número de probabilidades que són parámetros de la distribución es \(n-1=2\), lo que junto con \(n\) que es otyro parámetro determina que ``trinomial'' se refiera tanto al total de categorías como al número de parámetros, aunque, en realidad tan sólo hay dos componentes \(X_1\) y \(X_2\) independientes (concepto este que se definirá con precisión más adelante).

Estudiamos los posibles alineamientos de dos secuencias de 5 nucleótidos, en un contexto en el que las probabilidades de \(A_1\) y \(A_2\) son, respectivamente 0.6 y 0.2, es decir una Trinomial M(5; 0.6, 0.2) que dan lugar a la tabla siguiente.

\begin{longtable}[]{@{}ccccccc@{}}
\toprule\noalign{}
\(X_{1} \backslash X_{2}\) & 0 & 1 & 2 & 3 & 4 & 5 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & (0,0,5) & (0,1,4) & (0,2,3) & (0,3,2) & (0,4,1) & (0,5,0) \\
1 & (1,0,4) & (1,1,3) & (1,2,2) & (1,3,1) & (1,4,0) & \\
2 & (2,0,3) & (2,1,2) & (2,2,1) & (2,3,0) & & \\
3 & (3,0,2) & (3,1,1) & (3,2,0) & & & \\
4 & (4,0,1) & (4,1,0) & & & & \\
5 & (5,0,0) & & & & & \\
\end{longtable}

A partir de la tabla anterior podemos determinar las probabilidades conjuntas:

\begin{longtable}[]{@{}ccccccc@{}}
\toprule\noalign{}
\(X_{1} \backslash X_{2}\) & 0 & 1 & 2 & 3 & 4 & 5 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0.0003 & 0.0016 & 0.0032 & 0.0032 & 0.0016 & 0.0003 \\
1 & 0.0048 & 0.0192 & 0.0288 & 0.0192 & 0.0048 & \\
2 & 0.0288 & 0.0864 & 0.0864 & 0.0288 & & \\
3 & 0.0864 & 0.1728 & 0.0864 & & & \\
4 & 0.1296 & 0.1296 & & & & \\
5 & 0.0778 & & & & & \\
\end{longtable}

\subsection{Distribuciones marginales}\label{distribuciones-marginales}

\begin{itemize}
\item
  Dado un vector aleatorio, puede interesar el comportamiento individual de una o cada una de sus componentes \(X_i\).
\item
  La distribución de la componente \(i\)-ésima se denomina \textbf{distribución marginal} de \(X_i\).
\item
  Representa el comportamiento de \(X_i\) sin tener en cuenta las otras componentes, es decir, como si fuera una variable aleatoria unidimensional.
\end{itemize}

\subsubsection{Las marginales están en los márgenes}\label{las-marginales-estuxe1n-en-los-muxe1rgenes}

\begin{itemize}
\tightlist
\item
  El nombre de \textbf{distribución marginal} proviene del hecho de que en una distribución bivariada discreta como la trinomial, los valores de una fila coinciden con los valores de \(X_2\), y todos los de una columna con los de \(X_1\). Los valores en la fila 0 o columna 0 (los márgenes) representan precisamente las distribuciones marginales.
\end{itemize}

\subsubsection{Densidades marginales discretas}\label{densidades-marginales-discretas}

\begin{itemize}
\tightlist
\item
  La densidad marginal de \(X\) es:
\end{itemize}

\[
f_X(x) = f_1(x) = \sum_j f(x, y_j)
\]

y la de \(Y\) es:

\[
f_Y(y) = f_2(y) = \sum_i f(x_i, y)
\]

\subsubsection{Trinomial M(5; 0.6, 0.2): Distribuciones marginales}\label{trinomial-m5-0.6-0.2-distribuciones-marginales}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}
  >{\centering\arraybackslash}p{(\linewidth - 16\tabcolsep) * \real{0.1111}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(X_1 \backslash X_2\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
0
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
4
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
5
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(X_2\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(P[X_2 = x]\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & (0,0,5) & (0,1,4) & (0,2,3) & (0,3,2) & (0,4,1) & (0,5,0) & 0 & 0.0102 \\
1 & (1,0,4) & (1,1,3) & (1,2,2) & (1,3,1) & (1,4,0) & & 1 & 0.0768 \\
2 & (2,0,3) & (2,1,2) & (2,2,1) & (2,3,0) & & & 2 & 0.2304 \\
3 & (3,0,2) & (3,1,1) & (3,2,0) & & & & 3 & 0.3456 \\
4 & (4,0,1) & (4,1,0) & & & & & 4 & 0.2592 \\
5 & (5,0,0) & & & & & & 5 & 0.0778 \\
X\_2 & 0 & 1 & 2 & 3 & 4 & 5 & & 1.0000 \\
\(P[X_2 = x]\) & 0.3277 & 0.4096 & 0.2048 & 0.0512 & 0.0064 & 0.0003 & 1.0000 & \\
\end{longtable}

\subsection{Distribuciones condicionales}\label{distribuciones-condicionales}

\begin{itemize}
\item
  A veces nos interesa la distribución de una componente si conocemos que la otra ha tomado un valor determinado.
\item
  En el ejemplo de los alineamientos, podríamos querer conocer los posibles valores y probabilidades de un alineamiento, si sabemos que hay exactamente un ``gap'' en la secuencia de prueba.
\end{itemize}

\subsubsection{Densidad condicional}\label{densidad-condicional}

¿Qué podemos decir de la distribución de \(Y\) si conocemos el valor de \(X\)?

\[
f(y \mid X = x) = P[Y = y \mid X = x] = \frac{P[X = x, Y = y]}{P[X = x]} = \frac{f(x, y)}{f_X(x)}
\]

siempre que \(f_X(x) > 0\).

\subsubsection{Trinomial M(5; 0.6, 0.2): Distribución condicional}\label{trinomial-m5-0.6-0.2-distribuciuxf3n-condicional}

Distribución de \(X_1\) condicionada a que \(X_2 = 1\).

\begin{longtable}[]{@{}lrrr@{}}
\toprule\noalign{}
\((X_1, 1)\) & \(P(X_1, 1)\) & \(P_{X_2}(1)\) & \(P(X_1 \mid X_2 = 1)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
(0,1,4) & 0.002 & 0.41 & 0.004 \\
(1,1,3) & 0.019 & 0.41 & 0.047 \\
(2,1,2) & 0.086 & 0.41 & 0.211 \\
(3,1,1) & 0.173 & 0.41 & 0.422 \\
(4,1,0) & 0.13 & 0.41 & 0.316 \\
Total & & & 1 \\
\end{longtable}

\subsection{Vectores aleatorios absolutamente continuos}\label{vectores-aleatorios-absolutamente-continuos}

\begin{itemize}
\tightlist
\item
  Diremos que \((X, Y)\) es absolutamente continua si existe una función \(f(x, y)\), llamada \textbf{función de densidad conjunta absolutamente continua} o \textbf{bivariada}, tal que, para todo \((x, y) \in \mathbb{R}^2\),
\end{itemize}

\[
F(x, y) = \int_{-\infty}^{x} \int_{-\infty}^{y} f(u, v)\, du \, dv
\]

\begin{itemize}
\tightlist
\item
  Si existe, la función de densidad absolutamente continua es única.
\end{itemize}

\subsubsection{Propiedades de la función de densidad conjunta}\label{propiedades-de-la-funciuxf3n-de-densidad-conjunta}

\begin{itemize}
\item
  \(f(x, y) \geq 0\)
\item
  La masa total de probabilidad es 1:
\end{itemize}

\[
\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} f(x, y)\, dx\,dy = 1
\]

\begin{itemize}
\tightlist
\item
  Para cualquier conjunto \(S\):
\end{itemize}

\[
P\{(X, Y) \in S\} = \int_S f(x, y) \, dx \, dy
\]

En particular, la probabilidad de que \((X, Y)\) esté en un rectángulo:

\[
P(a_1 < X \leq a_2, b_1 < Y \leq b_2) = \int_{a_1}^{a_2} \int_{b_1}^{b_2} f(x, y) \, dx \, dy
\]

\subsubsection{Densidades marginales en el caso continuo}\label{densidades-marginales-en-el-caso-continuo}

\begin{itemize}
\tightlist
\item
  Las densidades marginales son:
\end{itemize}

\[
f_X(x) = \int_{-\infty}^{\infty} f(x, y) \, dy
\]

\[
f_Y(y) = \int_{-\infty}^{\infty} f(x, y) \, dx
\]

\subsubsection{Densidad condicional en el caso continuo}\label{densidad-condicional-en-el-caso-continuo}

\begin{itemize}
\tightlist
\item
  La densidad de \(Y\) condicionada a un valor de \(X\) es:
\end{itemize}

\[
f(y \mid X = x) = \frac{f(x, y)}{f_X(x)}
\]

siempre que \(f_X(x) > 0\).

\subsubsection{La Distribución Normal Bivariante}\label{la-distribuciuxf3n-normal-bivariante}

El ejemplo más importante de una distribución de probabilidad absolutamente continua para vectores aleatorios es la \textbf{distribución normal bivariante}. Esta distribución describe dos variables aleatorias continuas, \(X\) y \(Y\), cuya relación está modelada por una correlación lineal y tiene forma de campana (gaussiana) en dos dimensiones.

\paragraph{Función de Densidad Conjunta}\label{funciuxf3n-de-densidad-conjunta}

La función de densidad conjunta de la distribución normal bivariante con medias \(\mu_X\), \(\mu_Y\), desviaciones estándar \(\sigma_X\), \(\sigma_Y\) y coeficiente de correlación \(\rho\) es:

\[
f(x, y) = \frac{1}{2 \pi \sigma_X \sigma_Y \sqrt{1 - \rho^2}} \exp \left( -\frac{1}{2(1 - \rho^2)} \left[ \frac{(x - \mu_X)^2}{\sigma_X^2} + \frac{(y - \mu_Y)^2}{\sigma_Y^2} - \frac{2\rho(x - \mu_X)(y - \mu_Y)}{\sigma_X \sigma_Y} \right] \right)
\]

Esta expresión se generaliza fácilmente de la distribución normal univariante, pero en este caso incluye términos adicionales que representan la interacción entre \(X\) y \(Y\).

\paragraph{Ejemplo}\label{ejemplo}

En vez de proporcionar un código para visualizar la distribución normal bivariante podéis seguir este enlace: \url{https://datasciencegenie.com/3d-contour-plots-of-bivariate-normal-distribution/} en donde se extiende lo que acabamos de discutir y se proporciona algunos ejemplos con R.

\paragraph{Distribuciones Marginales}\label{distribuciones-marginales-1}

Para obtener las \textbf{distribuciones marginales} a partir de una \textbf{normal bivariante}, debemos integrar la densidad conjunta sobre una de las variables. Dado que estamos trabajando con una distribución normal bivariante, su densidad conjunta está dada por:

\[
f_{X,Y}(x, y) = \frac{1}{2 \pi \sigma_X \sigma_Y \sqrt{1 - \rho^2}} \exp\left( -\frac{1}{2(1 - \rho^2)} \left[ \frac{(x - \mu_X)^2}{\sigma_X^2} + \frac{(y - \mu_Y)^2}{\sigma_Y^2} - \frac{2\rho(x - \mu_X)(y - \mu_Y)}{\sigma_X \sigma_Y} \right] \right)
\]

Para obtener la \textbf{marginal de \(X\)}, debemos integrar sobre \(Y\):

\[
f_X(x) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dy
\]

Al realizar esta integral, se obtiene que la distribución marginal de \(X\) es:

\[
f_X(x) = \frac{1}{\sqrt{2 \pi \sigma_X^2}} \exp\left( -\frac{(x - \mu_X)^2}{2 \sigma_X^2} \right)
\]

Esto muestra que \(X\) sigue una distribución normal con media \(\mu_X\) y varianza \(\sigma_X^2\), es decir, \(X \sim N(\mu_X, \sigma_X^2)\).

Del mismo modo, para la \textbf{marginal de \(Y\)}, integramos sobre \(X\):

\[
f_Y(y) = \int_{-\infty}^{\infty} f_{X,Y}(x, y) \, dx
\]

La solución de esta integral da:

\[
f_Y(y) = \frac{1}{\sqrt{2 \pi \sigma_Y^2}} \exp\left( -\frac{(y - \mu_Y)^2}{2 \sigma_Y^2} \right)
\]

Lo que significa que \(Y\) sigue una distribución normal con media \(\mu_Y\) y varianza \(\sigma_Y^2\), es decir, \(Y \sim N(\mu_Y, \sigma_Y^2)\).

\paragraph{Ejemplo}\label{ejemplo-1}

Supongamos que tenemos una distribución normal bivariante con los siguientes parámetros:

\begin{itemize}
\tightlist
\item
  \(\mu_X = 100\), \(\sigma_X = 15\)
\item
  \(\mu_Y = 50\), \(\sigma_Y = 10\)
\item
  \(\rho = 0.5\)
\end{itemize}

La densidad conjunta es:

\[
f_{X,Y}(x, y) = \frac{1}{2 \pi (15)(10) \sqrt{1 - 0.5^2}} \exp\left( -\frac{1}{2(1 - 0.5^2)} \left[ \frac{(x - 100)^2}{15^2} + 
       \frac{(y - 50)^2}{10^2} - \frac{2(0.5)(x - 100)(y - 50)}{(15)(10)} \right] \right)
\]

Integrando sobre \(Y\), obtenemos la distribución marginal de \(X\):

\[
f_X(x) = \frac{1}{\sqrt{2 \pi (15^2)}} \exp\left( -\frac{(x - 100)^2}{2 \cdot 15^2} \right)
\]

De manera análoga, la marginal de \(Y\) es:

\[
f_Y(y) = \frac{1}{\sqrt{2 \pi (10^2)}} \exp\left( -\frac{(y - 50)^2}{2 \cdot 10^2} \right)
\]

\subsubsection{Distribuciones Condicionales}\label{distribuciones-condicionales-1}

La distribución condicional de una variable dado un valor específico de la otra también es normal univariante. Por ejemplo, la distribución condicional de \(X\) dado \(Y = y\) es:

\[
X \mid Y = y \sim N \left( \mu_X + \rho \frac{\sigma_X}{\sigma_Y} (y - \mu_Y), (1 - \rho^2)\sigma_X^2 \right)
\]

De forma análoga, la distribución condicional de \(Y\) dado \(X = x\) es:

\[
Y \mid X = x \sim N \left( \mu_Y + \rho \frac{\sigma_Y}{\sigma_X} (x - \mu_X), (1 - \rho^2)\sigma_Y^2 \right)
\]

\paragraph{Ejemplo}\label{ejemplo-2}

Podemos calcular la distribución condicional de \(X\) dado que \(Y = 180\) cm, y mostrar cómo cambia la distribución de \(X\) bajo esta condición:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Valores originales}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{100}\NormalTok{, }\DecValTok{50}\NormalTok{)}
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\NormalTok{rho }\OtherTok{\textless{}{-}} \FloatTok{0.5}

\CommentTok{\# Condicionar X dado Y = 180}
\NormalTok{y\_cond }\OtherTok{\textless{}{-}} \DecValTok{180}
\NormalTok{mu\_cond }\OtherTok{\textless{}{-}}\NormalTok{ mu[}\DecValTok{1}\NormalTok{] }\SpecialCharTok{+} \FloatTok{0.6} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{10}\SpecialCharTok{/}\DecValTok{7}\NormalTok{) }\SpecialCharTok{*}\NormalTok{ (y\_cond }\SpecialCharTok{{-}}\NormalTok{ mu[}\DecValTok{2}\NormalTok{])}
\NormalTok{sigma\_cond }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}} \FloatTok{0.6}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\SpecialCharTok{*} \DecValTok{10}

\CommentTok{\# Mostrar la media y desviación estándar condicionales}
\NormalTok{mu\_cond}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 211.4286
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{sigma\_cond}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8
\end{verbatim}

Esto nos dice que el peso medio de una persona con altura de 180 cm es mayor que el peso medio de la población total, y su desviación estándar es menor debido a la correlación positiva entre peso y altura.

\subsection{Independencia de variables aleatorias}\label{independencia-de-variables-aleatorias}

Una vez introducido el concepto de distribución conjunta pasamos a estudiar un caso particularmente importante de distribución conjunta, la independencia.
De forma aparentemente contradictoria, en este caso, las variables se caracterizan por el hecho de que \emph{no varían conjuntamente} sino que lo hacen \emph{independientemente} las unas de las otras.

De manera intuitiva podemos decir que dos variables aleatorias son independientes si los valores que toma una de ellas no afectan a los de la otra ni a sus probabilidades.

En muchas ocasiones la independencia será evidente a partir del experimento, por ejemplo, es independiente el resultado del lanzamiento de un dado y el de una moneda tres veces. Por tanto las variables:

\begin{itemize}
\tightlist
\item
  \(X_1\): ``Puntuación obtenida con el dado'' y
\item
  \(X_2\): ``Número de caras obtenidas al lanzar tres veces una moneda'' serán variables independientes.
\end{itemize}

En otras ocasiones tenemos una dependencia clara, por ejemplo, al lanzar un dado consideremos las variables

\begin{itemize}
\tightlist
\item
  \(Y_1=\): puntuación del dado,
\item
  \(Y_2=\): variable indicadora de puntuación par.
\end{itemize}

Es evidente que existe una clara dependencia, si sabemos que \(Y=1\), la variable \(X\) sólo puede tomar los valores 2 , 4 o 6 ; si sabemos que \(X=3\), entonces, \(Y=0\) forzosamente.

Algunas veces podemos suponer la existencia de una cierta relación entre variables, aunque sea en forma algo abstracta y sin concretar. Por ejemplo si realizamos unas mediciones sobre unos individuos, las variables altura en cm y peso en Kg probablemente estarán relacionadas, los valores de una influirán en los valores de la otra. Intentar determinar la naturaleza exacta de la relación entre ambas es lo que en estadística conocemos como un problema de correlación (si nos interesa unicamente la asociación) o de regresión (si uqeremos modelizar una variable en función d ela otra).

Si queremos una definición algo más formal, basta con que recordemos que dos sucesos son independientes si la probabilidad de la intersección es igual al producto de probabilidades, aplicando esta definición a sucesos del tipo \(X \leq a\) tenemos la definición siguiente:

\subsubsection{Primera caracterización de la independencia}\label{primera-caracterizaciuxf3n-de-la-independencia}

Diremos que dos variables aleatorias \(X\) e \(Y\) son independientes si y sólo si su función de distribución conjunta puede expresarse como el producto de las funciones de distribución marginales, es decir si

\[
F_{X,Y}(x,y)= P\left( (X \leq x) \cap (Y \leq b)\right)=P(X \leq x) \times P(Y \leq y)=F_{X}(x) \times F_{Y}(y)
\]

Fijémonos que, como en otros casos, la función que nos permite caracterizar una condición de forma general es la función de distribución.

\paragraph{Variables discretas independientes}\label{variables-discretas-independientes}

En el caso de las variables discretas la caracterización de la independencia puede hacerse, además, por las funciones de masa de probabilidad:

Diremos que dos variables aleatorias \textbf{discretas} \(X\) e \(Y\) son independientes si y sólo si su función de masa de probabilidad conjunta puede expresarse como el producto de las funciones de masa de probabilidad marginales, es decir si

\[
f_{X,Y}(x,y)= P\left( (X = x) \cap (Y = y)\right)=P(X = x) \times P(Y = y)=f_{X}(x) \times f_{Y}(y)
\]

\subsubsection{Propiedades de las variables independientes}\label{propiedades-de-las-variables-independientes}

Como consecuencia inmediata de la independencia de \(X\) e \(Y\), se cumple lo siguiente:

\[
P(a<X \leq c \cap b<Y \leq d)=P(a<X \leq c) \cdot P(b<Y \leq d)
\]
Que podría re-enunciarse diciendo que la probabilidad conjunta en un rectangulo definido por los valores ``a, c, b, d'' es el producto de las probabilidades marginales en los segmentos ``ac'', para \(X\) y ``bd'' para \(Y\).

\subsection{Momentos de vectores aleatorios}\label{momentos-de-vectores-aleatorios}

Una vez hemos introducido los vectores aleatorios, que como hemos señalado, son variables aleatorias bi, tri o \(n\)-dimensionales tiene sentido preguntarse como se extienden a dichos vectores los conceptos y propiedades que introdujimos para variables aleatorias unidimensionales.

Ya hemos visto como, para las funciones de probabilidad, la función de densidad o la función de distribución, existen extensiones imediatas, la función de densidad conjunta o la función de distribución conjunmta.

Hemos visto también que, además de dichas extensiones, aparecen nuevos conceptos, que sólo tienen sentido en dos o más dimensiones, como las funciones de densidad condicionales o funciones de densidad marginales.

Al considerar conceptos como la media o la varianza veremos que sucede algo similar:

\begin{itemize}
\tightlist
\item
  Por un lado conceptos como el de esperanza se extiende imediatamente al vector de medias.
\item
  Por otro, conceptos como la varianza, han de tener en cuenta ahora, la posibilidad de variación conjunta entre dos o más variables lo que lleva a introducir magnitudes como la covarianza y la correlación.

  \begin{itemize}
  \tightlist
  \item
    La extensión del concepto de varianza pasa ahora a combinar extensiones y conceptos nuevos en lo que se conoce como matriz de varianzas-covarianzas.
  \end{itemize}
\end{itemize}

\subsubsection{Esperanza de un vector aleatorio o vector de medias}\label{esperanza-de-un-vector-aleatorio-o-vector-de-medias}

La \textbf{esperanza matemática} de un vector aleatorio es un vector que contiene las esperanzas matemáticas de cada una de las componentes de dicho vector.

Si tenemos un vector aleatorio bivariante \(\mathbf{X}=(X_1,X_2)\), su esperanza \(\mathbb{E}(\mathbf{X})\) está dada por:

\[
\mathbb{E}(\mathbf{X})=
\begin{pmatrix}
\mathbb{E}(X_1)\\
\mathbb{E}(X_2)
\end{pmatrix}
\]

Consideremos un experimento en el que estamos midiendo el nivel de expresión génica de dos genes \(X_1\) y \(X_2\) en una muestra de células. Si los niveles promedio de expresión son \(\mu_1=5\) y \(\mu_2=8\), entonces la esperanza del vector aleatorio sería:

\[
\mathbb{E}(\mathbf{X})=
\begin{pmatrix}
5\\
8
\end{pmatrix}
\]

\subsubsection{Covarianza entre dos variables aleatorias}\label{covarianza-entre-dos-variables-aleatorias}

La \textbf{covarianza} entre dos variables aleatorias \(X_1\) y \(X_2\) es una medida del grado de dependencia \emph{lineal} entre ellas.

La covarianza se define como

\[
\text{Cov}(X_1,X_2)=\mathbb{E}[(X_1-\mathbb{E}(X_1))(X_2-\mathbb{E}(X_2))]
\]

Supongamos que estamos midiendo la cantidad de dos metabolitos \(X_1\) y \(X_2\) en una muestra, y queremos saber si sus concentraciones tienden a aumentar o disminuir juntas. Si obtenemos una covarianza de 0.5, y conocemos la escala en que varían los datos, podemos concluir que existe ligera tendencia a que los aumentos en \(X_1\) estén asociados con aumentos en \(X_2\).

\subsubsection{Covarianza y correlación}\label{covarianza-y-correlaciuxf3n}

El ejemplo anterior es claramente insatisfactorio, puesto que valores de 0.5 pueden sugerir una gran dependencia o cas ninguna, segun cual sea la escala o el rango de variación de los valores que se consideran.

Para evitar esta arbitrariedad se introduce la correlación lineal.

La \textbf{correlación} entre dos variables aleatorias es una medida estandarizada del grado de dependencia lineal entre dos variables (es decir de lacovarianza), que toma valores entre -1 y 1 y que se define como:

\[
\text{Corr}(X_1,X_2)=\frac{\text{Cov}(X_1,X_2)}{\sqrt{\text{Var}(X_1)\text{Var}(X_2)}}
\]

En el caso de los metabolitos mencionados anteriormente, si \(\text{Cov}(X_1,X_2)=0.5\), \(\text{Var}(X_1)=2\) y \(\text{Var}(X_2)=3\), podemos calcular la correlación, que valdría:

\[
\text{Corr}(X_1,X_2)=\frac{0.5}{\sqrt{2\times 3}}=\frac{0.5}{\sqrt{6}}\approx 0.204
\]

Esto indica una correlación positiva débil entre las concentraciones de los dos metabolitos.

Obsérvese, sin embargo que si en vez de los valores anteriores para las varianzas de \(X\) e \(Y\) hubiéramos tenido \(\text{Var}(X_1)=1\) y \(\text{Var}(X_2)=.5\) el valor de la correlación habría sido:

\[
\text{Corr}(X_1,X_2)=\frac{0.5}{\sqrt{1\times 0.5}}=\frac{0.5}{\sqrt{0.5}}\approx 0.7071
\]
Este ejemplo muestra como la correlación aporta más información sobre la dependencia lineal, puesto que, además de tener en cuenta la variación conjunta, tiene en cuenta la variabilidad individual de cada componente.

\subsubsection{Matriz de varianzas-covarianzas}\label{matriz-de-varianzas-covarianzas}

La \textbf{matriz de varianzas-covarianzas} de un vector aleatorio \(\mathbf{X}=(X_1,X_2)\) es una matriz que contiene las varianzas de las componentes en la diagonal y las covarianzas fuera de la diagonal. Está definida como:

\[
\text{Cov}(\mathbf{X})=
\begin{pmatrix}
\text{Var}(X_1)&\text{Cov}(X_1,X_2)\\
\text{Cov}(X_2,X_1)&\text{Var}(X_2)
\end{pmatrix}
\]

Siguiendo con el ejemplo de los metabolitos, si \(\text{Var}(X_1)=2\), \(\text{Var}(X_2)=3\), y la covarianza es \(0.5\), la matriz de covarianzas sería:

\[
\text{Cov}(\mathbf{X})=
\begin{pmatrix}
2&0.5\\
0.5&3
\end{pmatrix}
\]

Esto nos indica la dispersión de cada variable y la relación entre ambas.

\textbf{La distribución normal bivariante}

Una de las distribuciones más importantes que describe el comportamiento conjunto de dos variables aleatorias es la \textbf{distribución normal bivariante}.

Un vector aleatorio \(\mathbf{X}=(X_1,X_2)\) tiene una distribución normal bivariante si su función de densidad conjunta está dada por:

\[
f(x_1,x_2)=\frac{1}{2\pi\sigma_1\sigma_2\sqrt{1-\rho^2}}\exp\left(-\frac{1}{2(1-\rho^2)}\left[\frac{(x_1-\mu_1)^2}{\sigma_1^2}-2\rho\frac{(x_1-\mu_1)(x_2-\mu_2)}{\sigma_1\sigma_2}+\frac{(x_2-\mu_2)^2}{\sigma_2^2}\right]\right)
\]

Aquí, \(\mu_1\) y \(\mu_2\) son las medias de \(X_1\) y \(X_2\), \(\sigma_1^2\) y \(\sigma_2^2\) son las varianzas, y \(\rho\) es el coeficiente de correlación.

\subsubsection{Matriz de correlaciones}\label{matriz-de-correlaciones}

La \textbf{matriz de correlaciones} de un vector aleatorio bivariante \(\mathbf{X}=(X_1,X_2)\) es una matriz simétrica \(2\times 2\) que contiene los coeficientes de correlación entre las componentes \(X_1\) y \(X_2\). La correlación mide la relación lineal entre las variables y se define como:

\[
\text{Corr}(X_1,X_2)=\frac{\text{Cov}(X_1,X_2)}{\sqrt{\text{Var}(X_1)\text{Var}(X_2)}}
\]

La matriz de correlaciones \(\text{Corr}(\mathbf{X})\) está dada por:

\[
\text{Corr}(\mathbf{X})=
\begin{pmatrix}
1 & \text{Corr}(X_1,X_2)\\
\text{Corr}(X_2,X_1) & 1
\end{pmatrix}
\]

Dado que \(\text{Corr}(X_1,X_2)=\text{Corr}(X_2,X_1)\), la matriz es simétrica, y los elementos diagonales son siempre \(1\) porque la correlación de una variable consigo misma es \(1\).

\paragraph{Relación con la matriz de covarianzas}\label{relaciuxf3n-con-la-matriz-de-covarianzas}

La matriz de correlaciones está relacionada con la \textbf{matriz de covarianzas} de la forma siguiente:

Si \(\Sigma\) es la matriz de covarianzas de \(\mathbf{X}=(X_1,X_2)\), con \(\Sigma=\begin{pmatrix} \text{Var}(X_1) & \text{Cov}(X_1,X_2)\\ \text{Cov}(X_2,X_1) & \text{Var}(X_2) \end{pmatrix}\), la matriz de correlaciones se obtiene ``normalizando'' cada covarianza dividiendo por el producto de las desviaciones estándar de las respectivas variables:

\[
\text{Corr}(\mathbf{X})=
\begin{pmatrix}
1 & \frac{\text{Cov}(X_1,X_2)}{\sigma_1\sigma_2}\\
\frac{\text{Cov}(X_2,X_1)}{\sigma_1\sigma_2} & 1
\end{pmatrix}
\]

donde \(\sigma_1=\sqrt{\text{Var}(X_1)}\) y \(\sigma_2=\sqrt{\text{Var}(X_2)}\).

Supongamos que medimos dos variables, como la altura \(X_1\) y el peso \(X_2\) de un grupo de personas. Sabemos que:

\begin{itemize}
\tightlist
\item
  \(\text{Var}(X_1)=25\) (varianza de la altura),
\item
  \(\text{Var}(X_2)=100\) (varianza del peso),
\item
  \(\text{Cov}(X_1,X_2)=40\) (covarianza entre altura y peso).
\end{itemize}

La \textbf{matriz de covarianzas} sería:

\[
\Sigma=
\begin{pmatrix}
25 & 40\\
40 & 100
\end{pmatrix}
\]

La correlación entre \(X_1\) y \(X_2\) se calcula como:

\[
\text{Corr}(X_1,X_2)=\frac{40}{\sqrt{25 \times 100}}=\frac{40}{50}=0.8
\]

Por lo tanto, la \textbf{matriz de correlaciones} será:

\[
\text{Corr}(\mathbf{X})=
\begin{pmatrix}
1 & 0.8\\
0.8 & 1
\end{pmatrix}
\]

Esto indica una fuerte correlación positiva entre la altura y el peso de las personas en este grupo. La matriz de correlaciones nos proporciona una forma normalizada de comparar la dependencia entre las variables, sin depender de las unidades de medida.

\subsubsection{Segunda caracterización de la independencia}\label{segunda-caracterizaciuxf3n-de-la-independencia}

La \textbf{independencia} entre dos variables aleatorias \(X_1\) y \(X_2\) puede caracterizarse también a través de sus \textbf{esperanzas} de la siguiente manera:

Dos variables son \textbf{independientes} si la esperanza del producto de ambas es igual al producto de las esperanzas de cada una por separado. Es decir si se verifica que:

\[
\mathbb{E}[X_1 X_2] = \mathbb{E}[X_1] \mathbb{E}[X_2]
\]

Esta propiedad refleja que, cuando las variables son independientes, el valor esperado del producto no se ve afectado por la interacción entre ellas, lo que implica que no hay dependencia entre las dos.

Una consecuencia importante de esta propiedad es cómo afecta a la \textbf{covarianza} entre \(X_1\) y \(X_2\).

Si \(X_1\) y \(X_2\) son \textbf{independientes}, entonces, por la propiedad anterior, \(\mathbb{E}[X_1 X_2] = \mathbb{E}[X_1] \mathbb{E}[X_2]\) lo que, a su vez, significa que la covarianza es cero:

\[
\text{Cov}(X_1, X_2) = \mathbb{E}[X_1]\mathbb{E}[X_2] - \mathbb{E}[X_1]\mathbb{E}[X_2] = 0
\]

Por lo tanto, \textbf{si dos variables son independientes, necesariamente su covarianza es cero}.

Sin embargo, la inversa no es cierta: el hecho de que la covarianza sea cero no implica que las variables sean independientes.

\subsubsection{Relación entre incorrelación e independencia}\label{relaciuxf3n-entre-incorrelaciuxf3n-e-independencia}

Cuando la covarianza entre dos variables es cero, se dice que las variables son \textbf{incorreladas}.
Aunque la \textbf{independencia} implica que las variables son incorreladas, lo contrario no siempre es verdad: dos variables pueden ser incorreladas (tener covarianza cero) pero \textbf{no independientes}.

Un ejemplo clásico es el siguiente: si consideramos una variable aleatoria \(X\) y definimos \(Y = X^2\), entonces, aunque la covarianza entre \(X\) y \(Y\) puede ser cero (especialmente si \(X\) tiene una distribución simétrica alrededor de 0, como la normal estándar), \(X\) y \(Y\) no son independientes, porque el valor de \(Y\) está completamente determinado por \(X\).

Consideremos dos variables aleatorias \(X_1\) y \(X_2\) que siguen una distribución normal conjunta bivariante con media cero:

\[
(X_1, X_2) \sim \mathcal{N}\left(\mathbf{0}, \Sigma \right)
\]

Si la \textbf{matriz de covarianzas} \(\Sigma\) es diagonal, es decir, \(\text{Cov}(X_1, X_2) = 0\), entonces \(X_1\) y \(X_2\) son incorreladas.

En este caso particular, cuando las variables son normales, la incorrelación \textbf{sí} implica independencia, porque en distribuciones normales la ausencia de correlación (covarianza cero) también implica que no hay ninguna dependencia entre las variables.

Sin embargo, en otras distribuciones que no son normales, la incorrelación no garantiza la independencia, lo que subraya la importancia de distinguir entre los dos conceptos.

\newpage

\section{Grandes muestras}\label{grandes-muestras}

\subsection{Introducción: Aproximaciones asintóticas}\label{introducciuxf3n-aproximaciones-asintuxf3ticas}

En estadística y teoría de la probabilidad, el estudio de las grandes muestras juega un papel crucial debido a su relevancia tanto en la definición frecuentista de probabilidad como en la construcción de estimadores en la práctica estadística.

\begin{itemize}
\item
  Desde la perspectiva de la probabilidad frecuentista, la probabilidad se define como el límite de la frecuencia relativa de un evento cuando el número de ensayos tiende a infinito.
\item
  En el contexto de la estadística, las grandes muestras sirven como base para muchas aproximaciones importantes, como las distribuciones de muestreo, las estimaciones de parámetros y la validación de inferencias.
\end{itemize}

La ley de los grandes números y el teorema central del límite son ejemplos clave de teoremas que se fundamentan en el comportamiento de las muestras grandes, proporcionando las bases para muchos de los métodos estadísticos utilizados en la inferencia moderna.

\subsection{Ley de los Grandes Números (Ley débil)}\label{ley-de-los-grandes-nuxfameros-ley-duxe9bil}

La \textbf{ley de los grandes números} establece que, a medida que el tamaño de la muestra aumenta, la media muestral se aproxima a la media de la población.

Formalmente, la ley de los grandes números en su versión débil se enuncia de la siguiente manera:

Sea \(X_1, X_2, \dots, X_n\) una secuencia de variables aleatorias independientes e idénticamente distribuidas (i.i.d.) con esperanza \(\mu = \mathbb{E}[X_i]\) y varianza \(\sigma^2 = \text{Var}(X_i)\), entonces para cualquier \(\epsilon > 0\),

\[
\lim_{n \to \infty} P \left( \left| \frac{1}{n} \sum_{i=1}^n X_i - \mu \right| \geq \epsilon \right) = 0.
\]

Esto significa que, con alta probabilidad, la media muestral \(\frac{1}{n} \sum_{i=1}^n X_i\) se aproxima a \(\mu\) a medida que \(n\) crece.

\subsubsection{Ejemplo}\label{ejemplo-3}

Imaginemos un dado equilibrado. Sabemos que la esperanza de cada lanzamiento es el valor promedio de los números en el dado, que es

\[
\mu = \frac{1+2+3+4+5+6}{6} = 3.5.
\]

Ahora, supongamos que lanzamos el dado repetidamente y calculamos la media de los resultados. Al principio, con pocos lanzamientos, la media puede estar alejada de 3.5, pero a medida que aumentan los lanzamientos, la media se acercará más y más a 3.5, como lo predice la ley de los grandes números. Es decir, a medida que lanzamos más veces el dado, la probabilidad de que la media de los resultados se aleje de 3.5 por más de una cantidad arbitraria disminuye.

Podemos ilustrarlo con el siguiente código de R

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Definir la función para simular lanzamientos de un dado}
\NormalTok{simular\_dado }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(max\_n) \{}
\NormalTok{  medias }\OtherTok{\textless{}{-}} \FunctionTok{numeric}\NormalTok{(max\_n)  }\CommentTok{\# Vector para almacenar las medias muestrales}
  \ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{max\_n) \{}
\NormalTok{    lanzamientos }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, n, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{)  }\CommentTok{\# Lanzar el dado n veces}
\NormalTok{    medias[n] }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(lanzamientos)  }\CommentTok{\# Calcular la media de los lanzamientos}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(medias)}
\NormalTok{\}}

\CommentTok{\# Simular para un tamaño máximo de muestra de 10000 lanzamientos}
\NormalTok{max\_n }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{medias }\OtherTok{\textless{}{-}} \FunctionTok{simular\_dado}\NormalTok{(max\_n)}

\CommentTok{\# Graficar las medias muestrales a medida que n aumenta}
\FunctionTok{png}\NormalTok{(}\StringTok{"images/LLN1.png"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{max\_n, medias, }\AttributeTok{type =} \StringTok{"l"}\NormalTok{, }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{"Número de lanzamientos (n)"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Media muestral"}\NormalTok{,}
     \AttributeTok{main =} \StringTok{"Ley de los Grandes Números}\SpecialCharTok{\textbackslash{}n}\StringTok{ Media de los lanzamientos de un dado"}\NormalTok{, }\AttributeTok{cex.main=}\FloatTok{0.7}\NormalTok{)}
\FunctionTok{abline}\NormalTok{(}\AttributeTok{h =} \FloatTok{3.5}\NormalTok{, }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{lty =} \DecValTok{2}\NormalTok{)  }\CommentTok{\# Línea horizontal en 3.5}
\FunctionTok{dev.off}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## pdf 
##   2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\SpecialCharTok{::}\FunctionTok{include\_graphics}\NormalTok{(}\StringTok{"images/LLN1.png"}\NormalTok{,}\AttributeTok{rel\_path =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\includegraphics[width=0.9\linewidth]{images/LLN1} \end{center}

Este comportamiento es una manifestación intuitiva de la ley débil de los grandes números, ya que nos garantiza que la media muestral se acercará a la media poblacional a medida que el número de observaciones aumente.

\subsection{El teorema central del límite}\label{el-teorema-central-del-luxedmite}

El teorema central del límite (a partir de ahora, TCL) presenta un doble interés. Por un lado, proporciona a la estadística un resultado crucial para abordar el estudio de la distribución asintótica de muchos tipos de variables aleatorias. Como se verá en próximos capítulos, va a resultar básico en la construcción de contrastes de hipótesis y de intervalos de confianza, dos herramientas esenciales en estadística aplicada.

Además, el TCL proporciona una explicación teórica fundamentada a un fenómeno habitual en experimentos reales: las variables estudiadas presentan muchas veces una distribución empírica aproximadamente normal.

El TCL forma parte de un conjunto de propiedades relativas a las convergencias de variables aleatorias. En este tema se estudia sólo un tipo de convergencia, la convergencia en ley, ya que es necesaria para entender el enunciado del TCL. Se descarta, pues, en este documento el estudio de los otros tipos de convergencias (en probabilidad, casi segura, etc.) y el estudio de las leyes de los grandes números.

Posiblemente el lector con poca formación en análisis matemático hallará alguna dificultad en la primera lectura de la definición de convergencia en ley y en el enunciado del TCL. Si es este el caso, los ejemplos incluidos han de ayudar en su comprensión. Consideramos al TCL un resultado básico con el que hay que familiarizarse, ya que se aplicará repetidamente en los próximos temas.

\subsubsection{Sumas de variables aleatorias}\label{sumas-de-variables-aleatorias}

El TCL estudia el comportamiento de las sumas de variables aleatorias. En temas anteriores se han visto ya ejemplos de sumas de variables aleatorias.

Formalmente, la suma de dos variables aleatorias corresponde a la siguiente aplicación: si \(X_{1}\) y \(X_{2}\) son dos variables aleatorias definidas sobre \(\Omega\), la suma es:

\[
\begin{aligned}
X_{1}+X_{2}: & \Omega \rightarrow \mathbb{R} \\
& \omega \mapsto X_{1}(\omega)+X_{2}(\omega)
\end{aligned}
\]

La suma de dos variables puede extenderse sin dificultad a sumas de tres, cuatro,\ldots{} y, en general, \(n\) variables aleatorias.

El TCL se ocupa de las sucesiones de variables aleatorias. En el contexto del TCL una sucesión corresponde a un conjunto donde el primer elemento es una variable aleatoria, el segundo elemento es la suma de dos variables aleatorias, el tercero es la suma de tres variables aleatorias, y así sucesivamente.

Una sucesión es un conjunto de elementos infinitos, que se designan simbólicamente mediante \(\left\{X_{n}\right\}\).
Cada uno de los elementos de la sucesión (que es una variable aleatoria) lleva asociada una determinada función de distribución:

\[
X_{n} \rightarrow F_{n}
\]

Así pues, la sucesión de variables aleatorias lleva asociada una secuencia paralela de funciones de distribución.

\subsubsection{Definición de convergencia en ley}\label{definiciuxf3n-de-convergencia-en-ley}

La siguiente definición se ocupa del comportamiento de las sucesiones.
Sea \(\left\{X_{n}\right\}\) una sucesión de variables aleatorias, y sea \(\left\{F_{n}\right\}\) la correspondiente sucesión de funciones de distribución. Se dice que \(\left\{X_{n}\right\}\) converge en ley a una variable aleatoria \(X\) de función de distribución \(F\) si:

\[
\lim _{n \rightarrow \infty} F_{n}(x)=F(x) \quad \text { para todo } \mathrm{x} \text { donde } F \text { es contínua. }
\]

Se indica que la sucesión converge en ley mediante el símbolo:

\[
X_{n} \stackrel{\mathrm{L}}{\rightarrow} X
\]

El significado de la definición es que, al aumentar arbitrariamente \(n\), las sucesivas funciones de distribución de la secuencia se aproximan a la distribución \(F\) de la variable \(X\).

En los ejemplos se presentan gráficamente algunas situaciones donde diferentes sucesiones de variables aleatorias convergen en ley a una variable aleatoria normal.

\subsubsection{Enunciado del teorema central del límite}\label{enunciado-del-teorema-central-del-luxedmite}

A continuación se presenta el enunciado del TCL en la versión de Lindeberg y Lévy.
Teorema:
Sea \(X_{1}, X_{2}, \ldots, X_{n}\), un conjunto de variables aleatorias independientes idénticamente distribuidas, cada una de ellas con función de distribución \(F\), y supongamos que \(E\left(X_{k}\right)\) \(=\mu \mathrm{y} \operatorname{var}\left(X_{k}\right)=\sigma^{2}\) para cualquier elemento del conjunto. Si designamos a la suma normalizada de \(n\) términos con el símbolo:

\[
S_{n}^{*}=\frac{X_{1}+X_{2}+\cdots+X_{n}-n \mu}{\sigma \sqrt{n}}
\]

entonces la sucesión de sumas normalizadas converge en ley a la variable aleatoria normal tipificada \(\mathrm{Z} \sim N(0,1)\), es decir:

\[
S_{n}^{*} \xrightarrow{\mathrm{L}}
\]

El teorema anterior tiene dos importantes corolarios:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Si consideramos la suma ordinaria de las \(n\) variables aleatorias, es decir, \(S_{n}=X_{1}+X_{2}+\ldots+X_{n}\), entonces la sucesión de sumas ordinarias converge en ley a una normal de media \(n \mu\) y varianza \(n \sigma^{2}\).
\item
  Si consideramos el promedio de las \(n\) variables aleatorias, es decir, \(n^{-1} S_{n}\), entonces la sucesión de promedios converge en ley a una normal de media \(\mu\) y varianza \(n^{-1} \sigma^{2}\).
\end{enumerate}

\paragraph{Comentarios al teorema:}\label{comentarios-al-teorema}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La convergencia a la normal tipificada se produce con cualquier tipo de variable que cumpla las condiciones del teorema, sea discreta o absolutamente continua.
\item
  Un sinónimo para indicar que una sucesión converge en ley a una normal es señalar que es asintóticamente normal.
\item
  El TCL presenta el comportamiento de sumas infinitas de variables aleatorias. Veremos posteriormente como interpretar el resultado para valores finitos.
\item
  Existen otras versiones del TCL dónde se relajan las condiciones de la versión de Lindeberg y Lévy, que, como se ha visto, obliga a las variables aleatorias a tener idénticas medias y varianzas. Dichas versiones del TCL necesitan el conocimiento de conceptos matemáticos que exceden el nivel al que se orienta Statmedia, y por esta razón se omite su enunciado.
\end{enumerate}

\subsubsection{Algunos ejemplos de aplicación del TCL}\label{algunos-ejemplos-de-aplicaciuxf3n-del-tcl}

\paragraph{Normalidad asintótica de la Binomial.}\label{normalidad-asintuxf3tica-de-la-binomial.}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Parámetros de la distribución binomial}
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{1000}  \CommentTok{\# Número de ensayos}
\NormalTok{p }\OtherTok{\textless{}{-}} \FloatTok{0.5}   \CommentTok{\# Probabilidad de éxito}
\NormalTok{size }\OtherTok{\textless{}{-}} \DecValTok{10000}  \CommentTok{\# Número de simulaciones}

\CommentTok{\# Generar una variable aleatoria binomial}
\NormalTok{binomial\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rbinom}\NormalTok{(size, n, p)}

\CommentTok{\# Estimación de la media y la desviación estándar de la distribución binomial}
\NormalTok{mean\_binom }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{*}\NormalTok{ p}
\NormalTok{sd\_binom }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(n }\SpecialCharTok{*}\NormalTok{ p }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ p))}

\CommentTok{\# Generar la distribución normal aproximada}
\NormalTok{normal\_sample }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(size, }\AttributeTok{mean =}\NormalTok{ mean\_binom, }\AttributeTok{sd =}\NormalTok{ sd\_binom)}

\CommentTok{\# Graficar los histogramas de la binomial y la normal}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{))  }\CommentTok{\# Organizar gráficos en dos paneles}

\CommentTok{\# Histograma de la muestra binomial}
\FunctionTok{hist}\NormalTok{(binomial\_sample, }\AttributeTok{breaks =} \DecValTok{50}\NormalTok{, }\AttributeTok{probability =} \ConstantTok{TRUE}\NormalTok{, }
     \AttributeTok{col =} \FunctionTok{rgb}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, n), }
     \AttributeTok{main =} \StringTok{"Distribución Binomial"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Valor"}\NormalTok{, }
     \AttributeTok{ylab =} \StringTok{"Densidad"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{density}\NormalTok{(binomial\_sample), }\AttributeTok{col =} \StringTok{"blue"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}

\CommentTok{\# Histograma de la distribución normal aproximada}
\FunctionTok{hist}\NormalTok{(normal\_sample, }\AttributeTok{breaks =} \DecValTok{50}\NormalTok{, }\AttributeTok{probability =} \ConstantTok{TRUE}\NormalTok{, }
     \AttributeTok{col =} \FunctionTok{rgb}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, n), }
     \AttributeTok{main =} \StringTok{"Distribución Normal Aproximada"}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"Valor"}\NormalTok{, }
     \AttributeTok{ylab =} \StringTok{"Densidad"}\NormalTok{)}
\FunctionTok{lines}\NormalTok{(}\FunctionTok{density}\NormalTok{(normal\_sample), }\AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{FundamentosInferenciaEstadistica_files/figure-latex/unnamed-chunk-15-1.pdf}}

\paragraph{Normalidad asintótica de la suma de puntuaciones de un dado}\label{normalidad-asintuxf3tica-de-la-suma-de-puntuaciones-de-un-dado}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Parámetros de la simulación}
\NormalTok{num\_simulaciones }\OtherTok{\textless{}{-}} \DecValTok{10000}  \CommentTok{\# Número de simulaciones}
\NormalTok{num\_lanzamientos }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1000}\NormalTok{, }\DecValTok{10000}\NormalTok{)  }\CommentTok{\# Diferentes tamaños de muestra}

\CommentTok{\# Función para simular la suma de las puntuaciones de un dado}
\NormalTok{simular\_suma\_dado }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(n) \{}
\NormalTok{  suma }\OtherTok{\textless{}{-}} \FunctionTok{rowSums}\NormalTok{(}\FunctionTok{matrix}\NormalTok{(}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{6}\NormalTok{, n }\SpecialCharTok{*}\NormalTok{ num\_simulaciones, }\AttributeTok{replace =} \ConstantTok{TRUE}\NormalTok{), }
                        \AttributeTok{ncol =}\NormalTok{ n))  }\CommentTok{\# Simulación de las sumas}
  \FunctionTok{return}\NormalTok{(suma)}
\NormalTok{\}}

\CommentTok{\# Graficar las distribuciones de las sumas para diferentes tamaños de muestra}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{))  }\CommentTok{\# Organizar gráficos en 2x2}

\ControlFlowTok{for}\NormalTok{ (n }\ControlFlowTok{in}\NormalTok{ num\_lanzamientos) \{}
\NormalTok{  suma\_dado }\OtherTok{\textless{}{-}} \FunctionTok{simular\_suma\_dado}\NormalTok{(n)}
  \CommentTok{\# Histograma de la suma de las puntuaciones del dado}
  \FunctionTok{hist}\NormalTok{(suma\_dado, }\AttributeTok{breaks =} \DecValTok{50}\NormalTok{, }\AttributeTok{probability =} \ConstantTok{TRUE}\NormalTok{, }
       \AttributeTok{col =} \FunctionTok{rgb}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\FloatTok{0.5}\NormalTok{), }\AttributeTok{xlim =} \FunctionTok{c}\NormalTok{(}\FunctionTok{min}\NormalTok{(suma\_dado), }\FunctionTok{max}\NormalTok{(suma\_dado)), }
       \AttributeTok{main =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Suma de"}\NormalTok{, n, }\StringTok{"lanzamientos de un dado"}\NormalTok{), }
       \AttributeTok{xlab =} \StringTok{"Suma de puntuaciones"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"Densidad"}\NormalTok{)}
  \CommentTok{\# Superponer la curva de densidad normal (aproximación asintótica)}
\NormalTok{  mean\_dado }\OtherTok{\textless{}{-}} \FloatTok{3.5} \SpecialCharTok{*}\NormalTok{ n  }\CommentTok{\# Media esperada de la suma (media de un dado es 3.5)}
\NormalTok{  sd\_dado }\OtherTok{\textless{}{-}} \FunctionTok{sqrt}\NormalTok{(n }\SpecialCharTok{*}\NormalTok{ (}\DecValTok{35} \SpecialCharTok{/} \DecValTok{12}\NormalTok{))  }\CommentTok{\# Desviación estándar de la suma (varianza de un dado es 35/12)}
  \FunctionTok{curve}\NormalTok{(}\FunctionTok{dnorm}\NormalTok{(x, }\AttributeTok{mean =}\NormalTok{ mean\_dado, }\AttributeTok{sd =}\NormalTok{ sd\_dado), }
        \AttributeTok{col =} \StringTok{"red"}\NormalTok{, }\AttributeTok{lwd =} \DecValTok{2}\NormalTok{, }\AttributeTok{add =} \ConstantTok{TRUE}\NormalTok{)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{FundamentosInferenciaEstadistica_files/figure-latex/unnamed-chunk-16-1.pdf}}

\subsubsection{Casos particulares más notables}\label{casos-particulares-muxe1s-notables}

Aunque el TCL tiene multitud de casos particulares interesantes, son especialmente relevantes para el desarrollo de los próximos temas los siguientes casos:

\paragraph{\texorpdfstring{Promedio de \(\boldsymbol{n}\) variables aleatorias}{Promedio de \textbackslash boldsymbol\{n\} variables aleatorias}}\label{promedio-de-boldsymboln-variables-aleatorias}

Al considerar \(n\) variables independientes, todas con la misma distribución, cada una de ellas con esperanza igual a \(\mu\) y varianza igual a \(\sigma^{2}\), el promedio es asintóticamente normal con media \(\mu\) y varianza \(n^{-1} \sigma^{2}\). Este resultado proporciona una distribución asintótica a la media de \(n\) observaciones en el muestreo aleatorio simple que se estudiará en el próximo tema.

\paragraph{\texorpdfstring{Binomial de parámetros \(n\) y \(p\)}{Binomial de parámetros n y p}}\label{binomial-de-paruxe1metros-n-y-p}

Es asintóticamente normal con media \(n p\) y varianza \(n p\) (1-p). Históricamente (de Moivre, 1733), es el primer resultado demostrado de convergencia a una normal.

\paragraph{\texorpdfstring{Poisson de parámetro \(n \lambda\)}{Poisson de parámetro n \textbackslash lambda}}\label{poisson-de-paruxe1metro-n-lambda}

Es asintóticamente normal con media \(n \lambda\) y varianza \(n \lambda\).

\subsubsection{Interpretación del teorema central del límite}\label{interpretaciuxf3n-del-teorema-central-del-luxedmite}

El TCL hace referencia a sucesiones infinitas, por tanto, la igualdad de las distribuciones se alcanza sólo en el límite, y hace mención a una distribución final teórica o de referencia.

Sin embargo, puede utilizarse esta distribución final de referencia para aproximar distribuciones correspondientes a sumas finitas. Algunos casos particulares importantes (binomial, Poisson, etc.) alcanzan grados de aproximación suficientes para sumas con no demasiados términos.

Los resultados que se indican a continuación son, por tanto, aproximaciones que se consideran usualmente suficientes, pero conllevan errores numéricos de aproximación.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Binomial: aproximar si \(n \geq 30\) y \(0.1 \leq p \leq 0.9\) a una normal de media \(n p\), varianza \(n p(1-p)\). Ver aquí más detalles.
\item
  Poisson: aproximar si \(\lambda \geq 10\) a una normal de media \(\lambda\) y varianza \(\lambda\). Ver aquí más detalles.
\end{enumerate}

Desde \href{https://github.com/ASPteaching/simple-CLT-Demo}{este enlace} puede accederse a un repositorio de github desde donde descargar una aplicación Shiny que permite ilustrar el teorem central del límite para distintas distribuciones, con muestras de distinto tamaño y parámetros de valores distintos.

Un poco de práctica con la aplicación permite ver que a la larga si el tamaño muestral es lo suficientemente grande, la suma o la media de los valores se distribuye claramente como una distribución normal.

Esto, además, va a depender del valor de los parámetros. Así por ejemplo, para aproximar una distribución de Poisson de parámetro \(\lambda=1\) por una normal, necesitaríamos un tamaño muestral mayor que si, con el mismo tamaño, tenemos una ley de Poisson de parámetro \(\lambda=10\).

\begin{center}\includegraphics[width=1\linewidth]{images/simPoisson_1_11} \end{center}

Una idea en la que debemos insistir es que cuando aproximaos una distribución de Poisson por una normal, podemos visualizarlo pensando en que estamos sumando muestras de unaa ley de Poisson de parámetro inferior

Por ejemplo en la figura vemos que, aunque la muestra individual con \(\lambda=1\) no tiene aspecto de normal, cuando sumamos las 11 observacion, las sumas tienden a distribuirse normalmente.

Es por esto que decimos que en virtd del TCK una distribución de Poisson de parámetro \(\lambda=11\) puede considerarse aproximadamente normal, porque podemos visualizarla como 11 distribuciones no normales cuya suma, en virtud del TCL tienden a la normalidad.

\subsubsection{Acerca de las variables aproximadamente normales}\label{acerca-de-las-variables-aproximadamente-normales}

En general, cuando se estudia en experimentos reales una determinada variable no se conoce su distribución teórica. Sin embargo, puede establecerse su distribución empirica a partir de una muestra más o menos amplia.

Una forma habitual de presentar la distribución empírica es construir el histograma de clases de dicha variable. Es un hecho conocido desde el siglo XIX que esta distribución empírica presenta muchas veces una forma que es aproximadamente normal. Por ejemplo, al realizar un estudio sobre el peso de adultos varones de dieciocho años en Catalunya, se observó la distribución siguiente en la muestra:

\begin{center}\includegraphics[width=1\linewidth]{images/pesosVaronesCat} \end{center}

El TCL permite dar una explicación a este fenómeno. La variable peso de un adulto viene determinada en cada individuo por la conjunción de multitud de diferentes factores. Algunos de estos factores son ambientales (dietas, ejercicio, enfermedades, etc.) y otros son congénitos. Con el nivel actual de conocimiento no se pueden desglosar completamente todos los factores que intervienen, pero puede aceptarse en cambio que la variable peso es el resultante de la suma de diferentes variables primarias, congénitas o ambientales, y que posiblemente no todas tienen el mismo grado de influencia. Seguramente, estas variables primarias tampoco tienen la misma media, varianza o, incluso, la misma distribución.

La versión del TCL que se ha presentado aquí exige estas condiciones para la convergencia a la normal, pero, como ya se ha comentado antes otras versiones más elaboradas del TCL permiten modelar la suma de variables de forma menos restringida. En este contexto, al considerar la variable peso como una suma más o menos extensa (pero finita) de diferentes variables primarias, es esperable que ocurra que la variable resultante, el peso, siga una distribución aproximadamente normal.

De forma similar es explicable la normalidad aproximada que se observa en muchas variables biométricas (pesos, alturas, longitudes, concentraciones de metabolitos, distribuciones de edad, etc.) así cómo en muchos otros contextos (distribución de rentas, errores de medición, etc.). A pesar de esta ubicuidad de la distribución normal, el lector no debe inferir que es forzosamente, ni mucho menos, la distribución de referencia en todo estudio aplicado.

\newpage

\section{Introducción a la inferencia estadística}\label{introducciuxf3n-a-la-inferencia-estaduxedstica}

\subsection{Inferencia estadística}\label{inferencia-estaduxedstica}

El cálculo de probabilidades proporciona el marco matemático para modelizar fenómenos en los que interviene el azar. En este contexto, partimos de un espacio de probabilidad \((\Omega, \mathcal{A}, P)\) y una variable aleatoria \(X: \Omega \to \mathbb{R}\).\\
Cuando su distribución es conocida, podemos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  realizar cálculos deductivos (por ejemplo, probabilidades o cuantiles),
\item
  modelizar fenómenos aleatorios usando distribuciones que consideramos razonables.
\end{enumerate}

Por ejemplo, si asumimos que el peso de los recién nacidos se distribuye como una \(N(\mu=3\text{ kg}, \sigma=0.25\text{ kg})\), podemos calcular la probabilidad de que un recién nacido pese entre 2.9 y 3.1 kg, o determinar un intervalo que contenga al 50\% o al 95\% de las observaciones.

En todos estos ejemplos, \textbf{partimos de un modelo probabilístico conocido} y, a partir de él, obtenemos conclusiones.

En inferencia estadística ocurre lo contrario:\\
\textbf{tenemos una muestra \((x_1, \ldots, x_n)\) y queremos aprender sobre la distribución desconocida que generó esos datos.}\\
No es factible pesar \emph{todos} los recién nacidos ni medir exhaustivamente todos los individuos de una población. La idea es que una muestra bien tomada debe contener información suficiente para decir algo sobre la población.

Así, el objetivo de la inferencia estadística es:

\textbf{Obtener información sobre la distribución de probabilidad de un fenómeno a partir de observaciones parciales.}

\subsection{Problemas de inferencia estadística}\label{problemas-de-inferencia-estaduxedstica}

Según el tipo de conclusión que deseemos extraer, distinguimos tres tipos de problemas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \textbf{Estimación puntual.}\\
  Queremos obtener un valor numérico que estime una característica desconocida de la población (media, proporción, varianza\ldots).
\item
  \textbf{Estimación por intervalo.}\\
  Queremos determinar un intervalo dentro del cual es razonable pensar que se encuentra el parámetro, con un cierto nivel de confianza.
\item
  \textbf{Contraste de hipótesis.}\\
  Queremos decidir si los datos son compatibles con una afirmación sobre la población.

  \begin{itemize}
  \tightlist
  \item
    \emph{Paramétrico}: la afirmación es sobre parámetros.
  \item
    \emph{No paramétrico}: la afirmación es sobre la forma de la distribución.
  \end{itemize}
\end{enumerate}

Estos tres tipos de problemas constituyen la base del resto del curso y de gran parte de la estadística clásica.

\subsection{Distribución de la población}\label{distribuciuxf3n-de-la-poblaciuxf3n}

En toda situación inferencial existe un cierto grado de desconocimiento sobre la distribución que rige el fenómeno. Consideramos una variable aleatoria \(X\) con distribución \(F\), conocida solo parcialmente.

A menudo expresamos este desconocimiento mediante una \textbf{familia de distribuciones}:

\[
X \sim F \in \mathcal{F},
\]

donde \(\mathcal{F}\) puede ser, por ejemplo:

\begin{itemize}
\tightlist
\item
  todas las distribuciones normales,
\item
  todas las distribuciones simétricas,
\item
  todas las distribuciones discretas sobre \(\mathbb{N}\).
\end{itemize}

Un caso muy habitual es cuando la distribución está determinada por uno o varios parámetros desconocidos. Entonces escribimos:

\[
\{\,F_\theta : \theta \in \Theta \subset \mathbb{R}^k \,\}.
\]

A esta familia la llamamos \textbf{modelo estadístico}: describe las distribuciones posibles para los datos.

\subsubsection{Ejemplo}\label{ejemplo-4}

La vida útil de un componente electrónico que no envejece puede modelizarse con una distribución de Weibull:

\[
f_\theta(x) =
\begin{cases}
\alpha \beta x^{\beta-1} e^{-\alpha x^\beta}, & x\ge 0,\\[4pt]
0, & x<0.
\end{cases}
\]

La familia de distribuciones asociada es

\[
\mathcal{F}=\left\{F_{\theta}: \theta=(\alpha, \beta) \in(0, \infty) \times(0, \infty)\right\}
\]

\subsection{Muestra aleatoria simple}\label{muestra-aleatoria-simple}

\textbf{Ejemplo: Variabilidad entre muestras}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{))}
\ControlFlowTok{for}\NormalTok{(i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{)\{}
\NormalTok{  x }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{30}\NormalTok{,}\DecValTok{10}\NormalTok{,}\DecValTok{2}\NormalTok{)}
  \FunctionTok{hist}\NormalTok{(x, }\AttributeTok{main=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Muestra"}\NormalTok{,i))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{FundamentosInferenciaEstadistica_files/figure-latex/unnamed-chunk-19-1.pdf}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

Para estudiar un problema inferencial analizamos una muestra de tamaño \(n\).\\
Seleccionamos \(n\) individuos de la población:

\[
\omega_1,\omega_2,\ldots,\omega_n,
\]

y observamos en ellos la variable de interés \(X\), obteniendo los valores muestrales:

\[
X(\omega_1)=x_1,\; X(\omega_2)=x_2,\; \ldots,\; X(\omega_n)=x_n.
\]

En términos probabilísticos, consideramos que estos valores proceden de variables aleatorias:

\[
X_1, X_2, \ldots, X_n,
\]

todas con la \textbf{misma distribución} que \(X\) y \textbf{mutuamente independientes}.

\subsubsection{Definición (Muestra aleatoria simple)}\label{definiciuxf3n-muestra-aleatoria-simple}

Una muestra aleatoria simple (m.a.s.) de tamaño \(n\) de una variable aleatoria \(X\sim F\) es una colección:

\[
X_1, X_2, \ldots, X_n \stackrel{\text{i.i.d.}}{\sim} X.
\]

La realización de la muestra es el vector de valores observados:

\[
(x_1,x_2,\ldots,x_n)\in\mathbb{R}^n.
\]

\subsubsection{Distribución de la muestra}\label{distribuciuxf3n-de-la-muestra}

La muestra completa puede interpretarse como un vector aleatorio \(n\)-dimensional:

\[
\mathbf{X}=(X_1,\ldots,X_n).
\]

Su distribución conjunta es:

\[
G(x_1,\ldots,x_n) = F(x_1)\cdots F(x_n),
\]

gracias a la independencia.

\subsubsection{Casos particulares}\label{casos-particulares}

\begin{itemize}
\tightlist
\item
  \textbf{Variable discreta}:
\end{itemize}

\[
p_G(x_1,\ldots,x_n)=\prod_{i=1}^n p_F(x_i).
\]

\begin{itemize}
\tightlist
\item
  \textbf{Variable absolutamente continua}:
\end{itemize}

\[
g(x_1,\ldots,x_n)=\prod_{i=1}^n f(x_i).
\]

\subsubsection{Ejemplo}\label{ejemplo-5}

Una moneda con probabilidad \(\theta\) de salir cara define la variable:

\[
X =
\begin{cases}
1,& \text{si sale cara},\\
0,& \text{si sale cruz.}
\end{cases}
\]

Con \(X\sim B(1,\theta)\).\\
Si lanzamos 3 veces, la distribución conjunta de \((X_1,X_2,X_3)\) viene dada por:

\[
g_\theta(x_1,x_2,x_3)
= \theta^{x_1+x_2+x_3}(1-\theta)^{3-(x_1+x_2+x_3)}.
\]

\subsection{Estadísticos}\label{estaduxedsticos}

Para extraer información sobre la población definimos funciones de la muestra llamadas \textbf{estadísticos}.

\subsubsection{Definición}\label{definiciuxf3n}

Dada una muestra i.i.d. \(X_1,\ldots,X_n\), un estadístico es cualquier variable aleatoria de la forma:

\[
T = T(X_1,\ldots,X_n),
\]

que \textbf{no depende de parámetros desconocidos}.

Un \textbf{estimador} de un parámetro \(\theta\) es un estadístico cuyo rango está incluido en el espacio de parámetros \(\Theta\).

\subsection{Distribución en el muestreo de un estadístico}\label{distribuciuxf3n-en-el-muestreo-de-un-estaduxedstico}

Dado un estadístico \(T(X_1,\ldots,X_n)\), su \textbf{distribución de muestreo} es la distribución de probabilidad de dicho estadístico cuando repetimos el procedimiento de muestreo.

Por ejemplo:

\[
P\left(T(X_1,\ldots,X_n)>t_0\right).
\]

Calcular esta distribución puede ser sencillo o extremadamente difícil según la forma de \(T\) y la distribución poblacional \(F\).

Métodos típicos para obtenerla:

\begin{itemize}
\tightlist
\item
  cambio de variable,
\item
  transformaciones,
\item
  uso de la función generadora de momentos,
\item
  Teorema Central del Límite.
\end{itemize}

\subsubsection{Ejemplo}\label{ejemplo-6}

Sea \(X\) una variable con densidad:

\[
f_\theta(x) = e^{-(x-\theta)} e^{-e^{-(x-\theta)}},\qquad \theta\in\mathbb{R}.
\]

Consideramos:

\[
T = \sum_{i=1}^n e^{-X_i}.
\]

La transformación \(Y=e^{-X}\) sigue una exponencial de parámetro \(e^{-\theta}\). Por tanto, la suma \(T\) sigue una distribución Gamma \(\Gamma(e^{-\theta}, n)\).

\subsubsection{Ejemplo}\label{ejemplo-7}

Sea \(X\sim \text{Poisson}(\lambda)\), y \(\bar X\) la media muestral de \(n\) observaciones.

Como \(\sum X_i\sim \text{Poisson}(n\lambda)\), entonces:

\[
P(\bar X=r)
= P\left(\sum X_i = nr\right)
= \frac{e^{-n\lambda}(n\lambda)^{nr}}{(nr)!}.
\]

\subsubsection{Ejemplo}\label{ejemplo-8}

Simulación de medias muestrales para visualizar su distribución:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{sim }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{5000}\NormalTok{, }\FunctionTok{mean}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{30}\NormalTok{, }\AttributeTok{mean =} \DecValTok{3}\NormalTok{, }\AttributeTok{sd =} \FloatTok{0.25}\NormalTok{)))}
\FunctionTok{hist}\NormalTok{(sim, }\AttributeTok{breaks =} \DecValTok{30}\NormalTok{, }\AttributeTok{main =} \StringTok{"Distribución en el muestreo de la media"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{FundamentosInferenciaEstadistica_files/figure-latex/unnamed-chunk-20-1.pdf}}

Aquí \(\theta=(\alpha,\beta)\in(0,\infty)^2\).

\textbf{Ejemplo 2.}\\
Queremos estimar la masa \(\mu\) de partículas observadas en una cámara de burbujas. Observamos mediciones:

\[
x_i = \mu + \varepsilon_i,\qquad i=1,\ldots,n,
\]

donde los errores \(\varepsilon_i\) son simétricos.

\begin{itemize}
\tightlist
\item
  Enfoque paramétrico:
\end{itemize}

\[
X\sim N(0,\sigma),\qquad \sigma>0.
\]

\begin{itemize}
\tightlist
\item
  Enfoque no paramétrico:
\end{itemize}

\[
X \sim F \in\{\text{distribuciones simétricas}\}.
\]

Ambos enfoques son válidos según el grado de simplificación que aceptemos.

\subsection{La distribución empírica}\label{la-distribuciuxf3n-empuxedrica}

A partir de una muestra \(X_1,\ldots,X_n\) podemos asociar una distribución particular basada exclusivamente en las observaciones:

\[
F_n(x) = \frac{k(x)}{n},
\]

donde \(k(x)\) es el número de datos muestrales menores o iguales que \(x\).\\
Esta distribución se denomina \textbf{distribución empírica}.

En la práctica, ordenamos la muestra:

\[
x_{(1)} \le x_{(2)} \le \cdots \le x_{(n)},
\]

y definimos:

\[
F_n(x) =
\begin{cases}
0, & x<x_{(1)},\\[4pt]
k/n, & x_{(k)} \le x < x_{(k+1)},\\[4pt]
1, & x \ge x_{(n)}.
\end{cases}
\]

\subsubsection{Ejemplo}\label{ejemplo-9}

Muestra:

\[
5.1,\; 3.4,\; 1.2,\; 17.6,\; 2.1,\; 16.4,\; 4.3.
\]

Ordenada:

\[
1.2,\; 2.1,\; 3.4,\; 4.3,\; 5.1,\; 16.4,\; 17.6.
\]

Podemos representarla con R:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{5.1}\NormalTok{, }\FloatTok{3.4}\NormalTok{, }\FloatTok{1.2}\NormalTok{, }\FloatTok{17.6}\NormalTok{, }\FloatTok{2.1}\NormalTok{, }\FloatTok{16.4}\NormalTok{, }\FloatTok{4.3}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(}\FunctionTok{ecdf}\NormalTok{(x), }\AttributeTok{main=}\StringTok{"Distribución empírica"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{FundamentosInferenciaEstadistica_files/figure-latex/unnamed-chunk-21-1.pdf}}

La distribución empírica depende \textbf{solo de los datos observados} y no coincide necesariamente con la distribución poblacional ni con la distribución conjunta del muestreo.

\subsection{Momentos muestrales}\label{momentos-muestrales}

Sea \(F_n\) la distribución empírica. Sus momentos se denominan \textbf{momentos muestrales}:

\[
a_k = \frac{1}{n}\sum_{i=1}^n x_i^k,
\]

y los momentos muestrales centrados:

\[
b_k = \frac{1}{n}\sum_{i=1}^n (x_i - \bar x)^k.
\]

\subsubsection{Observaciones}\label{observaciones}

\begin{itemize}
\item
  El momento muestral de orden 1 es la \textbf{media muestral}:
  \[
  a_1 = \bar x.
  \]
\item
  El momento muestral centrado de orden 2 es la \textbf{varianza muestral}:
  \[
  b_2 = \frac{1}{n}\sum_{i=1}^n (x_i - \bar x)^2.
  \]
\end{itemize}

\subsection{Distribución en el muestreo de los momentos muestrales}\label{distribuciuxf3n-en-el-muestreo-de-los-momentos-muestrales}

\textbf{Ejemplo: TCL aplicado a momentos muestrales}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{4}\NormalTok{)}
\NormalTok{medias }\OtherTok{\textless{}{-}} \FunctionTok{replicate}\NormalTok{(}\DecValTok{4000}\NormalTok{, }\FunctionTok{mean}\NormalTok{(}\FunctionTok{rexp}\NormalTok{(}\DecValTok{40}\NormalTok{)))}
\FunctionTok{hist}\NormalTok{(medias, }\AttributeTok{breaks=}\DecValTok{30}\NormalTok{, }\AttributeTok{freq=}\ConstantTok{FALSE}\NormalTok{)}
\FunctionTok{curve}\NormalTok{(}\FunctionTok{dnorm}\NormalTok{(x,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{40}\NormalTok{)), }\AttributeTok{add=}\ConstantTok{TRUE}\NormalTok{, }\AttributeTok{col=}\StringTok{"blue"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\pandocbounded{\includegraphics[keepaspectratio]{FundamentosInferenciaEstadistica_files/figure-latex/unnamed-chunk-22-1.pdf}}

Los momentos muestrales son estadísticos, por lo que tienen distribución de muestreo.\\
Si denotamos \(\alpha_k = E[X^k]\), entonces:

\[
E(a_k) = \alpha_k
\]

y

\[
\operatorname{Var}(a_k)
= \frac{1}{n}\left( \alpha_{2k} - \alpha_k^2 \right).
\]

En cuanto a la varianza muestral:

\[
s^2 = \frac{1}{n}\sum_{i=1}^n (X_i - \bar X)^2,
\]

se obtiene:

\[
E(s^2)=\frac{n-1}{n}\sigma^2.
\]

La expresión de \(\operatorname{Var}(s^2)\) es más compleja y depende de los momentos centrados de orden 4.

\subsection{Muestreo en poblaciones normales}\label{muestreo-en-poblaciones-normales}

Cuando \(X\sim N(\mu,\sigma)\), las distribuciones en el muestreo de algunos estadísticos importantes pueden obtenerse exactamente.\\
Dos estadísticos fundamentales son:

\begin{itemize}
\tightlist
\item
  la \textbf{media muestral} \(\bar X\),
\item
  la \textbf{varianza muestral} \(S^2=\sum_{i=1}^n (X_i - \bar X)^2\).
\end{itemize}

Partimos de:

\[
\bar X \sim N\!\left(\mu,\; \frac{\sigma^2}{n}\right).
\]

Pero la distribución de \(S^2\) es más interesante, ya que da lugar a la primera de las distribuciones derivadas de la normal.

\subsubsection{La distribución chi-cuadrado y la varianza muestral}\label{la-distribuciuxf3n-chi-cuadrado-y-la-varianza-muestral}

Un resultado fundamental es:

\[
\frac{(n-1)S^2}{\sigma^2} \sim \chi^2_{\,n-1}.
\]

Esto significa que la distribución chi-cuadrado \textbf{no aparece arbitrariamente}, sino de manera natural como la distribución del estadístico de variancia muestral en población normal.

Además, la media y la varianza cumplen:

\[
E(\chi_k^2)=k,\qquad 
\operatorname{Var}(\chi_k^2)=2k.
\]

La aditividad proviene directamente de las propiedades de la distribución normal.

\subsubsection{\texorpdfstring{La distribución t de Student y el estadístico \(T\)}{La distribución t de Student y el estadístico T}}\label{la-distribuciuxf3n-t-de-student-y-el-estaduxedstico-t}

Si \(\sigma\) es desconocida y la reemplazamos por \(S\), la variable

\[
T = \frac{\bar X - \mu}{S/\sqrt{n}}
\]

sigue una \textbf{distribución t de Student} con \(n-1\) grados de libertad.

La t surge de forma natural al estandarizar la media muestral usando la varianza estimada.

Su densidad es:

\[
f(t)=
\frac{\Gamma((m+1)/2)}{\Gamma(m/2)\sqrt{m\pi}}
\left(1 + \frac{t^2}{m}\right)^{-(m+1)/2}.
\]

A medida que \(m\to\infty\), la t converge a la normal estándar.

\subsubsection{La distribución F de Fisher y la razón de varianzas.}\label{la-distribuciuxf3n-f-de-fisher-y-la-razuxf3n-de-varianzas.}

Si tenemos dos muestras normales independientes:

\[
X_1,\ldots,X_{n_1} \sim N(\mu_1,\sigma_1),
\]
\[
Y_1,\ldots,Y_{n_2} \sim N(\mu_2,\sigma_2),
\]

entonces el cociente:

\[
F = \frac{S_1^2/(n_1-1)}{S_2^2/(n_2-1)}
\]

sigue una distribución F de Fisher con \((n_1-1,n_2-1)\) grados de libertad.

Esta distribución aparece naturalmente al comparar dos varianzas muestrales de normales.

Su densidad general es:

\[
f(x)=
\frac{m^{m/2} n^{n/2} \Gamma((m+n)/2)}
{\Gamma(m/2)\Gamma(n/2)}
\frac{x^{m/2-1}}{(mx+n)^{(m+n)/2}},
\qquad x>0.
\]

\subsection{Apéndice técnico (opcional)}\label{apuxe9ndice-tuxe9cnico-opcional}

Este apéndice reúne algunos resultados y demostraciones que, aunque útiles, interrumpen el flujo del capítulo si se presentan en la parte principal del texto.

\subsubsection{Función generadora de momentos de la media muestral}\label{funciuxf3n-generadora-de-momentos-de-la-media-muestral}

Sea \(X\) una variable aleatoria con función generadora de momentos \(M_X(t)\).\\
Consideremos la media muestral:

\[
\bar X_n = \frac{1}{n}\sum_{i=1}^n X_i,
\]

donde \(X_1,\ldots,X_n\) son i.i.d. con la misma distribución que \(X\).

\textbf{Resultado:}

\[
M_{\bar X_n}(t) = \left[ M_X\left(\frac{t}{n}\right) \right]^n.
\]

\textbf{Demostración por definición}

\[
\begin{aligned}
E\left(e^{t\bar X_n}\right)
&= E\left(e^{t\frac{1}{n}\sum X_i}\right)
= E\left(\prod_{i=1}^n e^{\frac{t}{n}X_i}\right)\\[4pt]
&= \prod_{i=1}^n E\left(e^{\frac{t}{n}X_i}\right)
= \left[ M_X\left(\tfrac{t}{n}\right)\right]^n.
\end{aligned}
\]

\textbf{Demostración alternativa por propiedades}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Para cualquier \(a\), \(M_{aX}(t)=M_X(at)\).
\item
  Por independencia:
  \[
  M_{\sum X_i}(t)=\prod M_{X_i}(t).
  \]
\end{enumerate}

Aplicando ambas:

\[
M_{\bar X_n}(t) = M_{\sum X_i}(t/n)
= \prod M_X(t/n)
= \left[M_X(t/n)\right]^n.
\]

\subsubsection{Momentos centrales y relación con la varianza muestral}\label{momentos-centrales-y-relaciuxf3n-con-la-varianza-muestral}

Para el momento muestral centrado de orden 2:

\[
b_2 = \frac{1}{n} \sum (X_i - \bar X)^2,
\]

se cumple:

\[
E(b_2) = \frac{n-1}{n}\sigma^2.
\]

\textbf{Idea de demostración}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Expandimos:
  \[
  (X_i - \bar X)^2 = X_i^2 - 2X_i\bar X + \bar X^2.
  \]
\item
  Sumando y tomando esperanzas aparecen términos:
  \[
  E(X_i^2),\; E(\bar X^2),\; E(X_i\bar X).
  \]
\item
  Usando independencia y simetría se obtiene el resultado final.
\end{enumerate}

El cálculo completo es estándar pero laborioso.

\subsubsection{Propiedades asintóticas de los momentos muestrales}\label{propiedades-asintuxf3ticas-de-los-momentos-muestrales}

\paragraph{Convergencia}\label{convergencia}

Los momentos muestrales convergen en probabilidad a los momentos poblacionales:

\[
a_k \xrightarrow{P} \alpha_k.
\]

Aplicando la desigualdad de Tchebychev:

\[
P(|a_k - \alpha_k|\ge \varepsilon)
\le
\frac{\alpha_{2k}-\alpha_k^2}{n\varepsilon^2}
\to 0.
\]

Esta propiedad será fundamental en la noción de \textbf{estimador consistente}.

\paragraph{Distribución asintótica}\label{distribuciuxf3n-asintuxf3tica}

Usando el Teorema Central del Límite sobre \(n a_k = \sum X_i^k\), obtenemos:

\[
\frac{a_k - \alpha_k}{\sqrt{\operatorname{Var}(a_k)}}
\xrightarrow{\mathcal{L}} N(0,1).
\]

En particular:

\[
a_k \approx AN\left(
\alpha_k,\;
\sqrt{\frac{\alpha_{2k}-\alpha_k^2}{n}}
\right).
\]

\subsubsection{Recordatorio: propiedades útiles de la distribución Gamma}\label{recordatorio-propiedades-uxfatiles-de-la-distribuciuxf3n-gamma}

Recordamos que si \(Y\sim \Gamma(p, \alpha)\) con densidad:

\[
f_Y(y) = \frac{\alpha^p}{\Gamma(p)} y^{p-1} e^{-\alpha y},
\qquad y>0,
\]

entonces:

\[
E(Y) = \frac{p}{\alpha},
\qquad
\operatorname{Var}(Y) = \frac{p}{\alpha^2}.
\]

Además, si \(Y_1\) y \(Y_2\) son gammas independientes:

\[
Y_1 \sim \Gamma(p_1,\alpha),\qquad
Y_2 \sim \Gamma(p_2,\alpha),
\]

entonces:

\[
Y_1 + Y_2 \sim \Gamma(p_1+p_2, \alpha).
\]

Esto explica la \textbf{reproductividad} de la chi-cuadrado, ya que:

\[
\chi_k^2 \equiv \Gamma\left(\frac{k}{2}, \frac12\right).
\]

\subsubsection{\texorpdfstring{Derivación estructurada de \(\chi^2\), \(t\) y \(F\)}{Derivación estructurada de \textbackslash chi\^{}2, t y F}}\label{derivaciuxf3n-estructurada-de-chi2-t-y-f}

Aquí resumimos las relaciones esenciales:

\paragraph{Varianza muestral en población normal}\label{varianza-muestral-en-poblaciuxf3n-normal}

\[
\frac{(n-1)S^2}{\sigma^2}\sim \chi^2_{n-1}.
\]

Surge al sumar cuadrados de variables normales estandarizadas independientes.

\paragraph{Estadístico t de Student}\label{estaduxedstico-t-de-student}

\[
T = \frac{\bar X - \mu}{S/\sqrt{n}}
\sim t_{n-1}.
\]

Cuando la varianza poblacional es desconocida, sustituir \(\sigma\) por \(S\) introduce variabilidad adicional → aparece la t.

\paragraph{Estadístico F de Fisher}\label{estaduxedstico-f-de-fisher}

\[
F = \frac{S_1^2/(n_1-1)}{S_2^2/(n_2-1)}
\sim F_{n_1-1,\,n_2-1}.
\]

El cociente de dos chi-cuadrados normalizados genera la F.

Estas relaciones son la base de los contrastes t, F y ANOVA que se utilizarán en capítulos posteriores.

\subsubsection{Asintótica útil para inferencia}\label{asintuxf3tica-uxfatil-para-inferencia}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Media muestral}
\end{enumerate}

\[
\sqrt{n}\,(\bar X - \mu)\xrightarrow{\mathcal{L}} N(0,\sigma^2).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Momentos muestrales}
\end{enumerate}

\[
\frac{a_k - \alpha_k}{\sqrt{\operatorname{Var}(a_k)}}
\xrightarrow{\mathcal{L}} N(0,1).
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Distribución empírica (Glivenko-Cantelli)}
\end{enumerate}

\[
\sup_x |F_n(x)-F(x)| \xrightarrow{\text{c.s.}} 0.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  \textbf{Teorema Central del Límite}
\end{enumerate}

\[
\frac{\sum X_i - n\mu}{\sigma\sqrt{n}}
\xrightarrow{\mathcal{L}} N(0,1).
\]

Estas propiedades justifican métodos de inferencia aproximada y son el fundamento del método delta y del bootstrap que aparecerán más adelante.

\newpage

\section{Estimación puntual}\label{estimaciuxf3n-puntual}

\subsection{El problema de la estimación puntual}\label{el-problema-de-la-estimaciuxf3n-puntual}

Informalmente, la estimación de parámetros consiste en buscar aproximaciones a los valores de estos, calculables a partir de una muestra, que sean lo más precisas posible. El problema, claro, es que para medir cuán precisas son estas aproximaciones sería necesario conocer los valores de los parámetros y, como estos son siempre desconocidos, debemos basarnos en el uso de estimadores con buenas propiedades que, en algún sentido, nos garanticen esa proximidad.
Más formalmente podemos plantear el problema de la siguiente manera:
Sea \(X\) una v.a. con distribución \(F_{\theta}\) donde \(\theta=\left(\theta_{1}, \ldots, \theta_{k}\right) \in \Theta \subset \mathbb{R}^{k}\) y sea \(X_{1}, X_{2}, \ldots, X_{n}\) una muestra de \(n\) v.a. de \(X\). El problema de la estimación puntual consiste en obtener alguna aproximación de \(\theta\) en base a la información disponible en la muestra mediante un estimador de \(\theta\) que definimos a continuación.
Definició 2.1 Sea \(X_{1}, X_{2}, \ldots, X_{n}\) una muestra aleatoria simple de \(X\) con distribución \(F_{\theta}\) donde \(\theta \in \Theta \subset \mathbb{R}^{k}\). Un estadístico \(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\) se denomina un estimador puntual de \(\theta\) si \(T\) es una función definida en el espacio muestral y cuyos valores pertenecen al mismo espacio paramétrico \(\Theta\) que los parámetros.''

Ejemplo 2.1.1 Sea \(X_{1}, X_{2}, \ldots, X_{n}\) una muestra aleatoria simple de una v.a. de Poisson \(X \sim P(\lambda)\). Para estimar \(\lambda\) podemos utilizar:

\[
\begin{aligned}
& T_{1}=\bar{X}=\frac{1}{n} \sum_{i=1}^{n} X_{i} \\
& T_{2}=s^{2}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
\end{aligned}
\]

ya que \(E(X)=\operatorname{var}(X)=\lambda\), pero también

\[
\begin{aligned}
T_{3} & =\frac{2}{n(n+1)} \sum_{i=1}^{n} X_{i} \cdot i \\
T_{4} & =X_{i}
\end{aligned}
\]

Ejemplo 2.1.2 Sea \(X_{1}, X_{2}, \ldots, X_{n}\) una m.a.s. de \(X \sim B(1, p)\), con \(p\) desconocido. Podemos estimar p de las siguientes maneras:

\[
\begin{aligned}
& T_{1}=\bar{X}=(1 / n) \sum_{i=1}^{n} X_{i} \\
& T_{2}=1 / 2 \\
& T_{3}=\left(X_{1}+X_{2}\right) / 2
\end{aligned}
\]

En cada caso resulta claro que algunos estimadores no son muy razonables mientras que la decisión entre los otros no está necesariamente clara. Básicamente debemos ocuparnos de dos problemas:

\begin{itemize}
\tightlist
\item
  Dado un modelo estadístico \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\), ¿cómo podemos obtener estimadores de \(\theta\) que tengan ``buenas'' propiedades?
\item
  Dado varios estimadores para un mismo parámetro ¿cómo podemos escoger el mejor en base a algún criterio?
\end{itemize}

Para poder alcanzar estos dos objetivos empezaremos por estudiar las propiedades de los estimadores, así como las medidas de optimalidad que podremos utilizar para decidir entre varios estimadores.
De entrada nos restringiremos al caso en que \(\Theta \subseteq \mathbb{R}\) o en que queremos aproximar alguna función \(g(\theta)\) de los parámetros donde \(g\) es del tipo \(g: \Theta \rightarrow\) \(\mathbb{R}\).

\subsubsection{Criterios de optimalidad de estimadores. El Riesgo}\label{criterios-de-optimalidad-de-estimadores.-el-riesgo}

Una forma de poder comparar entre diversos estimadores consiste en definir una función de pérdida que nos permita cuantificar de alguna manera la pérdida, o coste asociado, al estimar el valor real del parámetro, es decir, \(\theta\), mediante la aproximación que proporciona un estimador, es decir, \(t\).

Definició 2.2 Una función de pérdida es una aplicación

\[
\begin{aligned}
L: & \Theta \times \Theta \rightarrow \mathbb{R} \\
& (\theta, t) \rightarrow L(\theta, t)
\end{aligned}
\]

La función de pérdida cuantifica el coste asociado a la desviación entre un estimador \(t\) y el valor verdadero del parámetro \(\theta\).

Para ser válida, debe cumplir los siguientes criterios: (a), (b), (c):

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(L(\theta, t) \geq 0, \quad \forall \theta, t \in \Theta\)
\item
  \(L(\theta, t)=0\), si \(\theta=t\)
\item
  \(L(\theta, t) \leq L\left(\theta, t^{\prime}\right)\), si \(d(\theta, t) \leq d\left(\theta, t^{\prime}\right)\) donde \(d\) es una distancia en \(\Theta\).
\end{enumerate}

Por ejemplo, son funciones de pérdida:

\[
\begin{gathered}
L_{1}(\theta, t)=|\theta-t| \quad L_{2}(\theta, t)=(\theta-t)^{2} \\
L_{3}(\theta, t)=\left|\frac{\theta-t}{\theta}\right| \quad L_{4}(\theta, t)=\left(\frac{\theta-t}{\theta}\right)^{2} \\
L_{5}(\theta, t)= \begin{cases}c>0 & \text { si }|\theta-t|>\epsilon \\
0 & \text { si }|\theta-t| \leq \epsilon\end{cases}
\end{gathered}
\]

\subsubsection{El error cuadrático medio}\label{el-error-cuadruxe1tico-medio}

Una de las funciones de pérdida más usuales es la función de pérdida cuadrática \(L_{2}(\theta, t)=(\theta-t)^{2}\). Uno de los motivos de su uso es que el riesgo asociado a esta función de pérdida \(E_{\theta}\left[(\theta-T)^{2}\right]\), que llamamos error cuadrático medio \(E Q M_{T}\), representa una medida de la variabilidad del estimador \(T\) en torno a \(\theta\) semejante a la medida de dispersión en torno a la media que representa la varianza.
Además, del desarrollo de esta expresión se obtiene un interesante resultado que muestra cuáles pueden ser las propiedades más interesantes para un estimador.
Sea \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\) y sea \(T\) un estimador de \(\theta\). El error cuadrático medio de \(T\) para estimar \(\theta\) vale

\[
E Q M_{T}(\theta)=E_{\theta}\left[(\theta-T)^{2}\right]=E\left[\theta^{2}-2 \theta T+T^{2}\right]=\theta^{2}-2 \theta E_{\theta}(T)+E_{\theta}\left(T^{2}\right)
\]

Ahora, sumando y restando \(\left(E_{\theta}(T)\right)^{2}\), obtenemos

\[
\begin{aligned}
E Q M_{T}(\theta) & =E_{\theta}\left(T^{2}\right)-\left(E_{\theta}(T)\right)^{2}+\left(E_{\theta}(T)\right)^{2}+\theta^{2}-2 \theta E_{\theta}(T)= \\
& =\operatorname{var}(T)+\left(E_{\theta}(T)-\theta\right)^{2}
\end{aligned}
\]

El término \(\left(E_{\theta}(T)-\theta\right)^{2}\) es el cuadrado del sesgo de \(T\), que se define como

\[
b_{\theta}(T)=E_{\theta}(T)-\theta
\]

Definició 2.5 El error cuadrático medio \(E Q M_{T}(\theta)\), o simplemente \(E Q M\), de un estimador \(T\) para estimar el parámetro \(\theta\) es la suma de su varianza más el cuadrado de la diferencia entre su valor medio y el verdadero valor del parámetro, que llamamos sesgo.

Si en la búsqueda de estimadores de mínimo riesgo nos basamos en la función de pérdida cuadrática, parece que los estimadores más deseables deberían ser aquellos en los que la varianza y el sesgo sean lo más pequeños posibles. Idealmente, quisiéramos reducir ambas cantidades a la vez. En la práctica, sin embargo, observamos que, en general, no suele ser posible reducir simultáneamente la varianza y el sesgo. Además, incluso si fuera práctico calcular el \(E Q M\) para cada estimador, encontraríamos que, para la mayoría de las familias de probabilidad \(P_{\theta}\), no existiría ningún estimador que minimizase el \(E Q M\) para todos los valores de \(\theta\). Es decir, que un estimador puede tener un \(E Q M\) mínimo para algunos valores de \(\theta\), mientras que otro lo tendrá en otros valores de \(\theta\).

Ejemplo 2.1.4 Sea \(X_{1}, X_{2}, \ldots, X_{n}\) una muestra aleatoria simple de \(X \sim\) \(N(\mu, \sigma)\), donde suponemos \(\sigma\) conocida, y sean

\[
T_{1}=\bar{X} \quad T_{2}=\frac{\sum_{i=1}^{n} X_{i}}{n+1}
\]

Calculando la media y la varianza de los estimadores, tenemos

\[
\begin{array}{lll}
E_{\mu}\left(T_{1}\right)=\mu & \Rightarrow b_{T_{1}}(\mu)=0 & \operatorname{var}_{\mu}\left(T_{1}\right)=\frac{\sigma^{2}}{n} \\
E_{\mu}\left(T_{2}\right)=\frac{n}{n+1} \mu & \Rightarrow b_{T_{2}}(\mu)=\frac{-1}{n+1} \mu & \operatorname{var}_{\mu}\left(T_{2}\right)=\frac{n}{(n+1)^{2}} \sigma^{2}
\end{array}
\]

de donde

\[
\begin{aligned}
& E Q M_{\mu}\left(T_{1}\right)=\operatorname{var}\left(T_{1}\right)=\frac{\sigma^{2}}{n} \\
& E Q M_{\mu}\left(T_{2}\right)=\frac{1}{(n+1)^{2}} \mu^{2}+\frac{n}{(n+1)^{2}} \sigma^{2}
\end{aligned}
\]

que son respectivamente una recta y una parábola. De manera que para algunos valores de \(\mu\) tenemos que \(E Q M_{\mu}\left(T_{1}\right)<E Q M_{\mu}\left(T_{2}\right)\) y para otros, al revés. La figura 2.1 muestra esta diferencia.

Ejemplo 2.1.5 Un ejemplo trivial bastante interesante es el siguiente. Para estimar un parámetro \(\theta\), el estimador que consiste en un valor fijo \(\theta_{0}\), tiene riesgo 0 en \(\theta=\theta_{0}\). Sin embargo, el riesgo aumenta considerablemente al alejarnos del valor real de \(\theta\). Por lo tanto, no resulta un estimador razonable, aunque su riesgo pueda ser mínimo para algún (único) valor de \(\theta\).

Figura 2.1: Comparación del riesgo de dos estimadores

Los ejemplos anteriores nos muestran que los criterios de preferencia entre estimadores basados en el riesgo o en el \(E Q M\) no son de gran utilidad general ya que muchos estimadores pueden ser incomparables. Ante este hecho nos planteamos si es posible completar el criterio de minimizar el riesgo mediante alguna propiedad o criterio adicional. Las posibles soluciones obtenidas a esta cuestión siguen dos vías:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Restringir la clase de estimadores considerados a aquellos que cumplan alguna propiedad adicional de interés, eliminando estimadores indeseables para que el criterio de minimizar el riesgo permita seleccionar uno preferible a los demás. Este criterio lleva a considerar las propiedades deseables de los estimadores como falta de sesgo, consistencia, eficiencia y analizar cómo combinarlas con el criterio de mínimo riesgo. Este proceso culmina con el estudio de los Estimadores Sin Sesgo Uniformemente de Mínima Varianza (ESUMV).
\item
  Reforzar el criterio de preferencia de estimadores mediante la reducción de toda la función de riesgo \(R_{T}(\theta)\) a un único valor representativo que permita ordenar linealmente todos los estimadores. Este criterio nos lleva a los Estimadores Bayes y a los Estimadores Minimax.
\end{enumerate}

\subsection{Estudio de las propiedades deseables de los estimadores}\label{estudio-de-las-propiedades-deseables-de-los-estimadores}

\subsubsection{El sesgo}\label{el-sesgo}

Supongamos que tenemos un modelo estadístico \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\) y un estimador \(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\) de una función medible \(g(\theta)\) del parámetro. Una forma razonable de valorar qué tan próximos son los valores de \(T\) a los de \(g(\theta)\) es ver si, en promedio, los valores de \(T\) coinciden con el valor medio de \(g(\theta)\).

Definició 2.6 Bajo las condiciones mencionadas, si \(E_{\theta}(T)\) es la esperanza de \(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\) y \(g(\theta)\) es una función del parámetro (en particular la identidad), la diferencia

\[
b_{T}(\theta)=b_{T}(\theta)=E_{\theta}(T)-g(\theta)
\]

se denomina sesgo del estimador \(T\) para estimar \(g(\theta)\). Si el sesgo es nulo, es decir, si:

\[
E_{\theta}(T)=g(\theta), \quad \forall \theta \in \Theta
\]

diremos que \(T\) es un estimador insesgado de \(g(\theta)\).
Ejemplo 2.2.1 Los dos ejemplos más conocidos son el de la media y la varianza muestrales.

\begin{itemize}
\tightlist
\item
  La media muestral es un estimador insesgado de \(\mu\).
\item
  La varianza muestral es un estimador con sesgo de la varianza poblacional. En concreto, su sesgo vale:
\end{itemize}

\[
b_{s^{2}}\left(\sigma^{2}\right)=E_{\sigma^{2}}\left(s^{2}\right)-\sigma^{2}=\frac{n-1}{n} \sigma^{2}-\sigma^{2}=\frac{-1}{n} \sigma^{2}
\]

El uso de estimadores insesgados es conveniente en muestras de tamaño grande. En estas, \(\operatorname{var}_{\theta}(T)\) es a menudo pequeña y entonces, como \(E_{\theta}(T)=\) \(g(\theta)+b_{T}(\theta)\), es muy probable obtener estimaciones centradas en este valor en lugar de en el entorno de \(g(\theta)\).

Ejemplo 2.2.2 Sea \(X_{1}, X_{2}, \ldots, X_{n}\) una muestra aleatoria simple de \(X \sim\) \(U(0, \theta)\). Tomemos \(T=\max \left\{X_{1}, X_{2}, \ldots, X_{n}\right\}\) como el estimador del máximo de la distribución. Obviamente podemos decir que \(T<\theta\) y, por lo tanto,
la estimación siempre está sesgada. Como hemos visto en el ejemplo ??, la distribución en el muestreo de \(T\) es

\[
H_{\theta}(t)=P_{\theta}[T \leq t]=\left(\frac{t}{\theta}\right)^{n}
\]

y su función de densidad es

\[
f_{\theta}(\theta)=H_{\theta}^{\prime}(\theta)=\frac{n}{\theta}\left(\frac{t}{\theta}\right)^{n-1}
\]

Su esperanza (ver ejemplo ??) vale

\[
E_{\theta}(T)=\int_{0}^{\theta} t \cdot\left[\frac{n}{\theta}\left(\frac{t}{\theta}\right)^{n-1}\right] d t=\frac{n}{n+1} \theta
\]

de donde el sesgo de \(T\) para estimar \(\theta\) es

\[
b_{T}(\theta)=\frac{n}{n+1} \theta-\theta=-\frac{1}{n+1} \theta
\]

Podemos preguntarnos si podríamos mejorar este estimador corrigiendo el sesgo de forma análoga a lo que hacíamos con \(\hat{s}^{2}\), es decir, tomando un estimador corregido para el sesgo

\[
T^{\prime}=\frac{n+1}{n} T \text { que, por construcción, verifica: } E\left(T^{\prime}\right)=\theta \text {. }
\]

Consideremos el estimador de mínimo riesgo en el sentido del error cuadrático medio, es decir, el estimador que minimiza \(E\left[(\theta-T)^{2}\right]\). De hecho, como hemos visto en el ejemplo ??, conviene elegir el que minimice \(E\left[(\theta-T)^{2} / \theta^{2}\right]\), porque también minimiza el EQM, pero alcanza un mínimo absoluto. Este estimador es

\[
T^{\prime \prime}=\frac{n+2}{n+1} T
\]

y, por tanto, es más adecuado que \(T^{\prime}\), ya que tiene un menor riesgo respecto al error cuadrático medio.
Cuando, como aquí, nos encontramos con que dado un estimador podemos encontrar otro de menor riesgo, decimos que el primero no es admisible respecto de la función de pérdida. En este caso decimos que \(T^{\prime}\) no es admisible respecto al EQM. ¡Cuidado! Esto no significa que no podamos usarlo, sino que existe otro con menor riesgo, ya que existe otro \(T^{\prime \prime}\) preferible a él que, por cierto, no es centrado. Efectivamente

\[
E_{\theta}\left(T^{\prime \prime}\right)=\frac{n+2}{n+1} E_{\theta}(T)=\frac{(n+2) n}{(n+1)^{2}} \theta
\]

El ejemplo anterior muestra que, debido a la descomposición \(E Q M_{T}(\theta)=\) \(\operatorname{var}_{\theta}(T)+b_{T}^{2}(\theta)\), puede ser preferible un estimador con sesgo a otro que no lo tenga.
En general, sin embargo, eliminar el sesgo no es una mala estrategia, sobre todo porque al restringirnos a la clase de los estimadores insesgados obtenemos una solución constructiva que permitirá obtener estimadores insesgados de mínima varianza en condiciones bastante generales.
Los siguientes ejemplos ilustran dos propiedades interesantes del sesgo. Por un lado, muestran que no siempre existe un estimador insesgado. Por otro lado, vemos cómo a veces, incluso teniendo un estimador insesgado para un parámetro \(E_{\theta}(T)=\theta\), una función \(g(T)\) no es necesariamente un estimador insesgado de \(g(\theta)\).

Ejemplo 2.2.3 Consideremos una variable \(X\) con distribución de Bernoulli \(B(1, p)\). Supongamos que deseamos estimar \(g(p)=p^{2}\) con una única observación. Para que un estimador \(T\) no tenga sesgo para estimar \(p^{2}\) sería necesario que

\[
p^{2}=E_{p}(T)=p \cdot T(1)+(1-p) \cdot T(0), \quad 0 \leq p \leq 1
\]

es decir, para cualquier valor de \(p \in[0,1]\) se debería verificar

\[
p^{2}=p \cdot(T(1)-T(0))+T(0)
\]

Esto claramente no es posible, ya que la única forma en que una función lineal y una función parabólica coincidan en todo el intervalo \([0,1]\) es cuando los coeficientes \(T(0)\) y \(T(1)\) valen cero.

Ejemplo 2.2.4 El parámetro \(\alpha\) de una ley exponencial con función de densidad

\[
f(x)=\alpha e^{-\alpha x} \mathbf{1}_{(0, \infty)}(x)
\]

es el inverso de la media de la distribución, es decir, \(\alpha=1 / E(X)\).
Un estimador razonable de \(\alpha=g(\mu)\) puede ser \(\hat{\alpha}=g(\hat{\mu})\), es decir, \(\hat{\alpha}=\) \(1 / \bar{X}\). Si aplicamos la propiedad de que la suma de variables aleatorias i.i.d. exponenciales sigue una ley gamma de parámetros \(n\) y \(\alpha\), se obtiene que este estimador tiene sesgo. Su esperanza es

\[
E(\hat{\alpha})=\frac{n}{n-1} \alpha
\]

El sesgo se corrige simplemente con

\[
\hat{\alpha}^{\prime}=\frac{n-1}{n} \hat{\alpha}
\]

\subsubsection{Consistencia}\label{consistencia}

La consistencia de un estimador es una propiedad bastante intuitiva que indica, de manera informal, que cuando aumenta el tamaño muestral, el valor del estimador se aproxima cada vez más al verdadero valor del parámetro.

Definició 2.7 Sea \(X_{1}, X_{2}, \ldots, X_{n}, \ldots\) una sucesión de variables aleatorias i.i.d. \(X \sim F_{\theta}, \theta \in \Theta\). Una sucesión de estimadores puntuales \(T_{n}=\) \(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\) se denomina consistente para \(g(\theta)\) si

\[
T_{n} \xrightarrow[n \rightarrow \infty]{P} g(\theta)
\]

para cada \(\theta \in \Theta\), es decir, si

\[
\forall \varepsilon>0 \quad \lim _{n \rightarrow \infty} P\left\{\left|T_{n}-g(\theta)\right|>\varepsilon\right\}=0
\]

Observemos que:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Se trata de un concepto asintótico: Hablamos de ?sucesiones de estimadores consistentes? más que de estimadores propiamente dichos.
\item
  La definición puede reforzarse si, en lugar de considerar convergencia en probabilidad (consistencia débil), consideramos convergencia casi segura o en media cuadrática:
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(T_{n}\) es fuertemente consistente si \(T_{n} \xrightarrow{\text { c.s. }} g(\theta)\)
\item
  \(T_{n}\) es consistente en media- \(r\) si \(E_{\theta}\left[\left|T_{n}-g(\theta)\right|^{r}\right] \longrightarrow 0\)
\end{itemize}

Ejemplo 2.2.5 Muchos estimadores consistentes lo son como consecuencia de las leyes de los grandes números. Recordemos que la Ley débil de los Grandes Números (Tchebychev) afirma que, dada una sucesión de v.a. independientes e idénticamente distribuidas con medias \(\mu<\infty\) y varianzas \(\sigma^{2}<\infty\), entonces

\[
\bar{X}_{n} \xrightarrow{P} \mu
\]

Como consecuencia de esta ley y dado que una muestra aleatoria simple es i.i.d., por definición, podemos afirmar que \(\bar{X}_{n}\) es consistente para estimar \(\mu\).

Ejemplo 2.2.6 La sucesión \(T_{n}=\max _{1 \leq i \leq n}\left\{X_{i}\right\}\) es consistente para estimar el máximo de una distribución uniforme en \([0, \theta]\) :

\[
P\left[\left|\max _{1 \leq i \leq n}\left\{X_{i}\right\}-\theta\right|>\varepsilon\right]=P\left[\theta-\max _{1 \leq i \leq n}\left\{X_{i}\right\}>\varepsilon\right]
\]

ya que \(X_{i} \in[0, \theta] y\), por lo tanto, podemos escribir:

\[
\begin{aligned}
P\left[\theta-\varepsilon>\max _{1 \leq i \leq n}\left\{X_{i}\right\}\right] & =P\left[\max _{1 \leq i \leq n}\left\{X_{i}\right\}<\theta-\varepsilon\right] \\
& =\left(\frac{\theta-\varepsilon}{\theta}\right)^{n}=\left(1-\frac{\varepsilon}{\theta}\right)^{n} \underset{n \rightarrow \infty}{\longrightarrow} 0
\end{aligned}
\]

Es inmediato comprobar que

\[
E\left[\left(\theta-T_{n}\right)^{2}\right]=\left(1-\frac{2 n}{n+1}+\frac{n}{n+2}\right) \theta^{2}
\]

que también tiende a cero cuando \(n \rightarrow \infty\), y por lo tanto \(T_{n}=\max _{1 \leq i \leq n}\left\{X_{i}\right\}\) también es consistente en media cuadrática.

Normalmente, cuando se habla de consistencia, se hace referencia a la convergencia en probabilidad, es decir, \(T_{n}\) es consistente si \(\lim _{n \rightarrow \infty} P\left(\left|T_{n}-g(\theta)\right|>\right.\) \(\varepsilon)=0\). Si el estimador no tiene sesgo, estamos en la situación de aplicar la desigualdad de Tchebychev \({ }^{1}\) :
Si \(E\left(T_{n}\right)=g(\theta)\), entonces

\[
P\left(\left|T_{n}-g(\theta)\right|>\varepsilon\right)=P\left(\left|T_{n}-E\left(T_{n}\right)\right|>\varepsilon\right) \underset{\text { Tchebychev }}{\leq} \frac{\operatorname{var}\left(T_{n}\right)}{\varepsilon^{2}}
\]

Así, para intentar establecer la consistencia de \(T\), debemos probar que

\[
\frac{\operatorname{var}\left(T_{n}\right)}{\varepsilon^{2}} \underset{n \rightarrow \infty}{\longrightarrow} 0
\]

Ejemplo 2.2.7 Sea \(M_{n}=\sum_{i=1}^{n} a_{i} X_{i}\) una combinación lineal de los valores de la muestra con coeficientes tales que \(\sum_{i=1}^{n} a_{i}=1\) y algún \(a_{i}>0\). ¿Es consistente \(M_{n}\) para estimar \(E(X)\) ?
Comencemos por ver que \(M_{n}\) no tiene sesgo

\[
\begin{aligned}
E\left(M_{n}\right) & =E\left(\sum_{i=1}^{n} a_{i} X_{i}\right)=\sum_{i=1}^{n} E\left(a_{i} X_{i}\right) \\
& =\sum_{i=1}^{n} a_{i} E\left(X_{i}\right) \stackrel{\text { i.i.d. }}{=} \sum_{i=1}^{n} a_{i} E(X)=E(X)
\end{aligned}
\]

{[}\^{}1{]}Calculemos la varianza

\[
\begin{aligned}
\operatorname{var}\left(M_{n}\right) & =\operatorname{var}\left(\sum_{i=1}^{n} a_{i} X_{i}\right)=\sum_{i=1}^{n} \operatorname{var}\left(a_{i} X_{i}\right) \\
& =\sum_{i=1}^{n} a_{i}^{2} \operatorname{var}\left(X_{i}\right)=\operatorname{var}(X) \sum_{i=1}^{n} a_{i}^{2}
\end{aligned}
\]

Si aplicamos ahora la desigualdad de Tchebychev tenemos:

\[
P\left(\left|M_{n}-\mu\right|>\varepsilon\right) \leq \frac{\sigma^{2} \sum a_{i}^{2}}{\varepsilon^{2}}
\]

lo cual no tiene por qué tender a 0 cuando \(n \rightarrow \infty\), y por lo tanto no podemos afirmar que el estimador es consistente. Por ejemplo, si \(a_{1}=\frac{1}{2}, a_{2}=a_{3}=\) \(\cdots=a_{n}=\frac{1}{2(n-1)}\) tendremos que \(\lim _{n \rightarrow \infty} \sum a_{i}^{2}=\frac{1}{4}\).
Observamos que el resultado obtenido no puede asegurar la consistencia de \(M_{n}\) para cualquier familia de coeficientes \(a_{1}, \ldots, a_{n}\), aunque, obviamente, el estimador es consistente para alguno (caso \(a_{i}=1 / n\) ).

\subsection{Propiedades de los estimadores consistentes}\label{propiedades-de-los-estimadores-consistentes}

Muchas de las propiedades de los estimadores son consecuencia directa de las propiedades de la convergencia en probabilidad, que se pueden revisar, por ejemplo, en Martin Pliego (1998a) capítulo 11.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Si \(T_{n}\) es consistente para estimar \(\theta\) y \(g: \mathbb{R} \rightarrow \mathbb{R}\) es una función continua, entonces \(g\left(T_{n}\right)\) es consistente para estimar \(g(\theta)\).
\item
  Si \(T_{1 n}\) y \(T_{2 n}\) son consistentes para estimar \(\theta_{1}\) y \(\theta_{2}\) respectivamente, entonces
  \(a T_{1 n} \pm b T_{2 n}\) es consistente para estimar \(a \theta_{1} \pm b \theta_{2}\)
  \(T_{1 n} \cdot T_{2 n}\) es consistente para estimar \(\theta_{1} \cdot \theta_{2}\)
  \(T_{1 n} / T_{2 n}\) es consistente para estimar \(\theta_{1} / \theta_{2}\), si \(\theta_{2} \neq 0\).
\item
  Sea \(a_{r}=(1 / n) \sum X_{i}^{r}\) el momento muestral de orden \(r\). Como se ha visto en el capítulo 1 , la esperanza de \(a_{r}\) es
\end{enumerate}

\[
E\left(a_{r}\right)=E\left[\frac{1}{n} \sum X_{i}^{r}\right]=\frac{1}{n} \sum E\left(X^{r}\right)=\frac{1}{n} n \alpha_{r}=\alpha_{r}
\]

donde \(\alpha_{r}\) es el momento poblacional de orden \(r\). Así pues, \(a_{r}\) no tiene sesgo para estimar \(\alpha_{r}\). Su varianza es

\[
\begin{aligned}
\operatorname{var}\left(a_{r}\right) & =\operatorname{var}\left(\frac{1}{n} \sum X_{i}^{r}\right)=\frac{1}{n^{2}} \sum \operatorname{var}\left(X^{r}\right)=\frac{1}{n} E\left[X^{r}-E\left(X^{r}\right)\right]^{2} \\
& =\frac{1}{n} E\left[X^{r}-\alpha_{r}\right]^{2}=\frac{1}{n} E\left(X^{2 r}+\alpha_{r}^{2}-2 \alpha_{r} X^{r}\right) \\
& =\frac{1}{n}\left(\alpha_{2 r}-\alpha_{r}^{2}\right) .
\end{aligned}
\]

Y si aplicamos la desigualdad de Tchebychev, se obtiene

\[
P\left(\left|a_{r}-\alpha_{r}\right| \geq \varepsilon\right) \leq \frac{E\left(a_{r}-\alpha_{r}\right)^{2}}{\varepsilon^{2}}=\frac{\operatorname{var}\left(a_{r}\right)}{\varepsilon^{2}}=\frac{\alpha_{2 r}-\alpha_{r}^{2}}{n \varepsilon^{2}} \underset{n \rightarrow \infty}{\longrightarrow} 0
\]

Así pues, hemos visto que los momentos muestrales son estimadores consistentes de los momentos poblacionales.

\subsubsection{Eficiencia}\label{eficiencia}

Como ya hemos visto, un objetivo deseable en la búsqueda de estimadores óptimos es considerar estimadores de ``mínimo riesgo'' o, si nos basamos en la función de pérdida cuadrática, estimadores que minimicen el error cuadrático medio \(E(\theta-T)^{2}\).
En general, es difícil encontrar estimadores que hagan mínimo el EQM para todos los valores de \(\theta\); sin embargo, si nos restringimos a los estimadores sin sesgo, el problema tiene solución en una gama más amplia de situaciones. Supongamos que \(T_{1}, T_{2}\) son dos estimadores sin sesgo de un parámetro \(\theta\). Para estos estimadores tenemos que

\[
\begin{aligned}
& E Q M_{T_{1}}(\theta)=\operatorname{var}_{\theta}\left(T_{1}\right)+b_{T_{1}}^{2}(\theta) \\
& E Q M_{T_{2}}(\theta)=\operatorname{var}_{\theta}\left(T_{2}\right)+b_{T_{2}}^{2}(\theta)
\end{aligned}
\]

Si los estimadores no tienen sesgo \(b_{T_{1}}(\theta)=b_{T_{2}}(\theta)=0\), el que tenga menor varianza tendrá el menor riesgo para estimar \(\theta\). Si, por ejemplo, \(\operatorname{var}\left(T_{1}\right) \leq\) \(\operatorname{var}\left(T_{2}\right)\), diremos que \(T_{1}\) es más eficiente que \(T_{2}\) para estimar \(\theta\).
Para dos estimadores con sesgo cero \(b_{T_{i}}(\theta)=0\), el cociente

\[
E R=\frac{E Q M_{T_{1}}(\theta)}{E Q M_{T_{2}}(\theta)}=\frac{\operatorname{var}_{\theta}\left(T_{1}\right)}{\operatorname{var}_{\theta}\left(T_{2}\right)}
\]

se denomina eficiencia relativa de \(T_{1}\) respecto a \(T_{2}\). Si solo hay dos estimadores de \(\theta\) puede ser fácil ver cuál es el más eficiente. Si hay más, la cosa se complica. El ``más eficiente'', en caso de que exista, se llamará el estimador sin sesgo de mínima varianza.

Figura 2.2: Comparación de la eficiencia de dos estimadores para un \(\theta\) dado

Definició 2.8 Sea \(\mathcal{S}(\theta)\) la clase de los estimadores sin sesgo de \(\theta\) y con varianza. Si para todos los estimadores de esta clase \(T \in \mathcal{S}(\theta)\) se verifica que

\[
\operatorname{var}_{\theta}(T) \leq \operatorname{var}_{\theta}\left(T^{*}\right) \quad \forall T \in \mathcal{S}(\theta)
\]

diremos que \(T^{*}\) es un estimador sin sesgo de mínima varianza de \(\theta\). Si la desigualdad es cierta \(\forall \theta \in \Theta\), diremos que \(T^{*}\) es un estimador sin sesgo uniforme de mínima varianza (ESUMV) \({ }^{2}\).

\subsection{Información de Fisher y cota de CramerRao}\label{informaciuxf3n-de-fisher-y-cota-de-cramerrao}

Obviamente, en un problema de estimación lo ideal es disponer de un ESUMV, pero esto no siempre es posible. Nos enfrentamos a varios problemas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  ¿Existen ESUMV para un parámetro \(\theta\) en un modelo dado?
\item
  En caso de que exista el ESUMV, ¿sabremos cómo encontrarlo?
\end{enumerate}

Este problema tiene solución, bajo ciertas condiciones, utilizando los teoremas de Lehmann-Scheffé y Rao-Blackwell y el concepto de suficiencia, que se discute más adelante.

{[}\^{}2{]}Una solución parcial aparece gracias al Teorema de Cramer-Rao, que permite establecer una cota mínima para la varianza de un estimador. Cuando un estimador alcanza esta cota, sabemos que es un estimador de varianza mínima.
Informalmente, este resultado sugiere que, bajo ciertas condiciones de regularidad, si \(T\) es un estimador insesgado de un parámetro \(\theta\), su varianza está acotada por una expresión que llamamos cota de Cramer-Rao \(\operatorname{CCR}(\theta)\)

\[
\operatorname{var}(T) \geq \operatorname{CCR}(\theta)
\]

Antes de establecer con precisión este teorema, consideremos el concepto de información de un modelo estadístico introducido por Fisher.

\subsection{Información y verosimilitud de un modelo estadístico}\label{informaciuxf3n-y-verosimilitud-de-un-modelo-estaduxedstico}

Una idea bastante razonable es esperar que un estimador funcione mejor en su intento de aproximarse al valor de un parámetro cuanto más información tenga para hacerlo. Por este motivo, la varianza del estimador y la información se presentan como cantidades opuestas: a mayor información, menor error (varianza) en la estimación:

\[
\operatorname{var}\left(T_{n}\right) \propto \frac{1}{I_{n}(\theta)}
\]

Ahora nos encontramos con el problema de cómo definir la cantidad de información (contenida en una muestra/de un modelo), para que se ajuste a la idea intuitiva de información. Fisher lo hizo a través de la función de verosimilitud.
Sea un modelo estadístico \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\) y una m.a.s. \(\left(X_{1}, X_{2}, \ldots, X_{n}\right)\), que toma valores \(\mathbf{x}=\left(x_{1}, x_{2}, \ldots, x_{n}\right)\). Si \(X\) es discreta, la función de masa de probabilidad indica, en términos generales, la probabilidad de observar la muestra, dado un valor del parámetro. Si \(X\) es absolutamente continua, esta interpretación ya no es tan directa.

\[
f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)= \begin{cases}P_{\theta}\left[X=x_{1}\right] \cdots P_{\theta}\left[X=x_{n}\right], & \text { si } X \text { es discreta } \\ f_{\theta}\left(x_{1}\right) \cdots f_{\theta}\left(x_{n}\right), & \text { si } X \text { es abs. continua }\end{cases}
\]

La función de verosimilitud se obtiene si consideramos, en la expresión anterior, que lo que queda fijado es la muestra y no el parámetro. Es decir, fijada una muestra x, la función de verosimilitud indica qué tan verosímil resulta, para cada valor del parámetro, que el modelo la haya generado.

Ejemplo 2.3.1 Supongamos que tenemos una m.a.s. \(x_{1}, x_{2}, \ldots, x_{n}\) de tamaño n de una variable aleatoria \(X\), que sigue una ley de Poisson de parámetro \(\lambda\) desconocido.

\[
X \sim F_{\lambda}=P(\lambda), \quad \lambda>0
\]

La función de probabilidad de la muestra, fijado \(\lambda\), es:

\[
g_{\lambda}\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\prod_{i=1}^{n} e^{-\lambda} \frac{\lambda^{x_{i}}}{x_{i}!}=e^{-n \lambda} \frac{\lambda^{\sum x_{i}}}{\prod_{i=1}^{n} x_{i}!}
\]

y la función de verosimilitud del modelo, fijada \(\mathbf{x}\), es:

\[
L\left(x_{1}, x_{2}, \ldots, x_{n} ; \lambda\right)=\prod_{i=1}^{n} e^{-\lambda} \frac{\lambda^{x_{i}}}{x_{i}!}=e^{-n \lambda} \frac{\lambda^{\sum x_{i}}}{\prod_{i=1}^{n} x_{i}!}
\]

Aunque la forma funcional de \(g_{\lambda}(\mathbf{x})\) y \(L(\mathbf{x} ; \lambda)\) es la misma, su aspecto es diferente, como se puede comprobar en la figura 2.3, donde damos valores a \(g_{\lambda}(\mathbf{x})\), variando \(\mathbf{x}\) o a \(L(\lambda ; \mathbf{x})\) variando \(\lambda\).

\subsection{Información de Fisher}\label{informaciuxf3n-de-fisher}

Para calcular la cantidad de información de Fisher contenida en una muestra sobre un parámetro, es necesario considerar modelos estadísticos regulares, es decir, donde se cumplen las siguientes condiciones de regularidad.

Definició 2.9 Diremos que \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\) es un modelo estadístico regular si se verifican las siguientes condiciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La población de donde proviene la muestra presenta un ?campo de variación? o soporte \(S_{\theta}=\{x \mid f(x ; \theta)>0\}=S\) que no depende de \(\theta\).
\item
  La función \(L(\mathbf{x} ; \theta)\) admite, al menos, las dos primeras derivadas.
\item
  Las operaciones de derivación e integración son intercambiables.
\end{enumerate}

Definició 2.10 Sea \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\) un modelo estadístico regular, es decir, donde se verifican las condiciones de regularidad 1-3 anteriores. Si \(Z=\frac{\partial}{\partial \theta} \log L(\mathbf{X} ; \theta)\), la cantidad de información de Fisher es

\[
I_{n}(\theta)=\operatorname{var}_{\theta}(Z)=\operatorname{var}_{\theta}\left(\frac{\partial}{\partial \theta} \log L(\mathbf{X} ; \theta)\right)
\]

Figura 2.3: Probabilidad de la suma de \(n=5\) valores muestrales para 10 muestras de la ley de Poisson con \(\lambda=3\) versus la función de verosimilitud para una muestra observada.

Las condiciones de regularidad son necesarias para calcular \(E_{\theta}\left(Z^{2}\right)\).
A continuación, presentamos algunas propiedades de la información de Fisher. Puedes ver la demostración en Ruiz-Maya y Pliego (1995).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La información de Fisher se puede expresar como:
\end{enumerate}

\[
I_{n}(\theta)=E_{\theta}\left[\left(\frac{\partial \log L(\mathbf{X} ; \theta)}{\partial \theta}\right)^{2}\right]
\]

Esto se puede comprobar, ya que si aplicamos las condiciones de regularidad

\[
\begin{aligned}
E(Z) & =E\left(\frac{\partial \log L(\mathbf{X} ; \theta)}{\partial \theta}\right)=\int_{S^{n}} \frac{\partial \log L(\mathbf{x} ; \theta)}{\partial \theta} L(\mathbf{x} ; \theta) d \mathbf{x} \\
& =\int_{S^{n}} \frac{\frac{\partial L(\mathbf{x} ; \theta)}{\partial \theta}}{L(\mathbf{x} ; \theta)} L(\mathbf{x} ; \theta) d \mathbf{x}=\int_{S^{n}} \frac{\partial L(\mathbf{x} ; \theta)}{\partial \theta} d \mathbf{x} \\
& =\frac{\partial}{\partial \theta}\left(\int_{S^{n}} L(\mathbf{x} ; \theta) d \mathbf{x}\right)=\frac{\partial}{\partial \theta} 1=0
\end{aligned}
\]

:::

De forma que \(E(Z)=0\), y por lo tanto, tendremos que \(\operatorname{var}_{\theta}(Z)=\) \(E_{\theta}\left(Z^{2}\right)\).
2. \(I_{n}(\theta)=0\) si y solo si \(L(\mathbf{x} ; \theta)\) no depende de \(\theta\).
3. Dadas dos m.a.s. \(\mathbf{x}_{1}, \mathbf{x}_{2}\) de tamaños \(n_{1}, n_{2}\) de la misma población, se verifica:

\[
I_{n_{1}, n_{2}}(\theta)=I_{n_{1}}(\theta)+I_{n_{2}}(\theta)
\]

De manera que podemos considerar una muestra de tamaño \(n\) como \(n\) muestras de tamaño 1 :

\[
I_{n}(\theta)=\sum_{i=1}^{n} I_{1}(\theta)=n \cdot i(\theta), \text { siendo } i(\theta)=I_{1}(\theta)
\]

Es decir

\[
E\left(\frac{\partial \log (L(\mathbf{X} ; \theta))}{\partial \theta}\right)=n E\left(\frac{\partial \log f(X ; \theta)}{\partial \theta}\right)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Se verifica la siguiente relación:
\end{enumerate}

\[
I_{n}(\theta)=E\left[\left(\frac{\partial \log L(\mathbf{X} ; \theta)}{\partial \theta}\right)^{2}\right]=-E\left[\frac{\partial^{2} \log L(\mathbf{X} ; \theta)}{\partial^{2} \theta}\right]
\]

Ejemplo 2.3.2 Vamos a calcular la cantidad de información de Fisher contenida en una m.a.s. extraída de una población \(N(\mu, \sigma)\) con \(\sigma=\sigma_{0}\) conocida. La función de verosimilitud es

\[
L(\mathbf{x} ; \mu)=\prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi} \sigma_{0}} e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma_{0}^{2}}}=\left(2 \pi \sigma_{0}^{2}\right)^{-n / 2} \exp \left(-\sum_{i=1}^{n} \frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma_{0}^{2}}\right)
\]

y su logaritmo

\[
\log L(\mathbf{x} ; \mu)=-\frac{n}{2} \log \left(2 \pi \sigma_{0}^{2}\right)-\frac{1}{2 \sigma_{0}^{2}} \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}
\]

Si derivamos respecto a \(\mu\)

\[
\frac{\partial \log L(\mathbf{x} ; \mu)}{\mu}=\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)}{\sigma_{0}^{2}}
\]

de donde

\[
\begin{aligned}
I_{n}(\mu) & =E\left(\frac{\partial \log L(\mathbf{X} ; \mu)}{\partial \mu}\right)^{2}=E\left(\frac{\sum_{i=1}^{n}\left(X_{i}-\mu\right)}{\sigma_{0}^{2}}\right)^{2} \\
& =\frac{1}{\sigma_{0}^{4}} E\left[\sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}+\sum_{i \neq j}\left(X_{i}-\mu\right)\left(X_{j}-\mu\right)\right] \\
& =\frac{1}{\sigma_{0}^{4}} n \sigma_{0}^{2}=\frac{n}{\sigma_{0}^{2}}
\end{aligned}
\]

Este cálculo también puede hacerse a partir de la tercera propiedad de la información de Fisher:

\[
I_{n}(\mu)=n E\left[\frac{\partial \log f(X ; \mu)}{\partial \mu}\right]=n \frac{1}{\sigma_{0}^{2}}=\frac{n}{\sigma_{0}^{2}}
\]

\subsection{La desigualdad de Cramer-Rao}\label{la-desigualdad-de-cramer-rao}

Una vez establecidas las condiciones de regularidad y características anteriores podemos enunciar el teorema de Cramer-Rao (1945).

Teorema 2.1 Dado un modelo estadístico regular \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\), es decir, un modelo donde se verifican las condiciones de regularidad enunciadas, cualquier estimador \(T \in \mathcal{S}(\theta)\) de la clase de los estimadores no sesgados y con varianza verifica

\[
\operatorname{var}_{\theta}(T) \geq \frac{1}{I_{n}(\theta)}
\]

Demostración:
El estimador \(T \in \mathcal{S}(\theta)\) no tiene sesgo, es decir que

\[
E(T)=\int_{S^{n}} T(\mathbf{x}) \cdot L(\mathbf{x} ; \theta) d \mathbf{x}=\theta
\]

Si derivamos e introducimos la derivada bajo el signo de la integral, obtenemos

\[
\begin{aligned}
\frac{\partial}{\partial \theta} E(T) & =\int_{S^{n}} \frac{\partial}{\partial \theta}(T(\mathbf{x}) \cdot L(\mathbf{x} ; \theta)) d \mathbf{x}=\int_{S^{n}} T(\mathbf{x}) \frac{\partial}{\partial \theta} L(\mathbf{x} ; \theta) d \mathbf{x} \\
& =\int_{S^{n}} T(\mathbf{x})\left(\frac{\frac{\partial}{\partial \theta} L(\mathbf{x} ; \theta)}{L(\mathbf{x} ; \theta)}\right) L(\mathbf{x} ; \theta) d \mathbf{x}
\end{aligned}
\]

Así pues

\[
1=\frac{\partial}{\partial \theta} \theta=\frac{\partial}{\partial \theta} E(T)=E(T Z)=\int_{S^{n}} T(\mathbf{x}) \cdot Z L(\mathbf{x} ; \theta) d \mathbf{x}
\]

En resumen

\[
E(T)=\theta, E(T Z)=1, E(Z)=0, \operatorname{var}(Z)=I_{n}(\theta)
\]

Si ahora consideramos el coeficiente de correlación al cuadrado entre \(T\) y \(Z\), tenemos

\[
\rho^{2}(T, Z)=\frac{[\operatorname{cov}(T, Z)]^{2}}{\operatorname{var}(T) \cdot \operatorname{var}(Z)}=\frac{[E(T Z)-E(T) E(Z)]^{2}}{\operatorname{var}(T) \cdot \operatorname{var}(Z)} \leq 1
\]

Si sustituimos los resultados hallados antes, obtenemos

\[
\frac{1}{\operatorname{var}(T) \cdot I_{n}(\theta)} \leq 1
\]

de donde se deduce la desigualdad enunciada.

Definició 2.11 Si un estimador alcanza la CCR (Cota de Cramer-Rao), diremos que es un estimador eficiente.

Todo estimador eficiente es de mínima varianza en la clase \(\mathcal{S}(\theta)\). Sin embargo, también puede suceder que exista un estimador de mínima varianza sin alcanzar necesariamente la CCR.

Ejemplo 2.3.3 Sea \(X \sim F_{\theta}=P(\lambda), \lambda>0\) (Poisson). Buscamos la \(C C R\) de los estimadores de \(\lambda\).

\[
\begin{aligned}
L(\mathbf{x} ; \lambda) & =\prod_{i=1}^{n} e^{-\lambda} \frac{\lambda^{x_{i}}}{x_{i}!}=e^{-n \lambda} \frac{\lambda^{\sum x_{i}}}{\prod_{i=1}^{n} x_{i}!} \\
\log L(\mathbf{x} ; \lambda) & =-n \lambda+\left(\sum x_{i}\right) \log \lambda-\log \left(\prod_{i=1}^{n} x_{i}!\right) \\
\frac{\partial \log (L(\mathbf{x} ; \lambda))}{\partial \lambda} & =-n+\frac{\sum x_{i}}{\lambda} \\
E\left[\frac{\partial \log L(\mathbf{x} ; \lambda)}{\partial \lambda}\right]^{2} & =E\left[n^{2}+\left(\frac{\sum X_{i}}{\lambda}\right)^{2}-\frac{2 n \sum X_{i}}{\lambda}\right] \\
& =n^{2}+\frac{1}{\lambda^{2}} E\left(\sum X_{i}\right)^{2}-\frac{2 n}{\lambda} n E(X)
\end{aligned}
\]

Aquí recordamos que la suma de variables de Poisson también es una Poisson, es decir:

\[
\sum X_{i} \sim P(n \lambda)
\]

por lo que

\[
E\left(\sum X_{i}\right)^{2}=\operatorname{var}\left(\sum X_{i}\right)+\left[E\left(\sum X_{i}\right)\right]^{2}=n \lambda+(n \lambda)^{2}
\]

Finalmente, se obtiene:

\[
E\left(Z^{2}\right)=n^{2}+\frac{n \lambda}{\lambda^{2}}+\frac{n^{2} \lambda^{2}}{\lambda^{2}}-2 n^{2}=\frac{n}{\lambda}
\]

De esta forma,

\[
I_{n}(\lambda)=\frac{n}{\lambda} \quad \Longrightarrow \quad \operatorname{var}(T) \geq \frac{\lambda}{n}
\]

Sabemos que la media aritmética verifica

\[
\operatorname{var}\left(\bar{X}_{n}\right)=\frac{\lambda}{n}
\]

lo cual coincide con la cota de Cramer-Rao, indicando que \(\bar{X}_{n}\) es el estimador eficiente de \(\lambda\).

Ejemplo 2.3.4 Para calcular la CCR o, dicho de otro modo, para que el inverso de

\[
E\left[\frac{\partial \log L(\mathbf{x} ; \theta)}{\partial \theta}\right]^{2}
\]

sea realmente la cota minima de \(\operatorname{var}(\widehat{\theta})\) en la clase \(\mathcal{S}(\theta)\), es necesario que se verifiquen las condiciones de regularidad. De lo contrario, se pueden obtener resultados absurdos.
Consideremos, por ejemplo, una variable aleatoria \(X\) con función de densidad

\[
f(x ; \theta)=\frac{3}{\theta^{3}} x^{2} \mathbf{1}_{[0, \theta]}(x)
\]

y esperanza

\[
E(X)=\int_{0}^{\theta} x \cdot \frac{3}{\theta^{3}} x^{2} d x=\frac{3}{4} \theta
\]

Ya que \(\theta=\frac{4}{3} E(X)\), esto sugiere estimar \(\theta\) mediante \(\widehat{\theta}=\frac{4}{3} \bar{X}\), que no tiene sesgo.
Por otro lado, si calculamos la varianza de \(X\), tenemos

\[
\operatorname{var}(X)=E\left(X^{2}\right)-E(X)^{2}=\frac{3}{80} \theta^{2}
\]

Sabemos que \(E(\widehat{\theta})=\theta, y\) además

\[
\operatorname{var}(\widehat{\theta})=\operatorname{var}\left(\frac{4}{3} \bar{X}\right)=\frac{\theta^{2}}{15 n}
\]

Si evaluamos \(I_{n}(\theta)\) en su forma más sencilla, obtenemos

\[
I_{n}(\theta)=n I(\theta)=n \frac{9}{\theta^{2}}
\]

Así, la CCR resulta ser mayor que la varianza de este estimador:

\[
\operatorname{var}(\widehat{\theta})=\frac{\theta^{2}}{15 n}<\frac{\theta^{2}}{9 n}
\]

lo cual es un resultado absurdo. Este error se debe a no considerar que el soporte de \(X\) depende de \(\theta\), por lo que no se cumplen las condiciones de regularidad, y la cota de Cramer-Rao no existe.

También ocurre que la varianza de un estimador es inferior a la CCR aunque esta exista. Esto puede pasar, por ejemplo, con algún estimador sesgado.

\subsection{Caracterización del estimador eficiente}\label{caracterizaciuxf3n-del-estimador-eficiente}

Calcular la cota de Cramer-Rao es una cosa; encontrar el estimador que alcanza esta cota y, en consecuencia, tiene varianza mínima es otra. La siguiente caracterización permite, en algunos casos, obtener directamente la forma del estimador eficiente.

Teorema 2.2 Sea \(T\) el estimador eficiente de \(\theta\), entonces se verifica

\[
\sum_{i=1}^{n} \frac{\partial}{\partial \theta} \log f\left(X_{i} ; \theta\right)=K(\theta, n)(T-\theta)
\]

donde \(K(\theta, n)\) es una función que depende de \(\theta\) y de \(n\) y que suele coincidir con la información de Fisher.
Demostración:
Si \(T\) es el estimador eficiente, entonces

\[
\operatorname{var}(T)=\frac{1}{I_{n}(\theta)}
\]

y, por lo tanto, \(\rho^{2}(T, Z)=1\).
En general, dadas dos variables aleatorias \(X\) e \(Y\), se sabe que si \(\rho(X, Y)=1\), entonces

\[
Y-E(Y)=\beta(X-E(X))
\]

Si aplicamos este resultado a \(T\) y \(Z\), tenemos

\[
\begin{aligned}
Z-E(Z) & =\beta(T-E(T)) \\
\frac{\partial \log L(\mathbf{x} ; \theta)}{\partial \theta} & =K(\theta, n)(T-\theta)
\end{aligned}
\]

Ejemplo 2.3.5 En el caso de la distribución de Poisson, tenemos

\[
\begin{aligned}
f(x ; \lambda) & =e^{-\lambda} \frac{\lambda^{x}}{x!} \\
\log f(x ; \lambda) & =-\lambda+x \log (\lambda)-\log (x!) \\
\frac{\partial \log f(x ; \lambda)}{\partial \lambda} & =-1+x \frac{1}{\lambda} \\
Z=\sum_{i=1}^{n} \frac{\partial \log f\left(X_{i} ; \lambda\right)}{\partial \lambda} & =\sum_{i=1}^{n}\left(-1+\frac{X_{i}}{\lambda}\right)
\end{aligned}
\]

Queremos ver que

\[
\sum_{i=1}^{n}\left(\frac{X_{i}}{\lambda}-1\right)=K(\theta, n)(T-\theta)
\]

Si reescribimos esta expresión, obtenemos

\[
\frac{1}{\lambda} \sum_{i=1}^{n} X_{i}-n=\frac{1}{\lambda}\left(\sum_{i=1}^{n} X_{i}-n \lambda\right)=\frac{n}{\lambda}\left(\frac{1}{n} \sum_{i=1}^{n} X_{i}-\lambda\right)
\]

Así, \(K(\lambda, n)=\frac{n}{\lambda}\), que coincide con la información de Fisher \(I_{n}(\lambda)\). Por el teorema anterior, se deduce que \(T=\bar{X}\) es el estimador eficiente \(y\), por lo tanto, de mínima varianza.

\subsection{Estadísticos suficientes}\label{estaduxedsticos-suficientes}

En un problema de inferencia puede suceder que los datos contengan información superflua o irrelevante a la hora de estimar el parámetro. También puede ocurrir lo contrario, que intentemos hacer la estimación sin utilizar toda la información disponible en la muestra. Ambas situaciones son indeseables. Parece razonable que, para estimar un parámetro, dada la dificultad derivada de disponer de varios estimadores entre los que queremos elegir el óptimo, nos basemos únicamente en aquellos que utilizan (solo) toda la información relevante.

Ejemplo 2.4.1 Supongamos que queremos estimar la proporción de piezas defectuosas \(\theta\) en un proceso de fabricación. Para ello, examinamos \(n\) piezas extraídas al azar a lo largo de una jornada y asignamos un 1 a las piezas defectuosas y un 0 a las que no lo son. Así, obtenemos una muestra aleatoria simple \(X_{1}, X_{2}, \ldots, X_{n}\) donde

\[
X_{i}= \begin{cases}1 & \text { con probabilidad } \theta \\ 0 & \text { con probabilidad }(1-\theta)\end{cases}
\]

Intuitivamente, está claro que para estimar \(\theta\) solo nos interesa el número de ceros y unos, es decir, el valor del estadístico

\[
T(\mathbf{X})=\sum_{i=1}^{n} X_{i}
\]

En este caso, un estadístico que considere la posición de los unos y los ceros en la muestra no aportaría nada relevante. En cambio, un estadístico que no considere todos los valores, como por ejemplo \(T(\mathbf{X})=X_{1}\), sería claramente menos adecuado.

Las observaciones del ejemplo anterior se justifican al observar que todas las muestras de tamaño \(n\) con el mismo número \(t\) de unos (1) tienen la misma probabilidad. En concreto, la función de probabilidad de una muestra \(x_{1}, x_{2}, \ldots, x_{n}\) es

\[
f_{\theta}\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\theta^{t}(1-\theta)^{n-t}
\]

donde \(t=\sum_{i=1}^{n} x_{i}, x_{i} \in\{0,1\}, i=1,2, \ldots, n\).
Como se puede ver, la probabilidad de la muestra solo depende del número de unos (o ceros) y no del orden en que aparecen en la muestra. El hecho de que la posición de los unos y los ceros en la muestra no aporte información relevante equivale a decir que el estadístico

\[
T(\mathbf{X})=\sum_{i=1}^{n} X_{i}
\]

contiene la misma información que \(X_{1}, X_{2}, \ldots, X_{n}\) para estimar \(\theta\). Observamos, sin embargo, varias diferencias entre basarse en \(T(\mathbf{X})\) o en \(X_{1}, X_{2}, \ldots, X_{n}\) :

\begin{itemize}
\tightlist
\item
  Al pasar de \(X_{1}, X_{2}, \ldots, X_{n}\) a \(\sum_{i=1}^{n} X_{i}\) hay una reducción de los datos que no implica pérdida de información.
\item
  Muchas muestras diferentes dan lugar al mismo valor de \(T\).
\end{itemize}

Fisher formalizó esta idea con el cálculo de la probabilidad condicionada de la observación muestral con \(T(\mathbf{X})=\sum_{i=1}^{n} X_{i}\) y para todo \(t=0,1, \ldots, n\) :

\[
\begin{aligned}
P_{\theta}[\mathbf{X}=\mathbf{x} \mid T=t] & =\frac{P_{\theta}[\mathbf{X}=\mathbf{x}, T=t]}{P_{\theta}(T=t)} \\
& =\frac{\theta^{t}(1-\theta)^{n-t}}{\binom{n}{t} \theta^{t}(1-\theta)^{n-t}}=\frac{1}{\binom{n}{t}}
\end{aligned}
\]

Es decir, dados \(\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in\{0,1\}^{n} \mathrm{y} t \in\{0,1, \ldots, n\}\), tenemos

\[
P_{\theta}[\mathbf{X}=\mathbf{x} \mid T=t]=\left\{\begin{array}{cc}
0 & \text { si } t \neq \sum_{i=1}^{n} x_{i} \\
\frac{1}{\binom{n}{t}} & \text { si } t=\sum_{i=1}^{n} x_{i}
\end{array}\right.
\]

Obviamente, \(P_{\theta}[\mathbf{X}=\mathbf{x}]\) depende de \(\theta\), que es el parámetro que queremos estimar. Sin embargo, la probabilidad condicionada \(P_{\theta}[\mathbf{X}=\mathbf{x} \mid T=t]\) no depende de \(\theta\). Tenemos entonces la siguiente expresión de la función de probabilidad de la muestra:

\[
P_{\theta}(\mathbf{X}=\mathbf{x})=P_{\theta}(T=t) \cdot P_{\theta}[\mathbf{X}=\mathbf{x} \mid T=t]
\]

Esta expresión muestra que \(P_{\theta}(\mathbf{X})\) se puede descomponer en dos factores, uno que depende de \(\theta, P_{\theta}(T=t)\), y otro que no depende de \(\theta\),

\[
P_{\theta}[\mathbf{X}=\mathbf{x} \mid T=t] .
\]

Una forma de ver esta descomposición es pensar que el estadístico \(T=\) \(\sum_{i=1}^{n} X_{i}\) ?acumula? o ?absorbe? toda la información relativa a \(\theta\), lo que se refleja en que la probabilidad de la muestra, dado \(T=t\), ya no depende de \(\theta\). Es decir, podemos imaginar la construcción de la muestra en dos etapas:

\begin{itemize}
\tightlist
\item
  En una primera etapa se elige el valor \(t\) para \(T\) con distribución \(B(n, \theta)\).
\item
  A continuación, se sitúan aleatoriamente \(t\) unos y \(n-t\) ceros en las \(n\) posiciones.
\end{itemize}

Cuando la estructura del estadístico \(T(\mathbf{X})\) hace que el segundo factor en la expresión anterior no dependa de \(\theta\), significa que la observación adicional de la muestra es irrelevante. En este caso diremos que \(T(\mathbf{X})\) es suficiente para la estimación de \(\theta\). Dado que esta propiedad de \(T\) queda caracterizada por la independencia de \(P_{\theta}[\mathbf{X}=\mathbf{x} \mid T=t]\) respecto a \(\theta\), se utiliza esta independencia para definir la suficiencia.

\subsubsection{Definició de estadísticop suficiente}\label{definiciuxf3-de-estaduxedsticop-suficiente}

Dado un modelo estadístico \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\) y un estadístico \(T\), diremos que \(T\) es suficiente para \(\theta\) si, dada una muestra \(\mathbf{X}=\left(X_{1}, X_{2}, \ldots, X_{n}\right)\), se verifica que la distribución de \(\mathbf{X}\) condicionada por el valor de \(T\) no depende de \(\theta\).

\begin{itemize}
\tightlist
\item
  No es necesario que \(F_{\theta}\) sea discreta, como en el ejemplo introductorio, o que la muestra sea una muestra aleatoria simple.
\item
  El estadístico suficiente para un parámetro puede ser \(k\)-dimensional.
\end{itemize}

Ejemplo 2.4.2 Dada una muestra \(X_{1}, X_{2}, \ldots, X_{n}\) de una distribución de Poisson, la función de probabilidad de la muestra es

\[
P_{\theta}\left(X_{1}=x_{1}, \ldots, X_{n}=x_{n}\right)=\frac{e^{-n \lambda} \lambda \sum x_{i}}{x_{1}!\cdots x_{n}!}
\]

Calculemos la probabilidad de la muestra condicionada por el valor del estadístico \(T=\sum_{i=1}^{n} X_{i}\) :

\[
\begin{aligned}
& P_{\theta}\left[X_{1}=x_{1}, \ldots, X_{n}=x_{n} \mid T=t\right]=\frac{P_{\theta}\left(X_{1}=x_{1}, \ldots, X_{n}=x_{n}, T=t\right)}{P_{\theta}(T=t)}
\end{aligned}
\]

\[
\begin{aligned}
& =\frac{t!}{x_{1}!\cdots x_{n}!}\left(\frac{1}{n}\right)^{t} \mathbf{1}_{\left\{\sum x_{i}=t\right\}}\left(x_{1}, \ldots, x_{n}\right)
\end{aligned}
\]

La probabilidad condicional no depende de \(\lambda y\), por lo tanto, \(T\) es suficiente para \(\lambda\). Conviene observar que, en este ejemplo, no todas las muestras tienen la misma probabilidad.

\subsubsection{Teorema de factorización}\label{teorema-de-factorizaciuxf3n}

La justificación de la suficiencia de un estadístico mediante la definición no siempre es sencilla, ya que la distribución condicional puede ser intratable con las herramientas disponibles. El teorema que se presenta a continuación proporciona un método sencillo para comprobar la suficiencia de un estadístico y, a menudo, sugiere cuál es el estadístico suficiente de menor dimensión posible.

Teorema 2.3 Neyman-Fisher. Sea \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\) un modelo estadístico y \(X_{1}, X_{2}, \ldots, X_{n}\) una muestra aleatoria simple de \(X\). Sea \(f_{\theta}(\mathbf{x})\) la función de probabilidad o la función de densidad de la muestra, según si \(X\) es discreta o absolutamente continua. Un estadístico \(T\) es suficiente para \(\theta\) si y solo si existen dos funciones medibles \(g_{\theta}\) y \(h\) tales que

\[
f_{\theta}(\mathbf{x})=g_{\theta}(T(\mathbf{x})) \cdot h(\mathbf{x})
\]

donde \(h\) no depende de \(\theta\) y g depende de \(\theta\) y, además, solo depende de la muestra a través de \(T\).

Veamos ahora la demostración del teorema de factorización, restringida al caso de variables discretas.

Demostración:
Comenzaremos suponiendo que \(T\) es suficiente y concluiremos que es posible la factorización.
Si \(T(\mathbf{X})\) es suficiente para la familia de distribuciones \(\left\{F_{\theta} ; \theta \in \Theta\right\}\), la función de probabilidad de la muestra condicionada por \(T\) no depende de \(\theta\). Dado que

\[
f_{\theta}(\mathbf{x})=P_{\theta}[T=T(\mathbf{x})] \cdot f_{\theta}[\mathbf{x} \mid T=T(\mathbf{x})]
\]

solo es necesario tomar \(g_{\theta}(t)=P_{\theta}[T=T(\mathbf{x})=t]\) y \(h(\mathbf{x})=f_{\theta}[\mathbf{x} \mid T=T(\mathbf{x})]\) para obtener el resultado.
Ahora supongamos que es posible la factorización y deduzcamos la suficiencia.
Si \(f_{\theta}(\mathbf{x})=g_{\theta}(T(\mathbf{x})) \cdot h(\mathbf{x})\) y llamamos \(A_{t}=\left\{\mathbf{x} \in X(\Omega)^{n} \mid T(\mathbf{x})=t\right\}\), entonces

\[
P_{\theta}[T(\mathbf{x})=t]=\sum_{A_{t}} g_{\theta}(T(\mathbf{x})) \cdot h(\mathbf{x})=g_{\theta}(t) \cdot \sum_{A_{t}} h(\mathbf{x})
\]

Consideremos ahora la distribución de la muestra condicionada a \(T=t\). El Teorema de Bayes para densidad permite escribir:

\[
\begin{aligned}
f_{\theta}(\mathbf{x} \mid T=t) & =\frac{f_{\theta}(\mathbf{x}, T=t)}{P_{\theta}(T=t)} \\
& = \begin{cases}\frac{g_{\theta}(t) \cdot h(\mathbf{x})}{g_{\theta}(t) \cdot \sum_{A_{t}} h(\mathbf{x})}=\frac{h(\mathbf{x})}{\sum_{A_{t}} h(\mathbf{x})} & \text { si } T(\mathbf{x})=t \\
0 & \text { si } T(\mathbf{x}) \neq t\end{cases}
\end{aligned}
\]

De modo que la distribución de \(\mathbf{X}\) condicionada por el valor de \(T\) no depende de \(\theta\), y, en consecuencia, \(T\) es suficiente.

Ejemplo 2.4.3 Si X sigue una distribución de Bernoulli, tenemos:

\[
f_{\theta}(\mathbf{x})=\theta^{\sum_{i=1}^{n} x_{i}}(1-\theta)^{n-\sum_{i=1}^{n} x_{i}}=g_{\theta}\left(\sum_{i=1}^{n} x_{i}\right) .
\]

Si tomamos \(h(\mathbf{x})=1\), queda probado que \(T=\sum_{i=1}^{n} X_{i}\) es suficiente.
Ejemplo 2.4.4 Si consideramos una muestra de una distribución de Poisson

\[
f_{\lambda}(\mathbf{x})=e^{-n \lambda} \frac{\lambda^{\sum_{i=1}^{n} x_{i}}}{x_{1}!x_{2}!\cdots x_{n}!}
\]

\(y\) tomamos \(T(\mathbf{x})=\sum_{i=1}^{n} x_{i}\), podemos escribir

\[
f_{\lambda}(\mathbf{x})=e^{-n \lambda} \lambda^{T(\mathbf{x})} \cdot\left(x_{1}!x_{2}!\cdots x_{n}!\right)^{-1}=g_{\lambda}(T(\mathbf{x})) \cdot h(\mathbf{x})
\]

donde

\[
g_{\lambda}(T(\mathbf{x}))=e^{-n \lambda} \lambda^{T(\mathbf{x})}, \quad h(\mathbf{x})=\left(x_{1}!x_{2}!\cdots x_{n}!\right)^{-1}
\]

De modo que \(g_{\lambda}(t)=e^{-n \lambda} \lambda^{t}\) depende de la muestra solo a través de \(T=\) \(\sum_{i=1}^{n} x_{i}\) y \(h(\mathbf{x})=\left(x_{1}!x_{2}!\cdots x_{n}!\right)^{-1}\) no depende de \(\lambda\).

Ejemplo 2.4.5 Supongamos que \(\mathbf{X}\) es una muestra aleatoria simple de una población \(X \sim N(\mu, \sigma)\), cuya función de densidad es

\[
f_{\mu, \sigma^{2}}\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\frac{1}{\left(\sqrt{2 \pi \sigma^{2}}\right)^{n}} \exp \left\{-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}\right\}
\]

Para evidenciar la factorización, utilizamos que

\[
\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}=\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}+n(\bar{x}-\mu)^{2} .
\]

Entonces,

\[
\begin{aligned}
f_{\mu, \sigma^{2}}\left(x_{1}, x_{2}, \ldots, x_{n}\right) & =\frac{1}{\left(\sqrt{2 \pi \sigma^{2}}\right)^{n}} \exp \left\{-\frac{1}{2 \sigma^{2}}\left(\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}+n(\bar{x}-\mu)^{2}\right)\right\} \\
& =\frac{1}{\left(\sqrt{2 \pi \sigma^{2}}\right)^{n}} \exp \left\{-\frac{1}{2 \sigma^{2}}\left(n s^{2}+n(\bar{x}-\mu)^{2}\right)\right\} \\
& =g_{\mu, \sigma^{2}}\left(\bar{x}, s^{2}\right) \cdot 1
\end{aligned}
\]

Así, vemos que el estadístico \(\left(\bar{X}, s^{2}\right)\) es suficiente para la estimación de \(\left(\mu, \sigma^{2}\right)\).
Si suponemos conocido uno de los dos parámetros \(\sigma^{2}\) o \(\mu\), podemos obtener una factorización en la que se ve que \(\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}\) es suficiente para \(\sigma^{2}\) (conocido \(\mu\) ) o \(\bar{x}\) es suficiente para \(\mu\) (conocido \(\sigma^{2}\) ).

En el ejemplo anterior se observa que el estadístico suficiente para un problema puede tener una dimensión superior a 1. En general, buscaremos el estadístico suficiente de menor dimensión posible, ya que a menor dimensión se elimina más información superflua. Si no es posible encontrarlo así, siempre podemos basarnos en el estadístico \(T=\left(X_{1}, X_{2}, \ldots, X_{n}\right)\), que es suficiente pero de dimensión máxima y, por lo tanto, no aporta ninguna reducción al problema de información. Estas reflexiones llevan a enunciar el principio de suficiencia, que aconseja condensar al máximo la información relevante en un estadístico suficiente \(T\) de la menor dimensión posible (``mínima'') y seleccionar un estimador \(T^{\prime}\) entre los estadísticos que sean función de la muestra a través de \(T: T^{\prime}(\mathbf{X})=\varphi(T(\mathbf{X}))\).

\subsubsection{Propiedades de los estadísticos suficientes}\label{propiedades-de-los-estaduxedsticos-suficientes}

Las siguientes propiedades se prueban de manera sencilla utilizando el teorema de factorización:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Si \(T\) es un estadístico suficiente para \(\theta\) y \(\varphi\) es una función inyectiva (o monótona diferenciable), entonces \(T_{1}=\varphi(T)\) también es suficiente para \(\theta\).
\end{enumerate}

Ejemplo 2.4.6 En la familia de la Poisson hemos visto que \(\sum_{i=1}^{n} X_{i}\) es suficiente para \(\lambda\). Entonces \(\bar{X}=\varphi\left(\sum_{i=1}^{n} X_{i}\right)\), donde \(\varphi(z)=(1 / n) z\) es inyectiva, es suficiente para \(\lambda\).
2. Si \(T\) es un estadístico suficiente para \(\theta\) y \(\varphi\) es una función paramétrica monótona diferenciable, entonces \(\varphi(T)\) también es suficiente para \(\varphi(\theta)\).
3. Si \(T_{1}, T_{2}\) son dos estadísticos suficientes para \(\theta\), entonces \(T_{1}\) es función de \(T_{2}\).

\subsection{Obtención de estimadores}\label{obtenciuxf3n-de-estimadores}

En el capítulo anterior hemos analizado el problema de la estimación puntual desde el punto de vista de, dado un estimador, ver ?qué tan bueno es? para estimar un parámetro.
Otra cuestión que nos podemos plantear, de hecho la primera cuestión que hay que plantearse en la práctica, es cómo obtener un estimador ?razonablemente bueno? de un parámetro. De hecho, desde el punto de vista práctico parece razonable empezar por ver cómo se obtiene un estimador y, una vez obtenido, analizar ?cuán bueno resulta?.
Existen muchos métodos para obtener estimadores, cada uno de los cuales puede llevarnos a unos resultados de diferente calidad.
Los principales métodos de estimación son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Método de los momentos
\item
  Método de la máxima verosimilitud
\item
  Método de Bayes
\item
  Otros métodos
\end{enumerate}

\subsection{El método de los momentos}\label{el-muxe9todo-de-los-momentos}

Este método fue introducido por K. Pearson a finales del siglo XIX y es el principio en que nos basamos cuando hacemos una estimación de la media o de la varianza poblacional a partir de la media o la varianza muestrales.
La idea del método de los momentos es bastante intuitiva. Si lo que queremos estimar (uno o varios parámetros) es una función de los momentos
poblacionales, entonces una estimación razonable puede consistir en tomar como estimador la misma función en la que los momentos poblacionales han sido sustituidos por los momentos muestrales.
Dado que estos últimos son estimadores consistentes de los momentos poblacionales, en condiciones bastante generales se puede garantizar que los estimadores obtenidos serán estimadores consistentes para las funciones de los momentos poblacionales estimadas.
Algunos ejemplos típicos de estimadores basados en el método de los momentos son:

\[
\widehat{\mu}=\bar{X}_{n} \quad \widehat{\sigma}=\sqrt{S^{2}} \quad \widehat{\sigma^{2}}=S^{2}
\]

Sea un modelo estadístico, \(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\), y \(X_{1}, X_{2}, \ldots, X_{n}\) una muestra aleatoria simple de \(X\). Sean \(m_{1}, m_{2}, ?, m_{k}\) los momentos poblacionales de orden \(1,2, ?, k\) de \(X\), que suponemos que existen,

\[
m_{k}=E\left(X^{k}\right)
\]

y \(a_{1}, a_{2}, ?, a_{k}\) los momentos muestrales respectivos

\[
a_{k}\left(X_{1}, X_{2}, \ldots, X_{n}\right)=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}
\]

Suponemos que estamos interesados en estimar:

\[
\theta=h\left(m_{1}, m_{2}, \ldots, m_{p}\right),
\]

donde \(h\) es una función conocida.
Definició 3.1 El método de los momentos consiste en estimar \(\theta\) por el estadístico

\[
T(\mathbf{X})=h\left(a_{1}, a_{2}, \ldots, a_{p}\right)
\]

\subsubsection{Observaciones}\label{observaciones-1}

\begin{itemize}
\tightlist
\item
  El método se extiende de forma sencilla a la estimación de momentos conjuntos. Podemos usar \(\frac{1}{n} \sum_{i=1}^{n} X_{i} Y_{i}\) para estimar \(E(X Y)\), etc.
\item
  Por la ley débil de los grandes números,
\end{itemize}

\[
a_{k}\left(X_{1}, X_{2}, \ldots, X_{n}\right)=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k} \xrightarrow{P} E\left(X^{k}\right),
\]

de modo que si lo que queremos es estimar los momentos muestrales, el método garantiza que los estimadores son consistentes y sin sesgo.

En este caso, además, los estimadores son asintóticamente normales. Si lo que se desea estimar es una función \(h\) continua de los momentos, entonces el método garantiza que el estimador \(T(\mathbf{X})\) es consistente y, bajo ciertas condiciones de regularidad, también es asintóticamente normal.

Ejemplo 3.1.1 Sea \(X \sim \Gamma(p, \alpha)\). Queremos estimar \(p\) y \(\alpha\). En lugar de conocer la función \(h\left(\theta_{1}, \theta_{2}\right)\) sabemos que:

\[
\begin{aligned}
m_{1} & =\frac{p}{\alpha}=E(X) \\
m_{2} & =\frac{p(p+1)}{\alpha^{2}}=E\left(X^{2}\right) \\
& =V(X)+[E(X)]^{2}=\frac{p}{\alpha^{2}}+\left(\frac{p}{\alpha}\right)^{2}=\frac{p^{2}+p}{\alpha^{2}}=
\end{aligned}
\]

De modo que podemos obtener las funciones deseadas ?aislando? p y \(\alpha\) como funciones de \(m_{1}\) y \(m_{2}\) :

\[
\begin{aligned}
\alpha^{2} & =\frac{p^{2}}{m_{1}^{2}} \\
\alpha^{2} & =\frac{p(p+1)}{m_{2}}
\end{aligned}
\]

Procediendo por igualación:

\[
\begin{aligned}
& \frac{p^{2}}{m_{1}^{2}}=\frac{p(p+1)}{m_{2}} \\
& \frac{p}{m_{1}}=\frac{p+1}{m_{2}} \\
& p m_{2}=p m_{1}^{2}+m_{1}^{2} \\
& p\left(m_{2}-m_{1}^{2}\right)=m_{1}^{2} \\
& p=\frac{m_{1}^{2}}{m_{2}-m_{1}^{2}} \\
& \alpha=\frac{m_{1}^{2}}{m_{2}-m_{1}^{2}} \\
& m_{1}
\end{aligned} \frac{m_{1}}{m_{2}-m_{1}^{2}} .
\]

Los estimadores por el método de los momentos se obtendrán ahora sustituyendo \(p\) y \(\alpha\) por \(\hat{p}\) y \(\hat{\alpha}\) en la expresión anterior, es decir:

\[
\widehat{p}=\frac{a_{1}^{2}}{a_{2}-a_{1}^{2}}
\]

Hacemos lo mismo para el parámetro \(\alpha\) :

\[
\widehat{\alpha}=\frac{a_{1}}{a_{2}-a_{1}^{2}}
\]

\subsection{El método del máximo de verosimilitud}\label{el-muxe9todo-del-muxe1ximo-de-verosimilitud}

\paragraph{Introducción}\label{introducciuxf3n-1}

El método de la máxima verosimilitud, introducido por Fisher, es un método de estimación que se basa en la función de verosimilitud, presentada en el capítulo anterior. Básicamente consiste en tomar como estimadores de los parámetros aquellos valores que hagan más probable observar precisamente lo que se ha observado, es decir, que hagan que la muestra observada resulte más verosímil.

Ejemplo 3.2.1 Tomemos 5 papeles. En cada uno de ellos ponemos o bien un ?+? o bien un ?-?, sin que se sepa qué hay en cada papel, y los guardamos en una bolsa. Nuestro objetivo es estimar el número de papeles con el signo ?? escrito. Extraemos tres papeles, devolviéndolos a la bolsa después de cada extracción, y observamos que ha salido lo siguiente: ?++-?. Los valores posibles para la probabilidad de ?-?, llamémosla p, son:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
En la bolsa hay & \(p\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(4 ?+\) ?, 1 ?-? & 0,2 \\
\(3 ?+\) ?, 2 ?-? & 0,4 \\
\(2 ?+\) ?, 3 ?-? & 0,6 \\
\(1 ?+\) ?, 4 ?-? & 0,8 \\
\end{longtable}

Supongamos que la variable \(X\) mide el número de ?-? en tres extracciones consecutivas y que, por tanto, sigue una distribución binomial:

\[
X \sim B(3, p(?-?))
\]

La probabilidad de sacar un ?-? es:

\[
P_{p}[X=1]=\binom{3}{1} \cdot p^{1}(1-p)^{2}
\]

Para cada uno de los valores de p, las probabilidades quedan asi:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(p\) & \(P_{p}[X=1]\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0.2 & \(3 \cdot 0.2 \cdot 0.8^{2}=0.384\) \\
0.4 & \(3 \cdot 0.4 \cdot 0.6^{2}=0.432\) \\
0.6 & \(3 \cdot 0.6 \cdot 0.4^{2}=0.288\) \\
0.8 & \(3 \cdot 0.8 \cdot 0.2^{2}=0.096\) \\
\end{longtable}

El valor de p que da una probabilidad mayor a la muestra, es decir, que la hace más verosímil, es \(p=0.4\). El método del máximo de verosimilitud consiste precisamente en tomar este valor como estimación de \(p\).

\paragraph{La función de verosimilitud}\label{la-funciuxf3n-de-verosimilitud}

Una vez introducido el método con un ejemplo, podemos pasar a definirlo con mayor precisión. Para ello, comenzaremos con el concepto de función de verosimilitud.
En el capítulo anterior presentamos la función de verosimilitud como la función que resulta de considerar que, en la función de probabilidad de la muestra, el parámetro es variable y la muestra queda fija. Es decir:

\[
\underbrace{f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)}_{\mathbf{x} \text { variable, } \theta \text { fijo }} \longrightarrow \underbrace{L\left(\theta ; x_{1}, x_{2}, \ldots, x_{n}\right)}_{\mathbf{x} \text { fija, } \theta \text { variable }}
\]

Esta definición es básicamente correcta. En el caso de las variables discretas, donde \(f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)\) representa la probabilidad de la muestra, fijado \(\theta\), resulta intuitivamente claro decir que la verosimilitud representa la ?probabilidad de la muestra para cada valor del parámetro?.
Refiriéndonos al ejemplo introductorio, resulta sencillo ver que se trata de ?dos puntos de vista? sobre la misma función. Fijado un valor del parámetro, por ejemplo, 0.4 , podemos considerar la probabilidad de diversas muestras posibles, como \(x=0, x=1, \ldots\), hasta \(x=3\) :

\[
\begin{aligned}
f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right) & =P_{0.4}[X=x], x=0,1, \ldots, 3 \\
& =\binom{3}{x} \cdot 0.4^{x}(0.6)^{3-x} .
\end{aligned}
\]

Análogamente, fijada una muestra, por ejemplo, \(x=1\), podemos considerar la probabilidad de esta para diversos valores del parámetro, \(p=0,0.2, \ldots, 1\).

\[
\begin{aligned}
L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right) & =P_{p}[X=1], x=0,0.2,0.4, \ldots, 1 \\
& =3 \cdot p(1-p)^{2} .
\end{aligned}
\]

En el caso de las distribuciones absolutamente continuas, el significado de la función de verosimilitud ya no es intuitivamente tan claro como en el caso de las discretas. En este caso, la función de densidad de la muestra ya no representa la probabilidad de esta como en el caso de las discretas. Algunos autores intentan solucionar esto explicando que existe una conocida aproximación en que la función de densidad es la probabilidad de un suceso ?infinitesimal?.
Lo que es importante en la función de verosimilitud, a la hora de hacer inferencias, es la parte que es función del parámetro. Esto hace que a menudo se considere que la expresión de la función de verosimilitud mantenga solo aquella parte de \(f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)\) que depende de \(\theta\), ignorando la parte que dependa solo de la muestra. Es decir, si podemos factorizar \(f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)\) como

\[
f(\mathbf{x} ; \theta)=c(\mathbf{x}) \cdot g(\mathbf{x} ; \theta)
\]

podremos prescindir de la ?constante? \(c(x)\) (constante porque no depende de \(\theta\) ) al considerar la verosimilitud.

\[
L(\theta ; \mathbf{x})=g(\mathbf{x} ; \theta) \propto f(\mathbf{x} ; \theta)
\]

Esto implica que \(L(\theta ; \mathbf{x})\) no tiene por qué integrar a 1 , como en el caso de las probabilidades, y que depende de las unidades de medida.

Ejemplo 3.2.2 Si \(X\) es discreta, \(X \sim \mathcal{P}(\lambda)\), y suponemos \(n=1\) (muestras de tamaño 1), tenemos que la f.d.p. de la muestra es:

\[
P[x ; \lambda]=e^{-\lambda} \frac{\lambda^{x}}{x!}
\]

con \(x=0,1, \ldots\) Ahora, si hemos observado \(x=5\), la función de verosimilitud vale:

\[
L(\lambda ; 5)=e^{-\lambda} \lambda^{5}\left[\frac{1}{5!}\right]
\]

Como solo nos interesa la parte que es función de \(\lambda\), podemos ignorar \(\frac{1}{5!}\), es decir:

\[
L(\lambda ; 5)=e^{-\lambda} \lambda^{5} \propto P[\mathbf{x} ; \lambda] .
\]

Ejemplo 3.2.3 Si dada una muestra de tamaño 1, por ejemplo, \(x=2\), de una ley de Poisson \(\mathcal{P}(\lambda)\) queremos comparar sus verosimilitudes respecto de los valores del parámetro \(\lambda=1.5\) o \(\lambda=3\), lo que haremos será basarnos en la razón de verosimilitudes:

\[
\begin{aligned}
\Lambda(\mathbf{x}) & =\frac{L\left(\lambda_{1} ; x\right)}{L\left(\lambda_{2} ; x\right)}=\frac{L(1.5 ; 2)}{L(3 ; 2)} \\
& =\frac{e^{-1.5} 1.5^{2}\left[\frac{1}{2!}\right]}{e^{-3} 3^{2}\left[\frac{1}{2!}\right]}=\frac{e^{-1.5} 1.5^{2}}{e^{-3} 3^{2}}=\frac{0.5020}{0.4481}=1.12 .
\end{aligned}
\]

Como se observa, al basarnos en la razón de verosimilitudes, la parte correspondiente solo a la muestra no se toma en cuenta. La razón de verosimilitudes sugiere que el valor \(\lambda=1.5\) hace la muestra más verosímil.

\paragraph{El método del máximo de verosimilitud}\label{el-muxe9todo-del-muxe1ximo-de-verosimilitud-1}

Si partimos de las dos ideas que hemos visto en la introducción:

\begin{itemize}
\tightlist
\item
  Escoger como estimación el valor que maximice la probabilidad de la muestra observada.
\item
  La verosimilitud de la muestra es una aproximación a la probabilidad de esta como función del valor del parámetro.
\end{itemize}

Una forma razonable de definir el EMV es entonces como aquel que maximice la verosimilitud.

Definició 3.2 Un estimador \(T: \Omega \longrightarrow \Theta\) es un estimador del máximo de verosimilitud para el parámetro \(\theta\) si cumple:

\[
L(T(\mathbf{x}) ; \mathbf{x})=\sup _{\theta \in \Theta} L(\theta ; \mathbf{x})
\]

Como suele ocurrir en problemas de maximización, este valor ni existe necesariamente ni tiene por qué ser único. Ahora bien, bajo ciertas condiciones (las habituales para los problemas de máximos y mínimos) el problema se podrá reducir a buscar un máximo para la función de verosimilitud.

Ejemplo 3.2.4 Supongamos que \(x_{1}, \ldots, x_{n}\) es una muestra de una población de Bernouilli, \(X \sim B e(p)\), donde queremos estimar p.~La función de masa de la probabilidad de \(X\) es:

\[
P\left[X=x_{i}\right]=P\left(x_{i} ; p\right)=p^{x_{i}}(1-p)^{1-x_{i}} \text { donde } x_{i} \in\{0,1\} ; i=1, \ldots, n
\]

La función de verosimilitud es:

\[
L(p ; \mathbf{x})=\prod_{i=1}^{n} p^{x_{i}}(1-p)^{1-x_{i}}=p^{\sum_{i=1}^{n} x_{i}}(1-p)^{\sum_{i=1}^{n}\left(1-x_{i}\right)}
\]

Debemos buscar el máximo de \(L(p ; \mathbf{x})\). En este caso, como en otros, es más sencillo buscar el máximo de su logaritmo, que, dado que es una función monótona, es el mismo que el máximo de \(L\)

\[
\ln L(p ; x)=\left(\sum_{i=1}^{n} x_{i}\right) \cdot \ln p+\left(n-\sum_{i=1}^{n} x_{i}\right) \cdot \ln (1-p)
\]

Derivamos respecto a p:

\[
\frac{\partial \ln L(p ; x)}{\partial p}=\frac{\sum_{i=1}^{n} x_{i}}{p}-\frac{n-\sum_{i=1}^{n} x_{i}}{1-p}
\]

e igualamos a cero la derivada, planteando lo que se denomina la ecuación de verosimilitud, cuyas soluciones nos conducirán eventualmente al estimador del máximo de verosimilitud.

\[
\frac{\sum_{i=1}^{n} x_{i}-n \hat{p}}{\hat{p}(1-\hat{p})}=0 \Rightarrow \hat{p}=\frac{\sum_{i=1}^{n} x_{i}}{n}
\]

Si la segunda derivada es negativa en \(\widehat{p}\) entonces será un máximo:

\[
\begin{aligned}
\frac{\partial^{2} \ln L(p ; x)}{\partial p^{2}} & =\frac{\partial}{\partial p}\left(\frac{\sum_{i=1}^{n} x_{i}-n p}{p(1-p)}\right)=\frac{-n[p(1-p)]-\left(\sum_{i=1}^{n} x_{i}-n p\right) \cdot(1-2 p)}{p^{2}\left(1-p^{2}\right)}= \\
& =\frac{-n p+n p^{2}-\sum_{i=1}^{n} x_{i}-n p-2 p \sum_{i=1}^{n} x_{i}-2 n p^{2}}{p^{2}(1-p)^{2}}= \\
& =\frac{\left[\sum_{i=1}^{n} x_{i}(1+2 p)-n p^{2}\right]}{p^{2} \cdot(1-p)^{2}}
\end{aligned}
\]

que es negativa cuando \(p=\hat{p}\), de forma que \(\hat{p}\) es efectivamente un máximo.
El método analítico expuesto en el ejemplo anterior, consistente en el cálculo de un extremo de una función, no se puede aplicar en todas las situaciones. En estos casos, una alternativa puede ser estudiar directamente la función de verosimilitud. Veamos un ejemplo:

Ejemplo 3.2.5 Sea \(X_{1}, \ldots, X_{n} \stackrel{i i d}{\sim} X \sim U(0, \theta) \quad \theta>0\) desconocido. Sabemos que:

\[
f(x ; \theta)=\left\{\begin{array}{c}
\frac{1}{\theta} \text { si } 0<\min \left\{x_{i}\right\} \leq \max \left\{x_{i}\right\} \leq \theta \\
0 \quad \text { en caso contrario }
\end{array}\right\}
\]

La derivada respecto a \(\theta\) es \(-\frac{n}{\theta^{n-1}}\), que se anula cuando \(\theta \underset{n \rightarrow \infty}{\longrightarrow} \infty\) que lleva a una solución sin sentido de la ecuación de verosimilitud. Una inspección de la gráfica de la función de verosimilitud revela que el EMV, en este caso,

Figura 3.1: Función de verosimilitud para una distribución uniforme
es \(\max \left\{X_{i}, \ldots, X_{n}\right\}\). Efectivamente, consideremos cualquier otro valor \(\theta^{*}\) diferente del máximo:

\[
\begin{aligned}
& \text { Si } \theta^{*}>X_{(n)} \Rightarrow \frac{1}{\left(\theta^{*}\right)^{n}}<\frac{1}{\left(X_{n}\right)^{n}}, \\
& \text { Si } \theta^{*}<X_{(n)} \Rightarrow L\left(\theta^{*} ; \mathbf{x}\right)=0
\end{aligned}
\]

ya que si un estimador toma un valor inferior al máximo de la muestra habrá algún valor muestral, \(x_{i}\) para el cual se verificará que \(\theta^{*}<x_{i}\), lo que hace la muestra inverosímil, y por tanto el estimador no es admisible.
A la vista de lo anterior, deducimos que el valor que maximiza \(L(\theta ; \mathbf{x})\) es el máximo de la muestra.

Ejemplo 3.2.6 El método del máximo de verosimilitud se extiende de forma inmediata a los parámetros \(K\)-dimensionales. Consideremos el caso de la
ley normal \(X \sim N\left(\mu, \sigma^{2}\right)\). Aquí el parámetro \(\theta\) es bidimensional, es decir: \(\theta=\left(\mu, \sigma^{2}\right) \in \Theta=\mathbb{R} \times \mathbb{R}^{+}\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La función de verosimilitud de una muestra de tamaño \(n\) es:
\end{enumerate}

\[
L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)=\prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}=\frac{1}{(2 \pi)^{n / 2}\left(\sigma^{2}(n / 2\right.} e^{-\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Sacando logaritmos
\end{enumerate}

\[
\log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)=-\frac{n}{2} \log (2 \pi)-\frac{n}{2} \log \left(\sigma^{2}\right)-\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  La derivada de \(L()\) es la matriz de derivadas:
\end{enumerate}

\[
D \log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)=\binom{\frac{\partial \log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)}{\partial \mu}}{\frac{\partial \log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)}{\partial \sigma^{2}}}=\left\{\begin{array}{c}
\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)}{\sigma^{2}} \\
\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{4}}-\frac{n}{2 \sigma^{2}}
\end{array}\right.
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{3}
\tightlist
\item
  Planteando y resolviendo la ecuación de verosimilitud tenemos:
\end{enumerate}

\[
D \log L\left(\left(\hat{\mu}, \hat{\sigma}^{2}\right) ; \mathbf{x}\right)=\left\{\begin{array}{c}
\frac{\sum_{i=1}^{n}\left(x_{i}-\hat{\mu}\right)}{\hat{\sigma}^{2}}=0 \\
\frac{\sum_{i=1}^{n}\left(x_{i}-\hat{\mu}\right)^{2}}{2 \hat{\sigma}^{4}}=\frac{n}{2 \hat{\sigma}^{2}}
\end{array}\right.
\]

de donde las raíces de la ecuación de verosimilitud son:

\[
\hat{m} u=\bar{x}, \quad \hat{\sigma}^{2}=\frac{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}}{n}=s^{2} .
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{4}
\tightlist
\item
  Para decidir si las raíces de la ecuación de verosimilitud corresponden a un máximo, analizamos la matriz de derivadas segundas, denominada Hessiana.
\end{enumerate}

\[
H=\left(\begin{array}{cc}
\frac{\partial^{2} z}{\partial x^{2}} & \frac{\partial^{2} z}{\partial x \partial y} \\
\frac{\partial^{2} z}{\partial y \partial x} & \frac{\partial^{2} z}{\partial y^{2}}
\end{array}\right)
\]

Una condición suficiente para que un punto \(\left(x_{0}, y_{0}\right)\) sea un máximo es que el determinante de \(H\) sea positivo y el menor en la posición ?11? negativo, es decir:
\(S i|H|>\left.0 y \frac{\partial^{2} z}{\partial x^{2}}\right|_{\left(x_{0}, y_{0}\right)}<0 \Longrightarrow\) Hay un máximo relativo en \(\left(x_{0}, y_{0}\right)\).
Si evaluamos el Hessiano en el punto \(\left(\bar{x}, s^{2}\right)\) tenemos:

\[
H=\left(\begin{array}{cc}
-\frac{n}{s^{2}} & 0 \\
0 & -\frac{n}{2 s^{4}}
\end{array}\right) .
\]

Las condiciones de extremo que hemos dado más arriba se verifican: \(H_{11}<0 y|H|>0\), de manera que podemos concluir que el estimador del máximo de verosimilitud de \(\left(\mu, \sigma^{2}\right)\) es, efectivamente, \(\left(\bar{x}, s^{2}\right)\).

\newpage

\section{Estimación por intérvalos}\label{estimaciuxf3n-por-intuxe9rvalos}

\subsection{Motivación de los intervalos de confianza: la estimación puntual casi siempre es falsa}\label{motivaciuxf3n-de-los-intervalos-de-confianza-la-estimaciuxf3n-puntual-casi-siempre-es-falsa}

Como se ha visto en el capítulo anterior, un estimador puntual intenta proporcionar la mejor aproximación posible, en uno u otro sentido, al valor verdadero de los parámetros poblacionales que se desean estimar y que en realidad nos son desconocidos.

Sin embargo, ésto debe entenderse en el sentido de que no hemos de creer que el resultado de la estimación puntual ha de coincidir forzosamente con el valor verdadero del parámetro poblacional que queremos estimar. De hecho en muchas ocasiones de lo que podemos estar seguros es de la no-coincidencia. Baste considerar, por ejemplo, una variable Normal y una estimación de su esperanza a través de la media muestral. Como se trata de una variable continua se tiene:

\[
P\left(\bar{X}_{n}=\mu\right)=0.
\]

Esta expresión debe ser interpretada en el sentido de que la coincidencia del estimador con el parámetro verdadero es un suceso de probabilidad cero.

La estimación por intervalos de confianza nos proporciona \emph{un rango de valores entre los que tendremos una cierta certeza o nivel de confianza de que se encuentre nuestro parámetro poblacional desconocido}.

\subsection{Definición formal de intervalo de confianza}\label{definiciuxf3n-formal-de-intervalo-de-confianza}

Dada una muestra aleatoria simple, que podemos suponer se ha obtenido de una variable aleatoria (población) cuya distribución depende de un parámetro \(\theta\), diremos que los estadísticos \(L_{1}\) y \(L_{2}\) son un intervalo de confianza para \(\theta\) con nivel de confianza \((1-\alpha) \cdot 100 \%\), si se verifica:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\mathrm{L}_{1}<\mathrm{L}_{2}\) para toda muestra de tamaño \(n\).
\item
  \(\mathrm{P}\left(\mathrm{L}_{1} \leq \theta \leq \mathrm{L}_{2}\right)=1-\alpha\).
\end{enumerate}

Hay que destacar que en la segunda condición, en nuestro contexto, el valor del parámetro es fijo, lo que es aleatorio son los estadísticos que delimitan el intervalo.

\subsection{Un ejemplo de construcción de un intervalo de confianza}\label{un-ejemplo-de-construcciuxf3n-de-un-intervalo-de-confianza}

\subsubsection{Planteamiento}\label{planteamiento}

Supongamos que tenemos una variable aleatoria que sigue una distribución Normal N \((\mu ; \sigma)\) donde la varianza es un valor fijo conocido \(\sigma^{2}=\sigma^2_0\). Nuestro objetivo es, dada una muestra aleatoria simple de tamaño \(n\) de la variable obtener un intervalo de confianza con nivel de confianza del \(95 \%\) para el parámetro \(\mu\) de la distribución.

\subsubsection{Desarrollo de la construcción}\label{desarrollo-de-la-construcciuxf3n}

Utilizaremos la propiedad de que la media muestral sigue una distribución Normal de parámetros \((\mu ; \sigma/\sqrt{n})\) y, por tanto, si construimos el estadístico

\[
z=\frac{\bar{X}-\mu}{\sigma_{0} / \sqrt{n}}
\]

su distribución es una Normal estándar \(\mathrm{N}(0,1)\).
El hecho de que sea una distribución conocida, que además no depende del parámetro que queremos estimar \(\mu\), nos permite, una vez construida la expresión siguiente

\[
P\left(-z_{\alpha / 2} \leq \frac{\bar{X}-\mu}{\sigma_{0} / \sqrt{n}} \leq z_{\alpha / 2}\right)=1-\alpha
\]

determinar, de manera independiente de \(\mu\) el valor \(z_{\alpha / 2}\) que delimita una probabilidad del \(95 \%\) dentro del intervalo centrado en cero \(\left(-z_{\alpha / 2} ; z_{\alpha / 2}\right)\). En este caso, para la distribución \(\mathrm{N}(0,1)\), el valor es aproximadamente 1,96.

\begin{center}\includegraphics[width=0.9\linewidth]{images/dNormalQuantil975} \end{center}

\[
P\left(-1,96 \leq \frac{\bar{X}-\mu}{\sigma_{0} / \sqrt{n}} \leq 1,96\right)=0,95
\]

Sólo nos resta despejar \(\mu\) de la expresión anterior para obtener el intervalo definitivo

\[
P\left(\bar{X}-1,96 \frac{\sigma_{0}}{\sqrt{n}} \leq \mu \leq \bar{X}+1,96 \frac{\sigma_{0}}{\sqrt{n}}\right)=0,95
\]

\subsection{¿Por qué hablamos de confianza y no de probabilidad?}\label{por-quuxe9-hablamos-de-confianza-y-no-de-probabilidad}

Cuando ya hemos calculado el valor de los estadísticos que delimitan un intervalo solemos decir de que dicho intervalo \emph{contiene el parámetro poblacional con un nivel de confianza, por ejemplo del 95 \(\%\)}. \textbf{No decimos} que la probabilidad de que el parámetro esté dentro del intervalo es de un \(95 \%\), puesto que esto no tiene sentido, ya que el parámetro es un valor fijo.

Por ejemplo, es correcto decir que el intervalo \((0,80 ; 0,86)\) contiene el parámetro \(p\) de una distribución Binomial con una confianza del \(95 \%\), pero sería incorrecto decir que la probabilidad de que el parámetro esté dentro del intervalo \((0,80 ; 0,86)\) es del \(95 \%\).

En nuestro contexto, el parámetro poblacional es el que es, y no asociamos ninguna probabilidad ni fenómeno aleatorio al respecto. En otros enfoques estadísticos (estadística bayesiana) sí que se considera el parámetro como un valor aleatorio, pero no es nuestro caso.

La confianza del intervalo debe ser entendida como la fracción de intervalos calculados a partir de una gran serie de muestras de tamaño idéntico que contienen el valor verdadero del parámetro poblacional.

\textbf{Simulación de intérvalos de confianza}

\begin{center}\includegraphics[width=0.9\linewidth]{images/simulaIC} \end{center}

\url{https://www.grbio.eu/statmedia/Statmedia_5/}

El enlace anterior apunta a una aplicación Shiny que permite simular un número determinado de intervalos de confianza para la media de una distribució Normal, basados en muestras del mismo tamaño, y comprobar en cuántas de las simulaciones el intervalo obtenido contiene el verdadero valor de la media poblacional a partir del cual se han simulado las muestras. El porcentaje de aciertos debería acercarse al nivel de confianza con el que se han construido los intervalos.

Manteniendo constante el tamaño muestral, incrementar el nivel de confianza del intervalo implica que la anchura de éste se incrementa. Es totalmente coherente con la lógica, puesto que al exigir mayor seguridad de que el parámetro esté incluido en el intervalo lo que hacemos es alejar los límites inferior y superior para incrementar la certeza de que incluya al parámetro.

Como veremos más adelante, la manera de disminuir la anchura del intervalo y mantener un nivel de confianza deseado es incrementar el tamaño de la muestra utilizada para la construcción del intervalo.

\subsection{Elementos de un intervalo de confianza}\label{elementos-de-un-intervalo-de-confianza}

A la hora de plantearnos la obtención de un intervalo de confianza hemos de adoptar una serie de decisiones previas.

\begin{itemize}
\item
  La primera y más importante es la elección del parámetro poblacional del cual deseamos obtener la estimación. Generalmente esta elección está relacionada la distribución que asumimos para la variable estudiada. De manera usual el parámetro poblacional se corresponde con alguna de las características de las distribuciones. Por ejemplo, si deseamos un intervalo de confianza para la probabilidad de un suceso trabajaríamos con el parámetro \(p\) de la distribución Binomial. En algún caso, sin embargo, podemos estar interesados en la obtención de un intervalo de confianza para algún parámetro, por ejemplo, la media poblacional, sin hacer ninguna suposición sobre la distribución de la variable. Estaríamos dentro de la denominada estimación no paramétrica.
\item
  Una segunda elección es el nivel de confianza con el que deseamos trabajar. No es una elección sin importancia, puesto que del nivel de confianza dependerá la precisión de la estimación que obtengamos, es decir, la anchura del intervalo. A mayor nivel de confianza exigido, mayor será el radio del intervalo y por tanto menor la precisión en la estimación. Generalmente se trabaja con niveles de confianza del orden del \(90 \%\) o \(95 \%\).
\item
  Relacionado con el punto anterior tenemos la elección del tamaño muestral utilizado para la construcción del intervalo. Hemos mencionado que aumentar la confianza significa aumentar la imprecisión de la estimación, sin embargo es posible ajustar una anchura del intervalo determinada para el nivel de confianza deseado jugando con el tamaño muestral utilizado.
\end{itemize}

La aplicación mostrada en la sección anterior nos permite ilustrar estos conceptos y ver cual es el efecto de modificar el nivel de confianza o el tamaño muestral sin que cambien el resto de condiciones. Generalmente el investigador fijará el nivel de confianza con el que desea trabajar y la precisión deseada para la estimación.

Con estas premisas y basándose generalmente en la información adicional proporcionada por una muestra piloto obtenida con anterioridad \emph{es posible determinar el tamaño muestral mínimo necesario para lograr los objetivos fijados}.

Si no se dispone de muestra piloto, es posible utilizar planteamientos alternativos, como los siguientes:

\begin{itemize}
\tightlist
\item
  Expresar la precisión en términos de fracciones de la desviación típica.
\item
  Utilizar las suposiciones más desfavorables posibles.
\end{itemize}

\subsection{Método del pivote}\label{muxe9todo-del-pivote}

El método del pivote es uno de los principales métodos de construcción de intervalos de confianza. Generaliza la técnica empleada en la construcción del intervalo utilizado como primer ejemplo.

Se basa en la elección de una variable aleatoria que sea función de la muestra y del parámetro a estimar, con la condición de que sea una función continua y monótona del parámetro y que su distribución sea conocida e \textbf{independiente del parámetro}.

La expresión ``distribución independiente del parámetro'' puede generar cierta confusión porqué, uno no puede evitar observar el pivote y ver que el parámetro se encuentra incluido en la formma del mismo. Por ejemplo, si suponemos \(X\sim N(\mu, \sigma_0)\), hemos visto que \(Z=\frac{(X-\mu)}{\sigma/\sqrt{n}}\) es el punto de partida para construir el intérvalo de confianza. Podemos decir que \(Z\) es un pivote para \(\mu\) porque \(Z=\frac{(X-\mu)}{\sigma/\sqrt{n}}\) aunque contenga a \(\mu\) en su expresión, sigue una distribución \(N(0,1)\) \emph{que es la misma sea cual sea el valor de \(\mu\) por lo que no depende de éste}.

De forma más general denominaremos ``estadístico pivote'' a una función \(\varphi(\theta, X)\) cuya distribución no depende del parámetro y que puede ser invertida para expresar el parámetro como la función (inversa), \(\phi^{-1}\) de \(\phi\).

Bajo estas condiciones, fijado el nivel de confianza \((1-\alpha) \cdot 100 \%\), es posible encontrar los valores \(a\) y \(b\) tales que

\begin{equation}
P(a \leq \varphi(\theta, X) \leq b)=1-\alpha
\label{eq:pivote}
\end{equation}

Por las condiciones exigidas sobre el estadístico, será posible despejar \(\theta\) de la ecuación anterior \eqref{eq:pivote} y obtener los límites para el intervalo.

\[
P\left(\varphi^{-1}(a, X) \leq \boldsymbol{\theta} \leq \varphi^{-1}(b, X)=1-\alpha\right.
\]

siendo \(\mathrm{L}_{1}=\varphi^{-1}(a, X)\) i \(\mathrm{L}_{2}=\varphi^{-1}(b, X)\) los límites del intervalo deseado.

Hemos de tener en cuenta que los valores \(a\) y \(b\) que verifican \eqref{eq:pivote} en general no son únicos. La elección se hace generalmente buscando que \emph{el intervalo tenga la máxima precisión, es decir, la longitud mínima}. Para distribuciones simétricas y unimodales (Normal o \(t\) de Student, por ejemplo) se consigue tomando el intervalo centrado, es decir, dejando una probabilidad de \(\alpha / 2\) a cada lado.

\subsection{Algunos estadísticos pivote}\label{algunos-estaduxedsticos-pivote}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Estadistico pivote
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Distribución del estadístico pivote
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Observaciones
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
a) Poblaciones Normales & & \\
\(Z=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}\) & \(\mathrm{N}(0,1)\) & Varianza conocida \\
\(T=\frac{\bar{X}-\mu}{\hat{S} / \sqrt{n}}\) & t de Student con n-1 grados de libertad & Varianza desconocida \\
\(\chi^{2}=\frac{(n-1) \hat{S}^{2}}{\sigma^{2}}\) & \(\chi^{2} \text { con } n-1 \text { grados de }\) libertad & \\
\(T=\frac{\left(\bar{X}_{1}-\bar{X}_{2}\right)-\left(\mu_{1}-\mu_{2}\right)}{S_{T} \sqrt{1 / n_{1}+1 / n_{2}}}\) & t de Student con \(\mathrm{n}_{1}+\mathrm{n}_{2}-2\) grados de libertad & \(\mathrm{S}_{\mathrm{T}}=\) estimación de la \(\sigma\) desconocida pero común a ambas poblaciones \\
b) Proporciones & & \\
\(T=\frac{\hat{p}-p}{\sqrt{\hat{p} \hat{q} / n}}\) & N(0,1) & Distribución asintótica \\
\end{longtable}

\subsection{Intervalo de confianza para la media de una distribución Normal}\label{intervalo-de-confianza-para-la-media-de-una-distribuciuxf3n-normal}

Dada una variable aleatoria con distribución Normal \(\mathrm{N}(\mu, \sigma)\), el objetivo es la construcción de un intervalo de confianza para el parámetro \(\mu\), basado en una muestra de tamaño \(n\) de la variable.

Desde el punto de vista didáctico hemos de considerar dos posibilidades sobre la desviación típica de la variable, que sea conocida o que sea desconocida y tengamos que estimarla a partir de la muestra. El caso de \(\sigma\) conocida, ya comentado anteriormente, no pasa de ser un caso académico con poca aplicación en la práctica, sin embargo es útil desde del punto de vista didáctico.

\subsubsection{Caso de varianza conocida}\label{caso-de-varianza-conocida}

Dada una muestra \(X_{1}, \ldots, X_{n}\), el estadístico

\[
z=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}
\]

se distribuye según una Normal estándar. Por tanto, aplicando el método del pivote podemos construir la expresión

\[
P\left(-z_{\alpha/ 2} \leq \frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \leq z_{\alpha / / 2}\right)=1-\alpha
\]

donde \(z_{\alpha / 2}\) es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de \(\alpha / 2\), de la que se deduce el intervalo de confianza

\[
\bar{X}-z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}+z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}
\]

\subsubsection{Caso de varianza desconocida}\label{caso-de-varianza-desconocida}

Dada una muestra \(X_{1}, \ldots, X_{n}\), el estadístico

\[
t=\frac{\bar{X}-\mu}{\hat{S} / \sqrt{n}}
\]

se distribuye según una \(t\) de Student de \(\mathrm{n}-1\) grados de libertad. Por tanto, y siguiendo pasos similares a los del apartado anterior, el intervalo de confianza resultante es

\[
\bar{X}-t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}} \leq \mu \leq \bar{X}+t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}}
\]

donde \(t_{\alpha / 2}\) es el valor de una distribución t de Student con \(\mathrm{n}-1\) grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\).

\subsubsection{Calculo con R}\label{calculo-con-r}

El lenguaje R contiene un gran número de procedimientos estadísticos implementados, pero los intérvalos de confianza no son uno de ellos. Es decir, apenas existen funciones de base para calcular intérvalos de confianza y estos aparecen ligados a las pruebas de hipótesis como es el caso de los intérvalos para la media, que tan sólo se pueden calcular con la función que realiza un test-t.

En esta sección mostraremos con algo de detalle cómo calcular un intervalo de confianza para la media de una muestra utilizando diferentes métodos:
1. Cálculo manual.
2. Uso de una función personalizada (\texttt{Calcula\_IC\_Media}).
3. Uso del paquete \texttt{DesctTols}.

\paragraph{Paso a paso: Cálculo manual del intervalo de confianza}\label{paso-a-paso-cuxe1lculo-manual-del-intervalo-de-confianza}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Generar datos simulados}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)  }\CommentTok{\# Para reproducibilidad}
\NormalTok{muestra }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{30}\NormalTok{, }\AttributeTok{mean =} \DecValTok{50}\NormalTok{, }\AttributeTok{sd =} \DecValTok{10}\NormalTok{)  }\CommentTok{\# 30 observaciones con media 50 y desviación estándar 10}

\CommentTok{\# Tamaño de la muestra}
\NormalTok{n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(muestra)}

\CommentTok{\# Media muestral}
\NormalTok{media }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(muestra)}

\CommentTok{\# Desviación estándar muestral}
\NormalTok{sd\_muestra }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(muestra)}

\CommentTok{\# Grados de libertad}
\NormalTok{gl }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{{-}} \DecValTok{1}

\CommentTok{\# Nivel de confianza}
\NormalTok{nivel\_confianza }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\NormalTok{alpha }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ nivel\_confianza}

\CommentTok{\# Valor crítico t}
\NormalTok{t\_critico }\OtherTok{\textless{}{-}} \FunctionTok{qt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ alpha }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{df =}\NormalTok{ gl)}

\CommentTok{\# Margen de error}
\NormalTok{margen\_error }\OtherTok{\textless{}{-}}\NormalTok{ t\_critico }\SpecialCharTok{*}\NormalTok{ sd\_muestra }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}

\CommentTok{\# Límites del intervalo}
\NormalTok{limite\_inferior }\OtherTok{\textless{}{-}}\NormalTok{ media }\SpecialCharTok{{-}}\NormalTok{ margen\_error}
\NormalTok{limite\_superior }\OtherTok{\textless{}{-}}\NormalTok{ media }\SpecialCharTok{+}\NormalTok{ margen\_error}

\CommentTok{\# Mostrar resultados}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Cálculo manual:}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Cálculo manual:
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Intervalo de confianza (95\%): ["}\NormalTok{, limite\_inferior, }\StringTok{", "}\NormalTok{, limite\_superior, }\StringTok{"]}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Intervalo de confianza (95%): [ 45.86573 ,  53.19219 ]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Media muestral: "}\NormalTok{, media, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Media muestral:  49.52896
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Margen de error: "}\NormalTok{, margen\_error, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Margen de error:  3.663229
\end{verbatim}

\paragraph{\texorpdfstring{Uso de la función \texttt{Calcula\_IC\_Media}}{Uso de la función Calcula\_IC\_Media}}\label{uso-de-la-funciuxf3n-calcula_ic_media}

Dado lo extenso del cálculo podemos definir una función para automatizar los pasos anteriores:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Calcula\_IC\_Media }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(muestra, }\AttributeTok{nivel\_confianza =} \FloatTok{0.95}\NormalTok{) \{}
  \CommentTok{\# Tamaño de la muestra}
\NormalTok{  n }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(muestra)}
  
  \CommentTok{\# Media muestral}
\NormalTok{  media }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(muestra)}
  
  \CommentTok{\# Desviación estándar muestral}
\NormalTok{  sd\_muestra }\OtherTok{\textless{}{-}} \FunctionTok{sd}\NormalTok{(muestra)}
  
  \CommentTok{\# Grados de libertad}
\NormalTok{  gl }\OtherTok{\textless{}{-}}\NormalTok{ n }\SpecialCharTok{{-}} \DecValTok{1}
  
  \CommentTok{\# Valor crítico t}
\NormalTok{  alpha }\OtherTok{\textless{}{-}} \DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ nivel\_confianza}
\NormalTok{  t\_critico }\OtherTok{\textless{}{-}} \FunctionTok{qt}\NormalTok{(}\DecValTok{1} \SpecialCharTok{{-}}\NormalTok{ alpha }\SpecialCharTok{/} \DecValTok{2}\NormalTok{, }\AttributeTok{df =}\NormalTok{ gl)}
  
  \CommentTok{\# Margen de error}
\NormalTok{  margen\_error }\OtherTok{\textless{}{-}}\NormalTok{ t\_critico }\SpecialCharTok{*}\NormalTok{ sd\_muestra }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(n)}
  
  \CommentTok{\# Límites del intervalo}
\NormalTok{  limite\_inferior }\OtherTok{\textless{}{-}}\NormalTok{ media }\SpecialCharTok{{-}}\NormalTok{ margen\_error}
\NormalTok{  limite\_superior }\OtherTok{\textless{}{-}}\NormalTok{ media }\SpecialCharTok{+}\NormalTok{ margen\_error}
  
  \CommentTok{\# Resultado como lista}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}
    \AttributeTok{media =}\NormalTok{ media,}
    \AttributeTok{margen\_error =}\NormalTok{ margen\_error,}
    \AttributeTok{limite\_inferior =}\NormalTok{ limite\_inferior,}
    \AttributeTok{limite\_superior =}\NormalTok{ limite\_superior,}
    \AttributeTok{nivel\_confianza =}\NormalTok{ nivel\_confianza}
\NormalTok{  ))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Si ahora la aplicamos a los datos anteriores, obtendremos el mismo resultado con una llamada mucho más compacta.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Calcular el intervalo con la función}
\NormalTok{resultado\_funcion }\OtherTok{\textless{}{-}} \FunctionTok{Calcula\_IC\_Media}\NormalTok{(muestra, }\AttributeTok{nivel\_confianza =} \FloatTok{0.95}\NormalTok{)}

\CommentTok{\# Mostrar resultados}
\FunctionTok{cat}\NormalTok{(}\StringTok{"Cálculo con la función:}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Cálculo con la función:
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Intervalo de confianza (95\%): ["}\NormalTok{, resultado\_funcion}\SpecialCharTok{$}\NormalTok{limite\_inferior, }\StringTok{", "}\NormalTok{, resultado\_funcion}\SpecialCharTok{$}\NormalTok{limite\_superior, }\StringTok{"]}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Intervalo de confianza (95%): [ 45.86573 ,  53.19219 ]
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Media muestral: "}\NormalTok{, resultado\_funcion}\SpecialCharTok{$}\NormalTok{media, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Media muestral:  49.52896
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cat}\NormalTok{(}\StringTok{"Margen de error: "}\NormalTok{, resultado\_funcion}\SpecialCharTok{$}\NormalTok{margen\_error, }\StringTok{"}\SpecialCharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Margen de error:  3.663229
\end{verbatim}

\paragraph{\texorpdfstring{Uso del paquete \texttt{DesctTols}}{Uso del paquete DesctTols}}\label{uso-del-paquete-descttols}

El paquete \texttt{Desctools} simplifica el cálculo e interpretación de intervalos de confianza.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Usar DescTools para intervalos de confianza}
\FunctionTok{library}\NormalTok{(DescTools)}
\FunctionTok{MeanCI}\NormalTok{(muestra, }\AttributeTok{conf.level =} \FloatTok{0.95}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##     mean   lwr.ci   upr.ci 
## 49.52896 45.86573 53.19219
\end{verbatim}

Como puede verse los tres métodos proporcionan el mismo resultado por lo que, en aras de la simplificación, siempre que se disponga de una función incorporada en un paquete utilizaremos ésta.

\subsubsection{Tamaño de muestra para la media de una distribución Normal}\label{tamauxf1o-de-muestra-para-la-media-de-una-distribuciuxf3n-normal}

La fórmula para el intervalo de confianza

\[
\bar{X}-t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}} \leq \mu \leq \bar{X}+t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}}
\]

nos da la expresión que permite calcular el tamaño muestral para conseguir una precisión determinada:

\[
n=\frac{t_{a / 2}^{2} \hat{S}^{2}}{d^{2}}
\]

donde \(d\) es el radio máximo deseado para el intervalo y \(t_{\alpha / 2}\) es el valor de una distribución \(t\) de Student, con \(\mathrm{n}-1\) grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\).

Para aplicar la fórmula es necesario conocer el valor estimado para la desviación típica. Tenemos varias opciones:

\begin{itemize}
\tightlist
\item
  Obtener una muestra piloto de un tamaño arbitrario, no necesariamente grande, y obtenida la estimación de la desviación típica sustituirla en la expresión anterior. El número de grados de libertad de la t de Student debe ser \(n_{1}-1\), donde \(n_{1}\) es el tamaño muestral de la muestra piloto. Una vez obtenido el intervalo basado en la nueva muestra, se debe comprobar que se ha logrado la precisión deseada para dar por definitivo el resultado.
\item
  Si no es posible la obtención de una muestra piloto, todavía es posible el cálculo del tamaño muestral si definimos el radio del intervalo como una fracción de la desviación típica de la población,
\end{itemize}

\[
d=K \sigma
\]

y utilizamos como fórmula para calcular el tamaño muestral

\[
n=\frac{z_{a / 2}^{2} \sigma^{2}}{d^{2}}
\]

donde \(z_{\alpha / 2}\) es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de \(\alpha / 2\).

La fórmula final que resulta es:

\[
n=\frac{z_{\alpha / 2}^{2}}{K^{2}}
\]

\begin{itemize}
\tightlist
\item
  La última posibilidad es sustituir en la expresión (1) el valor de la desviación típica por el valor máximo que se considere que pueda tomar basado en datos bibliográficos previos o en el criterio del investigador.
\end{itemize}

\paragraph{Calculo del tamaño muestral usando R}\label{calculo-del-tamauxf1o-muestral-usando-r}

Como en el caso anterior es posible implementar las fórmulas directamente con R o usar algún paquete específico \texttt{samplesize}o el mismo \texttt{DescTools} que incorpora la función \texttt{MeanCIn} que, a partir del intérvalo de confianza centrado en la media y la desviación retorna el tamaño necesario para alcanzar una precisión determinada.

Por ejemplo si en el ejemplo anterior, con una media de 49.53 y una desviación de 9,81 se desa una precisión (anchura del intérvalo entre dos) de 3 con confianza del 90\%:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(DescTools)}
\NormalTok{prec}\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{m }\OtherTok{\textless{}{-}} \FloatTok{49.53}
\NormalTok{conf }\OtherTok{=}\FloatTok{0.9}
\FunctionTok{MeanCIn}\NormalTok{(}\AttributeTok{ci=}\FunctionTok{c}\NormalTok{(m}\SpecialCharTok{{-}}\NormalTok{prec, m}\SpecialCharTok{+}\NormalTok{prec), }\AttributeTok{sd=}\FloatTok{9.8}\NormalTok{, }\AttributeTok{conf.level=}\NormalTok{conf) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 30.75626
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf }\OtherTok{=}\FloatTok{0.95}
\FunctionTok{MeanCIn}\NormalTok{(}\AttributeTok{ci=}\FunctionTok{c}\NormalTok{(m}\SpecialCharTok{{-}}\NormalTok{prec, m}\SpecialCharTok{+}\NormalTok{prec), }\AttributeTok{sd=}\FloatTok{9.8}\NormalTok{, }\AttributeTok{conf.level=}\NormalTok{conf) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 43.43345
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{conf }\OtherTok{=}\FloatTok{0.99}
\FunctionTok{MeanCIn}\NormalTok{(}\AttributeTok{ci=}\FunctionTok{c}\NormalTok{(m}\SpecialCharTok{{-}}\NormalTok{prec, m}\SpecialCharTok{+}\NormalTok{prec), }\AttributeTok{sd=}\FloatTok{9.8}\NormalTok{, }\AttributeTok{conf.level=}\NormalTok{conf) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 74.61462
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prec }\OtherTok{\textless{}{-}} \DecValTok{2}\NormalTok{; conf }\OtherTok{\textless{}{-}} \FloatTok{0.95}
\FunctionTok{MeanCIn}\NormalTok{(}\AttributeTok{ci=}\FunctionTok{c}\NormalTok{(m}\SpecialCharTok{{-}}\NormalTok{prec, m}\SpecialCharTok{+}\NormalTok{prec), }\AttributeTok{sd=}\FloatTok{9.8}\NormalTok{, }\AttributeTok{conf.level=}\NormalTok{conf) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 94.66357
\end{verbatim}

\subsection{Intervalo de confianza para la varianza de una distribución Normal}\label{intervalo-de-confianza-para-la-varianza-de-una-distribuciuxf3n-normal}

Dada una variable aleatoria con distribución Normal \(\mathrm{N}(\mu ; \sigma)\), el objetivo es la construcción de un intervalo de confianza para el parámetro \(\sigma\), basado en una muestra de tamaño \(n\) de la variable.

A partir del estadístico

\[
\mathrm{X}^{2}=\frac{(n-1) \hat{S}^{2}}{\sigma^{2}}
\]

la fórmula para el intervalo de confianza, con nivel de confianza \(1-\alpha\) es la siguiente

\[
\frac{(n-1) \hat{S}^{2}}{\chi_{\alpha a / 2}^{2}} \leq \sigma^{2} \leq \frac{(n-1) \hat{S}^{2}}{\chi_{1-\alpha / 2}^{2}}
\]

Donde \(\chi_{\alpha / 2}^{2}\) es el valor de una distribución Ji al cuadrado con \(n-1\) grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\).

Por ejemplo, dados los datos siguientes:

\begin{itemize}
\tightlist
\item
  Distribución poblacional: Normal
\item
  Tamaño de muestra: 10
\item
  Confianza deseada para el intervalo: \(95 \%\)
\item
  Varianza muestral corregida: 38,5
\end{itemize}

Un intervalo de confianza al \(95 \%\) para la varianza de la distribución viene dado por:

\[
\frac{9 \cdot 38,5}{19,031} \leq \sigma^{2} \leq \frac{9 \cdot 38,5}{2,699}
\]

que resulta, finalmente

\[
\sigma^{2} \in(18.207 ; 128,381)
\]

\subsection{Intervalo de confianza para una proporción}\label{intervalo-de-confianza-para-una-proporciuxf3n}

Dada una variable aleatoria con distribución Binomial \(\mathrm{B}(n, p)\), el objetivo es la construcción de un intervalo de confianza para el parámetro \(p\), basada en una observación de la variable que ha dado como valor \(x\). El mismo caso se aplica si estudiamos una Binomial \(\mathrm{B}(1, p)\) y consideramos el número de veces que ocurre el suceso que define la variable al repetir el experimento \(n\) veces en condiciones de independencia.

Existen dos alternativas a la hora de construir un intervalo de confianza para \(p\) :

\begin{itemize}
\tightlist
\item
  Considerar la aproximación asintótica de la distribución Binomial en la distribución Normal.
\item
  Utilizar un método exacto.
\end{itemize}

\subsubsection{Aproximación asintótica}\label{aproximaciuxf3n-asintuxf3tica}

Tiene la ventaja de la simplicidad en la expresión y en los cálculos, y es la más referenciada en la mayoría de textos de estadística. Se basa en la aproximación

\[
X \sim B(n, p) \rightarrow N(n p, \sqrt{n p q)}
\]

que, trasladada a la frecuencia relativa, resulta

\[
\hat{p}=X / n \rightarrow N(p, \sqrt{p q / n})
\]

Tomando como estadístico pivote

\[
Z=\frac{\hat{p}-p}{\sqrt{\hat{p} \hat{q} / n}}
\]

que sigue una distribución \(\mathrm{N}(0,1)\), y añadiendo una corrección por continuidad al pasar de una variable discreta a una continua, se obtiene el intervalo de confianza asintótico:

\[
\hat{p} \pm z_{c / 2 / 2} \sqrt{\frac{\hat{p} \hat{q}}{n}}+\frac{1}{2 n}
\]

donde \(z_{\alpha / 2}\) es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de \(\alpha / 2\) para un intervalo de confianza de \((1-\alpha) \cdot 100 \%\). Las condiciones generalmente aceptadas para considerar válida la aproximación asintótica anterior son:

\[
n \geq 30 \quad ; \quad n \hat{p} \geq 5 \quad ; \quad n \hat{q} \geq 5
\]

El intervalo obtenido es un intervalo asintótico y por tanto condicionado a la validez de la aproximación utilizada. Una información más general sobre los intervalos de confianza asintóticos puede encontrase aquí.

\paragraph{Cálculo con R}\label{cuxe1lculo-con-r}

Para ver como calcular un intervalo de confianza asintótico puede consultarse el ejemplo en \href{r-tutor.com}{R-Tutor}: \href{https://www.r-tutor.com/elementary-statistics/interval-estimation/interval-estimate-population-proportion}{interval-estimate-population-proportion}

\subsubsection{Intervalo exacto}\label{intervalo-exacto}

Aun cuando las condiciones anteriores no se verifiquen, es posible la construcción de un intervalo exacto, válido siempre pero algo más complicado en los cálculos. Es posible demostrar que un intervalo exacto para el parámetro \(p\) viene dado por los valores siguientes:

\[
p_{1}=\frac{X}{(n-X+1) F_{\alpha(2,2(n-X+1), 2 X}+X} ; p_{2}=\frac{(X+1) F_{\alpha(2), 2(X+1), 2(n-X)}}{(n-X)+(X+1) F_{\alpha(2,2,(X+1), 2(n-R)}}
\]

donde \(F_{\alpha / 2, a, b}\) es el valor de una distribución \(F\) de Fisher-Snedecor con a y b grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\) para un intervalo de confianza de \((1-\alpha) \cdot 100 \%\).

Una justificación de los intervalos de confianza exactos para distribuciones discretas puede encontrarse aquí.

\paragraph{Cálculo con R}\label{cuxe1lculo-con-r-1}

En general los paquetes de R implementan múltiples métodos exactos. Este es el caso de \texttt{DescTools}que implementa más de una docena de métodos (podéis hacer \texttt{?\ DescTools::BinomCI} para aprender cuales son).

Por ejemplo si hemos obtenido un valor de 37 con un tamaño muestral de 43 (es decir una estimación puntual de 37/43 = ``0.8604651) el intervalo de confianza se calculará como:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{BinomCI}\NormalTok{(}\AttributeTok{x=}\DecValTok{37}\NormalTok{, }\AttributeTok{n=}\DecValTok{43}\NormalTok{, }
        \AttributeTok{method=}\FunctionTok{eval}\NormalTok{(}\FunctionTok{formals}\NormalTok{(BinomCI)}\SpecialCharTok{$}\NormalTok{method))   }\CommentTok{\# return all methods}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                         est    lwr.ci    upr.ci
## wilson            0.8604651 0.7273641 0.9344428
## wald              0.8604651 0.7568980 0.9640322
## waldcc            0.8604651 0.7452701 0.9756601
## agresti-coull     0.8604651 0.7235600 0.9382469
## jeffreys          0.8604651 0.7348110 0.9395927
## modified wilson   0.8604651 0.7273641 0.9344428
## wilsoncc          0.8604651 0.7137335 0.9419725
## modified jeffreys 0.8604651 0.7348110 0.9395927
## clopper-pearson   0.8604651 0.7206752 0.9470234
## arcsine           0.8604651 0.7346862 0.9424696
## logit             0.8604651 0.7224337 0.9359412
## witting           0.8604651 0.7493378 0.9273288
## pratt             0.8604651 0.7661306 0.9472522
## midp              0.8604651 0.7321815 0.9414281
## lik               0.8604651 0.7372546 0.9420472
## blaker            0.8604651 0.7255152 0.9374534
\end{verbatim}

Ante la duda de que método usar lo mejor es usar el métod por defecto (el primero de la lista anterior).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{BinomCI}\NormalTok{(}\AttributeTok{x=}\DecValTok{37}\NormalTok{, }\AttributeTok{n=}\DecValTok{43}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##            est    lwr.ci    upr.ci
## [1,] 0.8604651 0.7273641 0.9344428
\end{verbatim}

\subsubsection{Tamaño muestral para una proporción}\label{tamauxf1o-muestral-para-una-proporciuxf3n}

A partir de la fórmula para el intervalo de confianza

\[
\hat{p} \pm z_{a / 2 / 2} \sqrt{\frac{\hat{p} \hat{q}}{n}}+\frac{1}{2 n}
\]

podemos determinar el tamaño muestral necesario con el fin de que la precisión de la estimación sea la deseada con antelación. La fórmula que resulta es

\[
n=\frac{z_{\alpha / 2}^{2} p q}{d^{2}}
\]

donde \(d\) es el radio máximo deseado para el intervalo y \(z_{\alpha / 2}\) tiene el significado habitual. Nótese que no hemos tenido en cuenta el último término de la primera expresión.

La aplicación efectiva de la fórmula obtenida requiere el conocimiento de \(p\) y de \(q=(1-p)\), valores que nos son desconocidos en la práctica. Para solventar este problema tenemos dos alternativas:

\begin{itemize}
\tightlist
\item
  Considerar el caso más desfavorable posible, es decir, aquel que verifique que \(p \cdot q\) da el valor máximo posible. Es fácil verificar que esto sucede si \(p=0,5\). En este caso el producto es \(p \cdot q=\) 0,25.
\item
  Utilizar un valor de referencia obtenido a partir de una muestra piloto o a partir de datos bibliográficos y utilizar el valor compatible con la información más cercano a \(p=0,5\).
\end{itemize}

A partir de la fórmula puede comprobarse que el tamaño muestral requerido, una vez fijada \(p\), crece al incrementarse la confianza del intervalo y crece también al incrementarse la precisión (al disminuir el radio).

\paragraph{Cálculo con R}\label{cuxe1lculo-con-r-2}

Para ver como determinar el tamaño muestral necesario para construir un intervalo de confianza para una proporción, pueden consultarse los mismos recursos

\begin{itemize}
\tightlist
\item
  Para el cálculo del tamaño muestral asociado a un intérvalo de confianza asintótico tótico puede consultarse \href{r-tutor.com}{R-Tutor}: \href{https://www.r-tutor.com/elementary-statistics/interval-estimation/sampling-size-population-proportion}{sampling-size-population-proportion}
\end{itemize}

\subsection{Intervalo de confianza para el parámetro de una distribución de Poisson}\label{intervalo-de-confianza-para-el-paruxe1metro-de-una-distribuciuxf3n-de-poisson}

Dada una variable aleatoria con distribución de Poisson \(\mathrm{P}(\lambda)\), el objetivo es la construcción de un intervalo de confianza para el parámetro \(\lambda\), basado en una muestra de tamaño \(n\) de la variable.

Del mismo modo que para una proporción, existe una solución exacta y una aproximación asintótica al intervalo de confianza para el parámetro \(\lambda\).

\subsubsection{Aproximación asintótica}\label{aproximaciuxf3n-asintuxf3tica-1}

Para valores del parámetro \(\lambda\) grandes, la distribución de Poisson puede aproximarse a una distribución Normal según:

\[
P(\lambda) \rightarrow N(\lambda, \sqrt{\lambda})
\]

Dada una muestra de \(n\) observaciones independientes distribuidas según una Poisson de parámetro \(\lambda, X_{\mathrm{i}}\) \(\sim \mathrm{P}(\lambda)\), como la distribución de Poisson es aditiva en \(\lambda\) se cumple que \(\sum X_{i} \sim P(n \lambda)\). Esta última distribución, si procede, podrá aproximarse a una distribución Normal:

\[
\sum_{i=1}^{n} X_{i} \rightarrow N(n \lambda \sqrt{n \lambda})
\]

Por tanto, es inmediato comprobar que:

\[
P\left(-z_{\alpha / 2} \sqrt{\lambda / n}<\bar{X}-\lambda<z_{\alpha / 2} \sqrt{\lambda / n}\right)=1-\alpha
\]

donde \(z_{\alpha / 2}\) es el valor de una distribución Normal standard que deja a su derecha una probabilidad de \(\alpha / 2\).

La desigualdad es equivalente a

\[
\bar{X}^{2}-2 \lambda \bar{X}+\lambda^{2}<\frac{\lambda}{n} z_{a / 2}^{2}
\]

El valor de \(\lambda\) estará comprendido entre las dos raíces de la ecuación de segundo grado

\[
\lambda^{2}+\lambda\left(-2 \bar{X}-\frac{z_{\alpha z / 2}^{2}}{n}\right)+\bar{X}^{2}=0
\]

Y, finalmente, se obtiene el intervalo de confianza

\[
\lambda \in\left(\bar{X}+\frac{z_{\alpha / 2}^{2}}{2 n} \mp \sqrt{\bar{X} \frac{z_{\alpha / 2}^{2}}{n}+\frac{z_{\alpha / 2}^{4}}{4 n^{2}}}\right)
\]

\subsubsection{Intervalo exacto}\label{intervalo-exacto-1}

Si no son aplicables las condiciones para utilizar la aproximación asintótica puede utilizarse la solución exacta, válida siempre. Puede demostrarse que el intervalo exacto para el parámetro \(\lambda\) viene dado por

\[
\lambda_{1}=\frac{1}{2 n} \chi_{1-a / 2}^{2}\left(2 \cdot \sum_{i=1}^{n} \chi_{i}\right) ; \lambda_{2}=\frac{1}{2 n} \chi_{a / 2}^{2}\left(2 \cdot \sum_{i=1}^{n} \chi_{i}+2\right)
\]

donde \(\chi_{\alpha / 2}^{2}(n)\) es el valor de una distribución Ji al cuadrado con \(n\) grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\).

\subsubsection{Tamaño de muestra para el parámetro de una distribución de Poisson}\label{tamauxf1o-de-muestra-para-el-paruxe1metro-de-una-distribuciuxf3n-de-poisson}

Para determinar el tamaño muestral, se parte de la aproximación

\[
P(\lambda) \rightarrow N(\lambda, \sqrt{\lambda})
\]

La expresión que resulta para el tamaño muestral es:

\[
n=\frac{z_{a / 2}^{2} \lambda}{d^{2}}
\]

Como suele ocurrir, la fórmula depende del parámetro desconocido y las alternativas vuelven a ser:

\begin{itemize}
\tightlist
\item
  Utilizar una muestra piloto o datos externos para estimar \(\lambda\) y tomar el valor máximo que se considere que puede valer.
\item
  Conformarse con una precisión del tipo \(d^{2}=K^{2} \lambda\), de manera que la fórmula queda reducida a
\end{itemize}

\[
n=z_{a / 2}^{2} / K^{2}
\]

\subsection{Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.}\label{intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.}

\subsubsection{Varianza común}\label{varianza-comuxfan}

\paragraph{Caso de varianza desconocida y común}\label{caso-de-varianza-desconocida-y-comuxfan}

Supondremos la existencia de dos poblaciones sobre las que una variable determinada sigue una distribución Normal con idéntica varianza en las dos. Sobre la población 1, la variable sigue una distribución \(\mathrm{N}\left(\mu_{1}, \sigma\right)\) y, sobre la población 2 , sigue una distribución \(N\left(\mu_{2}, \sigma\right)\). Igualmente supondremos que disponemos de dos muestras aleatorias independientes, una para cada población, de tamaños muestrales \(n_{1}\) y \(n_{2}\) respectivamente.

El objetivo es construir un intervalo de confianza, con nivel de confianza ( \(1-\alpha\) ) \(100 \%\), para la diferencia de medias

\[
\mu_{1}-\mu_{2}
\]

El método se basa en la construcción de una nueva variable \(D\), definida como la diferencia de las medias muestrales para cada población

\[
D=\bar{X}_{1}-\bar{X}_{2}
\]

Esta variable, bajo la hipótesis de independencia de las muestras, sigue una distribución Normal de esperanza

\[
\mu_{1}-\mu_{2}
\]

y de varianza

\[
\operatorname{Var}(D)=\sigma^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)
\]

La estimación conjunta, a partir de las dos muestras, de la varianza común viene dada por la expresión

\[
\hat{S}_{T}^{2}=\frac{\left(n_{1}-1\right) \cdot \hat{S}_{1}^{2}+\left(n_{2}-1\right) \cdot \hat{S}_{2}^{2}}{n_{1}+n_{2}-2}
\]

\(y\), utilizando la propiedad de que la variable

\[
\frac{\left(n_{1}+n_{2}-2\right) \hat{S}_{T}^{2}}{\sigma^{2}}
\]

sigue una distribución \(\chi^{2}\) con \(\mathrm{n}_{1}+\mathrm{n}_{2}-2\) grados de libertad, podemos construir un estadístico pivote que siga una distribución \(t\) de Student y que nos proporciona la fórmula siguiente para el intervalo de
confianza para la diferencia de medias:

\[
\left(\bar{X}_{1}-\bar{X}_{2}\right)-t_{a / 2} \cdot \hat{S}_{T} \cdot \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}} \leq \mu_{1}-\mu_{2} \leq\left(\bar{X}_{1}-\bar{X}_{2}\right)+t_{a k 2} \cdot \hat{S}_{T} \cdot \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}
\]

donde \(t_{\alpha / 2}\) es el valor de una distribución \(t\) de Student con \(\mathrm{n}_{1}+\mathrm{n}_{2}-2\) grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\).

\subsection{Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.}\label{intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.-1}

\subsubsection{Varianza diferente}\label{varianza-diferente}

\subsubsection{Caso de varianzas desconocidas y diferentes}\label{caso-de-varianzas-desconocidas-y-diferentes}

Cuando tenemos razones para suponer que la varianza no es común, no podemos utilizar el estadístico anterior. Hemos de destacar que, en esta situación, no existe un método exacto que permita obtener el intervalo de confianza deseado. Lo más que tenemos son aproximaciones a la solución. Un intervalo aproximado con nivel de confianza \((1-\alpha) \cdot 100 \%\) es

\[
\left(\bar{X}_{1}-\bar{X}_{2}\right)-t_{\alpha / 2} \cdot \sqrt{\frac{\hat{S_{1}}}{n_{1}}+\frac{\hat{S}_{2}}{n_{2}}} \leq \mu_{1}-\mu_{2} \leq\left(\bar{X}_{1}-\bar{X}_{2}\right)+t_{\alpha / 2} \cdot \sqrt{\frac{\hat{S_{1}}}{n_{1}}+\frac{\hat{S}_{2}}{n_{2}}},
\]

donde \(\hat{S}_{1}\) y \(\hat{S}_{2}\) son las varianzas muestrales corregidas para cada población y donde \(t_{\alpha / 2}\) es el valor de una distribución \(t\) de Student con \(g\) grados de libertad, donde

\[
g=\frac{\left(\hat{S}_{1}^{2} / n_{1}+\hat{S}_{2}^{2} / n_{2}\right)^{2}}{\frac{\left(\hat{S}_{1}^{2} / n_{1}\right)^{2}}{n_{1}+1}+\frac{\left(\hat{S}_{2}^{2} / n_{2}\right)^{2}}{n_{2}+1}}-2
\]

Si los grados de libertad resultantes son decimales, puede optarse por hacer una interpolación entre los dos valores enteros más cercanos o bien por tomar el valor más desfavorable, aquel que suponga un radio mayor para el intervalo de confianza y que coincide con el redondeo a la baja de los grados de libertad.

\subsubsection{Intérvalos de confianza y decisiones estadísticas}\label{intuxe9rvalos-de-confianza-y-decisiones-estaduxedsticas}

Es, por tanto, importante, antes de proceder a la obtención del intervalo de confianza para la diferencia de medias, verificar si la suposición de homogeneidad de varianzas es razonable o no. Una manera de verificarlo consiste en la construcción del intervalo para el cociente de varianzas, tal como se explica más adelante, y comprobar si en dicho intervalo está incluido el valor 1. La inclusión de la unidad dentro del intervalo resultante, la debemos interpretar en el sentido de que la muestra no proporciona evidencia suficiente para afirmar que las varianzas son diferentes y, por tanto, no es incorrecta la utilización del intervalo para varianza común. De manera análoga, el intervalo de confianza para la diferencia de medias nos puede servir para verificar la suposición de que las medias son iguales o diferentes; en este caso, si el valor 0 está incluido en el intervalo, la conclusión es que la muestra no proporciona evidencia suficiente para afirmar que las medias son diferentes.

Nota importante: El párrafo anterior nos introduce en la posibilidad de utilizar intervalos de confianza para verificar o rechazar ciertas suposiciones sobre el parámetro o los parámetros de las distribuciones. La técnica específica para la verificación de dichas suposiciones o hipótesis a partir de muestras aleatorias se verá en los temas siguientes, donde se introduce el concepto de contraste de hipótesis, sin embargo no podemos dejar de mencionar aquí que los intervalos de confianza nos pueden proporcionar una técnica alternativa o complementaria para la resolución de contrastes.

\subsection{Intervalo de confianza para el cociente de varianzas de distribuciones normales independientes}\label{intervalo-de-confianza-para-el-cociente-de-varianzas-de-distribuciones-normales-independientes}

Supondremos la existencia de dos poblaciones sobre las que una determinada variable sigue una distribución Normal. Sobre la población 1 la variable sigue una distribución \(N\left(\mu_{1}, \sigma_{1}\right)\) y sobre la población 2 sigue una distribución \(\mathrm{N}\left(\mu_{2}, \sigma_{2}\right)\). Igualmente supondremos que disponemos de dos muestras aleatorias independientes, una para cada población, de tamaños muestrales \(n_{1}\) y \(n_{2}\) respectivamente.

El objetivo es construir un intervalo de confianza, con nivel de confianza ( \(1-\alpha\) ) • \(100 \%\), para el cociente de varianzas

\[
\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}
\]

El estadístico pivote utilizado es

\[
F=\frac{\hat{S}_{1}^{2} / \sigma_{1}^{2}}{\hat{S}_{2}^{2} / \sigma_{2}^{2}}
\]

que sigue una distribución \(F\) de Fisher con \(n_{1}-1\) y \(n_{2}-1\) grados de libertad.
El intervalo de confianza que resulta es

\[
\frac{\hat{S}_{1}^{2} / \hat{S}_{2}^{2}}{F_{\alpha / 2}} \leq \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}} \leq \frac{\hat{S}_{1}^{2} / \hat{S}_{2}^{2}}{F_{1-\alpha / 2}}
\]

donde \(F_{\alpha / 2}\) es el valor de una distribución \(F\) de Fisher-Snedecor con \(n_{1}-1\) y \(n_{2}-1\) grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\).

\subsection{Complementos}\label{complementos}

\subsubsection{Interpretación geométrica de los intervalos de confianza}\label{interpretaciuxf3n-geomuxe9trica-de-los-intervalos-de-confianza}

Es posible tener una visión gráfica de los intervalos de confianza, los límites del intervalo pueden ser representados por curvas en el plano formado por el parámetro que queremos estimar y el estadístico utilizado para construir el pivote. Esta visión nos puede ayudar en la interpretación y la comprensión de los intervalos o de sus propiedades.

Por ejemplo, el intervalo del \(95 \%\) para la esperanza de una distribución Normal con varianza conocida y para una muestra de tamaño \(n=9\), de fórmula

\[
\bar{X}-z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}+z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}
\]

puede representarse por medio de la figura siguiente:

\begin{center}\includegraphics[width=0.8\linewidth]{images/interpretacionGeometrica} \end{center}

El eje horizontal representa la media muestral y el eje vertical el valor del intervalo para el parámetro \(\mu\). Como puede observarse los límites son líneas rectas y la anchura del intervalo es la misma para cualquier valor de la media.

Veamos ahora la representación gráfica del intervalo para una proporción. La fórmula es

\[
\hat{p} \pm z_{c / 2 / 2} \sqrt{\frac{\hat{p} \hat{q}}{n}}+\frac{1}{2 n}
\]

y, para una muestra de tamaño \(n=9\) y un intervalo de confianza del \(95 \%\), la gráfica resultante es:

\begin{center}\includegraphics[width=0.8\linewidth]{images/freqVsprop} \end{center}

El eje horizontal es la frecuencia relativa observada y el eje vertical el intervalo de confianza para la proporción. Podemos notar que la anchura del intervalo varía y que, en el caso más desfavorable, la máxima amplitud se da para una frecuencia observada de 0,5.

\subsubsection{Intervalos para muestras grandes}\label{intervalos-para-muestras-grandes}

Bajo ciertas condiciones de regularidad, es posible construir intervalos de confianza asintóticos de una manera bastante general.

Si suponemos que un parámetro \(\theta\) tiene una estimación máximo verosímil \(\theta^{*}\), la distribución asintótica del estimador, bajo condiciones generales de regularidad, es Normal, de media el valor verdadero del parámetro \(\theta\) y varianza igual a la cota de Cramér-Rao \(\sigma^{2}\left(\theta^{*}\right)\).

\[
1 / \sqrt{n \mathrm{E}\left(\frac{\partial}{\partial \theta} \ln f(X, \theta)\right)^{2}}=\sigma\left(\theta^{*}\right)
\]

Bajo las suposiciones anteriores, es posible construir un intervalo de confianza asintótico y con nivel de confianza \((1-\alpha) \cdot 100 \%\) a partir de

\[
P\left(-z_{\alpha / 2} \leq \frac{\theta^{*}-\theta}{1 / \sqrt{n \mathrm{E}\left(\frac{\partial}{\partial \theta} \ln f(X, \theta)\right)^{2}}} \leq z_{\alpha / 2}\right)=1-\alpha
\]

donde los valores de \(z_{\alpha / 2}\) se calculan a partir de la distribución \(N(0,1)\) de forma que \(P\left(|Z|>z_{\alpha / 2}\right)=\alpha\).
Es decir, se utiliza como estadístico pivote

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Estadístico pivote
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Distribución del estadístico pivote
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Observaciones
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(Z=\frac{\theta^{*}-\theta}{\sigma\left(\theta^{*}\right)}\) & N( 0,1 ) & Distribución asintótica, \(\theta^{*}\) es la estimación máximo verosimil del parámetro y \(\sigma\left(\theta^{*}\right)\) es la cota de Crámer-Rao \\
\end{longtable}

El intervalo de confianza aproximado que resulta es:

\[
\theta^{*}-z_{a / 2} \sigma\left(\theta^{*}\right) \leq \theta \leq \theta^{*}+z_{a / 2} \sigma\left(\theta^{*}\right)
\]

\subsubsection{Intervalos exactos para distribuciones discretas}\label{intervalos-exactos-para-distribuciones-discretas}

El procedimiento que permite obtener los intervalos exactos para los parámetros de las distribuciones discretas, por ejemplo los parámetros \(\lambda\) de la distribución de Poisson o \(p\) de la Binomial, se explica a continuación.

Consideramos que la variable aleatoria discreta tiene por recorrido \(\{0,1,2, \ldots\}\) y depende de un parámetro desconocido \(\theta\). Si suponemos que se ha obtenido una muestra de tamaño 1 y de valor \(k\) (donde \(k\) puede ser, por ejemplo, la frecuencia con que se ha presentado un suceso en \(n\) experiencias o la suma de \(n\) observaciones distribuidas según una distribución de Poisson), se trata de resolver las ecuaciones siguientes:

\[
\begin{aligned}
& \sum_{\substack{i=k \\
k}}^{\infty} P(x=i / \theta)=\alpha / 2 \\
& \sum_{i=0}^{k} P(x=i / \theta)=\alpha / 2
\end{aligned}
\]

Las soluciones \(\theta_{1}\) y \(\theta_{2}\) constituyen el intervalo de confianza de nivel de confianza \((1-\alpha) \cdot 100 \%\) buscado.

Veamos un ejemplo:
Supongamos que tenemos una variable Binomial con \(n=4\) y que una observación nos ha dado \(x=2\). ¿Cuál es el intervalo de confianza del \(95 \%\) para el parámetro \(p\) ?

Hemos de resolver las ecuaciones siguientes:

\[
\begin{aligned}
& P(X=0)+P(X=1)+P(X=2)=\binom{4}{0}(1-p)^{4}+\binom{4}{1} p(1-p)^{3}+\binom{4}{2} p^{2}(1-p)^{2}=0,025 \\
& P(X=2)+P(X=3)+P(X=4)=\binom{4}{2} p^{2}(1-p)^{2}+\binom{4}{3} p^{3}(1-p)+\binom{4}{4} p^{4}=0,025
\end{aligned}
\]

Utilizando un programa de cálculo numérico (el Mathematica, por ejemplo) obtenemos como soluciones significativas \(p_{1}=0,932414\), para la primera, y \(p_{2}=0,067586\), para la segunda; quedando finalmente el intervalo ( 0,\(067586 ; 0,932414\) ).

Podéis comprobar el resultado aquí, tomando \(n=4\) y \(x=2\).

En la bibliografia existen numerosas tablas para el cálculo de dichos intervalos, pero también son aplicables las fórmulas presentadas para la Binomial y la Poisson.

\subsubsection{Una aproximación diferente para la distribución de Poisson}\label{una-aproximaciuxf3n-diferente-para-la-distribuciuxf3n-de-poisson}

Hemos visto con anterioridad la construcción del intervalo de confianza para el parámetro \(\lambda\) de una distribución de Poisson. Los cálculos y la fórmula del intervalo eran algo complejos, sin embargo, si en lugar de trabajar directamente con la variable, efectuamos una transformación previa, en particular, si trabajamos con la raíz cuadrada de la variable, el problema puede simplificarse notablemente.

Puede demostrarse que

\[
X \rightarrow P(\lambda) \Rightarrow \sqrt{X} \rightarrow N(\sqrt{\lambda} ; 1 / 2)
\]

La transformación de la raíz cuadrada es una transformación estabilizadora de la varianza, la ventaja es que la varianza resultante \((0,25)\) no depende del parámetro \(\lambda\) que se ha de estimar, facilitando la obtención de resultados. En nuestro caso,

\[
\sqrt{\sum_{i=1}^{n} X_{i}} \rightarrow N\left(\sqrt{n \lambda_{3}} 1 / 2\right)
\]

y se obtiene fácilmente el intervalo de confianza

\[
\sqrt{\sum_{i=1}^{n} X_{i}}-\frac{z_{\alpha / 2}}{2}<\sqrt{n \lambda}<\sqrt{\sum_{i=1}^{n} X_{i}}+\frac{z_{\alpha / 2}}{2}
\]

donde \(z_{\alpha}\) es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de \(\alpha\).
Y, si despejamos,

\[
\lambda \in \frac{1}{n}\left(\frac{z_{\alpha / 2}}{2} \pm \sqrt{\sum_{i=1}^{n} X_{i}}\right)^{2}
\]

Comparad la fórmula obtenida con la desarrollada en el caso de no utilizar la transformación.

\subsubsection{Aproximación mediante Chébishev}\label{aproximaciuxf3n-mediante-chuxe9bishev}

El teorema de Chébishev nos proporciona una aproximación al problema de construcción de intervalos de confianza para los valores de una variable aleatoria independientemente de su distribución. No es por tanto una estimación paramétrica a través de intervalos de confianza, sino únicamente una manera de acotar la probabilidad de una variable aleatoria alrededor de su esperanza.

La ventaja del enfoque basado en Chébishev es que no es necesaria ninguna suposición sobre la distribución de la variable, la única condición es la existencia de esperanza y de varianza finita para la variable aleatoria.

El inconveniente es la falta de precisión de la estimación, puesto que trabajamos con una cota superior para la probabilidad de desviación de una variable aleatoria respecto a su esperanza.

La fórmula utilizada es

\[
P(|X-E(X)| \geq h) \leq \frac{\operatorname{Var}(X)}{h^{2}}
\]

donde \(h>0\).
Una vez que se dispone de los valores de la esperanza y de la varianza de la variable, es posible fijar la probabilidad deseada y despejar el valor de \(h\) que nos proporciona el radio del intervalo centrado en la esperanza.

\[
h^{2}=\frac{\operatorname{Var}(X)}{1-\text { Probabilidad deseada del intervalo }}
\]

El resultado final se interpreta en el sentido de que la probabilidad de que la variable se encuentre dentro del intervalo construido es mayor o igual que la probabilidad fijada.

\newpage

Pruebas de hipótesis

\subsection{Introducción}\label{introducciuxf3n-2}

\subsubsection{De las hipótesis científicas a las hipótesis estadísticas}\label{de-las-hipuxf3tesis-cientuxedficas-a-las-hipuxf3tesis-estaduxedsticas}

Antes de introducir los conceptos asociados al contraste estadístico de hipótesis, es conveniente situar este tema en el contexto más general de la \emph{confirmación de hipótesis}, materia que la filosofía de la ciencia estudia en profundidad. Así pues, en este punto solo se plantean consideraciones generales, dejando para los siguientes apartados cómo aborda la Estadística este tema.

Una cuestión esencial en cualquier rama de la ciencia -básica o aplicada- es cómo verificar hipótesis sobre un determinado fenómeno real. Muchas veces, cuando se expone este tema al estudiante durante las primeras etapas de su formación científica, el llamado método de razonamiento científico se simplifica en exceso, presentando la verificación de hipótesis en términos absolutos. En este esquema simplificado del método científico se expone cómo teorizar sobre un determinado aspecto de la realidad más o menos de la siguiente forma:

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  se formula una teoría (o una hipótesis, o una ley, \ldots) sobre el fenómeno de estudio\\
\item
  se diseña un experimento para tratar de corroborar dicha teoría\\
\item
  si los resultados del experimento concuerdan con la teoría, ésta se da provisionalmente por válida\\
\item
  si el experimento contradice la teoría, se vuelve al apartado a), se modifica la ley o se elabora una nueva, de modo que se ajuste a la realidad experimental.\\
\item
  cualquier teoría relacionada con aspectos de la realidad es siempre provisional, pendiente de ser revisada al entrar en conflicto con resultados de experimentos posteriores.
\end{enumerate}

Esta forma de proceder -como veremos, excesivamente simplista- se basa en el hecho de asumir que en cualquier experimento se obtendrán resultados que serán \emph{o bien totalmente contradictorios} con la teoría (y por tanto habrá que abandonarla inmediatamente) \emph{o bien concordantes} con la teoría (y por tanto resulta razonable mantenerla).

Antes se ha calificado este método de validación como absoluto: si obviamos el posible error experimental, la decisión que se tome no conllevará ningún error, ya que basta con verificar los resultados del experimento para aceptar o rechazar la teoría.

Debe quedar claro al lector que el esquema anterior \emph{no es el de un contraste estadístico}, y de hecho el desarrollo de este tema se encargará de revisarlo. En los próximos apartados se expondrá, para empezar, una primera idea fundamental en Estadística: cuando se introduce un modelo de probabilidad para explicar un fenómeno, emerge inevitablemente un error ya en la misma toma de decisión. En otras palabras, el esquema anterior debe revisarse en los puntos c) y d).

Una vez se han expuesto estas cuestiones fundamentales en los primeros puntos del capítulo, entraremos en el núcleo de este tema que consiste en el desarrollo ya puramente técnico del contraste estadístico de hipótesis.

\subsubsection{Del lenguaje natural a la hipótesis estadística}\label{del-lenguaje-natural-a-la-hipuxf3tesis-estaduxedstica}

Es necesario considerar, antes de afrontar la validación estadística de una hipótesis, cómo se plantea ésta en términos estadísticos, ya que su formulación exige una traducción del lenguaje natural.

Conviene pues recordar que una hipótesis sobre un determinado fenómeno se formula en lenguaje natural como una \emph{proposición sobre la realidad}. Por ejemplo, si se está estudiando determinada especie de aves, una posible hipótesis es que la proporción de machos es idéntica a la de hembras. Un segundo ejemplo nos lo proporciona el estudio del metabolismo humano en donde se propone como hipótesis que la concentración de cierta hormona se mantiene constante cuando se suministra un fármaco anabolizante.

Las hipótesis planteadas en los ejemplos, similares a otras que se trataran en este capítulo se denominan genéricamente \emph{hipótesis paramétricas} porque hacen referencia a características de la población que pueden relacionarse directamente con los parámetros de un modelo probabilístico que la describe. Por ejemplo, si utilizamos una distribución binomial para representar el número de aves hembra en un nido, la proporción de hembras se corresponde con el parámetro \(p\) de dicha distribución.

Así pues, el primer esfuerzo que debe realizar el experimentador es trasladar sus hipótesis, que generalmente expresa en lenguaje natural, a afirmaciones (proposiciones) sobre los parámetros de la distribución que considere más apropiada para describir el fenómeno que estudia.

En ocasiones, sin embargo, la selección misma del modelo probabilístico puede ser el problema. En estos casos la hipótesis se formulará en erminos de la distribución en vez de los parámetros de la misma. Por ejemplo al hablar de la concentración de la hormona durante la metabolizacioón de un fármaco el investigador puede desear decidir si es mas adecuada una distribución normal o una distribución gamma para representar dicha concentración. En este caso hablaríamos de \emph{hipótesis no paramétricas}, que se discutiran más adelante en el curso.

En los casos prácticos siguientes, cuya solución completa se verá a lo largo del capítulo, se presentan dos situaciones diferentes.

\subsubsection{Caso 1: Presentación}\label{caso-1-presentaciuxf3n}

Dos conocidos ornitólogos, especialistas en aves autóctonas del Amazonas Central, discrepan sobre la interpretación de los datos de una nueva especie de cacatúa que ha reseñado uno de ellos. La discusión la centraremos aquí en una de las variables del estudio: la proporción de hembras y machos en los nidos. Es importante precisar que estas cacatúas se caracterizan por incubar un solo huevo por nido.

El Dr.~da Souza Faria ha censado diez nidos, cuyos datos se detallarán después. Según su experiencia, esta especie tiene una gran semejanza con otra especie mejor estudiada, con una proporción idéntica de machos y hembras. Apoyado en los datos obtenidos, concluye que la nueva especie también tiene la misma proporción de individuos de cada sexo.

El Dr.~Calves discrepa de esta apreciación y sostiene que la proporción debe ser de seis hembras por cada 4 machos.

\subsubsection{Caso 1: Modelo de probabilidad}\label{caso-1-modelo-de-probabilidad}

El Dr.~da Souza Faria ha contado en 10 nidos el número de hembras (complementariamente, el de machos). La variable es, por tanto, discreta y su soporte es el conjunto \(\{0,1,2,3,4,5,6,7,8,9,10\}\).

Si asumimos que el posible nacimiento de hembras es independiente entre nidos, y definimos:

\[
X=\text { número de hembras en un total de } 10 \text { nidos. }
\]

la distribución de \(X\) es una distribución binomial, de parámetros \(n=10\) y \(p\) desconocida.

\[
f(k)=p(X=k)=\binom{10}{k} p^{k}(1-p)^{10-k}
\]

el único parámetro desconocido es la proporción \(\boldsymbol{p}\) de hembras. Las hipótesis estadísticas se referirán solo a \(p\).

\subsubsection{Caso 2: Presentación}\label{caso-2-presentaciuxf3n}

En el mundo del deporte profesional se controlan con mucha precisión algunos metabolitos que aparecen en bajas concentraciones en condiciones normales. Este es el caso de la statdrolona\footnote{La statdrolona no es ninguna hormona, aquí se ha adaptado la información de hormonas reales.}, que en individuos normales presenta una concentración media de 7.0 nanogramos por ml de orina. Este valor se ha establecido mediante una muestra muy grande de deportistas después de años de análisis antes, durante y después de competiciones. Asimismo, se ha descrito que la desviación estándar es de \(\mathbf{2 . 4 ~ n g} / \mathbf{m l}\). Estos dos valores poblacionales sirven como justificación médica a las autoridades deportivas para declarar cuándo la tasa de statdrolona se asocia a un presunto dopaje.

No obstante, un estudio reciente encargado por la asociación de deportistas ADG a un prestigioso departamento universitario de fisiología sostiene que, cuando se mide la concentración de statdrolona en individuos no dopados con cierto tipo de alimentos sobreabundantes en su dieta (queso parmesano, por ejemplo), el valor de la media poblacional es del orden de \(\mathbf{1 . 5}\) unidades mayor. En cambio, la desviación estándar poblacional se mantiene en el valor \(2,4 \mathrm{ng} / \mathrm{ml}\), es decir, equivalente a la normal. Si esta hipótesis fuera cierta, permitiría explicar algunos de los falsos positivos detectados en los últimos tiempos. Como prueba experimental aportan una serie de datos sobre 16 deportistas que se detallarán más adelante.

\subsubsection{Caso 2: Modelo de probabilidad}\label{caso-2-modelo-de-probabilidad}

El análisis de la concentración de statdrolona se mide en términos de nanogramos por \(\mathrm{mil} \cdot\) litro, por lo tanto, parece razonable considerarla como una variable continua. El conjunto de resultados posibles será un subconjunto de los reales.

Como muchas otras variables antropométricas, la concentración se puede asociar a la distribución Normal. Se puede justificar la adopción de este modelo de acuerdo con el teorema central del límite.

Según las autoridades deportivas, los valores en un deportista no dopado deben corresponder a una media de \(7.0 \mathrm{ng} / \mathrm{ml}\), mientras que para ADG la media puede ser mayor en algunas circunstancias. En cualquier caso, la variable:

\[
X=\text { concentración de statdrolona en un deportista. }
\]

se aceptará que tiene distribución Normal. Así, la discusión se centrará solo en el parámetro \(\mu\) desconocido, mientras que la desviación estándar se tomará, para simplificar la explicación, como \(\sigma=2.4\) (conocida), aunque se sabe que es más realista seleccionarla como desconocida (véase más adelante en el curso, o los temas anteriores de intérvalos de confianza y distribuciones en el muestreo).

La fórmula de la densidad Normal:

\[
f_{X}(x)=\frac{1}{2.4 \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^{2}}{2 \times 2.4^{2}}\right)
\]

indica para este caso que el único parámetro desconocido es la media de la población \(\boldsymbol{\mu}\), a la que se referirán las hipótesis estadísticas.

Ahora bien, también resulta importante describir la densidad de la media de los dieciséis deportistas, ya que jugará un papel importante en la construcción del test. Si aceptamos la distribución \(\mathrm{N}(\mu, 2.4)\) para un deportista, y \emph{consideramos que el muestreo es aleatorio simple}, entonces:

\[
\bar{X}_{16}=\text { media concentración statdrolona en } 16 \text { deportistas }
\]

que tendrá una densidad de la forma:

\[
\bar{X}_{16} \approx N(\mu, 2.4 / \sqrt{16})
\]

Simplificando 2.4 por la raíz cuadrada de 16 resulta 0.6 , así pues:

\[
f_{\bar{X}_{16}}(x)=\frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^{2}}{2 \times 0.6^{2}}\right)
\]

Una expresión más general para todo \(n\) sería:

\[
\bar{X}_{n} \approx N(\mu, 2.4 / \sqrt{n})
\]

La densidad para todo \(n\) es:

\[
f_{\bar{X}_{n}}(x)=\frac{\sqrt{n}}{2.4 \sqrt{2 \pi}} \exp \left(-\frac{n \times(x-\mu)^{2}}{2 \times 2.4^{2}}\right)
\]

Y una expresión para todo \(n\) y cualquier varianza es:

\[
f_{\bar{X}_{n}}(x)=\frac{\sqrt{n}}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{n \times(x-\mu)^{2}}{2 \times \sigma^{2}}\right)
\]

\subsection{Las hipótesis del contraste de hipótesis}\label{las-hipuxf3tesis-del-contraste-de-hipuxf3tesis}

La teoría del contraste de hipótesis es una de las partes más discutidas de la estadística, por motivos que esperamos iran quedando claros a medida que se avanza en este tema y los siguientes.

De hecho esta teoría ya nació entre la polémica porque, prácticamente desee sus comienzos hubieron dos escuelas de pensamiento enfrentadas. La escuela de Ronald A. Fisher, genético y estadístic británico y la de los matemáticos Polacos y Americanos Neymann y Pearson.

Con el fin de evitar que la polémica confunda el aprendizaje, al menos en esta fae inicial, lo que se presenta a continuación se basa principalmente en las ideas de Neymann y Pearson que, con la finalidad de encontrar el mejor contraste posible para un problema dado, plantearon los contrastes de hipótesis estadísticos como una \emph{decisión entre dos hipótesis}: la \textbf{hipótesis nula} y la \textbf{hipótesis alternativa}.

\begin{itemize}
\item
  La \emph{hipótesis nula} consiste, en general, en una afirmación sobre (alguna característica de) la población de origen de la muestra. Usualmente representa algún tipo de simplificación (por ejemplo: el tratamiento administrado NO tiene efecto por lo que no hay diferencia entre antes y después de recibirlo. La hipótesis nula se designa con el símbolo \(\mathbf{H}_{\mathbf{0}}\).
\item
  La \emph{hipótesis alternativa} es igualmente una afirmación sobre la población de origen, y, amenudo, aunque no siempre, consiste simplemente en negar la afirmación de \(\mathrm{H}_{0}\). La hipótesis alternativa se designa con el símbolo \(\mathbf{H}_{1}\).
\end{itemize}

En el estudio del contraste de hipótesis se suele partir del caso, que de tan sencillo resulta poco realista, en el cual las dos hipótesis hacen referencia a un único valor del parámetro. En esta situación general, las hipótesis se refieren a un parámetro \(\theta\) (theta). La formulación es:

\[
\begin{aligned}
& \mathrm{H}_{0}: \theta=\theta_{0} \\
& \mathrm{H}_{1}: \theta=\theta_{1}
\end{aligned}
\] De hecho, sería mucho más realista plantear que la alternativa a un valor \(\theta_0\) sea que el parámetro toma valores superiores (\(\mathrm{H}_{1}: \theta \geq \theta_{0}\)), inferiores (\(\mathrm{H}_{1}: \theta \leq \theta_{0}\)) o distintos (\(\mathrm{H}_{1}: \theta \neq \theta_{0}\))a \(\theta_0\). En la práctica este será el planteamiento de los tests que se presentará más adelante.

En la teoría del contraste de hipótesis este tipo de planteamiento se conoce como contraste de hipótesis \emph{simple contra simple}. Así pues, una hipótesis simple postula que el parámetro \(\theta\) solo puede tomar un valor, o, más técnicamente, que el conjunto de parámetros de una hipótesis simple consiste en un solo punto.

\subsubsection{Caso 1: Hipótesis para dirimir la controversia sobre el número de hembras}\label{caso-1-hipuxf3tesis-para-dirimir-la-controversia-sobre-el-nuxfamero-de-hembras}

El Dr.~da Souza Faria postula la misma proporción para machos y hembras. En términos de la proporción de la variable \(X\) (n.º de hembras en 10 nidos) esto equivale a la hipótesis de que la proporción (en la población) es \(\mathbf{0 . 5}\).

En cambio, según el Dr.~Calves la proporción es 6:4 a favor de las hembras, y por lo tanto equivale a la hipótesis de que el parámetro \(p\) en la variable Binomial es 0.6.

Así pues, si \(X\) es el número de hembras en 10 nidos, y \(p\) es la proporción de hembras, la forma final del contraste es:

\[
\begin{aligned}
& \mathrm{H}_{0}: \mathrm{p}=0.5 \\
& \mathrm{H}_{1}: \mathrm{p}=0.6
\end{aligned}
\]

Respecto a los datos obtenidos por da Souza son:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Nido & Polluelo & Nido & Polluelo \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & hembra & 6 & macho \\
2 & macho & 7 & hembra \\
3 & hembra & 8 & hembra \\
4 & hembra & 9 & macho \\
5 & macho & 10 & hembra \\
\end{longtable}

En resumen, ha observado que en \(\mathbf{6}\) de los nidos hay una hembra.

\subsubsection{Caso 2: Hipótesis a contrastar en el problema de la tasa de statdrolona}\label{caso-2-hipuxf3tesis-a-contrastar-en-el-problema-de-la-tasa-de-statdrolona}

Las autoridades deportivas postulan una media de \(7.0 \mathrm{ng} / \mathrm{ml}\), mientras que ADG indica una media de \(8.5 \mathrm{ng} / \mathrm{ml}\) para los individuos sometidos a este tipo de dieta. Por tanto, en síntesis el contraste consistirá en:

\[
\begin{aligned}
& \mathrm{H}_{0}: \mu=7,0 \\
& \mathrm{H}_{1}: \mu=8,5
\end{aligned}
\]

tanto para \(\mathrm{H}_{0}\) como para \(\mathrm{H}_{1}\) el modelo contempla \(\sigma=2,4\).\\
Los datos del estudio que ha obtenido la asociación ADG, y que según ellos respaldaban su tesis, han sido los siguientes:

\begin{longtable}[]{@{}cccc@{}}
\toprule\noalign{}
Individuo & Concentración & Individuo & Concentración \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 10.47 & 9 & 7.01 \\
2 & 5.39 & 10 & 11.36 \\
3 & 6.70 & 11 & 10.11 \\
4 & 9.91 & 12 & 5.89 \\
5 & 5.99 & 13 & 10.39 \\
6 & 11.67 & 14 & 10.67 \\
7 & 6.23 & 15 & 6.89 \\
8 & 6.69 & 16 & 11.27 \\
\end{longtable}

La media aritmética de los 16 atletas es \(\mathbf{8 . 5 4} \mathrm{ng} / \mathrm{ml}\).

\subsection{Compatibilidad de resultados e hipótesis}\label{compatibilidad-de-resultados-e-hipuxf3tesis}

Volviendo a la cuestión fundamental de la verificación de hipótesis, un resultado incompatible con una hipótesis es aquel que no puede haberse producido de ninguna manera si dicha hipótesis es cierta.

En este sentido, incompatible es sinónimo de imposible. En términos de probabilidad, un resultado incompatible es aquel que tiene probabilidad cero de producirse si la hipótesis es cierta. La lógica elemental indica que si se obtiene un resultado incompatible con una hipótesis, esta última es forzosamente falsa.

Ahora bien, cuando se toma un modelo aleatorio para explicar el fenómeno observado, el carácter probabilístico del modelo habitualmente evita que se descarte cualquier hipótesis por haber obtenido datos incompatibles con ella.

Al contrario, todos los resultados serán estrictamente compatibles con las dos hipótesis, o dicho de otro modo, cualquier conjunto de datos que se obtenga en el estudio se puede llegar a observar tanto bajo \(\mathrm{H}_{0}\) como bajo \(\mathrm{H}_{1}\). Esto rompe el esquema excesivamente simple expuesto antes en la verificación ideal de hipótesis.

En definitiva, si se modela la realidad como un fenómeno aleatorio, se debe abandonar la idea de la toma de decisiones basada solo en una inspección de resultados que descarte sin error en la toma de decisión una de las dos hipótesis.

\subsubsection{Caso 1: Compatibilidad de resultados e hipótesis}\label{caso-1-compatibilidad-de-resultados-e-hipuxf3tesis}

El Dr.~da Souza Faria ha obtenido una muestra de 6 hembras y 4 machos en los 10 nidos. Sin embargo, este es solo uno de los resultados posibles que se podían dar bajo la hipótesis nula. Si hubiera elegido como muestra otros nidos, podría haber encontrado otro número de hembras.

Como ya hemos visto, \(X\) (n.º de hembras en 10 nidos) es una \(\operatorname{Binomial}(10,0.5)\). En la tabla siguiente se detallan los resultados que podían haber sucedido bajo \(\mathrm{H}_{0}\), junto con la probabilidad de obtenerlos según la fórmula de la densidad binomial:

\begin{tabular}{r|r}
\hline
X & Prob\\
\hline
0 & 0.0010\\
\hline
1 & 0.0098\\
\hline
2 & 0.0439\\
\hline
3 & 0.1172\\
\hline
4 & 0.2051\\
\hline
5 & 0.2461\\
\hline
6 & 0.2051\\
\hline
7 & 0.1172\\
\hline
8 & 0.0439\\
\hline
9 & 0.0098\\
\hline
10 & 0.0010\\
\hline
\end{tabular}

Al igual que para \(\mathrm{H}_{0}\), la muestra obtenida por el Dr.~da Souza Faria con 6 hembras y 4 machos es solo uno de los resultados posibles que se podían dar bajo la hipótesis alternativa. En este caso \(X\) (n.º de hembras en 10 nidos) es una \(\operatorname{Binomial}(10,0.6)\).

En la tabla siguiente se detallan los resultados que podrían haberse observado bajo \(\mathrm{H}_{1}\), junto con la probabilidad de obtenerlos según la fórmula de la densidad binomial:

\begin{tabular}{r|r}
\hline
X & Prob\\
\hline
0 & 0.0001049\\
\hline
1 & 0.0015729\\
\hline
2 & 0.0106168\\
\hline
3 & 0.0424673\\
\hline
4 & 0.1114767\\
\hline
5 & 0.2006581\\
\hline
6 & 0.2508227\\
\hline
7 & 0.2149908\\
\hline
8 & 0.1209324\\
\hline
9 & 0.0403108\\
\hline
10 & 0.0060466\\
\hline
\end{tabular}

Un sencillo código R puede calcular las probabilidades tienen los once resultados bajo otras hipótesis que se podrían formular sobre el verdadero valor de la probabilidad \(p\) de la población.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{prob\_p }\OtherTok{\textless{}{-}}\NormalTok{ p }\CommentTok{\# p algun valor entre 0 y 1}
\FunctionTok{dbinom}\NormalTok{(}\AttributeTok{x=}\DecValTok{0}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\AttributeTok{size=}\DecValTok{10}\NormalTok{, }\AttributeTok{prob=}\NormalTok{prob\_p)}
\end{Highlighting}
\end{Shaded}

Podemos entender estas diferentes '' \(p\) '' como hipótesis distintas que se podrían haber establecido como alternativa a \(\mathrm{H}_{0}\). Excepto en los casos triviales \(p=0\) o \(p=1\), no hay ningún resultado que no pueda presentarse, aunque sea con probabilidades muy pequeñas.

\subsubsection{Caso 2: Compatibilidad de resultados e hipótesis}\label{caso-2-compatibilidad-de-resultados-e-hipuxf3tesis}

La asociación ADG ha obtenido una muestra con media \(8.54 \mathrm{ng} / \mathrm{ml}\) de statdrolona para 16 deportistas. Ya hemos visto en el modelo de probabilidad qué densidad asociamos con la variable de cada deportista y con la media de todos ellos. Hay que recordar que una variable continua tiene probabilidad cero de obtener un resultado puntual y que las probabilidades en variables continuas se calculan sobre intervalos. Así pues, el valor 8.54 debe interpretarse como un intervalo \((8.54-\epsilon, 8.54+\epsilon)\), ya que las medidas de los deportistas individualmente corresponden en realidad a cierto intervalo de precisión experimental (por ejemplo, 0.3 \(\mathrm{ng} / \mathrm{ml}\)). El valor 8.54 elegido como marca de un cierto intervalo no es en absoluto incompatible con la hipótesis nula. De hecho, es posible obtener cualquier media.

En la parte izquierda de la tabla que se presenta a continuación se detallan las probabilidades de diferentes resultados que podían haber sucedido bajo \(H_0\) expresadas en términos de la función de distribución. La media de los 11 resultados corresponde a una Normal (8.5, 0.6).

En la parte derecha de la tabla se detallan las probabilidades para intervalos de anchura \(0.3 ml\) más cercanos a la media bajo \(H_0\).

\begin{tabular}{c|c|c|c|c}
\hline
$X$ & $P(X\leq x)$ & $X-\epsilon$ & $X+\epsilon$ & $P(X)$\\
\hline
6.7 & 0.3085 & -Inf & 6.7 & 0.3085\\
\hline
7.0 & 0.5000 & 6.7 & 7.0 & 0.1915\\
\hline
7.3 & 0.6915 & 7.0 & 7.3 & 0.1915\\
\hline
7.6 & 0.8413 & 7.3 & 7.6 & 0.1499\\
\hline
7.9 & 0.9332 & 7.6 & 7.9 & 0.0918\\
\hline
8.2 & 0.9772 & 7.9 & 8.2 & 0.0441\\
\hline
8.5 & 0.9938 & 8.2 & 8.5 & 0.0165\\
\hline
8.8 & 0.9987 & 8.5 & 8.8 & 0.0049\\
\hline
9.1 & 0.9998 & 8.8 & 9.1 & 0.0011\\
\hline
9.4 & 1.0000 & 9.1 & 9.4 & 0.0002\\
\hline
9.7 & 1.0000 & 9.4 & 9.7 & 0.0000\\
\hline
\end{tabular}

En el caso de \(\mathrm{H}_{1}\) tampoco es incompatible ninguna media, y por tanto en particular no lo es el valor 8.54. Ahora la densidad de la media de los 16 valores es una variable aleatoria Normal \(\mathrm{N}(8.5,0.6)\).

En la parte izquierda de la tabla se detallan las probabilidades de diferentes resultados que podrían haber sucedido bajo \(\mathrm{H}_{1}\) expresadas en términos de la función de distribución. En la parte de la derecha se muestran las probabilidades para intervalos de anchura \(0.3 ml\)

\begin{tabular}{c|c|c|c|c}
\hline
$X$ & $P(X\leq x)$ & $X-\epsilon$ & $X+\epsilon$ & $P(X)$\\
\hline
6.7 & 0.0013 & -Inf & 6.7 & 0.0013\\
\hline
7.0 & 0.0062 & 6.7 & 7.0 & 0.0049\\
\hline
7.3 & 0.0228 & 7.0 & 7.3 & 0.0165\\
\hline
7.6 & 0.0668 & 7.3 & 7.6 & 0.0441\\
\hline
7.9 & 0.1587 & 7.6 & 7.9 & 0.0918\\
\hline
8.2 & 0.3085 & 7.9 & 8.2 & 0.1499\\
\hline
8.5 & 0.5000 & 8.2 & 8.5 & 0.1915\\
\hline
8.8 & 0.6915 & 8.5 & 8.8 & 0.1915\\
\hline
9.1 & 0.8413 & 8.8 & 9.1 & 0.1499\\
\hline
9.4 & 0.9332 & 9.1 & 9.4 & 0.0918\\
\hline
9.7 & 0.9772 & 9.4 & 9.7 & 0.0441\\
\hline
\end{tabular}

\subsection{No todo es igualmente probable\ldots{}}\label{no-todo-es-igualmente-probable}

La segunda consideración fundamental en un contraste de hipótesis estadístico es que no todos los resultados son igualmente probables bajo \(\mathrm{H}_{0} \circ \mathrm{H}_{1}\). Este es el principal argumento para establecer un criterio de decisión -una regla- que permita decidir en la práctica si es aceptable \(\mathrm{H}_{0}\) o bien \(\mathrm{H}_{1}\).

La idea provisional que debe guiar al lector en este momento, cuando inspecciona los casos prácticos, es que \emph{los resultados (muy) improbables bajo cierta hipótesis sugieren que ésta seguramente no es válida}. Así pues, en el contraste estadístico de hipótesis no hay resultados imposibles, solo improbables, y por lo tanto en las decisiones se introduce forzosamente una probabilidad de error.

\subsubsection{\texorpdfstring{Caso 1: Una región con número de hembras con baja probabilidad bajo \(\mathrm{H}_{0}\)}{Caso 1: Una región con número de hembras con baja probabilidad bajo \textbackslash mathrm\{H\}\_\{0\}}}\label{caso-1-una-regiuxf3n-con-nuxfamero-de-hembras-con-baja-probabilidad-bajo-mathrmh_0}

Hemos visto antes las probabilidades de obtener cada uno de los resultados posibles para \(X\): \(0,1, \ldots\), hasta 10 hembras. El sentido común indica que si se obtienen valores de X cercanos a 0 o a 10, la hipótesis \(p=0.5\) resulta poco verosímil.

Es importante entender que el verdadero valor de \(p\) (el valor en la población) no es, ni será nunca, conocido en la práctica, solo formulamos hipótesis sobre este valor.

Veamos cuál es la probabilidad de obtener valores mayores que 8 hembras. Para abreviar, designamos la región de valores mayores o iguales a 8 con el símbolo \(\mathrm{W}_{\alpha}=\{8,9,10\}\).

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
Valor de \(X\) & Prob. \(X>=X\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 1.0000 \\
1 & 0.9990 \\
2 & 0.9893 \\
3 & 0.9453 \\
4 & 0.8281 \\
5 & 0.6230 \\
6 & 0.3770 \\
7 & 0.1719 \\
8 & 0.0547 \\
9 & 0.0107 \\
10 & 0.0010 \\
\end{longtable}

\subsubsection{\texorpdfstring{Caso 2: Medias de las tasas de statdrolona improbables si se cumple \(\mathrm{H}_{0}\)}{Caso 2: Medias de las tasas de statdrolona improbables si se cumple \textbackslash mathrm\{H\}\_\{0\}}}\label{caso-2-medias-de-las-tasas-de-statdrolona-improbables-si-se-cumple-mathrmh_0}

De la misma manera que se ha razonado para el caso 1, en esta ocasión con las dos hipótesis ( \(\mu=7\) contra \(\mu=8.5\) ) que tenemos en el caso de la detección de la statdrolona, el sentido común indica que si obtenemos una media de statdrolona en los 16 atletas alejada del valor de referencia 7, hará inverosímil la hipótesis nula.

En la tabla siguiente se muestran las probabilidades de obtener valores mayores que 7 \(\mathrm{ng} / \mathrm{ml}\). Observemos particularmente la región de valores mayores que 7.9869, que se representará con el símbolo \(\mathrm{W}_{\alpha}\). Expresada como intervalo, \(\mathrm{W}_{\alpha}=[7.9869, \infty)\).

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
Miljana \((x)\) & Prob. \(X=x\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
6,506 & 0.7946 \\
6,671 & 0.7083 \\
6,835 & 0.6080 \\
7 & 0.5000 \\
7,165 & 0.3920 \\
7,329 & 0.2917 \\
7,494 & 0.2054 \\
7,658 & 0.1364 \\
7,823 & 0.0852 \\
7,987 & 0.0500 \\
8,152 & 0.0275 \\
\end{longtable}

\subsection{El papel privilegiado de la hipótesis nula: criterio de decisión}\label{el-papel-privilegiado-de-la-hipuxf3tesis-nula-criterio-de-decisiuxf3n}

Un contraste estadístico de hipótesis consta forzosamente de un criterio de decisión. En resumen, consiste en una regla operativa que divide en dos partes disjuntas el espacio muestral. Estas partes se llaman región crítica y región de aceptación respectivamente. En cualquier test estadístico, si la muestra obtenida pertenece a la región crítica, se debe aceptar \(\mathrm{H}_{1}\). En caso contrario, si pertenece a la región de aceptación, se aceptará \(\mathrm{H}_{0}\).

Un primer principio básico consiste en priorizar en el criterio de decisión a \(\mathrm{H}_{0}\), en el siguiente sentido: se construye el criterio fijando a priori la probabilidad de error asociada con el hecho de rechazar -erróneamente- \(\mathrm{H}_{0}\). A fin de que el criterio de decisión sea razonable debe resultar improbable obtener una muestra que pertenezca a la región crítica cuando sea cierta \(\mathrm{H}_{0}\). En el ejemplo siguiente se propondrá una regla de decisión provisional.

\subsubsection{Caso 1: N.º de nidos propuestos ad hoc como inicio de región crítica. Regla de decisión resultante}\label{caso-1-n.uxba-de-nidos-propuestos-ad-hoc-como-inicio-de-regiuxf3n-cruxedtica.-regla-de-decisiuxf3n-resultante}

Definiremos la región crítica de la siguiente forma:

\[
\mathrm{W}_{\alpha}=\{8,9,10\}
\]

Por lo tanto, la región de aceptación será:

\[
\mathrm{W}_{\alpha}^{\mathrm{C}}=\{0,1,2,3,4,5,6,7\}
\]

El criterio de decisión será por tanto:

\begin{itemize}
\tightlist
\item
  si el número de hembras es mayor o igual que 8, se acepta \(\mathrm{H}_{1}\) (la probabilidad de hembras es 0.6)\\
\item
  si el número de hembras es menor o igual que 7, se acepta \(\mathrm{H}_{0}\) (la probabilidad de hembras es 0.5)
\end{itemize}

Es importante entender en este momento que se propone ad hoc la región crítica. Más adelante se justificará por qué esta propuesta es razonable.

Nota: en la muestra obtenida se han observado 6 hembras, por tanto da Souza debe aceptar \(\mathrm{H}_{0}\).

\subsection{Hipótesis nula y nivel de significación}\label{hipuxf3tesis-nula-y-nivel-de-significaciuxf3n}

Se ha indicado anteriormente que, en los contrastes estadísticos, la hipótesis nula juega un papel privilegiado, ya que la regla de decisión se ajusta de acuerdo con la probabilidad de equivocarse al rechazar \(H_{0}\) cuando ésta es cierta.

Esta probabilidad se designa de forma equivalente como:

\begin{itemize}
\tightlist
\item
  error de tipo I (o de primera especie)\\
\item
  nivel de significación del contraste
\end{itemize}

y usualmente se simboliza con la letra griega alfa.\\
El nivel de significación se puede definir equivalentemente de las dos maneras siguientes:\\
- \(\alpha=\) probabilidad de rechazo de \(\mathbf{H}_{\mathbf{0}}\), cuando \(\mathrm{H}_{0}\) es cierta\\
- \(\alpha=\) probabilidad de que la muestra pertenezca a la región crítica, cuando \(\mathbf{H}_{0}\) es cierta.

\subsubsection{Caso 1: Nivel de significación}\label{caso-1-nivel-de-significaciuxf3n}

En el apartado 9.5.1 se ha indicado la tabla resultante de los cálculos de la cola derecha de la Binomial, cuando se verifica la hipótesis nula \((p=0.5)\). Como la definición de nivel de significación es:

\[
\alpha=\text { prob. muestra pertenezca a la región crítica, cuando } \mathbf{H}_{0} \text { es cierta }
\]

en la fila correspondiente a prob \((\mathrm{X} \geq 8)\) de la tabla anterior se puede observar la probabilidad de rechazar \(\mathrm{H}_{0}\) cuando ésta es cierta (véase el criterio de decisión adoptado en el apartado 9.6.1).

Simbólicamente hemos calculado:

\[
\alpha=p\left(X \geq 8 / H_{0}\right)=\sum_{i=8}^{10} p\left(X=i / H_{0}\right)=\sum_{i=8}^{10}\binom{10}{i} 0.5^{10}
\]

Resulta pues: \(\quad \alpha=0.0547\).

\subsubsection{Caso 1: Elección de la región crítica}\label{caso-1-elecciuxf3n-de-la-regiuxf3n-cruxedtica}

Se ha propuesto antes, de forma directa, la región crítica:

\[
\mathrm{W}_{\alpha}=\{8,9,10\}
\]

Podemos considerar ahora otra región que nos proporcionaría un nivel de significación idéntico (ver tabla de probabilidades bajo \(\mathrm{H}_{0}\)):

\[
\begin{gathered}
\mathrm{W}_{\alpha}^{\prime}=\{0,1,2\} \\
\alpha=0.0010+0.0098+0.0439=0.0547
\end{gathered}
\]

Ahora bien, un criterio de decisión basado en \(\mathrm{W}^{\prime}{ }_{\alpha}=\{0,1,2\}\) es absurdo, teniendo en cuenta que \(\mathrm{H}_{1}\) es \(p=0.6\). Veamos por qué.

El valor \(\alpha=0.0547\) indica que es improbable obtener menos de 3 hembras bajo \(\mathrm{H}_{0}\). Si se elige \(\mathrm{W}^{\prime}{ }_{\alpha}\) como región crítica, implica aceptar \(\mathrm{H}_{1}\) cuando el número de hembras es menor que 3. Sin embargo, cuando se consulta la tabla de probabilidades bajo \(\mathrm{H}_{1}\), resulta:\\
prob. (número hembras \(<3 / \mathrm{H}_{1}\) cierta) \(=0.0001+0.0016+0.0106=0.0123\)\\
Es, por tanto, todavía más improbable obtener 3 hembras bajo \(\mathrm{H}_{1}\). En otras palabras, \(\mathrm{W}^{\prime}{ }_{\alpha}\) induce un criterio absurdo, ya que llevaría a aceptar la hipótesis menos verosímil de las dos.

\subsubsection{Caso 2: Elección de la región crítica}\label{caso-2-elecciuxf3n-de-la-regiuxf3n-cruxedtica}

A continuación se definen las regiones crítica y de aceptación, respectivamente, como:

\[
\mathrm{W}_{\alpha}=[7.9869,+\infty) \quad \mathrm{W}_{\alpha}^{\mathrm{C}}=(-\infty, 7.9869)
\]

El criterio de decisión será, por tanto:\\
si el nivel de statdrolona es mayor o igual que 7.9869, se acepta \(\mathbf{H}_{\mathbf{1}}\) (el nivel es 8.5)\\
Al igual que en el caso 1, también se ha propuesto la región crítica de forma ad hoc. Si se consultan en la tabla del apartado 9.5.2 los valores de la cola derecha de la Normal, como la definición de nivel de significación es:

\[
\alpha=\text { prob. muestra pertenezca a la región crítica, cuando } \mathbf{H}_{0} \text { es cierta }
\]

en la fila correspondiente a prob \((\mathrm{X}>=7.987)\) de la tabla se puede observar la probabilidad de rechazar \(\mathrm{H}_{0}(\mu=7.0)\) cuando ésta es cierta. Simbólicamente hemos calculado:

\[
\alpha=p\left(\bar{X}_{16} \geq 7.9869 / H_{0}\right)=\int_{7.9869}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left\{-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right\} d x=\\ = 1-F_{Z}\left(\frac{7.9869-7}{2.4 / \sqrt{16}}\right)
\]

donde \(F_{z}\) es la función de distribución de la Normal tipificada \(N(0,1)\).\\
La región crítica \(\mathrm{W}_{\alpha}=[7.9869,+\infty)\) lleva asociado un nivel de significación \(\alpha=0.05\). Ahora bien, como el estadístico media muestral es una variable continua, concretamente Normal, se pueden encontrar infinitas regiones que satisfagan la condición:

\[
\operatorname{prob}\left(\operatorname{muestra} \text { en } \mathrm{W}_{\alpha} / \mathrm{H}_{0}\right)=0.05
\]

\subsection{Región crítica y formalización del contraste}\label{regiuxf3n-cruxedtica-y-formalizaciuxf3n-del-contraste}

La regla de decisión queda definida siempre (aunque sea implícitamente) a partir de una región crítica. A esta región crítica le corresponde un determinado nivel de significación.\\
La información contenida en la muestra se resume mediante un estadístico de test, así que una práctica habitual es definir la región crítica en función del estadístico de test empleado. Un estadístico de test es una variable aleatoria y, como tal, tiene asociada una ley de distribución que juega un papel capital en el contraste.

Reuniendo los conceptos, en un contraste de hipótesis \(\mathrm{H}_{0}\) contra \(\mathrm{H}_{1}\), tenemos:

\[
\begin{aligned}
\alpha & =\text { nivel de significación, } \\
\mathrm{W}_{\alpha} & =\text { región crítica, subconjunto del espacio muestral definido a partir de } \mathrm{T}
\end{aligned}
\]

Regla de decisión:

\begin{itemize}
\tightlist
\item
  si la muestra pertenece a \(\mathrm{W}_{\alpha}\) entonces rechazar \(\mathrm{H}_{0}\)\\
\item
  si la muestra no pertenece a \(\mathrm{W}_{\alpha}\) entonces rechazar \(\mathrm{H}_{1}\)
\end{itemize}

Finalmente:

\[
\alpha=\text { prob.(rechazar } H_{0} / H_{0} \text { cierta) = prob.(muestra pertenezca a } W_{\alpha} / H_{0} \text { cierta) }
\]

\subsubsection{Caso 1: Resumen de conceptos asociados al contraste. Región crítica}\label{caso-1-resumen-de-conceptos-asociados-al-contraste.-regiuxf3n-cruxedtica}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Región crítica
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathrm{W}_{\alpha}=\{8,9,10\}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Región de aceptación & \(\mathrm{W}_{\alpha}^{\mathrm{C}}=\{0,1,2,3,4,5,6,7\}\) \\
Estadístico de test & \(\mathrm{T}=\) número de hembras totales en los 10 nidos \\
Criterio de decisión: & \\
aceptar \(\mathrm{H}_{1}\) si & \(\mathrm{T} \geq 8\) \\
aceptar \(\mathrm{H}_{0}\) si & \(\mathrm{T} \leq 7\) \\
Nivel de significación & \(\alpha=0.0547\) \\
\end{longtable}

La distribución del estadístico de test T es una Binomial B (10, p). Se puede adoptar un estadístico alternativo: la frecuencia relativa \(=\mathbf{f r}\) del número de hembras en los 10 nidos.

\subsubsection{Caso 2: Tabla resumen de la región crítica, el estadístico de test y del criterio de decisión}\label{caso-2-tabla-resumen-de-la-regiuxf3n-cruxedtica-el-estaduxedstico-de-test-y-del-criterio-de-decisiuxf3n}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Región crítica
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathrm{W}_{\alpha}=[7.9869,+\infty)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Región de aceptación & \(\mathrm{W}_{\alpha}^{\mathrm{C}}=(-\infty, 7.9869)\) \\
Estadístico de test & \(\mathrm{T}=\) media de statdrolona en 16 atletas \\
Criterio de decisión: & \\
aceptar \(\mathrm{H}_{1}\) si & \(\mathrm{T} \geq 7.9869\) \\
aceptar \(\mathrm{H}_{0}\) si & \(\mathrm{T}<7.9869\) \\
Nivel de significación & \(\alpha=0.05\) \\
\end{longtable}

La distribución del estadístico de test T bajo \(\mathrm{H}_{0}\) es una normal \(\mathrm{N}(7,0.6)\).

\subsubsection{Región crítica frente a Estadístico de Test}\label{regiuxf3n-cruxedtica-frente-a-estaduxedstico-de-test}

En los párrafos anteriores se han introducido y utilizado los conceptos de estadístico de test y región crítica dandose a entender que la región crítica esta definida por \emph{aquellos valores del estadístico de test que llevan a rechazar la hipótesis nula}.

Aunque esta aproximación es habitual, también lo es el presentarlos ambos como dos formas equivalentes de definir una región de rechazo. Es decir, la decisión de rechazar \(H_0\) puede llevarse a cabo:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Mediante una \textbf{región crítica} \(\mathcal{R}\), entendida como un subconjunto del espacio muestral, de modo que se rechaza \(H_0\) cuando la muestra observada pertenece a \(\mathcal{R}\).
\item
  Mediante un \textbf{estadístico de contraste} \(T=T(X)\) y una condición sobre los valores que puede tomar dicho estadístico. En este caso, se rechaza \(H_0\) cuando \(T(X)\in C\), donde \(C\) es un subconjunto del espacio de valores de \(T\).
\end{enumerate}

En esta segunda formulación, la región crítica en el espacio muestral viene dada implícitamente por

\[
\mathcal{R}=\{x:T(x)\in C\}.
\]

Aunque la primera formulación es conceptualmente más general, en la práctica se trabaja casi siempre con el estadístico de contraste por ser más operativo. En este capítulo utilizaremos ambas formulaciones, dando preferencia a la segunda.

\subsection{Tabla de decisión del contraste}\label{tabla-de-decisiuxf3n-del-contraste}

Cuando se resuelve un contraste la decisión final puede ser correcta o bien conducir a un error. En esta tabla se presentan las cuatro posibles situaciones que se pueden producir:

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& Hipótesis verdadera & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hipótesis aceptada & \(\mathrm{H}_{0}\) & \(\mathrm{H}_{1}\) \\
\(\mathrm{H}_{0}\) & - & error tipo II \\
\(\mathrm{H}_{1}\) & error tipo I & - \\
\end{longtable}

Existe, por tanto, un segundo tipo de error, designado como error de tipo II o de segunda especie. Se puede definir de manera equivalente para cualquiera de las dos expresiones siguientes:

\begin{itemize}
\tightlist
\item
  \(1-\beta=\) probabilidad de rechazar \(\mathrm{H}_{1}\), cuando \(\mathrm{H}_{1}\) es cierta\\
\item
  \(1-\beta=\) probabilidad de que la muestra no pertenezca a la región crítica, cuando \(\mathbf{H}_{1}\) es cierta
\end{itemize}

En realidad, solo una de las hipótesis es verdadera. Una vez se obtenga la muestra, se aceptará o se rechazará \(\mathrm{H}_{1}\) según el criterio de decisión. Si se decide de manera equivocada, se producirá solo uno de los dos errores, según cuál sea la hipótesis verdadera. Es decir, a posteriori se produce, como mucho, solo uno de los errores.

Ahora bien, el contraste se lleva a cabo precisamente porque se ignora cuál de las dos hipótesis es la verdadera. Como consecuencia, sin que ello contradiga el párrafo anterior, los dos errores tienen importancia a priori.

Un contraste será más adecuado si son menores los dos errores asociados.

\subsubsection{Caso 1: Evaluación de los dos errores asociados al contraste}\label{caso-1-evaluaciuxf3n-de-los-dos-errores-asociados-al-contraste}

El criterio de decisión que se ha adoptado para este caso consiste en:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
aceptar \(\mathrm{H}_{1}\) si & \(\mathrm{T} \geq 8\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
aceptar \(\mathrm{H}_{0}\) si & \(\mathrm{T} \leq 7\) \\
Nivel de significación & \(\alpha=0.0547\) \\
\end{longtable}

Supongamos que \(\mathrm{H}_{1}\) es cierta, es decir, que \(p=0,6\). En la tabla siguiente podemos encontrar el valor del error de tipo II:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
Valor de \(X\) & Prob. \(X<=\mathrm{X}\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
0 & 0.0001 \\
1 & 0.0017 \\
2 & 0.0123 \\
3 & 0.0548 \\
4 & 0.1662 \\
5 & 0.3669 \\
6 & 0.6177 \\
7 & 0.8327 \\
8 & 0.9536 \\
9 & 0.9940 \\
10 & 1.0000 \\
\end{longtable}

\(1-\beta=\) prob. (rechazar \(H_{1}/H_{1}\) cierta)= prob. \((T \leq 7/H_{1}\) cierta) \(=\mathbf{0 . 8 3 2 7}\)\\
Simbólicamente corresponde a calcular:

\[
1-\beta=p\left(X<8 / H_{1}\right)=\sum_{i=0}^{7} p\left(X=i / H_{1}\right)=\sum_{i=0}^{7}\binom{10}{i} 0.6^{i} 0.4^{10-i}
\]

\subsubsection{\texorpdfstring{Caso 2: Cálculo explícito de los errores de primera ( \(\alpha\) ) y segunda especie (1- \(\beta\) )}{Caso 2: Cálculo explícito de los errores de primera ( \textbackslash alpha ) y segunda especie (1- \textbackslash beta )}}\label{caso-2-cuxe1lculo-expluxedcito-de-los-errores-de-primera-alpha-y-segunda-especie-1--beta}

El criterio de decisión que se ha elegido para este caso consiste en:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
aceptar \(\mathrm{H}_{1}\) si & \(\mathrm{T} \geq 7.9869\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Nivel de significación & \(\alpha=0.05\) \\
\end{longtable}

Supongamos que es cierta \(\mathrm{H}_{1}\), es decir, que \(\mu=8.5\). En la tabla siguiente podemos encontrar el valor del error de tipo II:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
Mitiana \((x)\) & Prob. \(X==x\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
5,933 & 1.0000 \\
6,189 & 0.9999 \\
6,446 & 0.9997 \\
6,703 & 0.9986 \\
6,96 & 0.9949 \\
7,216 & 0.9838 \\
7,473 & 0.9565 \\
7,73 & 0.9004 \\
7,987 & 0.8040 \\
8,243 & 0.6656 \\
8,5 & 0.5000 \\
\end{longtable}

\(1-\beta=\) prob. (rechazar \(\mathrm{H}_{1}/\mathrm{H}_{1}\) cierta)= prob. \((\mathrm{T}<7.9869/\mathrm{H}_{1})=1-0.8040=0.1960\)\\
Simbólicamente, corresponde a calcular:

\[
\begin{aligned}
1-\beta & =p\left(\bar{X}_{16}<7.9869 / H_{1}\right)=\int_{-\infty}^{7.9869} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-8.5)^{2}}{2 \times 0.6^{2}}\right) d x =\\
& =F_{Z}\left(\frac{7.9869-8.5}{2.4 / \sqrt{16}}\right)
\end{aligned}
\]

\subsection{Relación entre el error de tipo I y el de tipo II}\label{relaciuxf3n-entre-el-error-de-tipo-i-y-el-de-tipo-ii}

Es importante entender que no es posible reducir simultáneamente los dos errores en un contraste de hipótesis.

Supongamos que se intenta reducir a cero el nivel de significación. Esto equivale a plantear que la probabilidad de que una muestra pertenezca a la región crítica, en el caso de que sea cierta \(\mathrm{H}_{0}\), es cero. En la mayoría de situaciones aplicadas este hecho da lugar a una región crítica igual al conjunto vacío, o lo que es lo mismo, provoca que se acepte siempre \(\mathrm{H}_{0}\), independientemente del resultado obtenido en la muestra. Se llega por tanto a la situación absurda de poder prescindir de la muestra, aceptando siempre \(H_{0}\)! Así, reducir \(\alpha\) a cero tiene la grave contrapartida de rechazar siempre \(\mathrm{H}_{1}\), lo que implica a su vez que el error de tipo II sea uno. De manera análoga se puede razonar para un error de tipo II nulo. En conclusión, los dos errores están relacionados: disminuir \(\alpha\) conlleva reducir el tamaño de la región crítica y, por lo tanto, aumentar 1- \(\beta\).

\subsubsection{\texorpdfstring{Caso 1: Evaluación de \(\alpha\) y 1- \(\beta\) para diferentes regiones críticas}{Caso 1: Evaluación de \textbackslash alpha y 1- \textbackslash beta para diferentes regiones críticas}}\label{caso-1-evaluaciuxf3n-de-alpha-y-1--beta-para-diferentes-regiones-cruxedticas}

Una vez se especifica la región crítica, los errores de tipo I y II quedan determinados. En los dos cuadros siguientes hay dos regiones críticas y sus errores asociados. En la versión interactiva ( \emph{no disponible}) de Statmedia se podía cambiar dinámicamente la región crítica y se calculaban automáticamente los errores:

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-ProbsErrTipo2b} \end{center}

En el gráfico siguiente se representan los dos errores simultáneamente para diferentes regiones críticas. Para simplificar la comprensión del gráfico, se consideran solo regiones de la forma \(\{a, a+1, \ldots 10\}\), donde \(a\) es un entero entre 0 y 10. Así, por ejemplo, el punto de abscisas 8 representa la región crítica \(\{8,9,10\}\). La hipótesis alternativa considerada es \(p_{1}=0.6\), tal y como se indica en la leyenda del gráfico.

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-PlotProbsErrTipo2b} \end{center}

\subsubsection{\texorpdfstring{Caso 2: Relación entre los errores de primera ( \(\alpha\) ) y segunda especie (1- \(\beta\) )}{Caso 2: Relación entre los errores de primera ( \textbackslash alpha ) y segunda especie (1- \textbackslash beta )}}\label{caso-2-relaciuxf3n-entre-los-errores-de-primera-alpha-y-segunda-especie-1--beta}

La relación entre los errores de tipo I y II es más fácil de interpretar en este caso, dado que la media es un estadístico de distribución continua. En los cuadros siguientes se presentan dos regiones críticas y los errores asociados, visualizando el área que representan.

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-PlotProbsErrTipo_1_y_2} \end{center}

Aunque esta aplicación ya no está disponible en los siguientes enlaces encontraréis una versión actualizada de la misma, que permite investigar de forma interactiva la relación entre los errores de tipo I, tipo II y la potencia.

\begin{itemize}
\item
  \href{https://www.grbio.eu/statmedia/Statmedia_3/}{Error de tipo I, de tipo II y potencia en un Z-test (1 muestra normal, varianza conocida)}
\item
  \href{https://www.grbio.eu/statmedia/Statmedia_4/}{Errores de tipo I, II, potencia y p-valor en el test normal de una muestra, varianza conocida}
\end{itemize}

En el gráfico siguiente se representan los dos errores simultáneamente. Tomando siempre la misma alternativa:

\[
\mathrm{H}_{1}: \mu_{1}=8.5
\]

y para cada región crítica de la forma \([a,+\infty)\) se calculan \(\alpha\) y \(1-\beta\). En el eje de abscisas se representa el extremo inferior (a) de las regiones críticas más relevantes, las próximas a \(\mu_{0}\).

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-PlotProbsErrTipo_1_y_2b} \end{center}

\subsection{Potencia y test más potente}\label{potencia-y-test-muxe1s-potente}

La potencia de un contraste se define como:\\
\(\beta=\) prob.(aceptar \(H_{1}/H_{1}\) cierta) = prob.(muestra pertenezca a \(W_{a}/H_{1}\) cierta)\\
es, por tanto, la probabilidad complementaria al error del tipo II.\\
Retomando ideas anteriores, un contraste debe pretender un compromiso razonable entre el nivel de significación (lo más bajo posible) y la potencia (lo más alta posible).

En principio, si hay varios tests alternativos (basados en diferentes reglas de decisión y/o estadísticos) para resolver un mismo contraste paramétrico, el mejor test será aquel que, una vez fijados \(\mathrm{H}_{0}, \mathrm{H}_{1}\) y el nivel de significación \(\alpha\), proporcione la potencia más alta entre todos ellos.

Un test que tenga esta propiedad se denomina test más potente. Simbólicamente, si \(mp\) designa el test más potente, deberá cumplir:

\[
\begin{aligned}
& \beta_{m p}=\text { prob.(aceptar } \mathrm{H}_{1} \text { con el test } m p / \mathrm{H}_{1} \text { cierta) } \\
& \geq \beta_{t}=\text { prob.(aceptar } \mathrm{H}_{1} \text { con el test } t / \mathrm{H}_{1} \text { cierta) }
\end{aligned}
\]

donde \(t\) es cualquier otro test con el mismo nivel de significación que \(mp\).

\subsubsection{Caso 1: Potencia en hipótesis simple vs simple}\label{caso-1-potencia-en-hipuxf3tesis-simple-vs-simple}

En la tabla siguiente se indica la probabilidad para cada uno de los valores del soporte. Se destaca en color diferente la región crítica.

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-ProbsTestOptim} \end{center}

Se puede leer entonces que la potencia es:

\[
\beta=\operatorname{prob} .\left(\operatorname{aceptar} \mathrm{H}_{1} / \mathrm{H}_{1}\right)=\operatorname{prob} .\left(X \text { en } \mathrm{W}_{\alpha} / \mathrm{H}_{1}\right)=0.1673
\]

Simbólicamente hemos calculado:

\[
\beta=p\left(X \geq 8 / \mathrm{H}_{1}\right)=\sum_{i=8}^{10} p\left(X=i / \mathrm{H}_{1}\right)=\sum_{i=8}^{10}\binom{10}{i} 0.6^{i} 0.4^{10-i}
\]

Observamos que coincide con el cálculo anterior del error de tipo II para este ejemplo.

\subsubsection{Caso 2: Potencia en hipótesis simple vs simple}\label{caso-2-potencia-en-hipuxf3tesis-simple-vs-simple}

Hemos definido antes la región crítica para este caso. En el cuadro siguiente se pueden visualizar los dos errores (I= verde y II= naranja) y, opcionalmente, la potencia del test (región amarilla).

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-PlotProbsTestOptim} \end{center}

La definición de potencia aplicada a este caso resulta:

\[
\beta=\operatorname{prob} .\left(\operatorname{aceptar} \mathrm{H}_{1} / \mathrm{H}_{1}\right)=\operatorname{prob} .\left(X \text { en } \mathrm{W}_{\alpha} / \mathrm{H}_{1}\right)=0.80377
\]

Simbólicamente hemos calculado:

\[
\beta=p\left(\bar{X}_{16} \geq 7.9869 / H_{1}\right)=\int_{7.9869}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-8.5)^{2}}{2 \times 0.6^{2}}\right) d x
\]

En el documento interactivo se especifica la expresión para todo \(n\).

\subsection{Efecto del tamaño muestral}\label{efecto-del-tamauxf1o-muestral}

Los contrastes óptimos para las situaciones aplicadas más habituales ya están completamente resueltos, de modo que usualmente el experimentador solo debe elegir el nivel de significación que desee, (ver por ejemplo el capítulo de contrastes de una población).

Una vez elegido \(\alpha\), quedan fijadas tanto la región crítica como la potencia del contraste. La única manera de conseguir que un contraste mejore su potencia sin que repercuta en un aumento excesivo de \(\alpha\) es incrementar el tamaño muestral \(N\).

Aumentar \(N\) varía la ley de distribución del estadístico de test y generalmente disminuye su varianza. La consecuencia de mantener \(\boldsymbol{\alpha}\) constante y aumentar \(N\) se traduce en una mejora de las propiedades del test. Una pregunta crucial -abierta, de momento- es: ¿cuánta muestra hace falta?

\subsubsection{Caso 1}\label{caso-1}

En el documento interactivo se presenta un applet donde se calcula el error de tipo II cuando aumenta N. Aquí solo se presenta el gráfico donde se representan los dos errores simultáneamente para diferentes regiones críticas de la forma \(\{a, a+1, \ldots N\}\). La hipótesis alternativa está indicada en la leyenda.

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-SampleSizeEffect-1} \end{center}

\subsubsection{Caso 2}\label{caso-2}

Veremos aquí solo cómo afecta el tamaño de la muestra (para \(N=16\) y \(N=30\)) a los dos errores, manteniendo la región crítica constante. En el documento interactivo se pueden consultar otras combinaciones. Al aumentar \(N\), las distribuciones en el muestreo de la media bajo \(\mathrm{H}_{0}\) y \(\mathrm{H}_{1}\) presentan cada vez un menor solapamiento.

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-SampleSizeEffect-2} \end{center}

En el gráfico siguiente se observa el efecto de \(N\) para todo el rango de regiones críticas:

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-SampleSizeEffect-3} \end{center}

\subsection{Hipótesis simples vs.~hipótesis compuestas}\label{hipuxf3tesis-simples-vs.-hipuxf3tesis-compuestas}

Hasta ahora hemos tratado el caso más sencillo de contraste: dos hipótesis simples. En la práctica, las situaciones realmente interesantes conllevan -al menos- una hipótesis compuesta. Uno de los contrastes de hipótesis más habituales consiste en:

\[
\begin{aligned}
& \mathrm{H}_{0}: \theta=\theta_{0} \\
& \mathrm{H}_{1}: \theta \neq \theta_{0}
\end{aligned}
\]

es decir, la hipótesis alternativa es la simple negación de la nula. Este contraste se conoce como el de la alternativa bilateral.

Los conceptos de estadístico de test, de región crítica, de región de aceptación y de nivel de significación seguirán siendo los mismos. Ahora bien, como se verá a continuación, se debe ampliar la definición de potencia respecto al caso simple contra simple.

\subsubsection{Caso 1: Hipótesis compuestas}\label{caso-1-hipuxf3tesis-compuestas}

Cambiando el planteamiento inicial, supongamos que la polémica sobre la proporción de hembras en los nidos se refiere a si es equitativa o no respecto al número de machos. Las hipótesis a verificar entonces serán:

\[
\begin{aligned}
& \mathrm{H}_{0}: \mathrm{p}=0.5 \\
& \mathrm{H}_{1}: \mathrm{p} \neq 0.5
\end{aligned}
\]

Observemos primero que ya no es consistente mantener una región crítica basada solo en la cola derecha de la distribución, como en el caso simple contra simple, que en resumen consistía en:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.4444}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5556}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Regió crítica
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\mathrm{W}_{\alpha}=\{8,9,10\}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Estadístic de test & \(\mathrm{T}=\) nombre de femelles totals en els 10 nius \\
Nivell de significació & \(\alpha=0.0547\) \\
\end{longtable}

Ahora esta región ya no es adecuada. Basta con considerar el ejemplo de obtener una muestra con \(\mathrm{T}=0\). A pesar de ser sumamente improbable bajo \(\mathrm{H}_{0}\), el criterio impone aceptar la hipótesis nula, en contra de otras hipótesis más plausibles (cualquier con p \textless{} 0.5).

El sentido común indica que la región crítica debe abarcar ahora ambos extremos del soporte. Si tomamos por ejemplo:

\[
\mathrm{W}_{\alpha}=\{0,1,2,8,9,10\}
\]

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-RCSimpleVsComposta} \end{center}

la suma siguiente (que corresponde a los valores destacados en la tabla):

\[
\begin{aligned}
\alpha & =p\left(X \leq 2 / H_{0}\right)+p\left(X \geq 8 / H_{0}\right)=\sum_{i=0}^{2} p\left(X=i / H_{0}\right)+\sum_{i=8}^{10} p\left(X=i / H_{0}\right) \\
& =\left[\binom{10}{0}+\binom{10}{1}+\binom{10}{2}+\binom{10}{8}+\binom{10}{9}+\binom{10}{10}\right] 0.5^{10}
\end{aligned}
\]

nos proporciona el nivel de significación de este test bilateral.

\subsubsection{Caso 2: Hipótesis compuestas}\label{caso-2-hipuxf3tesis-compuestas}

A pesar de que seguramente todavía no es el contraste de hipótesis que realmente interesa a la asociación ADG, por razones didácticas supondremos que se pretende dirimir simplemente si es aceptable la media propuesta en la bibliografía. Las hipótesis que hay que verificar entonces serán:

\[
\begin{aligned}
& H_{0}: \mu=7 \\
& H_{1}: \mu \neq 7
\end{aligned}
\]

Ya no es consistente mantener una región crítica basada solo en la cola derecha de la distribución, como en el planteamiento original de este caso (que contrastaba una hipótesis simple contra otra simple).

Para entenderlo se puede considerar por ejemplo una muestra con una media muestral de 5. A pesar de ser sumamente improbable bajo \(\mathrm{H}_{0}\), dado que pertenece a la región de aceptación, el criterio impone aceptar la hipótesis nula, en contra de otras hipótesis más plausibles (cualquiera con \(\mu<7\)).

Nuevamente, el sentido común indica que la región crítica debe abarcar ahora ambos extremos del soporte. Si tomamos por ejemplo:

\[
\mathrm{W}_{\alpha}=(-\infty, 6.0131] \mathrm{U}[7.9869,+\infty)
\]

Se obtiene \(\alpha=0.1\). En el cuadro siguiente se visualiza la región crítica y se evalúa el nivel de significación resultante:

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-RCHipotesisComposta} \end{center}

Simbólicamente, el nivel de significación de este test se calcula de la siguiente forma:

\[
\begin{aligned}
\alpha & =p\left(\bar{X}_{16} \leq 6.0131 / H_{0}\right)+p\left(\bar{X}_{16} \geq 7.9869 / H_{0}\right) \\
& =\int_{-\infty}^{6.0131} f_{\bar{X}_{16}}(x) d x+\int_{7.9869}^{\infty} f_{\bar{X}_{16}}(x) d x \\
& =F_{Z}\left(\frac{6.0131-7}{2.4 / \sqrt{16}}\right)+1-F_{z}\left(\frac{7.9869-7}{2.4 / \sqrt{16}}\right)
\end{aligned}
\]

Donde:

\[
f_{\bar{X}_{16}}(x)=\frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right)
\]

\subsection{Función de potencia}\label{funciuxf3n-de-potencia}

Una de las diferencias conceptuales más importantes entre el caso de una hipótesis simple contra otra simple y el caso con una alternativa compuesta se encuentra en la definición de potencia. En este segundo caso ya no se presenta un único posible valor del parámetro bajo la hipótesis alternativa, sino que se contempla todo un conjunto. En la mayoría de tests habituales, será un intervalo real o una unión de intervalos reales. Por ejemplo:

\[
\mathrm{H}_{1}: \theta \neq \theta_{0}
\]

Desde el punto de vista de la estadística paramétrica clásica, una vez hecho el experimento aleatorio, \(\theta\) presenta solo uno de los posibles valores dentro del subconjunto de la alternativa, aunque éste sea desconocido. Por tanto, la definición de potencia enunciada antes:

\[
\beta=\operatorname{prob} .\left(\operatorname{aceptar} \mathrm{H}_{1} / \mathrm{H}_{1}\right. \text { cierta) }
\]

no se puede calcular globalmente para toda \(\mathrm{H}_{1}\), sino que se debe distinguir cada uno de los valores posibles dentro de \(\mathrm{H}_{1}\). De ahí el interés de definir la función de potencia:

\[
\beta(\theta)=\operatorname{prob}\left(\operatorname{aceptar} \mathrm{H}_{1} / \theta \text { cierto }\right)
\]

donde \(\theta\) es un valor cualquiera del parámetro, incluso valores correspondientes a \(\mathrm{H}_{0}\). Si \(\mathrm{H}_{0}\) es simple (un solo parámetro \(\theta_{0}\)), resultará:

\[
\beta\left(\theta_{0}\right)=\operatorname{prob}\left(\operatorname{aceptar} \mathrm{H}_{1} / \theta_{0} \text { cierto }\right)=\alpha
\]

\subsubsection{Caso 1: Función de potencia}\label{caso-1-funciuxf3n-de-potencia}

Ahora la potencia depende de la proporción concreta de hembras que se elija como alternativa. La expresión general es:

\[
1-\beta=p\left(3 \leq X \leq 7 / H_{1}\right)=\sum_{i=3}^{7} p\left(X=i / H_{1}\right)=\sum_{i=3}^{7}\binom{10}{i} p^{i}(1-p)^{10-i}
\]

dado que la región crítica es \(\mathrm{W}_{\alpha}=\{0,1,2,8,9,10\}\). En los cuadros siguientes se obtiene el valor de la potencia \((\beta)\) inicialmente para \(p=0.6\) y para \(p=0.8\) (en el documento interactivo se puede variar arbitrariamente la proporción bajo \(\mathrm{H}_{1}\)):

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-comparaProbs} \end{center}

En el gráfico siguiente se representa la función de potencia para todo el rango de parámetros:

\begin{center}\includegraphics[width=0.6\linewidth]{images/cap9-FuncPotencia1} \end{center}

\subsubsection{Caso 2: Función de potencia}\label{caso-2-funciuxf3n-de-potencia}

Ahora la potencia depende de la media concreta \(\mu_{1}\) que se elija como alternativa. La expresión general del error de tipo II es:

\[
\begin{aligned}
1-\beta & =p\left(6.0131 \leq \bar{X}_{16} \leq 7.9869 / H_{1}\right) \\
& =\int_{6.0131}^{7.9869} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{\left(x-\mu_{1}\right)^{2}}{2 \times 0.6^{2}}\right) d x \\
& =F_{z}\left(\frac{6.0131-\mu_{1}}{2.4 / \sqrt{16}}\right)+1-F_{z}\left(\frac{7.9869-\mu_{1}}{2.4 / \sqrt{16}}\right)
\end{aligned}
\]

dado que la región crítica es \(\mathrm{W}_{\alpha}=(-\infty, 6,0131] \mathrm{U}[7,9869,+\infty)\).\\
En el cuadro siguiente se obtiene el valor de la potencia ( \(\beta\) ) inicialmente para \(\mu=8.5\).

En el documento interactivo representado en la imagen puede cambiar el valor de la alternativa y observar los cambios en los dos errores y en la potencia:

\begin{center}\includegraphics[width=0.6\linewidth]{images/cap9-FuncPotencia2} \end{center}

En el gráfico siguiente se representan dos funciones de potencia, para \(\alpha=0.05, \sigma=\) 2.4 y que respectivamente corresponden a \(n=16\) (la situación de este caso 2) y a \(n=1\).
En el documento interactivo representado en la imagen se pueden variar todos aquellos parámetros que afectan a \(\beta: \alpha, \sigma y n\) y compararlos con la situación original.

\begin{center}\includegraphics[width=0.6\linewidth]{images/cap9-FuncPotencia3} \end{center}

\subsection{Tests óptimos}\label{tests-uxf3ptimos}

En muchas situaciones aplicadas se pueden plantear diferentes reglas de decisión para resolver un mismo contraste, de modo que proporcionen un mismo error de tipo I. Es necesario entonces adoptar un criterio adicional para escoger cuál es el mejor test posible para resolver este contraste. Tal como hemos visto en el caso de hipótesis simple vs.~simple, esto ocurre forzosamente por analizar el error de tipo II asociado a cada test. En el caso de una alternativa compuesta, esto lleva a estudiar el comportamiento de la función de potencia en todo el rango de parámetros asociados a la alternativa.

El estudio de los tests que presentan propiedades óptimas desde el punto de vista de la potencia sobrepasa los objetivos marcados por este curso El lector interesado puede consultar alguna definición más en los complementos, aunque esta información no es estrictamente necesaria para seguir ni el resto de este tema ni los ulteriores. En los próximos capítulos solo se señalará, a título informativo, cuándo un test es óptimo desde el punto de vista de la potencia. En nuestro desarrollo es suficiente conocer que existen resultados generales en estadística matemática que permiten asegurar cuándo existe este tipo de test y cómo obtenerlo.

\subsection{Pruebas bilaterales y pruebas unilaterales}\label{pruebas-bilaterales-y-pruebas-unilaterales}

Un contraste bilateral adopta en general la forma:

\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta \neq \theta_{0}
\]

En determinadas ocasiones el experimentador prefiere plantear directamente un contraste de la forma:

\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta>\theta_{0}
\]

conocido como contraste unilateral derecho. Obviamente, otra posibilidad es el unilateral izquierdo:

\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta<\theta_{0}
\]

En estos tres casos, el contraste de hipótesis es simple contra compuesta. En la mayoría de situaciones aplicadas, en realidad se pretenden resolver contrastes unilaterales que conllevan hipótesis compuestas. El unilateral derecho es entonces:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\linewidth - 6\tabcolsep) * \real{0.2500}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\mathrm{H}_{0}: \theta \leq \theta_{0}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
contra
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\mathrm{H}_{1}: \theta>\theta_{0}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
el izquierdo es: & \(\mathrm{H}_{0}: \theta \geq \theta_{0}\) & contra & \(\mathrm{H}_{1}: \theta<\theta_{0}\) \\
\end{longtable}

Aunque esta última formulación está relacionada con los contrastes unilaterales simple contra compuesta anteriores, las dos hipótesis no son técnicamente equivalentes. A fin de simplificar la interpretación de los contrastes unilaterales, atendiendo a los casos que se tratan en este curso, se formulan los contrastes de esta última manera (compuesta contra compuesta) y se toma el nivel de significación como si fuera el del contraste simple contra compuesta.

En cualquier caso, es importante entender que solo se ha resuelto uno de los tres contrastes (bilateral o unilateral) con un conjunto de datos concreto. Por ejemplo, es incorrecto desde el punto de vista metodológico comenzar contrastando bilateralmente y hacer después un test unilateral. El contraste que se debe emplear debe decidirse con base en conocimientos previos del problema, o bien siguiendo la cuestión de interés aplicado que se quiere responder.

\subsubsection{Caso 1: Prueba unilateral}\label{caso-1-prueba-unilateral}

Supongamos que la controversia entre los dos ornitólogos se hubiera planteado originalmente en los siguientes términos. Según da Souza, el número de hembras por nido es como máximo del 50\%. En cambio, para Calves, hay más hembras que machos. El contraste que hay que resolver para dirimir cuál de los dos especialistas tiene razón sería, pues:

\[
\begin{aligned}
& \mathrm{H}_{0}: \mathrm{p} \leq 0.5 \\
& \mathrm{H}_{1}: \mathrm{p}>0.5
\end{aligned}
\]

Respecto al caso general se sustituye el parámetro genérico \(\theta\) por p, y el valor \(\theta_{0}=0.5\). Tomando la región crítica como \(\mathrm{W}_{\alpha}=\{8,9,10\}\), en el cuadro siguiente se presenta el nivel de significación:

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-comparaProbs} \end{center}

\subsubsection{Caso 2: Prueba unilateral}\label{caso-2-prueba-unilateral}

El planteamiento siguiente se aproxima más a lo que realmente debería intentar aclarar la asociación de deportistas ADG. Si hacen caso a la fuerte sospecha de que la tasa de statdrolona ha aumentado, es más coherente plantear las siguientes hipótesis:

\[
\begin{aligned}
& \mathrm{H}_{0}: \mu \leq 7 \\
& \mathrm{H}_{1}: \mu>7
\end{aligned}
\]

Tal como ya se ha planteado en el caso 1, ahora se debe considerar una región crítica basada en la cola derecha de la distribución. Se deja al lector razonar por qué debe ser así. Cuando se toma, por ejemplo:

\[
\mathrm{W}_{\alpha}=[7,9869,+\infty)
\]

se obtiene \(\alpha=0.05\). En el cuadro siguiente se presenta la región crítica (en el documento interactivo se puede variar la región crítica y modificar por tanto el nivel de significación):

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-RCHipotesisComposta2} \end{center}

Simbólicamente, se calcula:

\[
\alpha=p\left(\bar{X}_{16} \geq 7.9869 / H_{0}\right)=\int_{7.9869}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right) d x=\\ = 1-F_{z}\left(\frac{7.9869-7}{2.4 / \sqrt{16}}\right)
\]

que nos proporciona el nivel de significación de este test unilateral. Así pues, no hay ninguna diferencia ni en el cálculo ni en el gráfico respecto a lo ya visto en el apartado de hipótesis simple contra simple. En relación con la potencia, se trata de una función que depende de la \(\mu\) concreta de la hipótesis alternativa (simple), y por esta razón resulta:

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-PotenciaHipotesisComposta} \end{center}

Una observación final referente a este caso 2. En el planteamiento actual solo queda ya la arbitrariedad consistente en asumir una \(\sigma=2.4\) poblacional fija. En el tema \(10\), se estudiará cómo abordar este estudio sin asumir más condición que el modelo de probabilidad Normal.

\subsection{Elección del nivel de significación}\label{elecciuxf3n-del-nivel-de-significaciuxf3n}

¿Qué nivel de significación se debe utilizar? En contra de cierta práctica estadística, desgraciadamente bastante extendida, en realidad no se puede responder a esta pregunta dando simplemente un valor al nivel de significación. Si se consultan publicaciones científicas aplicadas para conocer qué \(\alpha\) usar, en la mayoría de estudios se obtendrá que el más utilizado es \(\alpha=0.05\) (5\% de error), siendo el segundo lugar ex aequo \(\alpha=0.01\) (1\%) y \(\alpha=0.1\) (10\%). Estos son los niveles aconsejados en muchos textos elementales de estadística. Veamos por qué se han aconsejado estos valores.

Antes de la universalización del uso del ordenador, los cálculos estadísticos se completaban mediante diferentes tablas para encontrar las fronteras de la región crítica y decidir qué hipótesis aceptar. Los valores 5\%, 1\% y 10\% fueron inicialmente elegidos como los más representativos en las colecciones de tablas, ya que no resultaba práctico publicar tablas para cualquier \(\alpha\). Así, estos valores se fueron convirtiendo, con el paso del tiempo, en un convencionalismo más. Se ha llegado a producir el efecto perverso, en algunos campos del conocimiento, de que algunos editores mal informados solo aceptan trabajos con un 5\% de significación.

No obstante, no hay ninguna razón científica que indique que estos valores son forzosamente los más adecuados. Ya hemos visto que la potencia tiene también una importancia capital cuando hay que calificar la bondad del test, sin olvidar la influencia que tiene el tamaño de la muestra sobre \(1-\beta\). La metodología más razonable es obtener el p-valor y, si es posible, definir antes de la obtención de la muestra una diferencia mínima significativa que garantice la potencia deseada (definiremos a continuación estos dos conceptos). Solo con estas tres cantidades el contraste queda satisfactoriamente planteado.

Desde nuestro punto de vista, hoy en día, exponer las conclusiones de cualquier estudio solo a partir de un nivel de significación fijo para todos los contrastes es un procedimiento estadístico muy rudimentario.

\subsection{El p-valor}\label{el-p-valor}

La elección del nivel de significación, tal como se ha comentado anteriormente, es en cierta manera arbitraria. Sin embargo, una vez obtenida la muestra, se puede calcular una cantidad que sí permite resumir el resultado del experimento de manera objetiva. Esta cantidad es el p-valor, que corresponde al nivel de significación más pequeño posible que se puede elegir, para el cual todavía se aceptaría la hipótesis alternativa con las observaciones actuales. Cualquier nivel de significación elegido inferior al p-valor (simbólicamente \(\mathrm{p}_{\mathrm{v}}\)) conlleva aceptar \(\mathrm{H}_{0}\). Obviamente, como es una probabilidad, se cumple que:

\[
0 \leq p_{v} \leq 1
\]

El p-valor es una medida directa de lo inverosímil que resulta obtener una muestra como la actual si es cierta \(\mathrm{H}_{0}\). Los valores pequeños indican que es muy infrecuente obtener una muestra como la actual, en cambio, los valores altos muestran que es frecuente. El p-valor se utiliza para indicar cuánto (o cuán poco) contradice la muestra actual la hipótesis alternativa.

Informar sobre cuál es el p-valor tiene la ventaja de permitir que cualquiera decida qué hipótesis acepta basándose en su propio nivel de riesgo \(\boldsymbol{\alpha}\). Esto no es posible cuando se informa, como ha sido tradicional, indicando solo el resultado de la decisión, es decir, aceptando o rechazando \(\mathrm{H}_{0}\) con un \(\alpha\) fijo.

Cuando se proporciona el p-valor obtenido con la muestra actual, la decisión se hace según la siguiente regla:

\[
\begin{aligned}
& \text { si } \mathrm{p}_{\mathrm{v}} \leq \alpha, \text { aceptar } \mathrm{H}_{1} \\
& \text { si } \mathrm{p}_{\mathrm{v}}>\alpha, \text { aceptar } \mathrm{H}_{0}
\end{aligned}
\]

Desde el punto de vista práctico, algunos paquetes estadísticos proporcionan en sus listados el ``significance level'', cuya traducción literal es ``nivel de significación'', cuando en muchas ocasiones se refieren en realidad al p-valor (``p-value'').

\subsubsection{Caso 1: Cálculo del p-valor (prueba unilateral)}\label{caso-1-cuxe1lculo-del-p-valor-prueba-unilateral}

Sigamos con la hipótesis unilateral:

\[
\begin{aligned}
& H_{0}: p \leq 0.5 \\
& H_{1}: p>0.5
\end{aligned}
\]

Supongamos que, una vez obtenida la muestra de \(n=10\) nidos, resulta que en seis de ellos el polluelo corresponde a una hembra. Hay que recordar primeramente que en este caso el estadístico de test T es una variable discreta, y por lo tanto no es posible obtener cualquier \(\alpha\).

El p-valor es el menor \(\alpha\) que permite aceptar \(\mathrm{H}_{1}\). Con la tabla siguiente:

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-comparaProbs} \end{center}

Se obtiene el p-valor asociado a \(\mathrm{T}=6\) hembras. Consideremos principalmente los siguientes casos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Si se escogiera \(\alpha=0.1719\), la región crítica correspondiente sería \(\mathrm{W}_{\alpha}=\{7,8,9,10\}\). Como no se incluyen 6 hembras, habría que aceptar \(H_{0}\). Por tanto, \(\alpha\) no cumple la definición de p-valor, ya que se debe rechazar \(\mathrm{H}_{0}\): \(\mathrm{p}_{\mathrm{v}}\) debe ser forzosamente mayor.
\item
  Si se eligiera \(\alpha^{\prime}=0.3770\), la región crítica correspondiente sería \(W_{\alpha^{\prime}}=\{6,7,8,9,10\}\). Con \(\alpha^{\prime}\) se rechazaría \(H_{0}\).
\item
  Si se seleccionara \(\alpha^{\prime\prime}=0.6230\), la región crítica correspondiente sería \(\mathrm{W}_{\alpha^{\prime\prime}}=\{5,6,7,8,9,10\}\). Con \(\alpha^{\prime\prime}\) también se rechazaría \(\mathrm{H}_{0}\).
\end{enumerate}

Observamos que \(\alpha^{\prime}<\alpha^{\prime\prime}\), y entre los dos valores no es posible obtener ningún otro nivel de significación con el test que hemos planteado. Por tanto, \(\alpha^{\prime}\) es el nivel de significación mínimo con el que rechazaríamos \(H_{0}\) con la muestra actual o, dicho de otro modo, \(\alpha^{\prime}\) es el p-valor.

Este es el detalle de cómo se calcula el p-valor. Usualmente, de esto se encarga software especializado (un paquete estadístico, una hoja de cálculo,\ldots), que devuelve simplemente la información \(\mathrm{p}_{\mathrm{v}}=0.3770\). Ahora bien, lo que no resuelve el programa es qué debe decidir finalmente el experimentador, es decir, en nuestro caso, da Souza o Calves.

Pues bien, en este momento, se deberá comparar \(\mathrm{p}_{\mathrm{v}}\) con el nivel de significación elegido a priori (por ejemplo, \(\alpha=0.05\)):

\[
\mathrm{p}_{\mathrm{v}}=0.3770>\alpha=0.05 \text { por tanto, aceptar } \mathbf{H}_{\mathbf{0}}.
\]

El valor de \(p_{v}\) indica que hay una frecuencia del 37.7\% de obtener muestras con T \(\geq 6\) hembras bajo \(\mathrm{H}_{0}\) y, por tanto, que no hay indicios suficientes de discrepancia entre la muestra obtenida y la hipótesis de da Souza consistente en que \(\mathrm{p} \leq 0.5\).

Una vez más, hay que insistir en que \(\mathrm{p}_{\mathrm{v}}\) es un valor objetivo -cualquier experimentador dará el mismo valor una vez obtenida la muestra-, mientras que \(\alpha\) es subjetivo, elegido por el experimentador según su experiencia.

\subsubsection{Caso 2: Cálculo del p-valor (prueba unilateral)}\label{caso-2-cuxe1lculo-del-p-valor-prueba-unilateral}

Consideremos primero el cálculo del p-valor cuando las hipótesis son:

\[
\mathrm{H}_{0}: \mu \leq 7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu>7
\]

En el cuadro siguiente se presentan los datos obtenidos en el experimento, su media y la desviación estándar corregida, así como el p-valor y la decisión final según el nivel de significación 0.05. Como \(\mathrm{T}=8.54\), el p-valor corresponde a la cola de la curva Normal situada a la derecha de T. En el gráfico se superpone el color rojo del p-valor al verde de la zona correspondiente a \(\alpha\) en la parte más extrema de la cola.

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-CalculPvalorUnilateral} \end{center}

Así pues, se rechaza \(\mathbf{H}_{0}\), ya que \(\alpha=0.05>\mathrm{p}_{\mathrm{v}}=0.00513\). En el documento interactivo es posible elegir otros niveles de significación. Según el nivel elegido se aceptará o rechazará la hipótesis nula.

El cuadro anterior ilustra la relación entre los conceptos del p-valor y del nivel de significación, ahora bien, el lector NO debe extraer la conclusión de que debe ajustar \(\alpha\) en ningún sentido: \(\alpha\) se elige siempre a priori (antes del análisis), nunca en función de los datos (o del p-valor). Respecto al cálculo simbólico del p-valor, en el ejemplo se ajusta a la expresión siguiente:

\[
\begin{aligned}
p v & =p\left(\bar{X}_{16} \geq 8.54 / H_{0}\right) \\
& =\int_{8.54}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right) d x \\
& =1-F_{z}\left(\frac{8.54-7}{0.6}\right)=0.0513
\end{aligned}
\]

En el documento interactivo se pueden cambiar los datos de los dieciséis atletas, lo que permite resolver algunas de las cuestiones planteadas más adelante. Alternativamente al p-valor, también se puede visualizar la potencia o el error de tipo II.

\subsubsection{Caso 2: Cálculo del p-valor (prueba bilateral)}\label{caso-2-cuxe1lculo-del-p-valor-prueba-bilateral}

Consideremos ahora el cálculo del p-valor cuando las hipótesis son:

\[
\mathrm{H}_{0}: \mu=7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq 7
\]

El p-valor corresponde ahora a dos colas de la curva Normal: una es la misma que en el caso unilateral, es decir, la situada a la derecha de \(\mathrm{T}=8.54\), la segunda es la cola simétrica a la anterior respecto a \(\mu=7\), es decir, la cola izquierda situada en \(2 \mu-\mathrm{T}=5.46\). Como antes, en el cuadro se superpone el color rojo del p-valor al verde de la zona correspondiente a \(\alpha\) en la parte más extrema de las dos colas. En el documento interactivo se pueden cambiar datos, el nivel de significación y el punto donde se calcula la potencia.

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-CalculPvalorBilateral} \end{center}

El cálculo del p-valor se corresponde, con los datos originales, a:

\[
\begin{aligned}
p v & =p\left(\bar{X}_{16} \leq 5.46 / H_{0}\right)+p\left(\bar{X}_{16} \geq 8.54 / H_{0}\right) \\
& =\int_{-\infty}^{5.46} f_{\bar{X}_{16}}(x) d x+\int_{8.54}^{\infty} f_{\bar{X}_{16}}(x) d x \\
& =2 p\left(\bar{X}_{16} \geq 8.54 / H_{0}\right)=.01027
\end{aligned}
\]

Así pues, se rechaza \(\mathbf{H}_{\mathbf{0}}\), puesto que:

\[
\alpha=0.05>\mathrm{pv}=0.01027
\]

En general, si la distribución del estadístico es continua, como en este caso, se puede calcular fácilmente el p-valor de la prueba bilateral a partir de la unilateral, y viceversa. Así, si designamos con \(\mathrm{p}_{uni}\) y \(\mathrm{p}_{bil}\), respectivamente, los p-valores de la prueba unilateral y bilateral, tendremos que:

\begin{itemize}
\tightlist
\item
  Si \(\mathrm{p}_{uni} \leq 0.5\), entonces \(\mathrm{p}_{bil}=2 \mathrm{p}_{uni}\). Es decir, el p-valor es exactamente el doble que el de la prueba unilateral.
\item
  Si \(\mathrm{p}_{uni}>0.5\), entonces \(\mathrm{p}_{bil}=2(1-\mathrm{p}_{uni})\). Es decir, el p-valor es exactamente el doble que el complementario del p-valor de la prueba unilateral.
\end{itemize}

\subsection{Pruebas exactas y pruebas asintóticas}\label{pruebas-exactas-y-pruebas-asintuxf3ticas}

Los dos errores ( \(\alpha\) y \(1-\beta\) ) implicados en cualquier contraste son probabilidades que se basan en hipótesis sobre el parámetro que queremos contrastar. De manera similar a los intervalos de confianza (véase, por ejemplo, los intervalos para una proporción y para la media de una Normal), se pueden clasificar los tests en relación con la distribución empleada.

Si se puede establecer explícitamente para cualquier tamaño de muestra \(N\) qué distribución tiene el estadístico de test, y además es factible el cálculo de los errores, se obtendrá una fórmula válida para todo \(N\). Este es el caso de los dos ejemplos seguidos en este capítulo. Un test con estas características se denomina prueba exacta. La prueba t de Student para dos muestras y la prueba F de comparación de varianzas son ejemplos de uso cotidiano en experimentos reales.

En otros casos, cuando existe dificultad para resolver el cálculo de los errores con la verdadera distribución del estadístico, se recurre a las propiedades en el límite de las distribuciones. Un recurso habitual es aplicar el teorema central del límite si la distribución del estadístico tiende a una Normal. En este segundo caso, el test obtenido solo será válido para valores grandes de \(N\), y entonces se denomina prueba asintótica. Los ejemplos más conocidos son las diferentes pruebas de Ji-cuadrado.

\subsubsection{Caso 1: Test asintótico}\label{caso-1-test-asintuxf3tico}

Hasta el momento nos hemos basado para resolver los contrastes en la distribución exacta del estadístico \(T=\) número de hembras en diez nidos, que es una Binomial \((n, p)\), con \(n=10\) y \(p\) desconocida. La distribución exacta de T nos permite calcular p-valores, potencias, etc. para cualquier tamaño de muestra \(n\). No obstante, los cálculos con la distribución Binomial se pueden aproximar mediante la distribución Normal a partir de tamaños de muestra de treinta o mayores. La distribución asintótica de \(T\) es:

\[
T \approx N(n p, \sqrt{n p(1-p)})
\]

Por ejemplo, si se pretende contrastar:

\[
\begin{aligned}
& H_{0}: p=0.5 \\
& H_{1}: p \neq 0.5
\end{aligned}
\]

con \(n=36\), bajo \(\mathrm{H}_{0} T\) será aproximadamente \(N(18,3)\). En el documento interactivo se presenta un cuadro donde podemos comprobar las diferencias entre el p-valor exacto y el p-valor según la distribución asintótica para diferentes \(n\) y diferentes valores de T. Por ejemplo, para \(n=36\) y 28 hembras las diferencias son:

\[
\mathrm{p}_{\mathrm{v}}\text{ exacto }-\mathrm{p}_{\mathrm{v}}\text{ asintótico }=0.00119-0.00085<0.004
\]

¿Qué interés tiene entonces la distribución asintótica si conocemos la exacta? La ventaja se sitúa en el terreno del cálculo: la distribución Normal es más fácil de usar computacionalmente tanto si se evalúa mediante tablas (y calculadora) como si se evalúa con el ordenador. En cambio, la fórmula de la densidad Binomial conlleva dificultades operativas con los factoriales cuando \(n>30\).

\subsubsection{Caso 2: Test exacto}\label{caso-2-test-exacto}

Ya se ha analizado anteriormente con detalle la distribución de la media de \(n\) atletas cuando la variable observada es una Normal. En resumen, la densidad obtenida es una Normal de parámetros:

\[
\bar{X}_{n} \approx N(\mu, 2.4 / \sqrt{n})
\]

Por lo tanto, mediante esta distribución exacta del estadístico para cualquier tamaño de la muestra, se puede plantear sin la necesidad de aproximar a ninguna otra distribución el cálculo del p-valor, de la potencia, etc.

\subsection{Relación con los intervalos de confianza}\label{relaciuxf3n-con-los-intervalos-de-confianza}

Los contrastes de hipótesis están muy relacionados con la teoría de los intervalos de confianza. En muchos casos se puede resolver la misma cuestión aplicada formulándola por cualquiera de las dos vías. Por ejemplo, el contraste:

\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta \neq \theta_{0}
\]

se puede resolver planteando el intervalo de confianza para \(\theta\), con coeficiente de confianza \(1-\alpha\). Supongamos que el intervalo obtenido es \([a ; b]\). Entonces, si:

\[
\begin{aligned}
& \text { si } \theta_{0} \in[a ; b] \text { aceptar } \mathrm{H}_{0} \\
& \text { si } \theta_{0} \notin[a ; b] \text { aceptar } \mathrm{H}_{1}
\end{aligned}
\]

Este contraste tendrá como nivel de significación \(\alpha\). Es posible proporcionar incluso el p-valor si se ajusta la anchura del intervalo para que sea el más amplio posible y a la vez excluya \(\theta_{0}\).

Inversamente, es posible utilizar la región crítica de un contraste para proporcionar una estimación por intervalo del parámetro. Los contrastes bilaterales corresponden a intervalos también bilaterales centrados, mientras que los contrastes unilaterales derechos corresponden a estimaciones unilaterales por exceso y los unilaterales izquierdos, a estimaciones por defecto.

\subsubsection{Caso 2: Relación con los intervalos de confianza}\label{caso-2-relaciuxf3n-con-los-intervalos-de-confianza}

En el tema anterior se ha estudiado el intervalo de confianza para la media de una distribución Normal. Continuando con las premisas que se han seguido hasta ahora en el caso de la statdrolona, deberemos considerar el intervalo para la medida cuando la varianza es conocida.

\[
\bar{X}_{16}-z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_{16}+z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}
\]

Si tomamos como nivel de confianza \(1-\alpha=0.95\), con los datos obtenidos resulta:

\[
8.54-1.959 \frac{2.4}{\sqrt{16}} \leq \mu \leq 8.54+1.959 \frac{2.4}{\sqrt{16}}
\]

Es decir, se obtiene el intervalo \([\mathbf{7 , 3 6 4 6};9.7154]\). Atendiendo a que la media bajo la hipótesis nula es \(\mu=7\), y que no está incluida en el intervalo anterior, se rechaza la hipótesis nula: la media es significativamente diferente de 7. Es la misma conclusión que la que hemos obtenido en el contraste bilateral anterior. Además, dado que se ha calculado un intervalo bilateral, la hipótesis alternativa correspondiente a este intervalo es también bilateral.

\subsection{Tamaños de muestra. Diferencia mínima significativa}\label{tamauxf1os-de-muestra.-diferencia-muxednima-significativa}

Una de las preguntas más frecuentes en estadística aplicada se refiere a cuál es el tamaño muestral más adecuado. En primer lugar, si la prueba es asintótica, \(N\) debe ser suficientemente grande para que la distribución del estadístico bajo la hipótesis nula esté bien aproximada. En el caso de las aproximaciones normales, valores \(N \geq 30\) son usualmente aceptados. Esta consideración no se aplica si la prueba es exacta.

El segundo aspecto que hay que considerar se refiere a la potencia deseada en el contraste. Pero la potencia varía en función del parámetro en los contrastes con alternativa compuesta, así que, para formular correctamente el problema, el experimentador debe proporcionar una cantidad adicional: la diferencia mínima significativa \(\Delta\).

Para abreviar, ahora se detalla solo el contraste \(\mathrm{H}_{0}: \theta=\theta_{0}\) contra \(\mathrm{H}_{0}: \theta \neq \theta_{0}\), pero la base conceptual es parecida para las alternativas unilaterales.

El significado de \(\Delta\) es entonces el siguiente: el experimentador considera que no es importante en la práctica equivocarse aceptando la hipótesis nula (es decir, cometer un error de tipo II) en el rango de alternativas situadas en el intervalo \((\theta_{0}-\Delta ; \theta_{0}+\Delta)\). En cambio, \(\theta_{0} \pm \Delta\) son los dos primeros puntos, a medida que \(\theta\) se aleja de la hipótesis nula, que el experimentador considera importante diferenciar de \(\theta_{0}\). Es justamente en estos dos puntos donde se ajusta el tamaño de la muestra para garantizar la potencia deseada. Lógicamente, la potencia será todavía más alta si la alternativa finalmente cierta está aún a mayor distancia que \(\Delta\).

La elección concreta del valor de \(\Delta\) depende de cada situación aplicada, pero en cualquier caso es una cantidad elegida por el experimentador, no dictada por una regla estadística.

Una vez elegidos \(\Delta\) y la potencia deseada en ese punto, es posible indicar cuál es el tamaño mínimo de la muestra para resolver adecuadamente el problema. En algunos casos requerirá un experimento piloto antes de proceder con el experimento definitivo.

\subsubsection{Caso 2: Cálculo del tamaño de la muestra}\label{caso-2-cuxe1lculo-del-tamauxf1o-de-la-muestra}

El estadístico de test de este caso (la media de los atletas) tiene una distribución exacta conocida para todo \(n\) que se ha descrito anteriormente. Por lo tanto, aquí el experimentador debe elegir la diferencia mínima significativa (\(\boldsymbol{\Delta}\)) y la potencia (\(\boldsymbol{\beta}\)) para determinar el tamaño de la muestra adecuado. Supongamos que se quiere hacer el contraste bilateral:

\[
\mathrm{H}_{0}: \mu=7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq 7
\]

con las condiciones siguientes del experimento fijadas:

\[
\alpha=5 \% \quad \beta=90 \% \quad \Delta=0.8 \mathrm{ng} / \mathrm{ml}
\]

Dicho de otro modo, se pretende obtener una potencia del 90\% en los puntos:

\[
\mu_{0}-\Delta=6.2 \quad \mu_{0}+\Delta=7.8
\]

Estos son los dos primeros valores (menor y mayor que \(\mu_{0}=7\), respectivamente) que el experimentador no quiere que se confundan con \(\mathrm{H}_{0}\), excepto con un error del 10\%. Por tanto, se debe aislar el valor de \(n\) que cumpla las siguientes condiciones simultáneamente:

\[
\left\{\begin{array}{l}
p\left(\left|\bar{X}_{n}-\mu\right| \sqrt{n} / \sigma \geq z_{\alpha / 2} / \mathrm{H}_{0}\right)=\alpha \\
p\left(\left|\bar{X}_{n}-\mu\right| \sqrt{n} / \sigma \geq z_{\alpha / 2} / \mathrm{H}_{1 \Delta}\right)=\beta
\end{array}\right.
\]

\(\mathrm{H}_{1 \Delta}\) corresponde a la hipótesis simple \(\mu=\mu_{0}+\Delta\) (7.8 en el ejemplo). Atendiendo a la distribución de la media de \(n\) atletas bajo cada una de las hipótesis, la única incógnita es \(n\). Las constantes \(z_{\alpha / 2}\) y \(z_{1-\beta}\) corresponden a las colas derechas siguientes de la variable aleatoria Normal tipificada Z:

\[
p\left(Z \geq z_{\alpha / 2}\right)=\alpha / 2 \quad p\left(Z \geq z_{1-\beta}\right)=1-\beta
\]

Cuando se resuelve el sistema de ecuaciones anterior se obtiene la fórmula que proporciona el tamaño deseado:

\[
n=\left\{\frac{\sigma\left(z_{1-\beta}+z_{\alpha / 2}\right)}{\Delta}\right\}^{2}
\]

Sustituyendo por los valores concretos del ejemplo:

\[
n=\{2.4(1.645+1.960)/0.8\}^{2}=116.964
\]

Redondeando, el tamaño debe ser de 117 atletas. En el cuadro siguiente se muestra el tamaño de la muestra en función de la diferencia mínima significativa deseada, junto con otros parámetros que afectan el problema:

\begin{center}\includegraphics[width=0.9\linewidth]{images/cap9-SampleSize_i_MDS} \end{center}

Para los valores extremos de \(\alpha(0)\) y de \(\beta(1)\), el valor del tamaño de la muestra se hace infinito y no se puede representar en el cuadro anterior.

\subsection{Esquema de un contraste correctamente planteado}\label{esquema-de-un-contraste-correctamente-planteado}

Los conceptos expuestos hasta aquí son esenciales para entender qué es un contraste estadístico de hipótesis y poder aplicar correctamente los diferentes tests que se detallarán en próximos capítulos. En la práctica, y para la tranquilidad del experimentador, normalmente solo hay que preocuparse de identificar el problema que hay que resolver (contraste sobre una, dos o más poblaciones), la familia de distribución y finalmente aplicar tests ya deducidos, algunos casi centenarios. Ahora bien, el experimentador debe elegir las tres cantidades siguientes:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
1) nivel de significación \(\boldsymbol{\alpha}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Si no se tiene un criterio definido, se utilizará el estándar \(\alpha=\) 0.05.
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2) diferencia mínima significativa \(\Delta\) & Elegida sobre la base de la experiencia en el campo concreto de aplicación. \\
3) potencia deseada en el punto a distancia \(\Delta\) & Si no se tiene un criterio definido, se tomará \(\beta=0.8\) para \(\alpha=0.05\). \\
\end{longtable}

Con estas tres cantidades se podrá deducir usualmente el tamaño de muestra necesario, que completará el diseño esencial del test. La información final del resultado del contraste debe indicar estas tres cantidades junto con el p-valor obtenido. Resulta muy aconsejable acompañar el test con el intervalo de confianza equivalente, que puede orientar sobre la significación aplicada (no estadística) del contraste.

\subsection{Significación estadística y significación aplicada}\label{significaciuxf3n-estaduxedstica-y-significaciuxf3n-aplicada}

Al final de este tema resulta conveniente distinguir entre significación estadística y significación aplicada. Cuando se resuelve un contraste de hipótesis se indica que hay significación estadística (S.E.) como sinónimo de aceptación de la hipótesis alternativa. A lo largo de este tema se ha visto, en síntesis, que la S.E. se produce cuando los datos obtenidos en el experimento real y la hipótesis nula presentan una discrepancia que no se atribuye al azar, excepto en el porcentaje de casos marcado por el nivel de significación elegido.

Usualmente, el límite entre la S.E. y la no significación (que técnicamente corresponde a la frontera de la región crítica) depende de la variabilidad del estadístico de test utilizado. Aquí interviene pues de manera directa el tamaño de la muestra \(N\) y la varianza del estadístico, como también se ha visto en los dos casos presentados.

En determinadas situaciones, la variabilidad del estadístico es muy pequeña, de modo que el contraste es muy sensible a desviaciones pequeñas de la hipótesis nula. Puede suceder entonces que, cuando se obtienen los datos, el contraste señale que hay S.E., pero que la desviación respecto a la hipótesis nula sea irrelevante desde el punto de vista práctico. La conclusión es que conviene analizar esta significación aplicada (S.A.) cuando se hace un contraste de hipótesis. En muchos casos, la manera más sencilla es obtener el intervalo de confianza adecuado e interpretar la información del contraste junto con la del intervalo.

En resumen, cuando se aplica cualquier contraste no debemos conformarnos con la simple lectura del p-valor y decidir en consecuencia, sino que:

\begin{itemize}
\tightlist
\item
  si se ha detectado S.E., hay que valorar la S.A., por ejemplo, mediante un intervalo de confianza. Puede haber S.E. pero que no haya S.A.\\
\item
  si no se ha detectado S.E., hay que valorar si el tamaño de la muestra es suficiente para detectar (estadísticamente) las diferencias deseadas por el experimentador. Puede que no haya S.E. por un tamaño de muestra inadecuado y, por tanto, no se podría concluir sobre la S.A. Si el tamaño de la muestra es suficiente y no hay S.E., entonces tampoco hay S.A.
\end{itemize}

\subsubsection{Caso 2: Significación estadística y aplicada}\label{caso-2-significaciuxf3n-estaduxedstica-y-aplicada}

Con los datos realmente obtenidos en el estudio, y la hipótesis:

\[
\mathrm{H}_{0}: \mu=7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq 7
\]

ya hemos visto que la conclusión, para \(\alpha=0.05\), era indicar que hay significación estadística.

Supongamos que los fisiólogos aceptan que las diferencias en el nivel de la hormona son relevantes cuando hay más de \(0.2 \mathrm{ng} / \mathrm{ml}\) de diferencia en la media de la población. El intervalo bilateral en la muestra anterior es:\\
y permite afirmar que también hay significación aplicada.\\
Supongamos que la población tuviera una desviación estándar de \(0.1 \mathrm{ng} / \mathrm{ml}\) (en lugar de la 2.4 planteada hasta ahora), y se hubiera obtenido una media igual a 7.13. El contraste de hipótesis detectaría entonces igualmente que hay S.E., pero en cambio cuando se observa el intervalo de confianza:

Habría que concluir que no hay S.A. En este segundo caso, la varianza tan pequeña permite que el contraste sea muy sensible a pequeñas variaciones de la media. La S.E. en este último ejemplo no resulta relevante en la práctica.

\newpage

\section{Construcción de contrastes de hipótesis}\label{construcciuxf3n-de-contrastes-de-hipuxf3tesis}

\subsection{¿Qué significa ``construir'' un contraste de hipótesis?}\label{quuxe9-significa-construir-un-contraste-de-hipuxf3tesis}

En el capítulo 9 se han presentado los contrastes de hipótesis como procedimientos operativos basados en un \textbf{estadístico de contraste} y una \textbf{región crítica} asociada a dicho estadístico. En esta sección adoptamos ese mismo punto de vista y lo llevamos un paso más allá: no nos preguntamos cómo aplicar un contraste concreto, sino \textbf{cómo se construye un contraste en general} y qué criterios permiten decidir cuándo un contraste es preferible a otro.

\subsubsection{El contraste como regla de decisión}\label{el-contraste-como-regla-de-decisiuxf3n}

Sea \(X=(X_1,\dots,X_n)\) una muestra aleatoria con espacio muestral \(\mathcal{X}\) y distribución dependiente de un parámetro desconocido \(\theta\in\Theta\). Consideramos el contraste

\[
H_0:\theta\in\Theta_0
\qquad \text{frente a} \qquad
H_1:\theta\in\Theta_1,
\]

con \(\Theta_0\cap\Theta_1=\varnothing\).

Siguiendo la convención del capítulo 9, un contraste de hipótesis se construye especificando:

\begin{itemize}
\tightlist
\item
  un \textbf{estadístico de contraste} \(T=T(X)\),
\item
  una \textbf{región crítica para el estadístico} \(C\subset\mathbb{R}\),
\end{itemize}

de modo que se decide \textbf{rechazar \(H_0\)} cuando

\[
T(X)\in C.
\]

Este criterio define implícitamente una región crítica en el espacio muestral,

\[
\mathcal{R}=\{x\in\mathcal{X}:T(x)\in C\},
\]

pero en la práctica se trabaja casi siempre con \(T\) y \(C\), ya que simplifican la construcción y el análisis del contraste.

Desde este punto de vista, \textbf{construir un contraste equivale a elegir el estadístico \(T\) y la región \(C\)}.

\subsubsection{Nivel de significación como restricción básica}\label{nivel-de-significaciuxf3n-como-restricciuxf3n-buxe1sica}

El primer requisito que debe cumplir un contraste es el control del \textbf{error de tipo I}, es decir, la probabilidad de rechazar \(H_0\) cuando esta es verdadera.

El \textbf{nivel de significación} del contraste se define como

\[
\alpha
=
\sup_{\theta\in\Theta_0}
\mathbb{P}_\theta\bigl(T(X)\in C\bigr).
\]

Un contraste es de nivel \(\alpha\) si esta probabilidad no supera el valor prefijado \(\alpha\).

Fijar el nivel impone una restricción clara sobre la elección de \(C\), pero \textbf{no determina un contraste único}. Incluso fijando el modelo probabilístico, las hipótesis \(H_0\) y \(H_1\) y el nivel \(\alpha\), siguen existiendo múltiples elecciones posibles del estadístico \(T\) y de la región crítica \(C\).

\subsubsection{Primer ejemplo: distintos contrastes con el mismo nivel}\label{primer-ejemplo-distintos-contrastes-con-el-mismo-nivel}

Supongamos que \(X_1,\dots,X_n\) es una muestra de una distribución \(N(\mu,1)\) y consideramos el contraste

\[
H_0:\mu=0
\qquad \text{frente a} \qquad
H_1:\mu>0.
\]

Un estadístico natural es la media muestral \(\bar X\). Bajo \(H_0\) se tiene

\[
\bar X\sim N\!\left(0,\frac{1}{n}\right).
\]

Un contraste habitual consiste en rechazar \(H_0\) si

\[
\bar X>c,
\]

donde \(c\) se elige de modo que

\[
\mathbb{P}_{H_0}(\bar X>c)=\alpha.
\]

Sin embargo, este no es el único contraste posible de nivel \(\alpha\). Por ejemplo, también podríamos definir:

\begin{itemize}
\tightlist
\item
  Rechazar \(H_0\) si \(X_1>k\),
\item
  Rechazar \(H_0\) si \(0.8\,\bar X+0.2\,X_1>d\),
\end{itemize}

eligiendo \(k\) o \(d\) de forma que

\[
\mathbb{P}_{H_0}\bigl(T(X)\in C\bigr)=\alpha.
\]

Todos estos contrastes controlan el error de tipo I, pero \textbf{no utilizan la información de la muestra de la misma forma}. El control del nivel, por sí solo, no permite decidir qué contraste es preferible.

\subsubsection{Potencia como criterio de comparación}\label{potencia-como-criterio-de-comparaciuxf3n}

Para comparar contrastes de igual nivel se introduce la \textbf{potencia}.

Dado un contraste definido por \((T,C)\), su \textbf{función de potencia} es

\[
\beta(\theta)
=
\mathbb{P}_\theta\bigl(T(X)\in C\bigr),
\qquad \theta\in\Theta.
\]

Para \(\theta\in\Theta_0\), \(\beta(\theta)\) coincide con la probabilidad de error de tipo I. Para \(\theta\in\Theta_1\), \(\beta(\theta)\) es la probabilidad de rechazar correctamente \(H_0\).

Un contraste será tanto mejor cuanto mayor sea su potencia bajo la alternativa. En general, no existe un contraste que maximice simultáneamente la potencia para todos los valores de \(\theta\in\Theta_1\), lo que introduce un compromiso inevitable.

\subsubsection{Segundo ejemplo: misma alpha, distinta potencia}\label{segundo-ejemplo-misma-alpha-distinta-potencia}

En el ejemplo anterior, consideremos dos contrastes de nivel \(\alpha\):

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Contraste A}: rechazar \(H_0\) si \(\bar X>c\).
\item
  \textbf{Contraste B}: rechazar \(H_0\) si \(X_1>k\).
\end{enumerate}

Ambos controlan el error de tipo I al nivel \(\alpha\). Sin embargo, para \(\mu>0\) se tiene, en general,

\[
\mathbb{P}_\mu(\bar X>c)
>
\mathbb{P}_\mu(X_1>k),
\]

ya que \(\bar X\) utiliza toda la información de la muestra, mientras que \(X_1\) solo utiliza una observación.

Desde el punto de vista inferencial, el contraste A es preferible: \textbf{tiene mayor potencia y discrimina mejor entre \(H_0\) y \(H_1\)}.

\subsubsection{De contrastes razonables a contrastes óptimos}\label{de-contrastes-razonables-a-contrastes-uxf3ptimos}

El análisis anterior conduce naturalmente a distinguir entre:

\begin{itemize}
\tightlist
\item
  \textbf{Contrastes razonables}, que controlan el nivel y presentan un buen comportamiento práctico.
\item
  \textbf{Contrastes óptimos}, que maximizan la potencia según un criterio bien definido.
\end{itemize}

La noción de optimalidad es conceptualmente potente, pero muy restrictiva y solo se alcanza en situaciones ideales. La mayoría de los contrastes utilizados en la práctica no son óptimos en sentido estricto, sino soluciones que sacrifican optimalidad a cambio de generalidad o simplicidad.

Las secciones siguientes se centran en estos criterios de optimalidad y en las estrategias que se utilizan cuando no es posible alcanzarlos.

\subsection{Evidencia y decisión: dos enfoques clásicos}\label{evidencia-y-decisiuxf3n-dos-enfoques-cluxe1sicos}

La necesidad de comparar contrastes con el mismo nivel conduce de forma natural a preguntarse \textbf{qué criterio debe utilizarse para decidir cuándo un contraste es preferible a otro}. Históricamente, esta cuestión dio lugar a dos enfoques distintos para la inferencia por contrastes, asociados a :contentReference{oaicite:0} por un lado, y a :contentReference{oaicite:1} y :contentReference{oaicite:2} por otro.

Aunque ambos enfoques conviven hoy en la práctica estadística, sus objetivos y su interpretación del contraste de hipótesis son conceptualmente diferentes.

\subsubsection{El enfoque de Fisher: tests de significación}\label{el-enfoque-de-fisher-tests-de-significaciuxf3n}

En el enfoque de Fisher, el contraste se concibe como un \textbf{procedimiento para medir la evidencia de los datos contra la hipótesis nula}.

El punto de partida es:

\begin{itemize}
\tightlist
\item
  una hipótesis nula \(H_0\),
\item
  un estadístico de contraste \(T(X)\) cuya distribución bajo \(H_0\) es conocida o aproximable.
\end{itemize}

A partir del valor observado \(T(x)\), se define el \textbf{p-valor} como

\[
p=\mathbb{P}_{H_0}\bigl(T(X)\ge T(x)\bigr),
\]

o, más generalmente, como la probabilidad bajo \(H_0\) de obtener un valor del estadístico tan extremo o más que el observado.

En este enfoque:

\begin{itemize}
\tightlist
\item
  no se formula explícitamente una hipótesis alternativa,
\item
  no se habla de errores de tipo II ni de potencia,
\item
  el p-valor se interpreta como una \textbf{medida graduada de evidencia} contra \(H_0\).
\end{itemize}

La decisión de rechazar o no rechazar \(H_0\) es secundaria y, en cierto sentido, convencional.

\subsubsection{El enfoque de Neyman--Pearson: contraste como regla de decisión}\label{el-enfoque-de-neymanpearson-contraste-como-regla-de-decisiuxf3n}

En el enfoque de Neyman--Pearson, el contraste se plantea explícitamente como un \textbf{problema de decisión bajo incertidumbre}.

Se consideran dos hipótesis:

\[
H_0:\theta\in\Theta_0
\qquad \text{frente a} \qquad
H_1:\theta\in\Theta_1,
\]

y se construye un contraste que:

\begin{itemize}
\tightlist
\item
  controla el error de tipo I a un nivel prefijado \(\alpha\),
\item
  tiene la mayor potencia posible bajo la alternativa.
\end{itemize}

En este marco:

\begin{itemize}
\tightlist
\item
  el contraste se define por un estadístico \(T(X)\) y una región crítica \(C\),
\item
  el nivel \(\alpha\) es un requisito fundamental,
\item
  la \textbf{potencia} \(\beta(\theta)\) es el criterio de calidad del contraste.
\end{itemize}

El objetivo no es medir evidencia, sino \textbf{tomar una decisión con garantías probabilísticas bien definidas}.

\subsubsection{Diferencias conceptuales clave}\label{diferencias-conceptuales-clave}

Aunque en la práctica ambos enfoques suelen mezclarse, conviene tener presentes sus diferencias fundamentales:

\begin{itemize}
\tightlist
\item
  Fisher se centra en la \textbf{compatibilidad de los datos con \(H_0\)}.
\item
  Neyman--Pearson se centra en el \textbf{comportamiento a largo plazo del procedimiento de decisión}.
\item
  El p-valor es central en Fisher, pero secundario en Neyman--Pearson.
\item
  La potencia es central en Neyman--Pearson, pero no aparece en Fisher.
\end{itemize}

Estas diferencias no son meramente filosóficas: influyen directamente en \textbf{cómo se construyen los contrastes} y en qué criterios se consideran relevantes.

\subsubsection{Convivencia de ambos enfoques en la práctica}\label{convivencia-de-ambos-enfoques-en-la-pruxe1ctica}

En la práctica estadística actual es habitual encontrar procedimientos que combinan elementos de ambos enfoques:

\begin{itemize}
\tightlist
\item
  se calcula un p-valor,
\item
  se compara con un nivel \(\alpha\) prefijado,
\item
  se habla de potencia y tamaño muestral.
\end{itemize}

Esta convivencia no es contradictoria, pero sí puede resultar confusa si no se distinguen claramente los objetivos de cada marco teórico.

En las secciones siguientes adoptaremos principalmente el punto de vista de Neyman--Pearson, ya que permite \textbf{formular de manera precisa el problema de la construcción de contrastes óptimos}, sin perder de vista las limitaciones prácticas de dicho enfoque.

\subsection{Tests óptimos: el lema de Neyman--Pearson}\label{tests-uxf3ptimos-el-lema-de-neymanpearson}

En las secciones anteriores hemos visto que, una vez fijado el nivel de significación, existen múltiples contrastes posibles para un mismo problema, y que la potencia proporciona un criterio natural para compararlos. Surge entonces una pregunta fundamental:

¿es posible construir un contraste que sea óptimo en el sentido de maximizar la potencia?

El resultado central que responde a esta cuestión es el \textbf{lema de Neyman--Pearson}, que establece la forma del contraste más potente cuando ambas hipótesis son simples.

\subsubsection{Hipótesis simples y razón de verosimilitudes}\label{hipuxf3tesis-simples-y-razuxf3n-de-verosimilitudes}

Consideremos un modelo probabilístico dependiente de un parámetro \(\theta\) y el contraste entre dos hipótesis simples

\[
H_0:\theta=\theta_0
\qquad \text{frente a} \qquad
H_1:\theta=\theta_1,
\]

con \(\theta_0\neq\theta_1\).

Denotemos por \(f_0(x)\) y \(f_1(x)\) la función de densidad (o de probabilidad) de la muestra bajo \(H_0\) y \(H_1\), respectivamente. Se define la \textbf{razón de verosimilitudes} a favor de la alternativa como

\[
\Lambda(x)=\frac{f_1(x)}{f_0(x)}.
\]

Valores grandes de \(\Lambda(x)\) indican mayor compatibilidad de los datos con \(H_1\) que con \(H_0\).

\subsubsection{Enunciado del lema de Neyman--Pearson}\label{enunciado-del-lema-de-neymanpearson}

Entre todos los contrastes de nivel \(\alpha\) para contrastar \(H_0\) frente a \(H_1\), el contraste que rechaza \(H_0\) cuando

\[
\Lambda(X)\ge c
\]

para una constante \(c\) elegida de modo que

\[
\mathbb{P}_{H_0}\bigl(\Lambda(X)\ge c\bigr)=\alpha
\]

es el contraste \textbf{más potente}, es decir, el que maximiza la potencia

\[
\beta(\theta_1)=\mathbb{P}_{\theta_1}\bigl(\Lambda(X)\ge c\bigr)
\]

entre todos los contrastes de nivel \(\alpha\).

Este contraste se denomina \textbf{contraste de razón de verosimilitudes} y proporciona una solución óptima en el caso de hipótesis simples.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{Ejemplo: modelo normal con varianza conocida}\label{ejemplo-modelo-normal-con-varianza-conocida}

Sea \(X_1,\dots,X_n\) una muestra de una distribución \(N(\mu,\sigma^2)\), con \(\sigma^2\) conocida. Consideremos el contraste

\[
H_0:\mu=\mu_0
\qquad \text{frente a} \qquad
H_1:\mu=\mu_1,
\]

con \(\mu_1>\mu_0\).

La razón de verosimilitudes viene dada por

\[
\Lambda(x)
=\exp\!\left(
\frac{\mu_1-\mu_0}{\sigma^2}\sum_{j=1}^n x_j
-\frac{n(\mu_1^2-\mu_0^2)}{2\sigma^2}
\right).
\]

Dado que esta expresión es una función monótonamente creciente de \(\sum X_j\), el contraste más potente rechaza \(H_0\) cuando

\[
\sum_{j=1}^n X_j \ge c
\quad \Longleftrightarrow \quad
\bar X \ge c',
\]

donde la constante \(c'\) se elige de modo que

\[
\mathbb{P}_{H_0}(\bar X\ge c')=\alpha.
\]

Este procedimiento conduce exactamente al contraste Z unilateral habitual. El lema de Neyman--Pearson permite, en este caso, justificar su optimalidad para hipótesis simples.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{Ejemplo: modelo de Poisson}\label{ejemplo-modelo-de-poisson}

Sea \(X_1,\dots,X_n\) una muestra de una distribución Poisson con parámetro \(\lambda\). Consideremos el contraste

\[
H_0:\lambda=\lambda_0
\qquad \text{frente a} \qquad
H_1:\lambda=\lambda_1,
\]

con \(\lambda_1>\lambda_0\).

La razón de verosimilitudes es

\[
\Lambda(x)
=\left(\frac{\lambda_1}{\lambda_0}\right)^{\sum x_j}
\exp\!\left(-n(\lambda_1-\lambda_0)\right).
\]

Esta expresión es monótonamente creciente en \(\sum X_j\). Por tanto, el contraste más potente rechaza \(H_0\) cuando

\[
\sum_{j=1}^n X_j \ge c,
\]

donde \(c\) se elige de modo que

\[
\mathbb{P}_{H_0}\!\left(\sum_{j=1}^n X_j \ge c\right)=\alpha.
\]

Este ejemplo muestra que el lema de Neyman--Pearson no se limita al modelo normal y se aplica de forma natural a modelos discretos.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{Extensiones del lema de Neyman--Pearson}\label{extensiones-del-lema-de-neymanpearson}

El lema de Neyman--Pearson garantiza la existencia de un contraste óptimo únicamente en el caso de hipótesis simples. Sin embargo, en determinadas situaciones puede extenderse a hipótesis compuestas.

Consideremos un contraste unilateral

\[
H_0:\theta=\theta_0
\qquad \text{frente a} \qquad
H_1:\theta>\theta_0,
\]

dentro de una familia exponencial de una dimensión, con densidad de la forma

\[
f(x|\theta)=\exp\!\left\{\eta(\theta)T(x)-A(\theta)+B(x)\right\}.
\]

Si la razón de verosimilitudes entre \(\theta_1>\theta_0\) y \(\theta_0\) es monótona creciente en \(T(x)\), la región crítica obtenida mediante el lema de Neyman--Pearson \textbf{no depende del valor concreto de \(\theta_1\)}.

En este caso existe un contraste \textbf{uniformemente más potente} (UMP) para la alternativa unilateral, que rechaza \(H_0\) cuando

\[
T(X)\ge c,
\]

con \(c\) elegido de modo que el nivel sea \(\alpha\).

Este resultado explica la existencia de contrastes unilaterales simples y bien definidos en modelos como el normal, el Poisson o el binomial.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{Límites del enfoque}\label{luxedmites-del-enfoque}

Cuando:

\begin{itemize}
\tightlist
\item
  la familia no es exponencial,
\item
  la alternativa es bilateral,
\item
  o la región crítica depende del parámetro bajo \(H_1\),
\end{itemize}

no existe, en general, un contraste óptimo en el sentido de Neyman--Pearson.

En estas situaciones es necesario recurrir a procedimientos más generales, como los \textbf{contrastes de razón de verosimilitudes generalizados} o a aproximaciones asintóticas, que se estudiarán en la siguiente sección.

\subsection{Contrastes de razón de verosimilitudes generalizados}\label{contrastes-de-razuxf3n-de-verosimilitudes-generalizados}

En la sección anterior hemos visto que el lema de Neyman--Pearson permite construir contrastes óptimos en el caso de hipótesis simples, y que en algunas situaciones particulares puede extenderse a hipótesis compuestas unilaterales. Sin embargo, en muchos problemas de interés práctico estas condiciones no se cumplen.

Cuando no existe un contraste uniformemente más potente, una estrategia natural consiste en comparar \textbf{qué tan bien explican los datos las hipótesis nula y alternativa} mediante sus respectivas verosimilitudes. Esta idea conduce a los \textbf{contrastes de razón de verosimilitudes generalizados}.

\subsubsection{Definición del estadístico de razón de verosimilitudes}\label{definiciuxf3n-del-estaduxedstico-de-razuxf3n-de-verosimilitudes}

Sea \(L(\theta)\) la función de verosimilitud del modelo y consideremos el contraste

\[
H_0:\theta\in\Theta_0
\qquad \text{frente a} \qquad
H_1:\theta\in\Theta\setminus\Theta_0.
\]

Se define el \textbf{estadístico de razón de verosimilitudes} como

\[
\Lambda(X)
=
\frac{\sup_{\theta\in\Theta_0} L(\theta)}
{\sup_{\theta\in\Theta} L(\theta)}.
\]

Este cociente compara el mejor ajuste del modelo bajo la restricción impuesta por \(H_0\) con el mejor ajuste posible sin restricciones.

Por construcción, \(0\le\Lambda(X)\le 1\). Valores cercanos a uno indican que la restricción impuesta por \(H_0\) apenas reduce la verosimilitud, mientras que valores pequeños indican que el ajuste bajo \(H_0\) es sustancialmente peor que el del modelo completo.

En consecuencia, valores pequeños de \(\Lambda(X)\) proporcionan evidencia contra la hipótesis nula.

\subsubsection{Regla de decisión y aproximación asintótica}\label{regla-de-decisiuxf3n-y-aproximaciuxf3n-asintuxf3tica}

Bajo condiciones de regularidad bastante generales, y cuando el tamaño muestral es grande, se tiene que

\[
-2\log\Lambda(X)
\;\xrightarrow{d}\;
\chi^2_{\,\nu},
\]

donde \(\nu=\dim(\Theta_1)-\dim(\Theta_0)\) es el número de restricciones impuestas por \(H_0\).

Esto permite construir contrastes aproximados de nivel \(\alpha\) rechazando \(H_0\) cuando

\[
-2\log\Lambda(X)\ge \chi^2_{\nu,1-\alpha}.
\]

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{Ejemplo: comparación de parámetros en un modelo de Poisson}\label{ejemplo-comparaciuxf3n-de-paruxe1metros-en-un-modelo-de-poisson}

Sea \(X_1,\dots,X_n\) una muestra de una distribución Poisson con parámetro \(\lambda\). Consideremos el contraste

\[
H_0:\lambda=\lambda_0
\qquad \text{frente a} \qquad
H_1:\lambda\neq\lambda_0.
\]

La función de verosimilitud es

\[
L(\lambda)=\prod_{j=1}^n \frac{e^{-\lambda}\lambda^{x_j}}{x_j!}.
\]

El estimador de máxima verosimilitud bajo \(H_1\) es

\[
\hat\lambda=\bar X.
\]

Bajo \(H_0\), la verosimilitud se evalúa en \(\lambda_0\). Por tanto, el estadístico de razón de verosimilitudes es

\[
\Lambda(X)
=
\frac{L(\lambda_0)}{L(\hat\lambda)}.
\]

Un cálculo directo conduce a

\[
-2\log\Lambda(X)
=
2n\left[
\bar X\log\frac{\bar X}{\lambda_0}
-(\bar X-\lambda_0)
\right].
\]

Bajo \(H_0\), y para tamaños muestrales grandes, este estadístico sigue aproximadamente una distribución \(\chi^2_1\), lo que permite construir un contraste bilateral para \(\lambda\).

Este ejemplo muestra cómo el contraste de razón de verosimilitudes proporciona un procedimiento sistemático incluso cuando no existe un contraste óptimo en sentido de Neyman--Pearson.

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{Ejemplo: contraste en un modelo exponencial}\label{ejemplo-contraste-en-un-modelo-exponencial}

Sea \(X_1,\dots,X_n\) una muestra de una distribución exponencial con parámetro \(\lambda\). Consideremos el contraste

\[
H_0:\lambda=\lambda_0
\qquad \text{frente a} \qquad
H_1:\lambda\neq\lambda_0.
\]

La función de verosimilitud viene dada por

\[
L(\lambda)=\lambda^n\exp\!\left(-\lambda\sum_{j=1}^n X_j\right).
\]

El estimador de máxima verosimilitud bajo \(H_1\) es

\[
\hat\lambda=\frac{1}{\bar X}.
\]

El estadístico de razón de verosimilitudes es

\[
-2\log\Lambda(X)
=
2n\left[
\frac{\lambda_0}{\hat\lambda}
-\log\frac{\lambda_0}{\hat\lambda}
-1
\right].
\]

De nuevo, bajo \(H_0\) y para tamaños muestrales grandes, este estadístico se distribuye aproximadamente como una \(\chi^2_1\).

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\subsubsection{Ejemplo: contraste en un modelo trinomial}\label{ejemplo-contraste-en-un-modelo-trinomial}

Sea \((N_1,N_2,N_3)\) un vector de frecuencias con distribución multinomial (trinomial) con tamaño muestral \(n\) y probabilidades \((p_1,p_2,p_3)\), con \(p_1+p_2+p_3=1\).

Consideremos el contraste

\[
H_0:(p_1,p_2,p_3)=(p_{10},p_{20},p_{30})
\qquad \text{frente a} \qquad
H_1:(p_1,p_2,p_3)\neq(p_{10},p_{20},p_{30}).
\]

La verosimilitud es

\[
L(p_1,p_2,p_3)
=
\frac{n!}{N_1!N_2!N_3!}
\prod_{i=1}^3 p_i^{N_i}.
\]

Bajo \(H_1\), los estimadores de máxima verosimilitud son

\[
\hat p_i=\frac{N_i}{n},
\qquad i=1,2,3.
\]

El estadístico de razón de verosimilitudes toma la forma

\[
-2\log\Lambda
=
2\sum_{i=1}^3 N_i\log\frac{N_i}{n p_{i0}}.
\]

Bajo \(H_0\), y para tamaños muestrales grandes, este estadístico sigue aproximadamente una distribución \(\chi^2_2\), ya que hay dos grados de libertad independientes.

Este contraste constituye la base teórica de los \textbf{tests de ji-cuadrado de bondad de ajuste}, que se estudiarán con más detalle en secciones posteriores.

\subsubsection{Del contraste de razón de verosimilitudes al test ji-cuadrado}\label{del-contraste-de-razuxf3n-de-verosimilitudes-al-test-ji-cuadrado}

Una de las razones por las que el contraste de razón de verosimilitudes es tan importante es que, en modelos multinomiales, conduce directamente al test ji-cuadrado de bondad de ajuste.

Consideremos el caso trinomial. Sea \((N_1,N_2,N_3)\) un vector de frecuencias con distribución multinomial con tamaño muestral \(n\) y probabilidades \((p_1,p_2,p_3)\), con \(p_1+p_2+p_3=1\). Planteamos el contraste

\[
H_0:(p_1,p_2,p_3)=(p_{10},p_{20},p_{30})
\qquad \text{frente a} \qquad
H_1:(p_1,p_2,p_3)\neq(p_{10},p_{20},p_{30}).
\]

La verosimilitud es

\[
L(p_1,p_2,p_3)
=
\frac{n!}{N_1!N_2!N_3!}
\prod_{i=1}^3 p_i^{N_i}.
\]

Bajo \(H_1\), los estimadores de máxima verosimilitud son

\[
\hat p_i=\frac{N_i}{n},\qquad i=1,2,3.
\]

El estadístico de razón de verosimilitudes generalizado es

\[
\Lambda
=
\frac{L(p_{10},p_{20},p_{30})}{L(\hat p_1,\hat p_2,\hat p_3)}.
\]

Sustituyendo y simplificando, se obtiene el estadístico (a veces llamado \emph{G-test})

\[
-2\log\Lambda
=
2\sum_{i=1}^3 N_i\log\frac{N_i}{n p_{i0}}.
\]

Bajo condiciones generales (teorema de Wilks) y para tamaños muestrales grandes,

\[
-2\log\Lambda \;\xrightarrow{d}\; \chi^2_2,
\]

ya que en el modelo completo hay \(3\) probabilidades con una restricción (\(p_1+p_2+p_3=1\)), es decir, \(\dim(\Theta)=2\), mientras que bajo \(H_0\) no hay parámetros libres.

Para conectar con la estadística clásica, definimos las frecuencias esperadas bajo \(H_0\):

\[
E_i=n p_{i0},\qquad i=1,2,3.
\]

El test ji-cuadrado de Pearson utiliza el estadístico

\[
X^2=\sum_{i=1}^3 \frac{(N_i-E_i)^2}{E_i}.
\]

Cuando las frecuencias esperadas \(E_i\) son suficientemente grandes, se cumple que

\[
-2\log\Lambda \approx X^2,
\]

y ambos estadísticos tienen aproximadamente distribución \(\chi^2_2\) bajo \(H_0\). En particular, en este contexto los dos contrastes suelen dar conclusiones muy similares, aunque el contraste de razón de verosimilitudes es el que surge de manera natural a partir del principio de máxima verosimilitud.

Este razonamiento se extiende sin cambios esenciales al caso multinomial general con \(k\) categorías, donde el número de grados de libertad es \(k-1\).

\subsection{Tests de permutaciones}\label{tests-de-permutaciones}

En esta sección presentamos los \textbf{tests de permutaciones} como una alternativa general para la construcción de contrastes de hipótesis. A diferencia de los contrastes paramétricos clásicos, estos métodos no requieren especificar una distribución probabilística para los datos ni recurrir a aproximaciones asintóticas.

La validez de los tests de permutaciones se basa en una idea simple: \textbf{bajo la hipótesis nula, ciertas transformaciones de los datos no alteran su distribución}. En particular, si bajo \(H_0\) las observaciones son intercambiables, todas las permutaciones posibles de los datos son igualmente probables.

\subsubsection{Idea básica}\label{idea-buxe1sica}

El esquema general de un test de permutaciones es el siguiente:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Elegir un \textbf{estadístico de contraste} \(T(X)\) que mida la discrepancia entre los datos observados y lo esperado bajo \(H_0\).
\item
  Calcular el valor observado \(T(x)\).
\item
  Generar la distribución de \(T\) bajo \(H_0\) considerando todas (o muchas) permutaciones de los datos.
\item
  Calcular el \textbf{p-valor} como la proporción de permutaciones para las que el estadístico toma un valor tan extremo o más que el observado.
\end{enumerate}

Este procedimiento define un contraste exacto condicionado a los datos observados.

\subsubsection{Ejemplo 1: test de permutaciones con enumeración completa}\label{ejemplo-1-test-de-permutaciones-con-enumeraciuxf3n-completa}

Consideremos un ejemplo muy simple en el que podemos enumerar todas las permutaciones posibles.

Observamos dos grupos con una variable cuantitativa:

\begin{itemize}
\tightlist
\item
  Grupo A: \(x_A=(2,4)\)\\
\item
  Grupo B: \(x_B=(6,8)\)
\end{itemize}

Queremos contrastar

\[
H_0:\text{ambos grupos provienen de la misma distribución}
\]

frente a la alternativa unilateral de que los valores del grupo B tienden a ser mayores.

Como estadístico de contraste utilizamos la diferencia de medias

\[
T(X)=\bar X_A-\bar X_B.
\]

\subsubsection{Valor observado del estadístico}\label{valor-observado-del-estaduxedstico}

Podemos evaluar el estadístico de test como:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{xA }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{)}
\NormalTok{xB }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{, }\DecValTok{8}\NormalTok{)}

\NormalTok{T\_obs }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(xA) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(xB)}
\NormalTok{T\_obs}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -4
\end{verbatim}

\subsubsection{Distribución exacta por permutaciones}\label{distribuciuxf3n-exacta-por-permutaciones}

Bajo \(H_0\), cualquier asignación de dos observaciones al grupo A es igualmente probable. Existen exactamente \(\binom{4}{2}=6\) permutaciones posibles.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(xA, xB)}

\NormalTok{idx }\OtherTok{\textless{}{-}} \FunctionTok{combn}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{)}

\NormalTok{T\_perm }\OtherTok{\textless{}{-}} \FunctionTok{apply}\NormalTok{(idx, }\DecValTok{2}\NormalTok{, }\ControlFlowTok{function}\NormalTok{(i) \{}
  \FunctionTok{mean}\NormalTok{(x[i]) }\SpecialCharTok{{-}} \FunctionTok{mean}\NormalTok{(x[}\SpecialCharTok{{-}}\NormalTok{i])}
\NormalTok{\})}

\NormalTok{T\_perm}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -4 -2  0  0  2  4
\end{verbatim}

\paragraph{Cálculo del p-valor}\label{cuxe1lculo-del-p-valor}

Para la alternativa unilateral considerada, el p-valor se calcula como

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(T\_perm }\SpecialCharTok{\textless{}=}\NormalTok{ T\_obs)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.1666667
\end{verbatim}

Este test es \textbf{exacto}, no depende de ninguna aproximación y es válido incluso con tamaños muestrales muy pequeños.

\subsubsection{Ejemplo 2: test de permutaciones mediante simulación}\label{ejemplo-2-test-de-permutaciones-mediante-simulaciuxf3n}

En problemas más realistas, el número de permutaciones posibles es demasiado grande como para enumerarlas todas. En estos casos se utiliza una aproximación por simulación.

Consideremos dos grupos con tamaños moderados:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{xA }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{20}\NormalTok{, }\AttributeTok{mean =} \DecValTok{0}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\NormalTok{xB }\OtherTok{\textless{}{-}} \FunctionTok{rnorm}\NormalTok{(}\DecValTok{20}\NormalTok{, }\AttributeTok{mean =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{sd =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Queremos contrastar nuevamente la igualdad de distribuciones utilizando un test de permutaciones basado en la diferencia de medias.

\paragraph{\texorpdfstring{Implementación con el paquete \texttt{coin}}{Implementación con el paquete coin}}\label{implementaciuxf3n-con-el-paquete-coin}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(coin)}

\NormalTok{group }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{, }\StringTok{"B"}\NormalTok{), }\AttributeTok{each =} \DecValTok{20}\NormalTok{))}
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(xA, xB)}

\NormalTok{perm\_test }\OtherTok{\textless{}{-}} \FunctionTok{oneway\_test}\NormalTok{(}
\NormalTok{  x }\SpecialCharTok{\textasciitilde{}}\NormalTok{ group,}
  \AttributeTok{distribution =} \FunctionTok{approximate}\NormalTok{(}\AttributeTok{B =} \DecValTok{10000}\NormalTok{)}
\NormalTok{)}

\NormalTok{perm\_test}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Approximative Two-Sample Fisher-Pitman Permutation Test
## 
## data:  x by group (A, B)
## Z = -1.7268, p-value = 0.0795
## alternative hypothesis: true mu is not equal to 0
\end{verbatim}

\paragraph{Comparación con el test t clásico}\label{comparaciuxf3n-con-el-test-t-cluxe1sico}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(xA, xB, }\AttributeTok{var.equal =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Two Sample t-test
## 
## data:  xA and xB
## t = -1.7737, df = 38, p-value = 0.08413
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.08591100  0.07167293
## sample estimates:
## mean of x mean of y 
## 0.1416238 0.6487428
\end{verbatim}

\subsubsection{Comentario final}\label{comentario-final}

Los tests de permutaciones ilustran una forma alternativa de construir contrastes de hipótesis:

\begin{itemize}
\tightlist
\item
  el nivel se controla sin recurrir a distribuciones teóricas,
\item
  la región crítica se define a partir de la distribución inducida por las permutaciones,
\item
  y la validez del contraste descansa en una hipótesis de intercambio, no en un modelo paramétrico.
\end{itemize}

Estos métodos cierran de forma natural el recorrido de este capítulo, mostrando que la construcción de contrastes puede basarse en principios distintos pero complementarios.

\newpage

\section{Pruebas de una muestra}\label{pruebas-de-una-muestra}

\subsection{Introducción a los contrastes de una muestra.}\label{introducciuxf3n-a-los-contrastes-de-una-muestra.}

Este tema y el siguiente pueden ser considerados una plasmación práctica de los conceptos teóricos vistos en el capítulo anterior aplicados a los modelos probabilísticos más frecuentemente utilizados en la práctica estadística: el modelo normal y el modelo binomial. Presentamos en este capítulo algunos de los contrastes paramétricos más habituales que se utilizan para verificar si el valor poblacional supuesto a determinado parámetro de la distribución de probabilidad de una variable aleatoria es compatible con la información suministrada por una muestra aleatoria simple de dicha variable. En el siguiente capítulo trataremos el tema de la comparación de los valores de los parámetros entre dos poblaciones.

El término paramétrico aplicado a los contrastes hace referencia a la suposición previa de una distribución paramétrica de referencia para la variable aleatoria, distribución que viene caracterizada por el valor de sus parámetros, objeto de verificación a través de los contrastes propuestos.

Es evidente la relación existente entre la verificación a través de un contraste de hipótesis de la aceptación de un valor poblacional con los métodos de estimación de parámetros vistos en los capítulos 7 y 8 . Sobre todo existe una relación estrecha entre los contrastes de hipótesis paramétricos y la estimación por intervalos de confianza, tal y como se ha comentado en un apartado anterior.

\subsubsection{Esquema de los contrastes presentados}\label{esquema-de-los-contrastes-presentados}

El tema se distribuye en dos grandes bloques:

\begin{itemize}
\tightlist
\item
  Contrastes sobre los parámetros de una distribución Normal
\item
  Contrastes sobre una proporción
\end{itemize}

\subsubsection{Contrastes sobre los parámetros de una distribución Normal}\label{contrastes-sobre-los-paruxe1metros-de-una-distribuciuxf3n-normal}

En este apartado se estudian los contrastes sobre la media y la varianza de una distribución Normal.

\begin{itemize}
\tightlist
\item
  Premisas: en estos contrastes se supone que la variable aleatoria objeto de estudio sigue una distribución Normal. En el primer contraste presentado también se supone conocida la varianza de la distribución.
\item
  Contrastes presentados:
\item
  Sobre la media supuesta conocida la varianza
\item
  Sobre la media con la varianza desconocida
\item
  Sobre la varianza de la distribución
\end{itemize}

\subsubsection{Contrastes sobre una proporción}\label{contrastes-sobre-una-proporciuxf3n}

\begin{itemize}
\tightlist
\item
  Premisas: se supone una distribución Binomial para la variable aleatoria. El parámetro p es desconocido y es sobre el que se efectúa la inferencia. Presentamos la resolución aproximada basada en la aproximación a la distribución Normal, por tanto se deben verificar las condiciones que hacen válida dicha aproximación:
\end{itemize}

\[
n \geq 30 \quad n p_{0} \geq 5 \quad n\left(1-p_{0}\right) \geq 5
\]

\begin{itemize}
\tightlist
\item
  Contraste presentado:
\item
  Contraste para la proporción
\end{itemize}

\subsubsection{Esquema general de los contrastes presentados}\label{esquema-general-de-los-contrastes-presentados}

Para la mayoría de contrastes presentados el esquema seguido en su presentación es idéntico

\begin{itemize}
\tightlist
\item
  Presentación del contraste con una introducción y las premisas necesarias para el mismo.
\item
  Resolución del contraste con las 3 etapas principales: Formulación de las hipótesis nula y alternativa, cálculo del estadístico experimental, criterio de decisión.
\item
  Resolución del contraste a través de intervalos de confianza.
\item
  Cálculo del tamaño muestral necesario para realizar el contraste bajo los requerimientos deseados de potencia y nivel de significación.
\end{itemize}

\subsubsection{Contrastes paramétricos frente a no paramétricos}\label{contrastes-paramuxe9tricos-frente-a-no-paramuxe9tricos}

Un término importante a considerar en la metodología estadística es el de robustez. Una técnica estadística es robusta si se comporta bien cuando las suposiciones bajo las que se ha construido son vulneradas de alguna forma. Por ejemplo cuando una variable aleatoria es no Normal, pero el tamaño de la muestra es suficientemente grande, el Teorema Central del Límite garantiza que la media aritmética se distribuye aproximadamente como una Normal y el contraste sobre la media que presentamos, el T-test, es aproximadamente válido en el sentido de que el nivel de significación nominal es aproximadamente el mismo que el nivel de significación real bajo la hipótesis nula.

En caso de infringirse de modo más drástico las suposiciones del modelo, es necesario utilizar contrastes que superen dichas vulneraciones recurriendo a los contrastes no paramétricos o contrastes de libre distribución que quedan fuera del contenido del presente texto. Hay que destacar sin embargo, que la utilización de contrastes no paramétricos debe ser mesurada y restringida a casos estrictamente necesarios porque generalmente el comportamiento de dichos contrastes en términos de potencia estadística es peor que la de los contrastes paramétricos si se cumplen las condiciones requeridas por éstos.

\subsection{\texorpdfstring{Contraste de hipótesis para la media de una distribución Normal con varianza conocida: \(Z\)-test.}{Contraste de hipótesis para la media de una distribución Normal con varianza conocida: Z-test.}}\label{contraste-de-hipuxf3tesis-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-conocida-z-test.}

\subsubsection{Introducción}\label{introducciuxf3n-3}

Este primer contraste estadístico tiene más interés académico que práctico, ya que es poco frecuente en experimentación conocer uno de los parámetros poblacionales del modelo.

Información previa (premisas)
La situación es la siguiente: se observa una variable \(X\) sobre una población de estudio y se asume que la distribución de \(X\) es

\[
X \approx N(\mu, \sigma)
\]

donde \(\boldsymbol{\sigma}\) es conocida. Se desea comparar la media de la población \(\mu\) (desconocida) con cierto valor \(\mu_{0}\), fijado previamente, mediante la obtención de una muestra de tamaño \(n\).

\subsubsection{Resolución del contraste para la media de una distribución Normal con varianza conocida.}\label{resoluciuxf3n-del-contraste-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-conocida.}

Los pasos a seguir para resolver el contraste son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Establecer la hipótesis nula \(\left(H_{0}\right)\) y la alternativa \(\left(H_{1}\right)\), de acuerdo con una de las tres posibilidades siguientes:
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Contraste bilateral o de dos colas: corresponde a plantear en la alternativa que la media es diferente a un cierto valor prefijado \(\mu_{0}\), sin concretar si es mayor o menor.
\end{enumerate}

\[
\mathrm{H}_{0}: \mu=\mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq \mu_{0}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Contraste unilateral izquierdo: corresponde a plantear en la alternativa que la media es inferior a un cierto valor prefijado \(\mu_{0}\).
\end{enumerate}

\[
\mathrm{H}_{0}: \mu \geq \mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu<\mu_{0}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Contraste unilateral derecho: corresponde a plantear en la alternativa que la media es mayor que un cierto valor prefijado \(\mu_{0}\).
\end{enumerate}

\[
\mathrm{H}_{0}: \mu \leq \mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu>\mu_{0}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Cálculo del estadístico experimental
\end{enumerate}

En el caso que nos ocupa, no ha de sorprender que el estadístico que corresponde al test óptimo esté relacionado con la media muestral. Bajo \(\mathrm{H}_{0}\), la variable observada y su promedio siguen la distribución siguiente:

\[
\mathrm{H}_{0} \text { cierta } \Rightarrow X \approx N\left(\mu_{0}, \sigma\right) \Rightarrow \bar{X} \approx N\left(\mu_{0}, \frac{\sigma}{\sqrt{n}}\right)
\]

Si es cierta la hipótesis nula, el estadístico experimental \(z_{\text {exp }}\) que debe utilizarse sigue la distribución siguiente:

\[
Z_{\exp }=\frac{\bar{X}-\mu_{0}}{\sigma / \sqrt{n}} \approx \mathrm{~N}(0,1)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Criterio de decisión
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Contraste bilateral o de dos colas: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
\left|Z_{\exp }\right| \geq z_{\alpha / 2}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Contraste unilateral a la izquierda: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
Z_{\exp } \leq-z_{\alpha}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Contraste unilateral a la derecha: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
Z_{\exp } \geq z_{\alpha}
\]

Nota: \(z_{\alpha / 2}\) y \(z_{\alpha}\) son los valores críticos asociados a la \(\operatorname{Normal}(0,1)\) tales que:

\[
\operatorname{prob}\left(Z>z_{\alpha / 2}\right)=\alpha / 2
\]

\[
\operatorname{prob}\left(Z>z_{\alpha}\right)=\alpha
\]

\subsubsection{Intervalo de confianza para la media de una distribución Normal con varianza conocida.}\label{intervalo-de-confianza-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-conocida.}

Los límites para el intervalo de confianza para la media (para más detalles, véase el tema 8) son los que ya hemos presentado anteriormente:

\[
\bar{X}-z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}+z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}
\]

donde el símbolo \(z_{\alpha / 2}\) es el valor crítico tal que:

\[
\operatorname{prob}\left(Z>z_{\alpha / 2}\right)=\alpha / 2
\]

y que corresponde a un intervalo de confianza \(1-\alpha \%\). Este intervalo puede utilizarse de manera alternativa al contraste de hipótesis con nivel de significación \(\alpha \%\). Se decide aceptar \(\mathrm{H}_{0}\) si el valor que asume la hipótesis nula queda incluido en el intervalo.

Aún realizando el contraste en primer lugar, es aconsejable obtener el intervalo de confianza, puesto que ayuda a interpretar si existe significación aplicada además de la estadística.

Si se dispone de alguna información previa que sugiera el cálculo de sólo alguno de los dos intervalos unilaterales, bastará sustituir \(\mathrm{z}_{\alpha / 2}\) por \(\mathrm{z}_{\alpha}\) y descartar el límite superior o inferior del intervalo según el caso.

La decisión tomada en relación con estos intervalos es totalmente equivalente a las decisiones tomadas en relación con el contraste \(Z\)-test en sus respectivas alternativas unilaterales.

\subsubsection{Cálculo del tamaño muestral para la media de una distribución Normal con varianza conocida.}\label{cuxe1lculo-del-tamauxf1o-muestral-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-conocida.}

Supongamos que se desea realizar el contraste bilateral:

\[
\mathrm{H}_{0}: \mu=\mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq \mu_{0}
\]

Una vez el experimentador ha elegido el nivel de significación ( \(\alpha\) ) y la mínima diferencia significativa \((\Delta)\) asociada al punto de interés \(\mu_{0} \pm \Delta\), donde se desea que la potencia sea igual a \(\beta\), puede ya determinarse el tamaño de muestra adecuado que es:

\[
\mathbf{n}=\left[\frac{\mathrm{z}_{\alpha / 2}+\mathrm{z}_{1-\beta}}{\Delta}\right]^{2} \sigma^{2}
\]

Las constantes \(z_{\alpha / 2}\) y \(z_{1-\beta}\) corresponden a las siguientes colas derechas de una distribución Normal \(\mathrm{N}(0\), 1):

\[
p\left(Z \geq z_{\alpha / 2}\right)=\alpha / 2 \quad p\left(Z \geq z_{1-\beta}\right)=1-\beta
\]

Si el contraste es unilateral, basta cambiar en la expresión del tamaño de muestra \(z_{\alpha / 2}\) por \(z_{\alpha}\).

\subsection{\texorpdfstring{Contraste de hipótesis para la media de una distribución Normal con varianza desconocida: \(T\)-test.}{Contraste de hipótesis para la media de una distribución Normal con varianza desconocida: T-test.}}\label{contraste-de-hipuxf3tesis-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-desconocida-t-test.}

\subsubsection{Introducción}\label{introducciuxf3n-4}

Este contraste es mucho más utilizado en experimentación que el anterior, ya que en la práctica rara vez se conoce alguno de los parámetros poblacionales del modelo.

Información previa (premisas)
Ahora se observa una variable \(X\) sobre una población de estudio y se asume que la distribución de \(X\) es:

\[
X \approx N(\mu, \sigma)
\]

donde \(\boldsymbol{\sigma}\) es desconocida, es decir, no se conoce ningún parámetro de la distribución. Se desea comparar la media de la población \(\mu\) (desconocida) con cierto valor \(\mu_{0}\) fijado previamente, mediante la obtención de una muestra de tamaño \(n\).

\subsubsection{Resolución del contraste para la media de una distribución Normal con varianza desconocida.}\label{resoluciuxf3n-del-contraste-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-desconocida.}

Los pasos a seguir para resolver el contraste son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Establecer la Hipótesis nula \(\left(H_{0}\right)\) y la alternativa \(\left(H_{1}\right)\), de acuerdo a una de las tres posibilidades siguientes:
\end{enumerate}

\[
\mathrm{H}_{0}: \mu=\mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq \mu_{0}
\]

o bien

\[
\mathrm{H}_{0}: \mu \geq \mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu<\mu_{0}
\]

o bien

\[
\mathrm{H}_{0}: \mu \leq \mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu>\mu_{0}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Cálculo del estadístico experimental
\end{enumerate}

Bajo \(\mathrm{H}_{0}\), el estadístico de test sigue una distribución \(t\) de Student con \(n-1\) grados de libertad

\[
\mathrm{T}_{\text {exp }}=\frac{\bar{X}-\mu_{0}}{\hat{S} / \sqrt{n}} \approx t_{n-1}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Criterio de decisión
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Contraste bilateral o de dos colas: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
\left|T_{\exp }\right| \geq t_{\alpha / 2}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Contraste unilateral a la izquierda: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
T_{\exp } \leq-t_{\alpha}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Contraste unilateral a la derecha: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
T_{\mathrm{exp}} \geq t_{\alpha}
\]

Nota: \(t_{\alpha / 2}\) y \(t_{\alpha}\) son los valores críticos asociados a una variable \(T\) con distribución \(t\) de Student con \(\boldsymbol{n}-\mathbf{1}\) grados de libertad tales que:

\[
\operatorname{prob}\left(T>t_{\alpha / 2}\right)=\alpha / 2 \quad \operatorname{prob}\left(T>t_{\alpha}\right)=\alpha
\]

\subsubsection{Intervalo de confianza para la media de una distribución Normal con varianza desconocida.}\label{intervalo-de-confianza-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-desconocida.}

El intervalo de confianza para la media con varianza desconocida ya ha sido presentado (véase el tema 8). Si \(t_{\alpha / 2}\) indica el valor crítico tal que prob \(\left(T>\mathrm{t}_{\alpha / 2}\right)=\alpha / 2\), donde \(T\) es una variable con distribución \(t\) de Student con \(n-1\) grados de libertad, el intervalo con coeficiente de confianza \(1-\alpha \%\) es:

\[
\bar{X}-t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}} \leq \mu \leq \bar{X}+t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}}
\]

Este intervalo puede utilizarse de manera alternativa al contraste de hipótesis con nivel de significación \(\alpha \%\). Se decide aceptar \(\mathrm{H}_{0}\) si el valor que asume la hipótesis nula queda incluido en el intervalo.

Ya se ha recordado antes que es aconsejable obtener el intervalo de confianza para interpretar si existe significación aplicada.

Si se dispone de alguna información previa que sugiera el cálculo de uno de los dos intervalos unilaterales, bastará sustituir \(t_{\alpha / 2}\) por \(t_{\alpha} \mathrm{y}\) descartar el límite superior o inferior del intervalo según el caso.

La decisión tomada en relación con estos intervalos es totalmente equivalente a las decisiones tomadas con el contraste \(t\) de Student en sus alternativas unilaterales respectivas.

\subsubsection{Cálculo del tamaño muestral para la media de una distribución Normal con varianza desconocida.}\label{cuxe1lculo-del-tamauxf1o-muestral-para-la-media-de-una-distribuciuxf3n-normal-con-varianza-desconocida.}

Supongamos que se desea hacer el contraste bilateral:

\[
\mathrm{H}_{0}: \mu=\mu_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq \mu_{0}
\]

Una vez el experimentador ha elegido el nivel de significación ( \(\alpha\) ), la mínima diferencia significativa \((\Delta)\) y la potencia \((\beta)\), debe obtenerse una prueba piloto donde se estima la varianza. Luego puede ya determinarse el tamaño muestral adecuado, que es:

\[
\mathbf{n}=\left[\frac{\mathbf{t}_{\alpha / 2}+\mathbf{t}_{1-\beta}}{\Delta}\right]^{2} \hat{\mathrm{~S}}^{2}
\]

Las constantes \(t_{\alpha / 2}\) y \(t_{1-\beta}\) corresponden a los valores siguientes asociados con una distribución \(t\) de Student con grados de libertad igual al tamaño de la muestra piloto menos 1 :

\[
p\left(T \geq t_{\alpha / 2}\right)=\alpha / 2 \quad p\left(T \geq t_{1-\beta}\right)=1-\beta
\]

Si el contraste es unilateral, basta cambiar en la expresión del tamaño de muestra \(t_{\alpha / 2}\) por \(t_{\alpha}\).
Si el tamaño muestral obtenido es mayor que el de la muestra piloto, es necesario obtener una segunda muestra. Si al volver a calcular el contraste con la segunda muestra se sigue aceptando \(\mathrm{H}_{0}\), debe evaluarse nuevamente el tamaño de muestra con la varianza muestral resultante de la segunda muestra.

\subsection{Contraste de hipótesis para la varianza de una distribución Normal.}\label{contraste-de-hipuxf3tesis-para-la-varianza-de-una-distribuciuxf3n-normal.}

\subsubsection{Introducción}\label{introducciuxf3n-5}

Este test permite contrastar hipótesis acerca de la varianza poblacional, es decir, del parámetro del modelo que mide la variabilidad en la población.

Cabe destacar que la distribución de referencia en este contraste es la distribución Ji-cuadrado ( \(\chi^{2}\) ).

\subsubsection{Información previa (premisas)}\label{informaciuxf3n-previa-premisas}

Así pues, se observa una variable \(X\) sobre una población de estudio, y se asume que la distribución de \(X\) es:

\[
X \approx N(\mu, \sigma)
\]

donde no se conoce ningún parámetro de la distribución. Se desea comparar \(\sigma\) con cierto valor \(\sigma_{0}\) fijado previamente.

\subsubsection{Resolución del contraste para la varianza de una distribución Normal.}\label{resoluciuxf3n-del-contraste-para-la-varianza-de-una-distribuciuxf3n-normal.}

Los pasos a seguir para resolver el contraste son:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Establecer la hipótesis nula ( \(H_{0}\) ) y la alternativa ( \(H_{1}\) ), de acuerdo a una de las tres posibilidades siguientes:
\end{enumerate}

\[
\mathrm{H}_{0}: \sigma=\sigma_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \sigma \neq \sigma_{0}
\]

o bien

\[
\mathrm{H}_{0}: \sigma \geq \sigma_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \sigma<\sigma_{0}
\]

o bien

\[
\mathrm{H}_{0}: \sigma \leq \sigma_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \sigma>\sigma_{0}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Calcular el estadístico experimental
\end{enumerate}

El estadístico de test está basado en el estimador insesgado de la varianza. \(\mathrm{Si}_{0}\) es cierta se verifica:

\[
\mathrm{H}_{0} \text { cierta } \Rightarrow \chi_{\exp }^{2}=(\mathbf{n}-1) \frac{\hat{\mathrm{S}}^{2}}{\sigma_{0}^{2}} \approx \chi_{\mathrm{n}-1}^{2}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Criterio de decisión
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Contraste bilateral o de 2 colas: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
\chi^{2} \exp \leq \chi_{1-\alpha / 2}^{2} \text { o bien } \chi_{\exp }^{2} \geq \chi_{\alpha / 2}^{2}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Contraste unilateral a la izquierda: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
\chi^{2} \exp \leq \chi^{2}{ }_{1-\alpha}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Contraste unilateral a la derecha: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
\chi^{2} \exp \geq \chi^{2}{ }_{\alpha}
\]

Nota: \(\chi^{2}{ }_{\alpha / 2}\) y \(\chi^{2}{ }_{1-\alpha / 2}\) son los valores críticos asociados a una variable \(\chi^{2}\) con distribución Ji al cuadrado \(\operatorname{con} n-1\) grados de libertad tales que:

\[
\operatorname{prob}\left(\chi^{2}>\chi_{\alpha / 2}^{2}\right)=\alpha / 2
\]

\[
\operatorname{prob}\left(\chi^{2}<\chi^{2}{ }_{1-\alpha / 2}\right)=\alpha / 2
\]

\subsubsection{Intervalo de confianza para la varianza de una distribución Normal.}\label{intervalo-de-confianza-para-la-varianza-de-una-distribuciuxf3n-normal.}

Los límites para el intervalo de confianza para la varianza ya se han presentado en el tema 8 y la distribución de referencia es la distribución de Ji al cuadrado.

Si \(\chi^{2}{ }_{\alpha / 2}\) es el valor crítico correspondiente a una distribución de Ji al cuadrado con \(n-1\) grados de libertad que deja a su derecha una probabilidad igual a \(\alpha / 2, \chi^{2}{ }_{1-\alpha / 2}\) y el valor crítico para la misma distribución de Ji al cuadrado que deja a su izquierda una probabilidad \(\alpha / 2\), el intervalo es:

\[
\frac{(n-1) \hat{S}^{2}}{\chi_{\alpha / 2}^{2}} \leq \sigma^{2} \leq \frac{(n-1) \hat{S}^{2}}{\chi_{1-\alpha / 2}^{2}}
\]

Este intervalo puede utilizarse de manera alternativa al contraste de hipótesis (con nivel de significación \(\alpha \%)\). Se decide aceptar \(\mathrm{H}_{0}\) si el valor que asume la hipótesis nula queda incluido en el intervalo.

Si se dispone de alguna información previa que sugiera el cálculo de sólo uno de los intervalos unilaterales, bastará sustituir \(\chi^{2}{ }_{\alpha / 2}\) o \(\chi^{2}{ }_{1-\alpha / 2}\) por \(\chi^{2}{ }_{\alpha}\) o \(\chi^{2}{ }_{1-\alpha}\) y descartar el límite superior o inferior del intervalo según el caso.

La decisión tomada en relación con estos intervalos es totalmente equivalente a las decisiones tomadas en relación con el contraste de Ji al cuadrado en las alternativas unilaterales respectivas.

\subsection{Contraste de hipótesis para la proporción.}\label{contraste-de-hipuxf3tesis-para-la-proporciuxf3n.}

\subsubsection{Introducción:}\label{introducciuxf3n-6}

Este contraste estadístico se emplea en los estudios en los que la variable observada en cada individuo de la población es dicotómica, es decir, identifica sólo dos tipos de sucesos: éxito (motivo de estudio) y fracaso.

\subsubsection{Información previa (premisas)}\label{informaciuxf3n-previa-premisas-1}

Supongamos que se dispone de \(n\) observaciones independientes, cada una de las cuales sigue una distribución de Bernoulli de parámetro \(p\) :

\[
\mathrm{X}_{1}, \ldots \mathrm{X}_{\mathrm{n}} \quad \mathrm{X}_{\mathrm{i}} \approx \operatorname{Bernoulli}(\mathrm{p})
\]

La variable de estudio \(X\) es la suma de las \(n\) observaciones, definida también como el número de éxitos obtenidos en una muestra de tamaño \(n\).
\(X\) es una variable aleatoria de distribución Binomial:

\[
\mathrm{X}=\sum_{\mathrm{i}=1}^{\mathrm{n}} \mathrm{X}_{\mathrm{i}} \approx \mathrm{~B}(\mathrm{n}, \mathrm{p})
\]

y se quiere comparar el parámetro \(\boldsymbol{p}\) (desconocido) con valor \(p_{0}\) fijado a priori.
La frecuencia relativa (estimador del verdadero parámetro \(p\) a partir de la muestra) es

\[
\hat{\mathrm{P}}=\frac{\mathrm{X}}{\mathrm{n}}
\]

\subsubsection{Resolución del contraste para la proporción.}\label{resoluciuxf3n-del-contraste-para-la-proporciuxf3n.}

La resolución del contraste sigue los pasos siguientes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Establecer la hipótesis nula ( \(H_{0}\) ) y la alternativa ( \(H_{1}\) ), como ya es habitual tenemos las tres posibilidades siguientes:
\end{enumerate}

\[
\mathrm{H}_{0}: p=p_{0} \quad \text { contra } \quad \mathrm{H}_{1}: p \neq p_{0}
\]

o bien

\[
\mathrm{H}_{0}: p \geq p_{0} \quad \text { contra } \quad \mathrm{H}_{1}: p<p_{0}
\]

o bien

\[
\mathrm{H}_{0}: p \leq p_{0} \quad \text { contra } \quad \mathrm{H}_{1}: p>p_{0}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Cálculo del estadístico experimental
\end{enumerate}

El teorema central del límite permite aproximar una variable binomial para valores de tamaño \(n\) y para sucesos con probabilidad no extrema (menor que 0,1 o mayor que 0,9 ).

De ahí que si se supone cierta la hipótesis \(\mathrm{H}_{0}\) y se cumplen estas tres condiciones:

\[
n \geq 30 \quad n p_{0} \geq 5 \quad n\left(1-p_{0}\right) \geq 5
\]

entonces el estadístico siguiente sigue una distribución asintóticamente Normal

\[
Z_{\exp }=\frac{\hat{p}-p_{0}}{\sqrt{\frac{p_{0}\left(1-p_{0}\right)}{n}}} \approx N(0,1)
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Criterio de decisión
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Contraste bilateral o de dos colas: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
\left|Z_{\exp }\right| \geq z_{\alpha / 2}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Contraste unilateral a la izquierda: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
Z_{\exp } \leq-z_{\alpha}
\]

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Contraste unilateral a la derecha: rechazamos la hipótesis nula \(\mathbf{H}_{\mathbf{0}}\) si:
\end{enumerate}

\[
Z_{\exp } \geq z_{\alpha}
\]

Nota: \(z_{\alpha / 2}\) y \(z_{\alpha}\) son los valores críticos asociados con la distribución Normal \((0,1)\) tales que:

\[
\operatorname{prob}\left(Z>z_{\alpha / 2}\right)=\alpha / 2 \quad \operatorname{prob}\left(Z>z_{\alpha}\right)=\alpha
\]

\subsubsection{Intervalo de confianza para la proporción.}\label{intervalo-de-confianza-para-la-proporciuxf3n.}

El intervalo de confianza para la proporción que hemos considerado es parecido al del capítulo 8, pero sin la corrección de continuidad.

El intervalo de confianza \(1-\alpha \%\) para \(p\) queda definido por:

\[
\hat{p} \pm z_{\alpha / 2} \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}
\]

y , como es habitual, \(z_{\alpha / 2}\) es el valor crítico asociado con una \(\operatorname{Normal}(0,1)\) tal que:

\[
\operatorname{prob}\left(Z>z_{\alpha / 2}\right)=\alpha / 2
\]

Este intervalo puede utilizarse de manera alternativa al contraste de hipótesis con nivel de significación \(\alpha \%\). Se decide aceptar \(\mathrm{H}_{0}\) si el valor que asume en la hipótesis nula queda incluido en el intervalo.

Si sólo se desea calcular alguno de los dos intervalos unilaterales, bastará sustituir \(z_{\alpha / 2}\) por \(z_{\alpha}\) y descartar el límite superior o inferior del intervalo según el caso.

\subsubsection{Cálculo del tamaño muestral para la proporción.}\label{cuxe1lculo-del-tamauxf1o-muestral-para-la-proporciuxf3n.}

Supongamos que se quiere calcular el contraste bilateral:

\[
\mathrm{H}_{0}: \mathrm{p}=\mathrm{p}_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mathrm{p} \neq \mathrm{p}_{0}
\]

Una vez el experimentador ha elegido el nivel de significación ( \(\alpha\) ), la mínima diferencia significativa \((\Delta)\) y la potencia ( \(\beta\) ), puede ya determinarse el tamaño muestral adecuado, sin necesidad de obtener una prueba piloto, con la fórmula siguiente:

\[
\mathbf{n}=\left[\frac{z_{\alpha / 2} \sqrt{p_{0}\left(1-p_{0}\right)}+z_{1-\beta} \sqrt{p_{1}\left(1-p_{1}\right)}}{\Delta}\right]^{2}
\]

La proporción \(p_{1}\) corresponde a

\[
\text { si } p_{0} \leq 0,5 \text { entonces } p_{1}=p_{0}+\Delta \quad \text { si } p_{0}>0,5 \text { entonces } p_{1}=p_{0}-\Delta
\]

Las constantes \(z_{\alpha / 2}\) y \(z_{1-\beta}\) corresponden a las siguientes colas derechas de la variable aleatoria Normal \((0,1)\) :

\[
p\left(Z \geq z_{\alpha / 2}\right)=\alpha / 2 \quad p\left(Z \geq z_{1-\beta}\right)=1-\beta
\]

Si el contraste es unilateral, basta cambiar en la expresión del tamaño de muestra \(z_{\alpha / 2}\) por \(z_{\alpha}\), y la proporción \(p_{1}\) es entonces:

\[
\text { unilateral derecho: } \mathrm{p}_{1}=\mathrm{p}_{0}+\Delta \quad \text { unilateral izquierdo: } \mathrm{p}_{1}=\mathrm{p}_{0}-\Delta
\]

\subsection{Tabla resumen para una muestra.}\label{tabla-resumen-para-una-muestra.}

Los contrastes que hemos visto en este tema se resumen en:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Premisas
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\mathrm{H}_{0}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Estadístico
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Distribución
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\mathrm{H}_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rechazar \(\mathrm{H}_{0}\) si:
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(X\) Normal \(\sigma\) conocida & \(\mu=\mu 0\) & \(Z=\frac{\bar{X}-\mu_{0}}{\sigma / \sqrt{\mathbf{n}}}\) & Normal \((0,1)\) & \(\mu \neq \mu_{0}\) & \(\|Z\| \geq z_{\alpha} / 2\) \\
& & & & \(\mu>\mu_{0}\) & \(Z \geq z_{\alpha}\) \\
& & & & \(\mu<\mu_{0}\) & \(Z \leq-z_{\alpha}\) \\
\(X\) Normal \(\sigma\) desconocida & \(\mu=\mu_{0}\) & \(\mathrm{T}=\frac{\overline{\mathrm{X}}-\mu_{0}}{\hat{\mathrm{~S}} / \sqrt{\mathrm{n}}}\) & \(t\) de Student ( \(n-1\) ) & \(\mu \neq \mu_{0}\) & \(\|T\| \geq t_{\alpha / 2}\) \\
& & & & \(\mu>\mu_{0}\) & \(T \geq t_{\alpha}\) \\
& & & & \(\mu<\mu_{0}\) & \(T \leq-t_{\alpha}\) \\
\(X\) Normal \(\sigma\) desconocida & \(\sigma^{2}=\sigma_{0}{ }^{2}\) & \(\chi^{2}=(\mathbf{n}-\mathbf{1}) \frac{\hat{\mathbf{S}}^{2}}{\sigma_{0}^{2}}\) & Ji al cuadrado ( \(n-1\) ) & & \\
& & & & \(\sigma^{2} \neq \sigma_{0}^{2}\) & \(\begin{gathered} \chi^{2} \geq \chi_{\alpha / 2}^{2} \\ 0 \\ \chi^{2} \leq \chi^{2} 1-\alpha / 2 \end{gathered}\) \\
& & & & \(\sigma^{2}>\sigma_{0}{ }^{2}\) & \(\chi^{2} \geq \chi^{2}{ }_{\alpha}\) \\
& & & & \(\sigma^{2}<\sigma_{0}{ }^{2}\) & \(\chi^{2} \leq \chi^{2}{ }_{1-\alpha}\) \\
X Bernoulli \(\begin{gathered} n \geq 30, n p_{0} \geq 5 \\ n q_{0} \geq 5 \\ \left(q_{0}=1-p_{0}\right) \end{gathered}\) & \(p=p_{0}\) & \(Z=\frac{\hat{\mathbf{p}}-\mathbf{p}_{0}}{\sqrt{\frac{\mathbf{p}_{0} \mathbf{q}_{0}}{\mathbf{n}}}}\) & Normal \((0,1)\) & \(p \neq p_{0}\) & \(\|Z\| \geq z_{\alpha / 2}\) \\
& & & & \(p>p_{0}\) & \(Z \geq z_{\alpha}\) \\
& & & & \(p<p_{0}\) & \(Z \leq-z_{\alpha}\) \\
\end{longtable}

Notación:
\(\overline{\mathrm{X}}, \hat{\mathrm{S}}_{1}^{2}\) promedio y varianza muestral corregida
\(\hat{\mathbf{p}}\) frecuencia relativa del suceso en la muestra
\(\chi^{2}\) sigue la distribución de Ji al cuadrado, entonces \(\chi^{2} \alpha / 2, \chi^{2}{ }_{1-\alpha / 2}, \chi^{2} \alpha\) y \(\chi^{2}{ }_{1-\alpha}\) son:

\[
\begin{array}{cc}
\operatorname{prob}\left(\chi^{2}>\chi^{2} \alpha / 2\right)=\alpha / 2 & \operatorname{prob}\left(\chi^{2}<\chi^{2} 1-\alpha / 2\right)=\alpha / 2 \\
\operatorname{prob}\left(\chi^{2}>\chi^{2} \alpha\right)=\alpha & \operatorname{prob}\left(\chi^{2}<\chi^{2} \alpha\right)=1-\alpha
\end{array}
\]

si \(T\) es la variable aleatoria \(t\) de Student, \(\operatorname{prob}\left(T>t_{\alpha / 2}\right)=\alpha / 2\) y \(\operatorname{prob}\left(T>t_{\alpha}\right)=\alpha\)
si \(Z\) es la variable normal tipificada, \(\operatorname{prob}\left(Z>z_{\alpha / 2}\right)=\alpha / 2\) y \(\operatorname{prob}\left(Z>z_{\alpha}\right)=\alpha\)

\subsection{La importancia de elegir correctamente la hipótesis nula.}\label{la-importancia-de-elegir-correctamente-la-hipuxf3tesis-nula.}

En un fármaco, fabricado en serie, el contenido en \(m g\) de un producto de cierta toxicidad no debe alcanzar la cifra de 0,25 . Un aparato detector del contenido de producto mide con una desviación típica de 0,09. Para disminuir en lo posible los riesgos consiguientes a la salida al mercado del fármaco con un exceso en el contenido del referido producto, ¿de qué modo debería actuarse?

El investigador debe previamente comprobar los factores que puedan alterar la cadena de producción. De existir alteraciones debe estratificar la muestra para que sea representativa de todos los factores implicados. Si existe la posibilidad de obtener un tamaño muestral grande ha de ser aprovechada para aumentar la potencia del test. Si es preciso estratificar, pueden determinarse los estratos y dividir homogéneamente entre ellos la extracción de la muestra completa.

Es indeseable evidentemente suministrar al mercado un producto tóxico, de modo que el error que ha de estar muy bien controlado es el asociado a rechazar la hipótesis de toxicidad si esta es cierta. Cometer este error pondría en el mercado una partida de fármacos tóxica, de consecuencias graves desde el punto de vista de la salud pública.

En cambio, si se rechaza incorrectamente la hipótesis de no toxicidad y se invalida sin necesidad la partida, este segundo tipo de error es menos importante, ya que sólo tiene consecuencias económicas.

Desde este punto de vista, si se plantea el contraste siguiente con un nivel de significación \(\alpha=0,01\)

\[
\begin{aligned}
& \mathrm{H}_{0}: \mu \geq \mu_{0}=0.25 \\
& \mathrm{H}_{1}: \mu<0.25
\end{aligned}
\]

se tiene controlado el error de tipo I (se rechaza \(\mathrm{H}_{0}\) cuando ésta es cierta), que más arriba se ha justificado como el único con riesgo médico.

Si se rechaza la hipótesis nula, la partida de fármacos puede ser comercializada, ya que de darse esta circunstancia se encontrarían evidencias muy significativas \((\alpha=0,01)\) contra la hipótesis de que la partida sea tóxica.

Nótese que, si es cierta \(\mathrm{H}_{0}\), la probabilidad de encontrar una muestra que induzca a error sería 1/100.
En resumen, al plantear las hipótesis de esta manera se acepta que la hipótesis nula está asociada a rechazar partidas por su posible toxicidad. El posible error de tipo II, más complicado de estudiar, sólo tiene consecuencias económicas, mientras que el nivel de significación controla directamente el riesgo de intoxicación.

\subsection{Relación con los intervalos de confianza}\label{relaciuxf3n-con-los-intervalos-de-confianza-1}

Los contrastes de hipótesis están muy relacionados con la teoría de los intervalos de confianza. En muchos casos se puede resolver la misma cuestión aplicada formulándola por cualquiera de las dos vías. Por ejemplo, el contraste:

\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta \neq \theta_{0}
\]

puede resolverse planteando el intervalo de confianza para \(\theta\), con coeficiente de confianza \(1-\alpha\). Supongamos que el intervalo obtenido es \([\mathrm{a} ; \mathrm{b}]\). Entonces, si:

\[
\begin{aligned}
& \operatorname{si} \theta_{0} \in[\mathrm{a} ; \mathrm{b}] \text { aceptar } \mathrm{H}_{0} \\
& \operatorname{si} \theta_{0} \notin[\mathrm{a} ; \mathrm{b}] \text { aceptar } \mathrm{H}_{1}
\end{aligned}
\]

Este contraste tendrá como nivel de significación \(\alpha\). Es posible proporcionar incluso el \(p\)-valor si se ajusta la anchura del intervalo para que sea lo más ancho posible y al mismo tiempo excluya \(\theta_{0}\).

Inversamente, es posible utilizar la región crítica de un contraste para proporcionar una estimación por intervalo del parámetro. Los contrastes bilaterales corresponden a intervalos también bilaterales centrados, mientras que los contrastes unilaterales derechos corresponden a estimaciones unilaterales por exceso y los unilaterales izquierdos, a estimaciones por defecto.

\subsection{Relación entre el intervalo y el contraste}\label{relaciuxf3n-entre-el-intervalo-y-el-contraste}

\subsubsection{Intervalo de confianza para la varianza de una distribución Normal}\label{intervalo-de-confianza-para-la-varianza-de-una-distribuciuxf3n-normal-1}

Dada una variable aleatoria con distribución Normal \(\mathrm{N}(\mu ; \sigma)\), el objetivo es la construcción de un intervalo de confianza para el parámetro \(\sigma\), basado en una muestra de tamaño \(n\) de la variable.

A partir del estadístico

\[
\mathrm{X}^{2}=\frac{(n-1) \hat{S}^{2}}{\sigma^{2}}
\]

la fórmula para el intervalo de confianza, con nivel de confianza \(1-\alpha\) es la siguiente

\[
\frac{(n-1) \hat{S}^{2}}{\chi_{a / 2}^{2}} \leq \sigma^{2} \leq \frac{(n-1) \hat{S}^{2}}{\chi_{1-\alpha / 2}^{2}}
\]

Donde \(\chi^{2}{ }_{\alpha / 2}\) es el valor de una distribución Ji al cuadrado con \(n-1\) grados de libertad que deja a su derecha una probabilidad de \(\alpha / 2\).

Por ejemplo, dados los datos siguientes:

\begin{itemize}
\tightlist
\item
  Distribución poblacional: Normal
\item
  Tamaño de muestra: 10
\item
  Confianza deseada para el intervalo: \(95 \%\)
\item
  Varianza muestral corregida: 38,5
\end{itemize}

Un intervalo de confianza al \(95 \%\) para la varianza de la distribución viene dado por:

\[
\frac{9 \cdot 38,5}{19,031} \leq \sigma^{2} \leq \frac{9 \cdot 38,5}{2,699}
\]

que resulta, finalmente

\[
\sigma^{2} \in(18.207 ; 128,381)
\]

\section{Contrastes con dos muestras}\label{contrastes-con-dos-muestras}

\subsection{Introducción}\label{introducciuxf3n-7}

Un problema muy frecuente en las ciencias experimentales es la comprobación de la homogeneidad de dos grupos, esto es, la decisión de si existen diferencias entre ellos, en determinada característica.

La estadística paramétrica resuelve esta cuestión comparando los parámetros que caracterizan los dos grupos, que son considerados dos poblaciones a priori diferentes. El proceso consiste en obtener una muestra de cada grupo, y a partir de ellas contrastar la igualdad de los parámetros de la distribución de referencia. Por ejemplo, si la distribución de referencia es una normal, se contrasta si la media (poblacional) de los dos grupos es idéntica. De aquí que a veces se nombra este tema como comparaciones de dos muestras, aunque realmente las muestras sirven para inferir si hay diferencias significativas en las poblaciones de las cuales se han extraído.

Desde el punto de vista aplicado es importante distinguir los estudios experimentales y los estudios observacionales. En los primeros, el experimentador puede asignar los individuos al azar en cada grupo. Por ejemplo, al comparar la eficacia de dos fármacos en el tratamiento de una enfermedad, se puede muchas veces asignar los enfermos al azar a uno de los dos tratamientos. En cambio, si el estudio compara una variable biométrica en dos especies diferentes, los individuos están indefectiblemente asociados a su especie y no se pueden asignar al azar: el estudio es observacional.

Este tema trata de las comparaciones de dos grupos en las situaciones paramétricas más habituales y básicas: en primer lugar trata el caso en el que la variable sea normal comparando las medias y las varianzas, en segundo lugar, el caso en que la variable sea binomial, comparando entonces las proporciones.

\subsection{Premisas: independencia vs datos apareados}\label{premisas-independencia-vs-datos-apareados}

En el desarrollo de este tema destaca la importancia que tienen las premisas (requisitos) que deben cumplir los datos para la correcta aplicación de cada una de las técnicas de comparación.

La primera premisa se refiere a la independencia de los datos. En el tema de muestreo (ver aquí) se ha estudiado la definición y obtención de muestras aleatorias simples, que exige, entre otras condiciones, la independencia de los datos. En este sentido, las comparaciones de dos grupos que abordamos aquí siempre se basan en muestra aleatorias simples dentro de cada grupo.

Ahora bien, según el tipo de estudio, pueden presentarse situaciones de dependencia entre los datos de los dos grupos. La dependencia o independencia a la que se refieren los tests de este capítulo ha de entenderse siempre referida a la de los datos entre los dos grupos, sobreentendiendo la independencia exigida dentro del grupo.

\subsubsection{Ejemplo: Datos independientes vs apareados}\label{ejemplo-datos-independientes-vs-apareados}

Como primer ejemplo supongamos un experimento cuyo objetivo es comparar la eficacia de dos fármacos adelgazantes. Se toman 20 individuos y se asignan al azar 10 de ellos a cada uno de los dos tratamientos. Al cabo de dos meses se mide la diferencia de peso antes y después del tratamiento. Aquí los dos grupos (poblaciones) son respectivamente todos los participantes en el estudio, tratados con los 2 fármaco. Hay dos muestras de 10 individuos y los datos pueden considerarse con este diseño experimental independientes. Este ejemplo corresponde a una situación muy frecuente en análisis de datos conocida como comparación de 2 muestras independientes.

Supongamos en cambio que el experimento consiste en escoger a 10 individuos al azar, medir su peso, suministrarles durante dos meses el mismo tratamiento y medir finalmente de nuevo el peso. Hay también aquí 2 muestras de 10 individuos: los 10 valores antes del tratamiento y los 10 de después. Sin embargo, ahora los datos de las dos muestras presentan una probable dependencia que corresponde a este esquema:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Antes tratamiento
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
posible relación con datos de
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Después tratamiento
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
individuo 1 & \(==>\) & individuo 1 \\
\(\ldots\) & \(\ldots\) & \(\ldots\) \\
individuo 10 & \(==>\) & individuo 10 \\
\end{longtable}

Debido a esta situación experimental tan específica los datos aparecen de forma natural emparejados si nos atenemos a su posible dependencia. Este es una segunda situación muy frecuente en experimentación: la comparación de muestras apareadas.

\subsection{Premisas e hipótesis en comparaciones de medias de datos normales independientes.}\label{premisas-e-hipuxf3tesis-en-comparaciones-de-medias-de-datos-normales-independientes.}

Abordaremos primero cómo comparar las medias de dos grupos asociados a una variable normal cuando el muestreo se ha realizado de forma independiente entre los dos grupos.

Las premisas para aplicar el test que se describe a continuación son:

\begin{itemize}
\tightlist
\item
  las dos muestras son estocásticamente independientes entre sí
\item
  las muestras de cada grupo son muestras aleatorias simples
\item
  la variable observada en cada grupo es una variable normal
\item
  la varianza (poblacional) es idéntica en los dos grupos pero desconocida
\end{itemize}

La comprobación de esta última premisa se realiza con un test previo sobre las varianzas. Sin embargo, por motivos pedagógicos, se exponen después sus detalles. Es importante destacar que deberá estimarse la varianza a partir de la muestra, que es la situación real de muchos experimentos. En muchos textos de estadística se menciona otra situación parecida en la que se asume la varianza común (poblacional) conocida. Aquí no trataremos sus detalles, ya que su interés es más académico que aplicado.

Muchos autores han descrito la prueba sobre las medias de dos grupos con varianza desconocida como el diseño más habitual en experimentación: el objetivo es corroborar o descartar que dos grupos son homogéneos en promedio. De acuerdo a las premisas la variable observada sigue en la primera población una \(\operatorname{Normal}\left(\mu_{1}, \sigma\right)\) y en la segunda una \(\operatorname{Normal}\left(\mu_{2}, \sigma\right)\). Contrastar la homogeneidad de medias corresponde pues a:

\[
\mathrm{H}_{0}: \mu_{1}=\mu_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{1} \neq \mu_{2}
\]

La prueba que se describe a continuación resuelve hipótesis algo más generales que el de la igualdad de las medias, ya que el experimento puede consistir en comparar la diferencia de medias respecto a alguna cantidad \(\mathrm{d}_{0}\) escogida previamente:

\[
\mathrm{H}_{0}: \mu_{1}-\mu_{2}=\mathrm{d}_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{1}-\mu_{2} \neq \mathrm{d}_{0}
\]

donde la hipótesis de igualdad corresponde a escoger \(\mathrm{d}_{0}=0\). Como es ya habitual, pueden plantearse otro tipo de alternativas:

\[
\mathrm{H}_{0}: \mu_{1}-\mu_{2} \leq \mathrm{d}_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{1}-\mu_{2}>\mathrm{d}_{0}
\]

o bien:

\[
\mathrm{H}_{0}: \mu_{1}-\mu_{2} \geq \mathrm{d}_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{1}-\mu_{2}<\mathrm{d}_{0}
\]

\subsection{Comparación de medias de datos normales independientes.}\label{comparaciuxf3n-de-medias-de-datos-normales-independientes.}

\subsubsection{Estadístico de test y valores críticos}\label{estaduxedstico-de-test-y-valores-cruxedticos}

En el resto de esta sección asumiremos muestras de tamaño \(n_{1}\) y \(n_{2}\) respectivamente para las dos poblaciones. Los estadísticos se indican mediante:

\[
\begin{aligned}
& \bar{X}_{1}, \widetilde{S}_{1}^{2} \text { promedio y varianza muestral corregida de la } 1^{\mathrm{a}} \text { población } \\
& \bar{X}_{2}, \widetilde{S}_{2}^{2} \text { promedio y varianza muestral corregida de la } 2^{\mathrm{a}} \text { población }
\end{aligned}
\]

Para resolver el contraste descrito antes se dispone de un test óptimo basado en el siguiente estadístico de test:

\[
\mathrm{T}_{\exp }=\frac{\bar{X}_{1}-\bar{X}_{2}-d_{0}}{\sqrt{\frac{\left(n_{1}-1\right) \widetilde{S}_{1}^{2}+\left(n_{2}-1\right) \widetilde{S}_{2}^{2}}{n_{1}+n_{2}-2} \frac{\left(n_{1}+n_{2}\right)}{n_{1} n_{2}}}}
\]

conocido como contraste T para dos muestras independientes cuya distribución es la t de Student con \(\left(\mathrm{n}_{1}+\mathrm{n}_{2}-2\right)\) grados de libertad. Según el tipo de alternativa los valores críticos son:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(\mathrm{H}_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
rechazar \(\mathrm{H}_{0} \mathrm{si}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mu_{1}-\mu_{2} \neq \mathrm{d}_{0}\) & \(\left\|\mathrm{~T}_{\exp }\right\| \geq \mathrm{t}_{\alpha / 2}\) \\
\(\mu_{1}-\mu_{2}>\mathrm{d}_{0}\) & \(\mathrm{~T}_{\exp } \geq \mathrm{t}_{\alpha}\) \\
\(\mu_{1}-\mu_{2}<\mathrm{d}_{0}\) & \(\mathrm{~T}_{\exp } \leq-\mathrm{t}_{\alpha}\) \\
\end{longtable}

si T es la variable aleatoria t -Student \(\left(\mathrm{n}_{1}+\mathrm{n}_{2}-2\right)\) los valores \(\mathrm{t}_{\alpha / 2}\) y \(\mathrm{t}_{\alpha}\) son:

\[
\begin{gathered}
\operatorname{prob}\left(\mathrm{T}>\mathrm{t}_{\alpha / 2}\right)=\alpha / 2 \\
\operatorname{prob}\left(\mathrm{~T}>\mathrm{t}_{\alpha}\right)=\alpha
\end{gathered}
\]

en otras palabras, \(\mathrm{t}_{\alpha / 2}\) es el valor crítico bilateral de la T asociada a una probabilidad \(\alpha\) mientras que \(\mathrm{t}_{\alpha}\) es el valor crítico unilateral derecho de la misma v.a.

\subsubsection{Intervalo de confianza para la diferencia de medias.}\label{intervalo-de-confianza-para-la-diferencia-de-medias.}

Los límites para el intervalo de una diferencia de medias correspondientes a dos muestras independientes son:

\[
\bar{X}_{1}-\bar{X}_{2} \pm t_{\alpha / 2} \sqrt{\frac{\left(n_{1}-1\right) \widetilde{S}_{1}^{2}+\left(n_{2}-1\right) \widetilde{S}_{2}^{2}}{n_{1}+n_{2}-2} \frac{\left(n_{1}+n_{2}\right)}{n_{1} n_{2}}}
\]

el símbolo \(\mathrm{t}_{\alpha / 2}\) es el mismo valor crítico que antes: \(\operatorname{prob}\left(\mathrm{T}>\mathrm{t}_{\alpha / 2}\right)=\alpha / 2\) y corresponde a un intervalo de confianza \(1-\alpha \%\).

Este intervalo puede utilizarse de forma alternativa al contraste de hipótesis para decidir (con nivel de significación \(\alpha\) \%) si hay igualdad de los dos grupos. Se decidirá por la igualdad de los grupos si el valor 0 queda incluido en cualquier posición en el intervalo, es decir, el número 0 no ha de estar forzosamente en el centro del intervalo para aceptar \(\mathrm{H}_{0}\).

Si se ha planteado el contraste más general \(\mathrm{H}_{0}: \mu_{1}-\mu_{2}=\mathrm{d}_{0}\) bastará que el valor \(\mathrm{d}_{0}\) quede incluido en el intervalo.

Aún si se realiza el contraste T de dos muestras en primer lugar, es aconsejable obtener el I.C. de la diferencia de medias si éste ha resultado significativo, puesto que ayudará a interpretar si existe significación aplicada además de la estadística.

Si se dispone de alguna información previa y quiere calcularse sólo alguno de los dos intervalos unilaterales, bastará sustituir \(\mathrm{t}_{\alpha / 2}\) por \(\mathrm{t}_{\alpha} \mathrm{y}\) descartar el límite superior o inferior del intervalo según el caso. Por ejemplo, el intervalo unilateral derecho corresponde a:

\[
\left(-\infty, \bar{X}_{1}-\bar{X}_{2}+t_{\alpha} \sqrt{\frac{\left(n_{1}-1\right) \widetilde{S}_{1}^{2}+\left(n_{2}-1\right) \widetilde{S}_{2}^{2}}{n_{1}+n_{2}-2} \frac{\left(n_{1}+n_{2}\right)}{n_{1} n_{2}}}\right)
\]

La decisión tomada con este intervalo es totalmente equivalente a la decisión tomada con el contraste t Student de 2 muestras independientes con alternativa unilateral derecha.

\subsubsection{Cálculo del tamaño de muestra}\label{cuxe1lculo-del-tamauxf1o-de-muestra}

Supongamos que se desea realizar el contraste bilateral:

\[
\mathrm{H}_{0}: \mu_{1}-\mu_{2}=\mathrm{d}_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{1}-\mu_{2} \neq \mathrm{d}_{0}
\]

Una vez el experimentador ha elegido el nivel de significación ( \(\alpha\) ) la mínima diferencia significativa \((\Delta)\) y la potencia \((\beta)\) debe obtenerse una prueba piloto, donde se estima la varianza supuesta común. Luego puede ya determinarse el tamaño de muestra adecuado (se asumen las varianzas de las 2 poblaciones homogéneas) que es:

\[
n=2\left\{\frac{t_{1-\beta}+t_{\alpha / 2}}{\Delta}\right\}^{2} \frac{\left(n_{1}-1\right) \widetilde{S}_{1}^{2}+\left(n_{2}-1\right) \widetilde{S}_{2}^{2}}{n_{1}+n_{2}-2} \frac{\left(n_{1}+n_{2}\right)}{n_{1} n_{2}}
\]

Las constantes \(t_{\alpha / 2}\) y \(t_{1-\beta}\) corresponden a las siguientes colas derechas de la v.a. t-Student con \(\left(\mathrm{n}_{1}+\mathrm{n}_{2}-2\right)\) g.d.l.:

\[
p\left(T \geq t_{\alpha / 2}\right)=\alpha / 2 \quad p\left(T \geq t_{1-\beta}\right)=1-\beta
\]

Si el contraste es unilateral, basta cambiar en la expresión del tamaño de muestra \(t_{\alpha / 2}\) por \(t_{\alpha}\).

\subsection{Comparación de varianzas de datos normales independientes.}\label{comparaciuxf3n-de-varianzas-de-datos-normales-independientes.}

\subsubsection{Premisas e hipótesis en}\label{premisas-e-hipuxf3tesis-en}

Aquí se detalla cómo comparar las varianzas de dos grupos asociados a una variable normal cuando el muestreo se ha realizado de forma independiente entre los dos grupos.

Las premisas para aplicar el test que se describe a continuación son:

\begin{itemize}
\tightlist
\item
  las dos muestras son estocásticamente independientes entre sí
\item
  las muestras de cada grupo son muestras aleatorias simples
\item
  la variable observada en cada grupo es una variable normal
\end{itemize}

Es conveniente recordar que el test que aquí se describe debe efectuarse previamente al test t -Student de 2 muestras para comprobar la última de sus premisas (ver aquí para más detalles).

De acuerdo a las premisas la variable observada sigue en la primera población una Normal \(\left(\mu_{1}, \sigma_{1}\right)\) y en la segunda una Normal \(\left(\mu_{2}, \sigma_{2}\right)\). Contrastar la homogeneidad de varianzas corresponde pues a:

\[
\mathrm{H}_{0}: \sigma_{1}=\sigma_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \sigma_{1} \neq \sigma_{2}
\]

Como es ya habitual, pueden plantearse otro tipo de alternativas, aunque son menos utilizadas en experimentación:

\[
\mathrm{H}_{0}: \sigma_{1} \leq \sigma_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \sigma_{1}>\sigma_{2}
\]

o bien:

\[
\mathrm{H}_{0}: \sigma_{1} \geq \sigma_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \sigma_{1}<\sigma_{2}
\]

\subsubsection{Estadístico de test y valores críticos}\label{estaduxedstico-de-test-y-valores-cruxedticos-1}

Hemos asumido antes que las muestras eran de tamaño \(n_{1}\) y \(n_{2}\) respectivamente para las dos poblaciones y que los estadísticos se indican mediante:

\[
\begin{aligned}
& \bar{X}_{1}, \widetilde{S}_{1}^{2} \text { promedio y varianza muestral corregida de la } 1^{\mathrm{a}} \text { población } \\
& \bar{X}_{2}, \widetilde{S}_{2}^{2} \text { promedio y varianza muestral corregida de la } 2^{\mathrm{a}} \text { población }
\end{aligned}
\]

Para resolver el contraste descrito antes se dispone de un test óptimo basado en el siguiente estadístico de test:

\[
\mathrm{F}_{\exp }=\frac{\widetilde{S}_{1}^{2}}{\widetilde{S}_{2}^{2}}
\]

conocido como contraste F de varianzas para dos muestras independientes. La distribución del estadístico es la F de Fisher con \(\left(\mathrm{n}_{1}-1, \mathrm{n}_{2}-1\right)\) grados de libertad. Según el tipo de alternativa los valores críticos son:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(\mathrm{H}_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
rechazar \(\mathrm{H}_{0} \mathrm{si}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\sigma_{1} \neq \sigma_{2}\) & \(\mathrm{~F}_{\exp } \geq \mathrm{f}_{\alpha / 2} \circ \mathrm{~F}_{\exp } \leq \mathrm{f}_{1-\alpha / 2}\) \\
\(\sigma_{1}>\sigma_{2}\) & \(\mathrm{~F}_{\exp } \geq \mathrm{f}_{\alpha}\) \\
\(\sigma_{1}<\sigma_{2}\) & \(\mathrm{~F}_{\exp } \leq \mathrm{f}_{1-\alpha}\) \\
\end{longtable}

si \(F\) es la variable aleatoria con distribución F de ( \(\mathrm{n}_{1}-1, \mathrm{n}_{2}-1\) ) grados de libertad los valores \(\mathrm{f}_{\alpha / 2}, \mathrm{f}_{1-\alpha / 2}\), \(\mathrm{f}_{\alpha}\) y \(\mathrm{f}_{1-\alpha}\) son:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(\operatorname{prob}\left(F>\mathrm{f}_{\alpha / 2}\right)=\alpha / 2\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\operatorname{prob}\left(F<\mathrm{f}_{1-\alpha / 2}\right)=\alpha / 2\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\operatorname{prob}\left(F>\mathrm{f}_{\alpha}\right)=\alpha\) & \(\operatorname{prob}\left(F<\mathrm{f}_{\alpha}\right)=1-\alpha\) \\
\end{longtable}

en otras palabras, \(\mathrm{f}_{\alpha / 2}\) y \(\mathrm{f}_{\alpha}\) son valores críticos unilaterales derechos de la \(F\) (asociados respectivamente a una probabilidad \(\alpha / 2\) y \(\alpha\) ) mientras que \(f_{1-\alpha / 2}\) y \(f_{1-\alpha}\) son unilaterales izquierdos de la misma variable aleatoria.

\subsubsection{Intervalo de confianza para la razón de varianzas}\label{intervalo-de-confianza-para-la-razuxf3n-de-varianzas}

Los límites de un intervalo de confianza \(1-\alpha \%\) para el cociente de varianzas correspondientes a dos muestras independientes son:

\[
\left(f_{1-\alpha / 2} \frac{\widetilde{S}_{1}^{2}}{\widetilde{S}_{2}^{2}}, f_{\alpha / 2} \frac{\widetilde{S}_{1}^{2}}{\widetilde{S}_{2}^{2}}\right)
\]

los símbolos \(\mathrm{f}_{\alpha / 2}\) y \(\mathrm{f}_{1-\alpha / 2}\) son los mismos valores críticos que antes: prob ( \(F>\mathrm{f}_{\alpha / 2}\) ) \(=\alpha / 2\) y prob ( \(F< f_{1-\alpha / 2}=\alpha / 2\).

Este intervalo puede utilizarse de forma alternativa al contraste de hipótesis para decidir (con nivel de significación \(\alpha\) \%) si hay igualdad de varianzas de los dos grupos. Se decidirá que no hay diferencias significativas si el valor 1 queda incluido en cualquier posición en el intervalo. El número 1 no ha de estar forzosamente en el centro del intervalo para aceptar \(\mathrm{H}_{0}\).

\subsection{Comparaciones de medias de datos normales apareados}\label{comparaciones-de-medias-de-datos-normales-apareados}

\subsubsection{Premisas e hipótesis}\label{premisas-e-hipuxf3tesis}

Las premisas para aplicar el test que se describe a continuación son:

\begin{itemize}
\tightlist
\item
  las muestras corresponden a datos apareados
\item
  la muestra (agrupada por parejas) es aleatoria simple
\item
  la variable observada en cada grupo es una variable normal
\end{itemize}

El objetivo es muy parecido al descrito anteriormente: verificar si los dos grupos son homogéneos en promedio, sólo cambian las premisas y tipo de muestreo. La variable \(\mathrm{X}_{1}\) observada en la primera población sigue una \(\operatorname{Normal}\left(\mu_{1}, \sigma_{1}\right)\) y la variable \(\mathrm{X}_{2}\) en la segunda población una \(\operatorname{Normal}\left(\mu_{2}, \sigma_{2}\right)\). Así pues, contrastar la homogeneidad de medias corresponde igualmente a:

\[
\mathrm{H}_{0}: \mu_{1}=\mu_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{1} \neq \mu_{2}
\]

Ahora bien, este contraste se resuelve ahora calculando la variable diferencia entre \(\mathrm{X}_{1}\) y \(\mathrm{X}_{2}\). Si designamos con

\[
X_{d}=X_{1}-X_{2}
\]

a esta diferencia, entonces \(\mathrm{X}_{\mathrm{d}}\) es una \(\operatorname{Normal}\left(\mu_{\mathrm{d}}, \sigma_{\mathrm{d}}\right)\). La hipótesis de homogeneidad de las medias de las muestras apareadas se traduce en una prueba de una muestra normal, es decir:

\[
\mathrm{H}_{0}: \mu_{\mathrm{d}}=0 \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{\mathrm{d}} \neq 0
\]

Como es ya habitual, pueden plantearse otro tipo de alternativas:

\[
\mathrm{H}_{0}: \mu_{\mathrm{d}} \leq 0 \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{\mathrm{d}}>0
\]

o bien:

\[
\mathrm{H}_{0}: \mu_{\mathrm{d}} \geq 0 \quad \text { contra } \quad \mathrm{H}_{1}: \mu_{1}<0
\]

\subsubsection{Relación entre el contraste de datos apareados y el de una media (datos normales).}\label{relaciuxf3n-entre-el-contraste-de-datos-apareados-y-el-de-una-media-datos-normales.}

Se dispone de una muestra de datos apareados de tamaño n (es decir, n parejas). Los estadísticos se indican mediante:

\[\bar{X}_{d}, \quad \widetilde{S}_{d}^{2},\]
promedio y varianza muestral corregida de la resta de las 2 muestras

Para resolver el contraste descrito antes se dispone de un test óptimo basado en el siguiente estadístico de test:

\[
\mathrm{T}_{\exp }=\frac{\bar{X}_{d}}{\widetilde{S}_{d}} \sqrt{n}
\]

que \textbf{no es más que el contraste T para una muestra calculado con cuya distribución es la t de Student con (n-1) grados de libertad}.

Según el tipo de alternativa los valores críticos son:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(\mathrm{H}_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
rechazar \(\mathrm{H}_{0} \mathrm{si}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mu_{\mathrm{d}} \neq 0\) & \(\left\|\mathrm{~T}_{\exp }\right\| \geq \mathrm{t}_{\alpha / 2}\) \\
\(\mu_{\mathrm{d}}>0\) & \(\mathrm{~T}_{\exp } \geq \mathrm{t}_{\alpha}\) \\
\(\mu_{\mathrm{d}}<0\) & \(\mathrm{~T}_{\exp } \leq-\mathrm{t}_{\alpha}\) \\
\end{longtable}

si T es la variable aleatoria t -Student \((\mathrm{n}-1)\) los valores \(\mathrm{t}_{\alpha / 2}\) y \(\mathrm{t}_{\alpha}\) son:

\[
\operatorname{prob}\left(\mathrm{T}>\mathrm{t}_{\alpha / 2}\right)=\alpha / 2 \quad \operatorname{prob}\left(\mathrm{~T}>\mathrm{t}_{\alpha}\right)=\alpha
\]

en otras palabras, \(\mathrm{t}_{\alpha / 2}\) es el valor crítico bilateral de la T asociada a una probabilidad \(\alpha\) mientras que \(\mathrm{t}_{\alpha}\) es el valor crítico unilateral derecho de la misma v.a.

\subsubsection{Intérvalos de confianza para la diferencia}\label{intuxe9rvalos-de-confianza-para-la-diferencia}

El intervalo de confianza para la media de la variable diferencia es el mismo que el de la media de una muestra normal, es decir:

\[
\bar{X}_{d} \pm t_{\alpha / 2} \frac{\widetilde{S}_{d}}{\sqrt{n}}
\]

\subsubsection{Tamaño muestral}\label{tamauxf1o-muestral}

Finalmente, el tamaño de muestra también corresponde al mismo caso:

\[
n=\left(\frac{t_{\alpha / 2}+t_{1-\beta}}{\Delta}\right)^{2} \widetilde{S}_{d}^{2}
\]

\subsubsection{Ejemplo: efecto de una intervención sobre el colesterol HDL}\label{ejemplo-efecto-de-una-intervenciuxf3n-sobre-el-colesterol-hdl}

Se estudia el efecto de una intervención destinada a aumentar el colesterol HDL en un grupo de \(n = 10\) pacientes.
En cada paciente se mide el nivel de HDL (en mg/dL) antes y después de la intervención.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}

\NormalTok{HDL\_antes   }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{35}\NormalTok{, }\AttributeTok{sd =} \DecValTok{4}\NormalTok{), }\DecValTok{1}\NormalTok{)}
\NormalTok{HDL\_despues }\OtherTok{\textless{}{-}} \FunctionTok{round}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{10}\NormalTok{, }\AttributeTok{mean =} \DecValTok{45}\NormalTok{, }\AttributeTok{sd =} \DecValTok{4}\NormalTok{), }\DecValTok{1}\NormalTok{)}

\NormalTok{HDL\_antes}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 32.8 34.1 41.2 35.3 35.5 41.9 36.8 29.9 32.3 33.2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{HDL\_despues}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 49.9 46.4 46.6 45.4 42.8 52.1 47.0 37.1 47.8 43.1
\end{verbatim}

\paragraph{Definición de la variable diferencia}\label{definiciuxf3n-de-la-variable-diferencia}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{D }\OtherTok{\textless{}{-}}\NormalTok{ HDL\_despues }\SpecialCharTok{{-}}\NormalTok{ HDL\_antes}
\NormalTok{D}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 17.1 12.3  5.4 10.1  7.3 10.2 10.2  7.2 15.5  9.9
\end{verbatim}

\paragraph{Planteamiento de las hipótesis}\label{planteamiento-de-las-hipuxf3tesis}

Las hipótesis del contraste son

\[
H_0: \mu_D = 0
\quad \text{frente a} \quad
H_1: \mu_D \neq 0.
\]

\paragraph{Cálculo del estadístico de contraste}\label{cuxe1lculo-del-estaduxedstico-de-contraste}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{mean}\NormalTok{(D)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 10.52
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(D)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.645941
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T }\OtherTok{\textless{}{-}} \FunctionTok{mean}\NormalTok{(D) }\SpecialCharTok{/}\NormalTok{ (}\FunctionTok{sd}\NormalTok{(D) }\SpecialCharTok{/} \FunctionTok{sqrt}\NormalTok{(}\FunctionTok{length}\NormalTok{(D)))}
\NormalTok{T}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 9.124436
\end{verbatim}

Bajo la hipótesis nula, este estadístico sigue una distribución \(t\) de Student con \(n-1 = 9\) grados de libertad.

\paragraph{Decisión mediante el p-valor}\label{decisiuxf3n-mediante-el-p-valor}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2} \SpecialCharTok{*}\NormalTok{ (}\DecValTok{1} \SpecialCharTok{{-}} \FunctionTok{pt}\NormalTok{(}\FunctionTok{abs}\NormalTok{(T), }\AttributeTok{df =} \FunctionTok{length}\NormalTok{(D) }\SpecialCharTok{{-}} \DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 7.629805e-06
\end{verbatim}

\textbf{Uso de \texttt{t.test} sobre la variable diferencia}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(D)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  D
## t = 9.1244, df = 9, p-value = 7.63e-06
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##   7.911851 13.128149
## sample estimates:
## mean of x 
##     10.52
\end{verbatim}

\textbf{Uso de \texttt{t.test} con la opción \texttt{paired\ =\ TRUE}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(HDL\_despues, HDL\_antes, }\AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  HDL_despues and HDL_antes
## t = 9.1244, df = 9, p-value = 7.63e-06
## alternative hypothesis: true mean difference is not equal to 0
## 95 percent confidence interval:
##   7.911851 13.128149
## sample estimates:
## mean difference 
##           10.52
\end{verbatim}

Ambos procedimientos producen exactamente el mismo resultado, ya que en ambos casos el contraste
se basa en la variable diferencia.

La opción \texttt{paired\ =\ TRUE} no define un contraste distinto, sino que indica a R que debe construir
internamente la variable \(D = \text{HDL}_{\text{después}} - \text{HDL}_{\text{antes}}\)
y aplicar sobre ella un contraste de una muestra.

\subsubsection{Resumen: Datos independientes frente a datos apareados}\label{resumen-datos-independientes-frente-a-datos-apareados}

La distinción entre datos independientes y datos apareados no depende del contraste estadístico,
sino del diseño del estudio y del modo en que se han obtenido los datos.

\begin{itemize}
\item
  Datos independientes: Dos muestras son independientes cuando las observaciones de una muestra no guardan ninguna relación directa con las observaciones de la otra.
\item
  Datos apareados: En los datos apareados, cada observación de una muestra está emparejada con una observación concreta de la otra. El análisis no se centra en comparar dos poblaciones distintas, sino en estudiar la distribución de las diferencias.
\end{itemize}

Así pues es importante recordar que \textbf{no existen contrastes específicos para datos apareados.}

El apareamiento se incorpora al análisis transformando los datos originales en una muestra de diferencias, y aplicando posteriormente un contraste de una sola muestra sobre dicha variable.

\subsection{Comparaciones de 2 proporciones (datos independientes)}\label{comparaciones-de-2-proporciones-datos-independientes}

\subsubsection{Premisas e hipótesis}\label{premisas-e-hipuxf3tesis-1}

Otra de las pruebas estadísticas más básicas consiste en comprobar si la proporción de veces que ocurre un suceso es la misma en dos grupos diferentes. Se basa en la obtención de dos muestras donde en cada una de ellas se contabiliza el número de veces que ocurre el suceso estudiado.

Las premisas para aplicar el test que se describe a continuación son:

\begin{itemize}
\tightlist
\item
  las dos muestras son estocásticamente independientes entre sí
\item
  las muestras de cada grupo son dos muestras aleatorias simples de tamaños respectivos \(\mathrm{n}_{1}\) y \(\mathrm{n}_{2}\)
\item
  la variable observada en cada grupo corresponde a una variable binomial
\end{itemize}

El objetivo es corroborar o descartar que dos grupos son homogéneos en la proporción del suceso que se contabiliza. De acuerdo a las premisas la variable observada sigue en la primera población una Binomial \(\left(\mathrm{n}_{1}, \mathrm{p}_{1}\right)\) y en la segunda una Binomial \(\left(\mathrm{n}_{2}, \mathrm{p}_{2}\right)\). Contrastar la homogeneidad de proporciones corresponde pues a:

\[
\mathrm{H}_{0}: \mathrm{p}_{1}=\mathrm{p}_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \mathrm{p}_{1} \neq \mathrm{p}_{2}
\]

Pueden plantearse otro tipo de alternativas:

\[
\mathrm{H}_{0}: \mathrm{p}_{1} \leq \mathrm{p}_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \mathrm{p}_{1}>\mathrm{p}_{2}
\]

o bien:

\[
\mathrm{H}_{0}: \mathrm{p}_{1} \geq \mathrm{p}_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \mathrm{p}_{1}<\mathrm{p}_{2}
\]

\subsubsection{Estadístico de test y valores críticos}\label{estaduxedstico-de-test-y-valores-cruxedticos-2}

Los estadísticos necesarios para el test se indican mediante:
\(\hat{p}_{1}\) proporción del suceso en la \(1^{\mathrm{a}}\) muestra
\(\hat{p}_{2}\) proporción del suceso en la \(2^{\mathrm{a}}\) muestra

\[
\hat{p}=\frac{\mathrm{n}_{1} \hat{p}_{1}+\mathrm{n}_{2} \hat{p}_{2}}{\mathrm{n}_{1}+\mathrm{n}_{2}} \quad \hat{q}=1-\hat{p}
\]

Para resolver el contraste descrito antes se dispone de un test óptimo basado en el siguiente estadístico de test:

\[
\mathrm{Z}_{\exp }=\frac{\hat{p}_{1}-\hat{p}_{2}}{\sqrt{\frac{\hat{p} \hat{q}}{n_{1}}+\frac{\hat{p} \hat{q}}{n_{2}}}}
\]

cuya distribución asintótica (ver condiciones aquí) es la Normal ( 0,1 ). Según el tipo de alternativa los valores críticos son:

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\centering\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\(\mathrm{H}_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
rechazar \(\mathrm{H}_{0} \mathrm{si}\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathrm{p}_{1} \neq \mathrm{p}_{2}\) & \(\left\|\mathrm{Z}_{\exp }\right\| \geq \mathrm{z}_{\alpha / 2}\) \\
\(\mathrm{p}_{1}>\mathrm{p}_{2}\) & \(\mathrm{Z}_{\exp } \geq \mathrm{z}_{\alpha}\) \\
\(\mathrm{p}_{1}<\mathrm{p}_{2}\) & \(\mathrm{Z}_{\exp } \leq-\mathrm{z}_{\alpha}\) \\
\end{longtable}

si \(Z\) es la variable aleatoria normal tipificada, los valores \(\mathrm{z}_{\alpha / 2}\) y \(\mathrm{z}_{\alpha}\) son:

\[
\begin{gathered}
\operatorname{prob}\left(Z>\mathrm{z}_{\alpha / 2}\right)=\alpha / 2 \\
\operatorname{prob}\left(Z>\mathrm{z}_{\alpha}\right)=\alpha
\end{gathered}
\]

en otras palabras, \(z_{\alpha / 2}\) es el valor crítico bilateral de la \(\operatorname{Normal}(0,1)\) asociada a una probabilidad \(\alpha\) mientras que \(\mathrm{z}_{\alpha}\) es el valor crítico unilateral derecho de la misma variable aleatoria.

\subsubsection{Condiciones de aplicación del test}\label{condiciones-de-aplicaciuxf3n-del-test}

Esta prueba tiene carácter asintótico, para que la aproximación a la \(\operatorname{Normal}(0,1)\) sea adecuada se requiere que:

\[
\begin{array}{cc}
\mathrm{n}_{1} \geq 30 & \mathrm{n}_{2} \geq 30 \\
\mathrm{n}_{1} \hat{p}_{1} \geq 5 & \mathrm{n}_{2} \hat{p}_{2} \geq 5
\end{array}
\]

\subsubsection{Intervalo de confianza para la diferencia de proporciones (datos independientes).}\label{intervalo-de-confianza-para-la-diferencia-de-proporciones-datos-independientes.}

Los límites para el intervalo de una diferencia de proporciones correspondientes a dos muestras independientes son:

\[
\hat{p}_{1}-\hat{p}_{2} \pm z_{\alpha / 2} \sqrt{\frac{\hat{p}_{1}\left(1-\hat{p}_{1}\right)}{n_{1}}+\frac{\hat{p}_{2}\left(1-\hat{p}_{2}\right)}{n_{2}}}
\]

el símbolo \(\mathrm{z}_{\alpha / 2}\) es el mismo valor crítico que antes: \(\operatorname{prob}\left(Z>\mathrm{z}_{\alpha / 2}\right)=\alpha / 2\).y corresponde a un intervalo de confianza \(1-\alpha \%\).

Este intervalo puede utilizarse de forma alternativa al contraste de hipótesis para decidir (con nivel de significación \(\alpha\) \%) si hay igualdad de los dos grupos. Se decidirá por la igualdad de los grupos si el valor 0 queda incluido en cualquier posición en el intervalo.

Aún si se realiza el contraste de dos proporciones en primer lugar, es aconsejable obtener el I.C. de la diferencia de medias si éste ha resultado significativo, puesto que ayudará a interpretar si existe significación aplicada además de la estadística.

Si se dispone de alguna información previa y quiere calcularse sólo alguno de los dos intervalos unilaterales, bastará sustituir \(\mathrm{z}_{\alpha / 2}\) por \(\mathrm{z}_{\alpha} \mathrm{y}\) descartar el límite superior o inferior del intervalo según el caso. Por ejemplo, el intervalo unilateral derecho corresponde a:

\[
\left(-\infty, \hat{p}_{1}-\hat{p}_{2} \pm z_{\alpha} \sqrt{\frac{\hat{p}_{1}\left(1-\hat{p}_{1}\right)}{n_{1}}+\frac{\hat{p}_{2}\left(1-\hat{p}_{2}\right)}{n_{2}}}\right)
\]

\subsubsection{Cálculo del tamaño de muestra en el contraste de proporciones de datos independientes.}\label{cuxe1lculo-del-tamauxf1o-de-muestra-en-el-contraste-de-proporciones-de-datos-independientes.}

Supongamos que se desea realizar el contraste bilateral:

\[
\mathrm{H}_{0}: \mathrm{p}_{1}=\mathrm{p}_{2} \quad \text { contra } \quad \mathrm{H}_{1}: \mathrm{p}_{1} \neq \mathrm{p}_{2}
\]

Una vez el experimentador ha elegido el nivel de significación ( \(\alpha\) ) la mínima diferencia significativa \((\Delta)\) y la potencia \((\beta)\) debe obtenerse una prueba piloto donde se estiman las proporciones del suceso tanto en las 2 poblaciones por separado como en la población conjunta. Luego puede ya determinarse el tamaño de muestra adecuado:

\[
n=\left(\frac{z_{\alpha / 2} \sqrt{2 \hat{p} \hat{q}}+z_{\beta} \sqrt{\hat{p}_{1}\left(1-\hat{p}_{1}\right)+\hat{p}_{2}\left(1-\hat{p}_{2}\right)}}{\Delta}\right)^{2}
\]

Las constantes \(z_{\alpha / 2}\) y \(z_{1-\beta}\) corresponden a las siguientes colas derechas de la v.a. \(\operatorname{Normal}(0,1)\)

\[
p\left(Z \geq z_{\alpha / 2}\right)=\alpha / 2 \quad p\left(Z \geq z_{1-\beta}\right)=1-\beta
\]

Si el contraste es unilateral, basta cambiar en la expresión del tamaño de muestra \(z_{\alpha / 2}\) por \(z_{\alpha}\).

\subsection{Comparaciones de dos muestras: Tabla resumen}\label{comparaciones-de-dos-muestras-tabla-resumen}

Los contrastes vistos en este tema se resumen en:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}
  >{\raggedright\arraybackslash}p{(\linewidth - 10\tabcolsep) * \real{0.1667}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Premisas
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\mathrm{H}_{0}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Estadístico
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Distribución
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\mathrm{H}_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Rechazar \(\mathrm{H}_{0} \mathrm{si}\) :
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2 muestras normales datos independientes varianzas iguales & \(\mu_{1}-\mu_{2}=\mathrm{d}_{0}\) & \(\mathrm{T}_{\text {exp }}=\frac{\bar{X}_{1}-\bar{X}_{2}-d_{0}}{\sqrt{\frac{\left(n_{1}-1\right) \widetilde{S}_{1}^{2}+\left(n_{2}-1\right) \widetilde{S}_{2}^{2}}{n_{1}+n_{2}-2} \frac{\left(n_{1}+n_{2}\right)}{n_{1} n_{2}}}}\) & t-Student ( \(\mathrm{n}_{1}+\mathrm{n}_{2}-2\) ) & \(\mu_{1}-\mu_{2} \neq \mathrm{d}_{0}\) & \(\left\|\mathrm{T}_{\exp }\right\| \geq \mathrm{t}_{\alpha / 2}\) \\
& & & & \(\mu_{1}-\mu_{2}>\mathrm{d}_{0}\) & \(\mathrm{T}_{\text {exp }} \geq \mathrm{t}_{\alpha}\) \\
& & & & \(\mu_{1}-\mu_{2}<\mathrm{d}_{0}\) & \(\mathrm{T}_{\text {exp }} \leq-\mathrm{t}_{\alpha}\) \\
2 muestras normales datos independientes & \(\sigma_{1}=\sigma_{2}\) & \(\mathrm{F}_{\text {exp }}=\frac{\widetilde{S}_{1}^{2}}{\widetilde{S}_{2}^{2}}\) & Fisher ( \(\mathrm{n}_{1}-1, \mathrm{n}_{2}-1\) ) & \(\sigma_{1} \neq \sigma_{2}\) & \(\mathrm{F}_{\text {exp }} \geq \mathrm{f}_{\alpha / 2}\) o \(\mathrm{F}_{\exp } \leq \mathrm{f}_{1-\alpha / 2}\) \\
& & & & \(\sigma_{1}>\sigma_{2}\) & \(\mathrm{F}_{\text {exp }} \geq \mathrm{f}_{\alpha}\) \\
& & & & \(\sigma_{1}<\sigma_{2}\) & \(\mathrm{F}_{\text {exp }} \leq \mathrm{f}_{1-\alpha}\) \\
2 muestras normales datos apareados & \(\mu_{\mathrm{d}}=0\) & \(\mathrm{T}_{\text {exp }}=\frac{\bar{X}_{d}}{\widetilde{S}_{d}} \sqrt{n}\) & t-Student (n-1) & \(\mu_{\mathrm{d}} \neq 0\) & \(\left\|\mathrm{T}_{\text {exp }}\right\| \geq \mathrm{t}_{\alpha / 2}\) \\
& & & & \(\mu_{\mathrm{d}}>0\) & \(\mathrm{T}_{\exp } \geq \mathrm{t}_{\alpha}\) \\
& & & & \(\mu_{\mathrm{d}}<0\) & \(\mathrm{T}_{\text {exp }} \leq-\mathrm{t}_{\alpha}\) \\
\(\mathrm{n}_{1}\) y \(\mathrm{n}_{2} \geq 30 \mathrm{n}_{1} \overline{\mathrm{p}}_{1} \geq 5 \mathrm{n}_{2} \overline{\mathrm{p}}_{2} \geq 5\) & \(\mathrm{p}_{1}=\mathrm{p}_{2}\) & \(\mathrm{Z}_{\exp }=\frac{\hat{p}_{1}-\hat{p}_{2}}{\sqrt{\frac{\hat{p} \hat{q}}{n_{1}}+\frac{\hat{p} \hat{q}}{n_{2}}}}\) & Normal \((0,1)\) & \(\mathrm{p}_{1} \neq \mathrm{p}_{2}\) & \(\left\|\mathrm{Z}_{\text {exp }}\right\| \geq \mathrm{z}_{\alpha / 2}\) \\
& & & & \(\mathrm{p}_{1}>\mathrm{p}_{2}\) & \(\mathrm{Z}_{\text {exp }} \geq \mathrm{z}_{\alpha}\) \\
& & & & \(\mathrm{p}_{1}<\mathrm{p}_{2}\) & \(\mathrm{Z}_{\text {exp }} \leq-\mathrm{z}_{\alpha}\) \\
\end{longtable}

Notación.:
\(\bar{X}_{1}, \widetilde{S}_{1}^{2}\) promedio y varianza muestral corregida de la \(1{ }^{\text {a }}\) población
\(\bar{X}_{2}, \widetilde{S}_{2}^{2}\) promedio y varianza muestral corregida de la \(2^{\mathrm{a}}\) población
\(\bar{X}_{d}, \widetilde{S}_{d}^{2}\) promedio y varianza muestral corregida de la resta de las 2 muestras
\(\hat{p}_{1}\) proporción del suceso en la \(1^{\mathrm{a}}\) muestra
\(\hat{p}_{2}\) proporción del suceso en la \(2^{\mathrm{a}}\) muestra
\(\hat{p}=\frac{\mathbf{n}_{1} \hat{p}_{1}+\mathbf{n}_{2} \hat{p}_{2}}{\mathbf{n}_{1}+\mathbf{n}_{2}} \quad \hat{q}=\mathbf{1}-\hat{p}\)
\(F\) sigue la distribución F de Fisher, entonces \(\mathrm{f}_{\alpha / 2}, \mathrm{f}_{1-\alpha / 2}, \mathrm{f}_{\alpha}\) y \(\mathrm{f}_{1-\alpha}\) son:

\[
\begin{aligned}
\operatorname{prob}\left(F>\mathrm{f}_{\alpha / 2}\right) & =\alpha / 2 \\
\operatorname{prob}\left(F>\mathrm{f}_{\alpha}\right) & =\alpha
\end{aligned}
\]

\[
\begin{gathered}
\operatorname{prob}\left(F<\mathrm{f}_{1-\alpha / 2}\right)=\alpha / 2 \\
\operatorname{prob}\left(f<\mathrm{f}_{\alpha}\right)=1-\alpha
\end{gathered}
\]

si \(T\) es la variable aleatoria t -Student, \(\operatorname{prob}\left(T>\mathrm{t}_{\alpha / 2}\right)=\alpha / 2\) y \(\operatorname{prob}\left(T>\mathrm{t}_{\alpha}\right)=\alpha\)
si Z es la variable normal tipificada, \(\operatorname{prob}\left(Z>\mathrm{z}_{\alpha / 2}\right)=\alpha / 2\) y prob \(\left(Z>\mathrm{z}_{\alpha}\right)=\alpha\)

\subsection{Complementos: efecto de las transformaciones de los datos en el test t}\label{complementos-efecto-de-las-transformaciones-de-los-datos-en-el-test-t}

Para acabar de comprender el funcionamiento del test T es interesante considerar el efecto que tiene sobre dicho contrastes dos típicas operaciones sobre un conjunto de datos:

\begin{itemize}
\tightlist
\item
  cambio de posición: esto es, sumar una constante a todos los datos.
\item
  cambio de escala: esto es, multiplicar por una constante todos los datos.
\end{itemize}

\subsubsection{Efecto del cambi de posición}\label{efecto-del-cambi-de-posiciuxf3n}

Veamos primero el efecto del primer tipo de cambio desde un punto de vista empírico, tomando dos grupos de datos independientes (para más detalles, corresponden a los datos del casol de este mismo tema). Los datos originales (en breve, diferencia de peso de unos pacientes en kilos) y el resultado del test T se detallan a continuación para poder comparar con en el cuadro más abajo donde se modificarán:

Supongamos que se ha detectado un error en la balanza que medía el peso, sistemático para todos los datos, lo cual implica sumar 2 kilos a todos los datos del estudio. Si se modifican adecuadamente los datos (sumar 2 a todos ellos):
se ha de observar que:

\begin{itemize}
\tightlist
\item
  las medias de los dos grupos se han incrementado en dos unidades
\item
  las desviaciones de los dos grupos se mantienen constantes
\item
  toda la inferencia de comparación de medias se mantiene constante (Estadístico T, p-valor, intervalo, etc).
\end{itemize}

Para entender este resultado empírico, y razonando ahora en general, si a todos los datos originales ( \(\mathrm{x}_{1}\), \(\left.\mathrm{x}_{2}, \ldots \mathrm{x}_{\mathrm{n}}\right)\) se les añade la constante \(k\)

\[
\mathrm{y}_{1}=\mathrm{x}_{1}+k, \mathrm{y}_{2}=\mathrm{x}_{2}+k, \ldots, \mathrm{y}_{\mathrm{n}}=\mathrm{x}_{\mathrm{n}}+k
\]

la media y la varianza de la nueva variable Y van a ser:

\[
\bar{Y}=\bar{X}+k \quad \widetilde{S}_{Y}^{2}=\widetilde{S}_{X}^{2}
\]

así pues, en el caso de tener dos grupos de datos, la varianza de cada grupo -y por tanto también la ponderada- se mantienen constantes. El estadístico de test va a ser:

\[
T_{Y}=\frac{\left(\bar{X}_{1}+k\right)-\left(\bar{X}_{2}+k\right)-d_{0}}{\sqrt{\frac{\left(n_{1}-1\right) \widetilde{S}_{1}^{2}+\left(n_{2}-1\right) \widetilde{S}_{2}^{2}}{n_{1}+n_{2}-2} \frac{\left(n_{1}+n_{2}\right)}{n_{1} n_{2}}}}=T_{K}
\]

La conclusión es que el test t no se ve alterado por un cambio de posición en todos los datos.

\subsubsection{Efecto de un cambio de escala}\label{efecto-de-un-cambio-de-escala}

Veamos ahora el efecto del segundo tipo de cambio desde un punto de vista empírico. Con los datos originales (corresponden a los datos del casol de este mismo tema), el resultado del test T es:

Supongamos que se decide cambiar de unidad, pasando a decigramos en lugar de kilogramos. Equivale a multiplicar por cien todos los datos del estudio. Modificando adecuadamente los datos siguientes:
se ha de observar que:

\begin{itemize}
\tightlist
\item
  las medias de los dos grupos se han multiplicado por cien
\item
  las desviaciones de los dos grupos se han multiplicado por cien
\item
  el Estadístico T y el p-valor se mantienen constantes (el I.C. es 100 veces mayor).
\end{itemize}

Para entender este resultado, razonando de nuevo en general, si todos los datos originales ( \(\mathrm{x}_{1}, \mathrm{x}_{2}, \ldots \mathrm{x}_{\mathrm{n}}\) ) se multiplican por \(k\)

\[
\mathrm{y}_{1}=k \mathrm{x}_{1}, \mathrm{y}_{2}=k \mathrm{x}_{2}, \ldots, \mathrm{y}_{\mathrm{n}}=k \mathrm{x}_{\mathrm{n}}
\]

la media y la varianza de la nueva variable Y van a ser:

\[
\bar{Y}=k \bar{X} \quad \widetilde{S}_{Y}^{2}=k^{2} \widetilde{S}_{X}^{2}
\]

así pues, en el caso de tener dos grupos de datos, la varianza de cada grupo -y por tanto también la ponderada- se multiplica por \(k^{2}\). El estadístico de test va a ser:

\[
T_{Y}=\frac{k \bar{X}_{1}-k \bar{X}_{2}-k d_{0}}{\sqrt{\frac{\left(n_{1}-1\right) k^{2} \widetilde{S}_{1}^{2}+\left(n_{2}-1\right) k^{2} \widetilde{S}_{2}^{2}}{n_{1}+n_{2}-2} \frac{\left(n_{1}+n_{2}\right)}{n_{1} n_{2}}}}=T_{X}
\]

y se cancelan la constante \(k\) en el numerador y el denominador. La conclusión es que el test t no se ve alterado por un cambio de escala todos los datos.

\#\#Muestreo aleatorio simple

Los valores de la muestra son elegidos de modo que las observaciones son independientes dos a dos y todas siguen la misma distribución probabilística.

Una propiedad matemática importante es que la función de densidad de la muestra, entendida como vector aleatorio, es el producto de las funciones de densidad de sus variables. Igualmente ocurre con la función de distribución.

En poblaciones finitas, una posibilidad de asegurar la aleatoriedad de los datos consiste en la utilización de números aleatorios.

En R es muy sencillo obtener números aleatorios enteros. Por ejemplo para generar diez aleatorios entre 1 y 25 haríamos simplemente:

\begin{itemize}
\tightlist
\item
  Si queremos que los números se puedan repetir
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{25}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{replace=}\ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 15 10 13  7  9  9 10 23 21  7
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Si queremos que sean aleatorios pero no puedan aparecer dos veces:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{25}\NormalTok{, }\DecValTok{10}\NormalTok{, }\AttributeTok{replace=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 21  6  2  5  8 12 13 18  1  9
\end{verbatim}

\subsection{Presentación del caso 1}\label{presentaciuxf3n-del-caso-1}

Una empresa farmacéutica está probando un nuevo fármaco para adelgazar denominado Prim. En esta fase del ensayo clínico se pretende comparar el efecto de Prim con un fármaco de la competencia conocido como Nofat. Se considerará relevante la diferencia si es de al menos 2 kilogramos en promedio entre los dos fármacos.

En la prueba piloto se desea experimentar sobre 20 personas voluntarias sometidas a una misma dieta, pero medicadas 10 de ellas con Prim y otras 10 con Nofat. La variable observada será la diferencia de peso en kilogramos entre el inicio y el final del estudio. Los datos iniciales son:

\begin{longtable}[]{@{}llll@{}}
\toprule\noalign{}
Individuo & Peso & Individuo & Peso \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & 127.5 & 11 & 117.5 \\
2 & 101.0 & 12 & 115.0 \\
3 & 99.5 & 13 & 139.5 \\
4 & 110.5 & 14 & 130.5 \\
5 & 115.5 & 15 & 125.5 \\
6 & 95.5 & 16 & 135.5 \\
7 & 105.5 & 17 & 115.5 \\
8 & 110.5 & 18 & 120.5 \\
9 & 98.5 & 19 & 118.5 \\
10 & 106.0 & 20 & 116.0 \\
\end{longtable}

\newpage

\section{Las pruebas ``Chi-cuadrado''}\label{las-pruebas-chi-cuadrado}

\subsection{Introducción}\label{introducciuxf3n-8}

Con el nombre de \textbf{pruebas de chi-cuadrado} se conoce una variedad de contrastes estadísticos que hacen referencia a problemas distintos pero que presentan los siguientes rasgos en común:

\begin{itemize}
\tightlist
\item
  Las muestras corresponden a \textbf{datos categóricos}, directamente o por categorización de una variable numérica; es decir, se observa si un individuo pertenece a un elemento de una partición \(A_{1}, A_{2}, \ldots, A_{k}\) del espacio muestral.
\item
  El estadístico del contraste tiene una estructura común:
\end{itemize}

\[
\sum_{i} \frac{(O_i - E_i)^2}{E_i}
\]

donde

\begin{itemize}
\tightlist
\item
  \(O_i\) es el número de observaciones en la categoría \(i\),
\item
  \(E_i\) es el número de observaciones esperadas en dicha categoría bajo la hipótesis nula.
\end{itemize}

En todos los casos, el estadístico del contraste tiene \textbf{distribución asintótica} \(\chi^2\).

Consideramos tres grandes grupos de pruebas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Pruebas de bondad de ajuste (\emph{goodness of fit}):

  \begin{enumerate}
  \def\labelenumii{(\alph{enumii})}
  \tightlist
  \item
    todos los parámetros de la distribución son conocidos;\\
  \item
    algunos parámetros de la distribución son desconocidos.
  \end{enumerate}
\item
  Pruebas de independencia.
\item
  Pruebas de homogeneidad.
\end{enumerate}

\subsection{\texorpdfstring{Pruebas \(\chi^2\) de bondad de ajuste}{Pruebas \textbackslash chi\^{}2 de bondad de ajuste}}\label{pruebas-chi2-de-bondad-de-ajuste}

\subsubsection{Hipótesis simples}\label{hipuxf3tesis-simples}

Sea \(X_1, X_2, \ldots, X_n\) una \textbf{muestra aleatoria simple (m.a.s.)} de una variable aleatoria \(X\). Queremos contrastar la hipótesis de que \(X\) sigue una distribución completamente especificada \(F_{\theta_0}\):

\[
\begin{aligned}
H_0 &: X \sim F_{\theta_0},\\
H_1 &: X \nsim F_{\theta_0}.
\end{aligned}
\]

Sea \(R\) el \textbf{soporte} (recorrido) de la distribución poblacional y consideremos una partición de \(R\) en \(k\) subconjuntos disjuntos \(R_1, R_2, \ldots, R_k\). Esto induce una partición del espacio muestral en los sucesos

\[
A_i = \{X \in R_i\}, \quad i=1,\ldots,k.
\]

Si \(n_i\) denota el número de observaciones muestrales que caen en \(R_i\), el vector de recuentos \((n_1, \ldots, n_k)\) sigue una distribución multinomial

\[
(n_1, \ldots, n_k) \sim M\bigl(n; p_1, \ldots, p_k\bigr),
\]

donde \(p_i = P(A_i)\).

Este planteamiento transforma el contraste sobre la distribución de \(X\) en un contraste sobre las probabilidades \((p_1, \ldots, p_k)\):

\[
\begin{aligned}
H_0 &: P(A_i) = p_i^0 = \int_{R_i} dF_{\theta_0}(x),\\
H_1 &: P(A_i) \neq p_i^0.
\end{aligned}
\]

Obsérvese que \textbf{no se contrasta} que el vector de recuentos tenga distribución multinomial (esto viene dado por el muestreo), sino si las probabilidades \(p_i\) coinciden con las impuestas por la hipótesis nula.

\subsubsection{Estadístico de Pearson}\label{estaduxedstico-de-pearson}

A comienzos del siglo XX, \textbf{Karl Pearson} propuso como estadístico de contraste la cantidad

\[
D^2 = \sum_{i=1}^k \frac{(n_i - n p_i^0)^2}{n p_i^0}.
\]

Este estadístico mide la discrepancia entre las frecuencias observadas y las esperadas bajo \(H_0\). Su interés fundamental radica en que se conoce su distribución asintótica bajo la hipótesis nula.

\paragraph{Teorema (Pearson)}\label{teorema-pearson}

Si las probabilidades \(p_1^0, \ldots, p_k^0\) son conocidas, entonces

\[
D^2 \xrightarrow[n\to\infty]{\mathcal{L}} \chi^2_{k-1}.
\]

Este resultado permite construir un contraste asintótico de nivel \(\alpha\) que rechaza \(H_0\) cuando

\[
D^2 \ge \chi^2_{k-1,1-\alpha}.
\]

\subsubsection{Observaciones prácticas}\label{observaciones-pruxe1cticas}

\begin{itemize}
\tightlist
\item
  El contraste es \textbf{asintótico}, por lo que se requiere un tamaño muestral suficientemente grande. En la práctica se exige que todas las frecuencias esperadas cumplan \(n p_i^0 \ge 5\).
\item
  El contraste depende de la partición elegida. Conviene tomar \(k \ge 5\) siempre que sea posible para evitar situaciones poco discriminantes.
\end{itemize}

\subsubsection{Ejemplo}\label{ejemplo-10}

Una compañía afirma que el número diario de accidentes laborales sigue una distribución de Poisson de parámetro \(\lambda=2\). Un estudio, basado en los accidentes producidos durante 200 días, da el resultado siguiente:

\begin{longtable}[]{@{}lcccccccc@{}}
\toprule\noalign{}
\(N^{\underline{O}}\) de accidentes & 0 & 1 & 2 & 3 & 4 & 5 & 6 & 7 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Días & 22 & 53 & 58 & 39 & 20 & 5 & 2 & 1 \\
\end{longtable}

Para contrastar el ajuste a una distribución de Poisson debemos calcular las probabilidades

\[
p_{i}^{0}=P_{\lambda=2}[X=i]=e^{-\lambda} \frac{\lambda^{i}}{i!}, \quad i=1, \ldots, 7 .
\]

Las frecuencias esperadas serán \(n p_{i}^{0}=200 p_{i}^{0}\). Cuando \(i=6,7\) los valores son demasiado pequeños, de forma que se agrupan los valores en una única categoría ``\(i \geq 5\)''.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(x_{i}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
0
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\geq 5\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\Sigma\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n_{i}\) & 22 & 53 & 58 & 39 & 20 & 8 & 200 \\
\(p_{i}^{0}\) & 0.135 & 0.271 & 0.271 & 0.180 & 0.090 & 0.053 & 1 \\
\(n p_{i}^{0}\) & 27.067 & 54.134 & 54.134 & 36.089 & 18.045 & 10.531 & 200 \\
\(\frac{\left(n p_{i}^{0}-n_{i}\right)^{2}}{n p_{i}^{0}}\) & 0.9486 & 0.0238 & 0.2761 & 0.2347 & 0.2119 & 0.6081 & 2.303 \\
\end{longtable}

El valor del estadístico de test es, por tanto, 2.303. El \(p\)-valor correspondiente, es decir, \(P\left(\chi_{6-1}^{2} \geq 2.303\right)\), es 0.80588 y, por tanto, no podemos rechazar la hipótesis de que los datos siguen una distribución de Poisson de parámetro \(\lambda=2\). Otra forma de tomar la misma decisión es observar que el percentil 0.95 de dicha distribución es \(\chi_{5,0.95}^{2}=11.07\), de donde, dado que \(2.303<\chi_{5,0.95}^{2}\), vemos que no podemos rechazar \(H_{0}\).

\subsubsection{Ejemplo}\label{ejemplo-11}

Un cierto modelo genético para unas plantas cuyas flores pueden ser blancas, rosas o rojas afirma que la proporción con la que deben aparecer es de \(1:2:1\). En un estudio se obtuvieron 113 flores blancas, 242 rosas y 112 rojas. ¿Concuerdan las observaciones con el modelo? Construimos la tabla de cálculos y obtenemos:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2083}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2083}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2083}}
  >{\centering\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2083}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\(A_{i}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Blanca
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Rosa
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Rojas
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\(\Sigma\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n_{i}\) & 112 & 242 & 112 & 467 \\
\(p_{i}^{0}\) & 0.25 & 0.5 & 0.25 & 1 \\
\(n p_{i}^{0}\) & 116.7 & 233 & 116.7 & 467 \\
\(\frac{\left(n p_{i}^{0}-n_{i}\right)^{2}}{n p_{i}^{0}}\) & 0.117 & 0.348 & 0.193 & \(\mathbf{0 . 6 5 7}\) \\
\end{longtable}

El valor crítico es el percentil de una distribución ji-cuadrado con dos grados de libertad, \(\chi_{2,0.95}^{2}=5.99\), de donde, dado que \(0.657<\chi_{2,0.95}^{2}\), vemos que no podemos rechazar \(H_{0}\).

Obsérvese que el primer ejemplo corresponde a una variable numérica que se ha categorizado, mientras que el segundo se refiere directamente a una distribución multinomial.

\subsubsection{Hipótesis compuestas}\label{hipuxf3tesis-compuestas}

El test de ajuste que hemos discutido en la sección anterior corresponde a una situación poco habitual. En la práctica, lo que nos interesará es decidir si los datos se ajustan a una determinada familia de distribuciones. Por ejemplo, antes de aplicar un test en el que se supone que los datos siguen una ley Normal, hay que verificar hasta qué punto es válida esta suposición.

En este caso nos encontramos en una situación análoga a la anterior, salvo por el hecho de que la distribución no está completamente especificada sino que depende de un parámetro \(m\)-dimensional.

\[
\begin{aligned}
X & \sim F_{\theta},\left(\theta \in \Theta \subset \mathbb{R}^{m}\right) \\
R & =\operatorname{Rec}(X)=\biguplus_{i=1}^{k} R_{i}, \quad A_{i}=\left\{X \in R_{i}\right\}, P\left(A_{i}\right)=p_{i}(\theta) \Longrightarrow \\
Y & =\left(n_{1}, \ldots, n_{k}\right), n_{i}=\# A_{i} \quad Y \sim M\left(n ; \mathbf{p}=\left(p_{1}(\theta), \ldots, p_{k}(\theta)\right)\right) .
\end{aligned}
\]

Una primera idea que se nos podría ocurrir para abordar este problema sería estimar \(\theta\) mediante un estimador \(\hat{\theta}\) y sustituir \(p_{i}^{0}\) por \(p_{i}(\hat{\theta})\) en (7.1). Esto no sería mala idea si la estimación se basase en una muestra distinta de la que se usa para realizar el ajuste.

Ahora bien, este no es el caso aquí. Si usamos la muestra para estimar los parámetros y después hacemos el ajuste, estamos ``forzando la muestra'' a seleccionar la distribución poblacional para que se ajuste bien a la muestra a través de la estimación de los parámetros (estamos haciendo un ajuste condicionado). Para compensarlo, intentaremos ser ``más exigentes'' a la hora de juzgar si las frecuencias observadas se corresponden con las esperadas, y eso se reflejará en que, en lugar de basarnos en una distribución \(\chi^{2}\) con \(k-1\) grados de libertad, lo haremos en una con \(k-1-m\) grados de libertad, donde \(m\) representará el número de parámetros que hemos tenido que estimar. Este resultado se expresa en el teorema siguiente:

\textbf{Teorema:} \emph{Bajo las condiciones del teorema 1 supongamos que las probabilidades \(p_{1}, \ldots, p_{k}\) dependen de parámetros desconocidos \(\theta=\theta_{1}, \ldots, \theta_{m}\). Sean \(\hat{\theta}=\hat{\theta}_{1}, \ldots, \hat{\theta}_{m}\) las estimaciones de máxima verosimilitud de los parámetros \(\theta\) y supongamos que se verifican las siguientes condiciones de regularidad:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Las derivadas parciales \(\frac{\partial p_{i}}{\partial \theta_{j}}, \frac{\partial^{2} p_{i}}{\partial \theta_{i} \partial \theta_{j}}\) existen y son continuas.
\item
  La matriz jacobiana \(\frac{\partial p_{i}}{\partial \theta_{j}}\), \(i=1, \ldots, k\), \(j=1, \ldots, m\), tiene rango \(m\).
\end{enumerate}

Entonces el estadístico

\[
D^{2}=\sum_{i=1}^{k} \frac{\left(n_{i}-n p_{i}(\hat{\theta})\right)^{2}}{n p_{i}(\hat{\theta})}
\]

verifica

\[
D^{2} \xrightarrow[n \rightarrow \infty]{£} \chi_{k-1-\operatorname{dim}(\Theta)}^{2}
\]

es decir, tiene distribución asintótica \(\chi^{2}\) con \(k-1-\operatorname{dim}(\Theta)\) grados de libertad.

Podemos proceder de forma análoga al caso de probabilidades conocidas para establecer el test siguiente:

\textbf{Definición 7.2} Test de bondad de ajuste cuando hay que estimar parámetros

Sean:

\[
\begin{aligned}
X & \sim F_{\theta},\left(\theta \in \Theta \subset \Re^{m}\right) \quad R: \operatorname{Rec}(X)=\biguplus_{i=1}^{k} R_{i} \\
A_{i} & =\left\{X \in R_{i}\right\}, P\left(A_{i}\right)=p_{i}(\theta) \\
Y & =\left(n_{1}, \ldots, n_{k}\right), n_{i}=\# A_{i}, \quad Y \sim M\left(n ; \mathbf{p}=\left(p_{1}(\theta), \ldots, p_{k}(\theta)\right)\right) .
\end{aligned}
\]

Entonces, para contrastar las hipótesis:

\[
\begin{array}{ll}
H_{0}: & X \sim F_{\theta}^{0} \Leftrightarrow \mathbf{p}=\left(p_{1}(\theta), \ldots, p_{k}(\theta)\right) \\
H_{1}: & \mathbf{p} \neq\left(p_{1}(\theta), \ldots, p_{k}(\theta)\right)
\end{array}
\]

el test consiste en rechazar \(H_{0}\) si \(D^{2} \geq \chi_{k-1-\operatorname{dim}(\Theta), 1-\alpha}^{2}\), donde

\[
\begin{aligned}
D^{2}= & \sum_{i=1}^{k} \frac{\left(n_{i}-n p_{i}(\hat{\theta})\right)^{2}}{n p_{i}(\hat{\theta})} \\
D^{2} & \underset{n \rightarrow \infty}{\stackrel{£}{\rightarrow}} \chi_{k-1-\operatorname{dim}(\Theta)}^{2}
\end{aligned}
\]

es un test asintótico de nivel \(\alpha\).
Este resultado establece que una región crítica para el test 7.2 tendrá la forma

\[
W=\left\{D^{2} \geq \chi_{k-1-\operatorname{dim}(\Theta), 1-\alpha}^{2}\right\}
\]

donde \(\chi_{k-1,1-\alpha}^{2}\) es el cuantil \(1-\alpha\) de una distribución \(\chi^{2}\) con \(k-1-\operatorname{dim}(\Theta)\) grados de libertad.

\subsubsection{Ejemplo}\label{ejemplo-12}

En el ejemplo anterior, cuando hemos ajustado unos datos a unas proporciones del tipo ``1:2:1'' o ``9:3:3:1'' estábamos suponiendo dos cosas:

\begin{itemize}
\tightlist
\item
  Un modelo genético (que no tenemos por qué conocer)
\item
  Unas probabilidades fijadas.
\end{itemize}

Esto lo hemos sintetizado en un vector numérico \(\left(p_{1}^{0}, \ldots, p_{k}^{0}\right)\). Por ejemplo, en (7.2.2) la proporción ``1:2:1'' viene de suponer:

\begin{itemize}
\tightlist
\item
  Como modelo: \(p^{2}, 2 p(1-p), q^{2}\),
\item
  Como probabilidades: \(p=\frac{1}{2}\).
\end{itemize}

A menudo nos interesa ajustar solo el modelo, es decir, decidir si, por ejemplo, el modelo \(p^{2}, 2 p(1-p), q^{2}\) describe bien los datos observados para algún \(p \in(0,1)\). En este caso, antes de comparar los observados \(n_{i}\) con los esperados \(p_{i}\), tendremos que estimar los valores de los \(p_{i}\).

Bajo la suposición de un modelo multinomial,

\[
\begin{array}{ll}
Y \sim M(n, \mathbf{p}(\theta), & \theta=p, \\
& p_{1}(\theta)=p^{2}, p_{2}(\theta)=2 p(1-p), p_{3}(\theta)=(1-p)^{2}
\end{array}
\]

la verosimilitud del modelo es:

\[
L\left(n_{1}, \ldots, n_{k} ; \mathbf{p}(\theta)\right) \propto\left(p^{2}\right)^{n_{1}} \cdot(2 p(1-p))^{n_{2}} \cdot\left(q^{2}\right)^{n_{3}}
\]

Una aplicación rutinaria del método de máxima verosimilitud da como estimador de máxima verosimilitud de \(p\):

\[
\hat{p}_{M V}=\frac{2 n_{1}+n_{2}}{2 n_{1}+2 n_{2}+2 n_{3}}
\]

Supongamos ahora que tenemos unos datos genéticos correspondientes al grupo sanguíneo \(M-N\) en una población de 6129 individuos, indios navajos, que son los siguientes:

\begin{longtable}[]{@{}lccc@{}}
\toprule\noalign{}
Grupo & \(M\) & \(M-N\) & \(N\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Individuos & 1787 & 3039 & 1303 \\
\end{longtable}

El estimador de máxima verosimilitud calculado sobre los datos del ejemplo es:

\[
\hat{p}_{M V}=\frac{2 \cdot 1787+3039}{2 \cdot 1787+2 \cdot 3039+2 \cdot 1303}=0.539
\]

de donde la tabla con los valores observados y esperados para hacer el test de ajuste es:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
M
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(M-N\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(N\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\Sigma\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n_{i}\) & 1787 & 3039 & 1303 & 6129 \\
\(p_{i}\left(\hat{p}_{M V}\right)\) & 0.539 & 2. 0.539. 0.461 & 0.461 & 1 \\
\(n p_{i}\left(\hat{p}_{M V}\right)\) & 1784 & 3046 & 1299.8 & 6129 \\
\(\frac{\left(n p_{i}\left(\hat{p}_{M V}\right)-n_{i}\right)^{2}}{n p_{i}\left(\hat{p}_{M V}\right)}\) & 0.0067 & 0.0166 & 0.0078 & 0.0311 \\
\end{longtable}

El valor crítico es el percentil de una distribución ji-cuadrado con dos menos un grados de libertad, \(\chi_{1,0.95}^{2}=3.841\), de donde, dado que \(0.0311<\chi_{1,0.95}^{2}\), vemos que no podemos rechazar \(H_{0}\).

\subsubsection{Ejemplo}\label{ejemplo-13}

En un estudio sobre bilingüismo se aplicó una prueba a una muestra de 211 alumnos y se obtuvieron 211 puntuaciones que, una vez tabuladas, eran las siguientes:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1026}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Puntuación
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((\leq 55]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((55-60]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((60-65]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((65-70]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((70-75]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((75-80]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((80-85]\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Frecuencia & 4 & 17 & 45 & 67 & 53 & 15 & 10 \\
\end{longtable}

¿Podemos aceptar la hipótesis de que la puntuación sigue una distribución normal? Fijémonos en que aquí no nos interesa más que el hecho de que sea normal, no una normal en concreto. Es decir, tenemos:

\[
\begin{array}{ll}
H_{0}: & X \sim N(\mu, \sigma) \\
H_{1}: & X \nsim N(\mu, \sigma) .
\end{array}
\]

En primer lugar estimamos los parámetros:

\[
\begin{aligned}
\hat{\mu} & =\bar{X}=68.52 \\
\hat{\sigma}^{2} & =S^{2}=6.44
\end{aligned}
\]

Cada categoría \(A_{i}\) es un intervalo del recorrido de la variable: \(A_{1}=X \in (-\infty, 55]\), \(A_{2}=X \in(55,60] \ldots\), de manera que si \(A_{i}=(a, b]\), las probabilidades \(p_{i}=P\left(A_{i}\right)\) se calcularán, si suponemos que \(Y\) representa una variable con distribución normal de media \(\hat{\mu}=\bar{x}\) y desviación típica \(\hat{\sigma}=s^{2}\):

\[
\begin{aligned}
p_{i}=p_{i}\left(\bar{x}, s^{2}\right) & =P_{\bar{x}, s^{2}}\left(X \in A_{i}\right)=F_{Y}(b)-F_{Y}(a) \\
& =\Phi\left(\frac{b-\bar{x}}{s}\right)-\Phi\left(\frac{a-\bar{x}}{s}\right),
\end{aligned}
\]

donde \(\Phi\) es la función de distribución de una variable \(N(0,1)\). Si calculamos las probabilidades en esos intervalos y construimos la tabla, obtenemos:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1026}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}
  >{\centering\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1282}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Puntuación
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((\leq 55]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((55-60]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((60-65]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((65-70]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((70-75]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((75-80]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((\geq 80)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n_{i}\) & 4 & 17 & 45 & 67 & 53 & 15 & 10 \\
\(p_{i}\left(\bar{x}, s^{2}\right)\) & 0.01786 & 0.07556 & 0.19774 & 0.29979 & 0.2528 & 0.11871 & 0.03654 \\
\(n \cdot p_{i}\left(\bar{x}, s^{2}\right)\) & 3.77 & 15.94 & 41.72 & 63.26 & 53.34 & 25.05 & 7.92 \\
\end{longtable}

Antes de calcular el valor del estadístico de test hay que fusionar las dos primeras columnas, ya que la frecuencia esperada es inferior a 5. La tabla final queda:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1176}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1471}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Puntuación
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((\leq 60]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((60-65]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((65-70]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((70-75]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((75-80]\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\((\geq 80)\)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(n_{i}\) & \(4+17\) & 45 & 67 & 53 & 15 & 10 \\
\(n \cdot p_{i}\left(\bar{x}, s^{2}\right)\) & \(3.77+15.94\) & 41.72 & 63.26 & 53.34 & 25.05 & 7.92 \\
\end{longtable}

El estadístico de test, \(D^{2}\), vale aquí: 5.144. Como hemos estimado 2 parámetros y la tabla final tiene 6 columnas, obtendremos el valor crítico de una \(\chi^{2}\) con \(6-2-1\) grado de libertad. En concreto: rechazaremos \(H_{0}\) si \(D^{2}>\chi_{(3,0.05)}^{2}\). Como esto no ocurre, no podemos rechazar \(H_{0}\).

\subsection{Pruebas de independencia en tablas de contingencia}\label{pruebas-de-independencia-en-tablas-de-contingencia}

Sea \(\Omega\) una población que admite dos descomposiciones diferentes en eventos excluyentes. Por ejemplo, una descomposición puede hacerse por sexo (hombres/mujeres) y la otra por tabaquismo (fumadores/no fumadores).

\[
\Omega=A_{1} \biguplus \cdots \biguplus A_{k}=B_{1} \biguplus \cdots \biguplus B_{r},
\]

donde el símbolo \(\biguplus\) indica unión disjunta. Supongamos que se realizan \(n\) observaciones o pruebas independientes, de modo que \(n_{ij}\) representa la frecuencia con la que se presenta el evento \(A_i \cap B_j\). Podemos disponer las observaciones en una tabla cruzada o de contingencia de \(r\) filas por \(k\) columnas:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(A_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\cdots\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(A_{k}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(\mathrm{B}_{1}\) & \(\mathrm{n}_{11}\) & \(\cdots\) & \(\mathrm{n}_{1k}\) & \(\mathrm{n}_{1\cdot}\) \\
\(\vdots\) & \(\vdots\) & \(\ddots\) & \(\vdots\) & \\
\(\mathrm{B}_{r}\) & \(\mathrm{n}_{r1}\) & \(\cdots\) & \(\mathrm{n}_{rk}\) & \(\mathrm{n}_{r\cdot}\) \\
& \(\mathrm{n}_{\cdot 1}\) & & \(\mathrm{n}_{\cdot k}\) & \(n\) \\
\end{longtable}

donde \(n_{i\cdot}=\sum_{j=1}^{k} n_{ij}\) es la frecuencia del evento \(A_i\) y \(n_{\cdot j}=\sum_{i=1}^{r} n_{ij}\) es la frecuencia del evento \(B_j\).

Supongamos que queremos contrastar la hipótesis de que las dos particiones son independientes, es decir,

\[
H_{0}: \quad A_i \text{ es estocásticamente independiente de } B_j,
\]

lo que equivale a

\[
P(A_i \cap B_j)=P(A_i)\,P(B_j), \quad i=1,\ldots,k,\; j=1,\ldots,r.
\]

Si indicamos \(p_{ij}=P(A_i \cap B_j)\) e introducimos los parámetros

\[
p_{1\cdot},\ldots,p_{r\cdot},\quad \sum_{i=1}^{r} p_{i\cdot}=1,\qquad
p_{\cdot 1},\ldots,p_{\cdot k},\quad \sum_{j=1}^{k} p_{\cdot j}=1,
\]

la hipótesis nula se expresará como

\[
p_{ij}=p_{i\cdot}\,p_{\cdot j}.
\]

Es fácil ver que, en este caso, los estimadores de máxima verosimilitud de las probabilidades marginales son las frecuencias relativas:

\[
\hat p_{i\cdot}=\frac{n_{i\cdot}}{n}, \qquad \hat p_{\cdot j}=\frac{n_{\cdot j}}{n},
\]

y la frecuencia esperada del evento \(A_i \cap B_j\) bajo \(H_0\) será

\[
n\,\hat p_{i\cdot}\,\hat p_{\cdot j}
= n\,\frac{n_{i\cdot}}{n}\,\frac{n_{\cdot j}}{n}
= \frac{n_{i\cdot}\,n_{\cdot j}}{n}.
\]

Aplicando el Teorema 7.2 se tiene que el estadístico

\[
D^{2}=\sum_{i=1}^{k}\sum_{j=1}^{r}
\frac{\left(n_{ij}-\frac{n_{i\cdot}n_{\cdot j}}{n}\right)^{2}}
{\frac{n_{i\cdot}n_{\cdot j}}{n}}
\]

verifica

\[
D^{2}\xrightarrow[n\to\infty]{\mathcal{L}} \chi^{2}_{(r-1)(k-1)}.
\]

Como consecuencia, el test de independencia para la hipótesis

\[
H_{0}: \quad P(A_i\cap B_j)=P(A_i)\,P(B_j)
\;\Longleftrightarrow\;
p_{ij}=p_{i\cdot}\,p_{\cdot j}
\]

consiste en calcular

\[
D^{2}=\sum_{i=1}^{k}\sum_{j=1}^{r}
\frac{\left(n_{ij}-\frac{n_{i\cdot}n_{\cdot j}}{n}\right)^{2}}
{\frac{n_{i\cdot}n_{\cdot j}}{n}}
\]

y rechazar \(H_{0}\) si

\[
D^{2}\ge \chi^{2}_{(k-1)(r-1),\,1-\alpha}.
\]

\subsubsection{Ejemplo}\label{ejemplo-14}

En un estudio de mercado se intenta determinar si existe alguna relación entre las preferencias de un grupo de consumidores por un tipo de vehículo y su nivel cultural. Se pregunta a 300 personas entre 20 y 50 años qué vehículo poseen y se clasifican en ``NINGUNO'', ``MOTOCICLETAS'', ``COCHES NORMALES'' y ``COCHES POTENTES''. El nivel cultural se determina según hayan cursado estudios ``ELEMENTALES'', ``DE GRADO MEDIO'' o ``SUPERIORES''. ¿Qué se puede concluir a partir de los siguientes datos?

\begin{longtable}[]{@{}cccccc@{}}
\toprule\noalign{}
& NINGUNO & MOTOS & C. NORMAL & C. POTENTE & TOTAL \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Elementales & 31 & 49 & 18 & 12 & 110 \\
Nivel medio & 11 & 59 & 26 & 25 & 121 \\
Superiores & 12 & 51 & 31 & 36 & 130 \\
TOTAL & 54 & 159 & 75 & 73 & 361 \\
\end{longtable}

La tabla de frecuencias esperadas es:

\begin{longtable}[]{@{}cccccc@{}}
\toprule\noalign{}
& NINGUNO & MOTOS & C. NORMAL & C. POTENTE & TOTAL \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Elementales & 16.5 & 48.4 & 22.9 & 22.2 & 110 \\
Nivel medio & 18.1 & 53.3 & 25.1 & 24.5 & 121 \\
Superiores & 19.4 & 57.3 & 27.0 & 26.3 & 130 \\
TOTAL & 54 & 159 & 75 & 73 & 361 \\
\end{longtable}

El valor del estadístico de contraste \(D^{2}\) calculado sobre estos datos es 29.76. El valor crítico de una distribución \(\chi^2\) con \((4-1)(3-1)=6\) grados de libertad y nivel de significación 0.05 es 12.59. Dado que

\[
29.76 \ge 12.59=\chi^{2}_{(3-1)(4-1),\,1-0.05},
\]

se rechaza la hipótesis de independencia; es decir, parece existir relación entre el nivel de estudios y el tipo de vehículo.

\subsection{Pruebas de homogeneidad}\label{pruebas-de-homogeneidad}

Supongamos que tenemos una misma partición

\[
\Omega=A_{1} \biguplus \cdots \biguplus A_{k},
\]

en \(r\) poblaciones:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 8\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(A_{1}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(\cdots\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\(A_{k}\)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
1 & \(\mathrm{n}_{11}\) & \(\cdots\) & \(\mathrm{n}_{1k}\) & \(\mathrm{n}_{1}\) \\
\(\vdots\) & \(\vdots\) & \(\ddots\) & \(\vdots\) & \\
\(r\) & \(\mathrm{n}_{r1}\) & \(\cdots\) & \(\mathrm{n}_{rk}\) & \(\mathrm{n}_{r}\) \\
& \(\mathrm{n}_{\cdot 1}\) & & \(\mathrm{n}_{\cdot k}\) & \(n\) \\
\end{longtable}

y queremos contrastar la hipótesis

\[
\begin{aligned}
p_{11}&=p_{21}=\cdots=p_{r1},\\
p_{12}&=p_{22}=\cdots=p_{r2},\\
&\ \vdots\\
p_{1k}&=p_{2k}=\cdots=p_{rk}.
\end{aligned}
\]

De forma análoga al apartado anterior puede establecerse que el estadístico

\[
D^{2}=\sum_{i=1}^{k}\sum_{j=1}^{r}
\frac{\left(n_{ij}-n_{i}\frac{n_{\cdot j}}{n}\right)^{2}}
{n_{i}\frac{n_{\cdot j}}{n}}
\]

verifica

\[
D^{2}\xrightarrow[n\to\infty]{\mathcal{L}} \chi^{2}_{(r-1)(k-1)},
\]

de modo que la hipótesis nula se rechazará siempre que

\[
D^{2}\ge \chi^{2}_{(k-1)(r-1),\,1-\alpha}.
\]

\subsubsection{Ejemplo}\label{ejemplo-15}

En un estudio antropológico se analiza la distribución de los grupos sanguíneos \(O,A,B,AB\) entre tres razas humanas. La siguiente tabla contiene las frecuencias observadas y esperadas, así como el análisis realizado con el programa SPSS, donde se observa que no se puede rechazar la hipótesis nula de que la probabilidad de cada grupo sanguíneo es la misma en todas las razas.

\textbf{Tabla de contingencia Raza × Grupo sanguíneo}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}
  >{\raggedright\arraybackslash}p{(\linewidth - 14\tabcolsep) * \real{0.1250}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Grupo sanguíneo
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Total
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& & & O & A & B & AB & \\
Raza & Caucásicos & Recuento & 32 & 11 & 7 & 2 & 52 \\
& & Frecuencia esperada & 29.0 & 8.8 & 9.4 & 4.8 & 52.0 \\
& & \% de grupo sanguíneo & 31.4\% & 35.5\% & 21.2\% & 11.8\% & 28.4\% \\
& Pigmeos & Recuento & 47 & 13 & 17 & 9 & 86 \\
& & Frecuencia esperada & 47.9 & 14.6 & 15.5 & 8.0 & 86.0 \\
& & \% de grupo sanguíneo & 46.1\% & 41.9\% & 51.5\% & 52.9\% & 47.0\% \\
& Esquimales & Recuento & 23 & 7 & 9 & 6 & 45 \\
& & Frecuencia esperada & 25.1 & 7.6 & 8.1 & 4.2 & 45.0 \\
& & \% de grupo sanguíneo & 22.5\% & 22.6\% & 27.3\% & 35.3\% & 24.6\% \\
Total & & Recuento & 102 & 31 & 33 & 17 & 183 \\
& & Frecuencia esperada & 102.0 & 31.0 & 33.0 & 17.0 & 183.0 \\
\end{longtable}

\newpage

\section{Estadística no paramétrica}\label{estaduxedstica-no-paramuxe9trica}

\subsection{Introducción}\label{introducciuxf3n-9}

En este capítulo presentaremos de forma breve algunos tests no paramétricos para problemas de una, dos o varias muestras. El objetivo de estos tests es disponer de alternativas a las pruebas de hipótesis de comparación clásicas cuando no se conoce la forma de la distribución de los datos o la ley de las variables. En particular, serán alternativas a los tests sobre la media o comparación de medias cuando no se verifica la suposición de normalidad de los datos. Nos referimos a los tests basados en poblaciones normales como contrastes paramétricos, ya que se basan en comparar medias o parámetros de la ley normal. En contraposición, los que consideramos aquí y que denominaremos contrastes no paramétricos pueden comparar medianas, cuantiles o incluso toda la distribución en bloque. Observemos, pues, que ``no paramétrico'' no significa que estos tests no comparen algún parámetro como la mediana; más bien significa que no queremos hacer determinadas suposiciones sobre la función de distribución de las variables.

Desde un punto de vista práctico, que es también el que adoptan muchos programas informáticos de análisis estadístico, distinguiremos entre:

\begin{itemize}
\tightlist
\item
  Problemas de una muestra
\item
  Problemas de dos muestras con datos apareados
\item
  Problemas de dos muestras independientes
\item
  Problemas de \(k\) muestras independientes.
\end{itemize}

Esta distinción nos permite clasificar las técnicas que estudiamos y compararlas con las correspondientes pruebas paramétricas:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}
  >{\raggedright\arraybackslash}p{(\linewidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Problema
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Test paramétrico
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Test no paramétrico
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Una muestra & Test \(t\) de una muestra & Test de los signos Test de los rangos con signo \\
Datos apareados & Test \(t\) de datos apareados & Test de los signos Test de los rangos con signo \\
Dos muestras ind. & Test \(t\) para dos muestras ind. (con test \(F\) previo) & Test \(U\) de Mann-Whitney \\
\(k\) muestras ind. & ANOVA de un factor & Test de Kruskal-Wallis \\
\end{longtable}

Además, algunos tests no paramétricos tienen otras utilidades, como los tests de aleatoriedad, los tests de rachas, etc.

\subsection{Test de los signos}\label{test-de-los-signos}

\subsubsection{Test para la mediana}\label{test-para-la-mediana}

Sea \(X\) una variable aleatoria con distribución continua \(F_{X}\) desconocida y \(M=Q_{50}\) su mediana o cuantil del \(50\%\), es decir, el valor tal que

\[
P(X \leq M)=0.5
\]

Supongamos que queremos contrastar las hipótesis

\[
\begin{aligned}
& H_{0}: M=m_{0} \\
& H_{1}: M \neq m_{0}
\end{aligned}
\]

Dada una muestra \(x_{1}, x_{2}, \ldots, x_{n}\), consideremos el ``signo'' de cada valor muestral por comparación con la mediana propuesta por la hipótesis \(H_{0}\), es decir,

\[
\operatorname{signe}\left(x_{i}\right)= \begin{cases}+ & \text { si } x_{i}>m_{0} \\ - & \text { si } x_{i}<m_{0}\end{cases}
\]

El estadístico \(B=\) ``Número de signos positivos'' es:

\[
B\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\sum_{i=1}^{n} I_{x_{i}>m_{0}}
\]

donde

\[
I_{x_{i}>m_{0}}=\left\{\begin{array}{cc}
1 & \text { si } x_{i}>m_{0}\left(\operatorname{signe}\left(x_{i}\right)=+\right) \\
0 & \text { si } x_{i}<m_{0}\left(\operatorname{signe}\left(x_{i}\right)=-\right)
\end{array}\right.
\]

Si la hipótesis nula es cierta, la distribución del estadístico \(B\) será una binomial de parámetros \(n\) y \(1/2\), y es razonable esperar que \(B\) tome valores próximos a \(n/2\); mientras que cuando sea falsa es de esperar que tome valores en las colas de la distribución. Así pues, una región crítica para el test será aquella en la que el número de signos positivos sea demasiado alto o demasiado bajo como para ser coherente con la hipótesis nula, que implica que hay tantos positivos como negativos. Podemos tomar como región crítica:

\[
W=\left\{B(\mathbf{x}) \leq b_{\alpha / 2}\right\} \cup\left\{B(\mathbf{x}) \geq b_{1-\alpha / 2}\right\}
\]

donde \(b_{\alpha / 2}\) y \(b_{1-\alpha / 2}\) se determinan de forma que la probabilidad de las dos colas de una distribución \(B\left(n, \frac{1}{2}\right)\) sea igual al nivel de significación \(\alpha\) (o algo menor que \(\alpha\)), es decir,

\[
\sum_{i=0}^{b_{\alpha / 2}}\binom{n}{i}\left(\frac{1}{2}\right)^{i}\left(\frac{1}{2}\right)^{n-i}+\sum_{i=b_{1-\alpha / 2}}^{n}\binom{n}{i}\left(\frac{1}{2}\right)^{i}\left(\frac{1}{2}\right)^{n-i} \leq \alpha
\]

\paragraph{Observaciones}\label{observaciones-2}

\begin{itemize}
\tightlist
\item
  Aunque con probabilidad teórica cero, porque la variable considerada tiene función de distribución continua, puede darse el caso \(x_{i}=m_{0}\), de signo indefinido. Si no es posible aumentar la precisión, se aconseja eliminar este valor muestral y descontarlo en consecuencia del tamaño de la muestra.
\item
  Si la hipótesis alternativa es \(M<m_{0}\) o bien \(M>m_{0}\), la región crítica se adapta a esta hipótesis de forma razonable, es decir:
\end{itemize}

\[
\begin{aligned}
& H_{1}: M<m_{0} \quad \Rightarrow \quad W=\left\{B(\mathbf{x}) \leq b_{\alpha}\right\} \\
& H_{1}: M>m_{0} \quad \Rightarrow \quad W=\left\{B(\mathbf{x}) \geq b_{1-\alpha / 2}\right\}
\end{aligned}
\]

\begin{itemize}
\tightlist
\item
  Algunos libros incluyen tablas de la distribución binomial que podemos usar para encontrar los valores críticos. Para \(n \geq 20\) podemos aproximar la binomial por una normal.
\end{itemize}

\paragraph{Ejemplo 1}\label{ejemplo-1-1}

La siguiente tabla recoge una muestra de 40 notas en un examen. Contraste, con un nivel de significación 0.05, la hipótesis de que el valor central (mediana) de las notas es 66.

\begin{longtable}[]{@{}cccccccccc@{}}
\toprule\noalign{}
71 & 67 & 55 & 64 & 82 & 66 & 74 & 58 & 79 & 61 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
78 & 46 & 84 & 93 & 72 & 54 & 78 & 86 & 48 & 52 \\
67 & 95 & 70 & 43 & 70 & 73 & 57 & 64 & 60 & 83 \\
73 & 40 & 78 & 70 & 64 & 86 & 76 & 62 & 95 & 66 \\
+ & + & - & - & + & 0 & + & - & + & - \\
+ & - & + & + & + & - & + & + & - & - \\
+ & + & + & - & + & + & - & - & - & + \\
+ & - & + & + & - & + & + & - & + & 0 \\
\end{longtable}

Si restamos 66 de las notas observadas y retenemos solo los signos de las diferencias, se obtienen 23 signos +, 15 signos - y 2 ceros. Descartados los ceros, \(B=23\) sobre un total de 38. Si hacemos un contraste bilateral con la aproximación normal, la región de aceptación es \(\{-1.96 \leq z \leq 1.96\}\).
Dado que

\[
z=\frac{(23-0.5)-38 \cdot 0.5}{\sqrt{38 \cdot 0.5 \cdot 0.5}}=1.14
\]

aceptamos la hipótesis de que la mediana es 66, al nivel 0.05.

Podemos hacer lo mismo con R:

Primero introducimos las notas y calculamos cuántos valores son superiores a 66, es decir, el número de signos positivos.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{notes}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{ (}\DecValTok{71}\NormalTok{,}\DecValTok{67}\NormalTok{,}\DecValTok{55}\NormalTok{,}\DecValTok{64}\NormalTok{,}\DecValTok{82}\NormalTok{,}\DecValTok{66}\NormalTok{,}\DecValTok{74}\NormalTok{,}\DecValTok{58}\NormalTok{,}\DecValTok{79}\NormalTok{,}\DecValTok{61}\NormalTok{,}\DecValTok{78}\NormalTok{,}\DecValTok{46}\NormalTok{,}\DecValTok{84}\NormalTok{,}\DecValTok{93}\NormalTok{,}\DecValTok{72}\NormalTok{,}\DecValTok{54}\NormalTok{,}\DecValTok{78}\NormalTok{,}\DecValTok{86}\NormalTok{,}\DecValTok{48}\NormalTok{,}\DecValTok{52}\NormalTok{,}\DecValTok{67}\NormalTok{,}\DecValTok{95}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{43}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{73}\NormalTok{,}\DecValTok{57}\NormalTok{,}\DecValTok{64}\NormalTok{,}\DecValTok{60}\NormalTok{,}\DecValTok{83}\NormalTok{,}\DecValTok{73}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{78}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{64}\NormalTok{,}\DecValTok{86}\NormalTok{,}\DecValTok{76}\NormalTok{,}\DecValTok{62}\NormalTok{,}\DecValTok{95}\NormalTok{,}\DecValTok{66}\NormalTok{)}
\NormalTok{notes[notes}\SpecialCharTok{\textgreater{}}\DecValTok{66}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 71 67 82 74 79 78 84 93 72 78 86 67 95 70 70 73 83 73 78 70 86 76 95
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B}\OtherTok{\textless{}{-}}\FunctionTok{length}\NormalTok{(notes[notes}\SpecialCharTok{\textgreater{}}\DecValTok{66}\NormalTok{])}
\NormalTok{B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 23
\end{verbatim}

Y finalmente calculamos la aproximación normal del estadístico y su p-valor. Aplicaremos una \emph{corrección por continuidad}, habitual en esta aproximación, restando 0.5 al estadístico B

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n}\OtherTok{\textless{}{-}}\FunctionTok{length}\NormalTok{(notes)}\SpecialCharTok{{-}}\FunctionTok{length}\NormalTok{(notes[notes}\SpecialCharTok{==}\DecValTok{66}\NormalTok{])}
\NormalTok{n}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 38
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z}\OtherTok{\textless{}{-}}\NormalTok{(B}\FloatTok{{-}0.5}\SpecialCharTok{{-}}\NormalTok{n}\SpecialCharTok{*}\FloatTok{0.5}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(n}\SpecialCharTok{*}\FloatTok{0.5}\SpecialCharTok{*}\FloatTok{0.5}\NormalTok{)}
\FunctionTok{round}\NormalTok{(z,}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.14
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pnorm}\NormalTok{(z))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.256145
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{2}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pnorm}\NormalTok{(B}\FloatTok{{-}0.5}\NormalTok{,}\AttributeTok{mean=}\NormalTok{n}\SpecialCharTok{*}\FloatTok{0.5}\NormalTok{,}\AttributeTok{sd=}\FunctionTok{sqrt}\NormalTok{(n}\SpecialCharTok{*}\FloatTok{0.5}\SpecialCharTok{*}\FloatTok{0.5}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.256145
\end{verbatim}

El p-valor, superior al nivel de significación, hace que aceptemos la hipótesis nula \(H_{0}: M=66\).

\subsubsection{Test de los signos para datos apareados}\label{test-de-los-signos-para-datos-apareados}

El test de los signos puede servir también en el caso de datos apareados.
Consideremos una muestra de dos variables \(X, Y\)

\[
\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \ldots,\left(x_{n}, y_{n}\right)
\]

con \(n\) observaciones en dos situaciones lo más homogéneas posible.
Supongamos que las distribuciones de las dos variables son similares, excepto quizá en un parámetro de localización como la mediana. Es decir, las dos situaciones consideradas solo pueden desplazar la distribución y no modifican su forma.

Ahora queremos contrastar la hipótesis de que no hay diferencia entre las dos situaciones: las diferencias observadas entre los valores \(x_{i}\) y \(y_{i}\) se deben al azar; es decir, las dos muestras \(x_{1}, \ldots, x_{n}\) e \(y_{1}, \ldots, y_{n}\) proceden de la misma población. Esto puede expresarse estadísticamente con la hipótesis \(H_{0}\) de igualdad de las distribuciones de probabilidad, que con las suposiciones asumidas es equivalente a la igualdad de medianas.
Si la hipótesis \(H_{0}\) es cierta, y la distribución de la variable diferencia \(D=X-Y\) es simétrica respecto del origen, se verificará

\[
P(X>Y)=P(X-Y>0)=\frac{1}{2}
\]

Así pues, podemos aplicar el test de los signos a la variable diferencia \(D=X-Y\). En general, aunque no necesariamente siempre, se tomará como valor de \(m_{0}\) el 0.

\paragraph{Ejemplo 2}\label{ejemplo-2-1}

Se quiere comparar el número de piezas defectuosas producidas por dos máquinas diferentes. Se observa la producción durante 10 días, con la misma producción diaria para ambas máquinas, aunque diferente cada día. Los resultados son:

\begin{longtable}[]{@{}lcccccccccc@{}}
\toprule\noalign{}
Día & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Máquina 1 & 46 & 110 & 70 & 54 & 60 & 120 & 82 & 76 & 37 & 28 \\
Máquina 2 & 42 & 87 & 75 & 50 & 48 & 108 & 80 & 67 & 40 & 25 \\
\end{longtable}

Con un nivel de significación \(\alpha=0.06\), ¿podemos aceptar que la primera máquina produce más piezas defectuosas?

\textbf{Solución}:

El hecho de que la producción total diaria de ambas máquinas sea la misma permite considerar los datos como apareados. Que la producción diaria sea diferente cada día aconseja utilizar un test no paramétrico.
Observemos los signos de las diferencias

\[
\begin{array}{lcccccccccc}
\text { Día: } & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
\text { Signo: } & + & + & - & + & + & + & + & + & - & +
\end{array}
\]

De modo que \(B=8\) sobre \(n=10\). En este contraste, la región crítica es unilateral y concretamente es \(W=\{8,9,10\}\), ya que

\[
P(B \geq 8)=\sum_{i=8}^{10}\binom{10}{i} 0.5^{10}=0.0547<\alpha=0.06
\]

Dado que la frecuencia observada es 8 y pertenece a la región crítica, rechazamos la igualdad y podemos aceptar que la máquina 1 produce más piezas defectuosas.

Para hacerlo con R introducimos los datos en dos vectores de la misma longitud. Calculamos la diferencia y el número de valores positivos. A partir de este número calculamos la probabilidad de la cola derecha de una binomial, ya que la hipótesis alternativa así lo requiere.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{maq1}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{46}\NormalTok{,}\DecValTok{110}\NormalTok{,}\DecValTok{70}\NormalTok{,}\DecValTok{54}\NormalTok{,}\DecValTok{60}\NormalTok{,}\DecValTok{120}\NormalTok{,}\DecValTok{82}\NormalTok{,}\DecValTok{76}\NormalTok{,}\DecValTok{37}\NormalTok{,}\DecValTok{28}\NormalTok{)}
\NormalTok{maq2}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{42}\NormalTok{,}\DecValTok{87}\NormalTok{,}\DecValTok{75}\NormalTok{,}\DecValTok{50}\NormalTok{,}\DecValTok{48}\NormalTok{,}\DecValTok{108}\NormalTok{,}\DecValTok{80}\NormalTok{,}\DecValTok{67}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{25}\NormalTok{)}
\NormalTok{dif}\OtherTok{\textless{}{-}}\NormalTok{maq1}\SpecialCharTok{{-}}\NormalTok{maq2}
\NormalTok{dif}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  4 23 -5  4 12 12  2  9 -3  3
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B}\OtherTok{\textless{}{-}}\FunctionTok{length}\NormalTok{(dif[dif}\SpecialCharTok{\textgreater{}}\DecValTok{0}\NormalTok{]);B}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 8
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dbinom}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{dbinom}\NormalTok{(}\DecValTok{9}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}\SpecialCharTok{+}\FunctionTok{dbinom}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0546875
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pbinom}\NormalTok{(B}\DecValTok{{-}1}\NormalTok{,}\DecValTok{10}\NormalTok{,}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.0546875
\end{verbatim}

El p-valor es inferior al nivel de significación 0.06 y, por tanto, rechazamos la hipótesis nula y aceptamos que la máquina 1 produce más piezas defectuosas.

\subsubsection{Test para datos binarios}\label{test-para-datos-binarios}

En el caso de una muestra de valores de una variable dicotómica, por ejemplo

\[
a, a, b, b, b, a, a, b, a, \ldots, b
\]

podemos aplicar el test de los signos para contrastar el equilibrio de las probabilidades de ambos valores.

\paragraph{Ejemplo 3}\label{ejemplo-3-1}

Ante un cambio en un servicio público se realiza una encuesta a 300 personas, a las cuales se les pregunta si el servicio ha mejorado o empeorado, sin posibilidad de ser indiferente. Ha resultado que 197 personas han dicho que el servicio ha mejorado y queremos contrastar este hecho con un nivel de significación del 0.01.

Bajo la hipótesis nula de equilibrio, el número \(B\) de personas que afirman que el servicio ha mejorado sigue una distribución binomial \(B(300,0.5)\), de forma que

\[
z=\frac{(197-0.5)-150}{\sqrt{300 \cdot 0.5 \cdot 0.5}}=5.37
\]

La región crítica de una cola es \(W=\{z>2.33\}\) para \(\alpha=0.01\), de manera que aceptamos la opinión de que el servicio ha mejorado.

\subsection{Test de McNemar}\label{test-de-mcnemar}

Es una variante del test de los signos. Supongamos que un conjunto de individuos se clasifica en dos categorías opuestas, que podemos indicar con los signos \(+\mathrm{i}-\).
Después de algún estímulo, es posible que algunos individuos cambien de categoría, de forma que se obtiene la tabla de frecuencias

\begin{longtable}[]{@{}cccc@{}}
\toprule\noalign{}
& & Después & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
& & - & + \\
Antes & + & \(a\) & \(b\) \\
& - & \(c\) & \(d\) \\
\end{longtable}

Solo \(a+d\) individuos han cambiado. Bajo la hipótesis nula de que las proporciones no cambian, las probabilidades son

\[
P(+\rightarrow-)=P(-\rightarrow+)=1 / 2
\]

de manera que la frecuencia esperada en estos dos casos es \((a+d) / 2\). Podemos aplicar el test ji-cuadrado

\[
\chi^{2}=\frac{(a-(a+d) / 2)^{2}}{(a+d) / 2}+\frac{(d-(a+d) / 2)^{2}}{(a+d) / 2}=\frac{(a-d)^{2}}{a+d} \quad \text { con } 1 \text { g.l. }
\]

Rechazaremos la hipótesis de equilibrio si \(\chi>\chi_{\alpha}^{2}\), donde \(\alpha\) es el nivel de significación. Si las frecuencias son pequeñas es conveniente utilizar la corrección de Yates

\[
\chi=\frac{(|a-d|-1)^{2}}{a+d}
\]

\subsection{Test de los rangos con signo de Wilcoxon}\label{test-de-los-rangos-con-signo-de-wilcoxon}

Visto como una extensión del test de los signos anterior, la idea de este test es utilizar, además del signo, la magnitud de las diferencias.

El \textbf{rango} de una observación es \emph{la posición que ocupa en la muestra ordenada}. Por ejemplo, si consideramos la muestra

\[
x_{1}=3 \quad x_{2}=0 \quad x_{3}=5 \quad x_{4}=1.9
\]
la muestra ordenada es

\[
x_{(1)}=0 \quad x_{(2)}=1.9 \quad x_{(3)}=3 \quad x_{(4)}=5
\]

de modo que los rangos son:

\[
r(0)=1 \quad r(1.9)=2 \quad r(3)=3 \quad r(5)=4
\]

Una parte importante de la estadística no paramétrica ha surgido de la sustitución de los valores cuantitativos de las muestras por sus rangos y de la obtención de estadísticos de contraste análogos a los utilizados con datos cuantitativos.

Podemos encontrar así, por ejemplo, un test equivalente al test \(t\) de Student pero basado en rangos, o un coeficiente de correlación, denominado de Spearman, con la misma fórmula que el de Pearson pero utilizando rangos.

Ahora nos centramos en la comparación de medianas, basada en rangos, y no en los coeficientes de correlación.

Supongamos que la hipótesis nula es la misma que en el test de la mediana, es decir:

\[
\begin{aligned}
& H_{0}: M=m_{0} \\
& H_{1}: M \neq m_{0}
\end{aligned}
\]

donde \(M\) representa la mediana de una variable o, con frecuencia, de la diferencia entre dos variables apareadas.

Wilcoxon propuso considerar los estadísticos:\\
\(T^{+}=\) Suma de los rangos de las observaciones con signo +\\
\(T^{-}=\) Suma de los rangos de las observaciones con signo -

\[
T^{+}=\sum_{i=1}^{n} r\left(\left|x_{i}-m_{0}\right|\right) I_{x_{i}>m_{0}}
\]

Si \(H_{0}\) es cierta, entonces es de esperar que \(T^{+}=T^{-}\).
El estadístico \(T^{+}\) se conoce con el nombre de estadístico de Wilcoxon y está tabulado, de forma que pueden encontrarse valores \(t_{\alpha / 2}\) y \(t_{1-\alpha / 2}\) tales que

\[
P\left[T^{+}<t_{\alpha / 2} \mid H_{0}\right]+P\left[T^{+}>t_{1-\alpha / 2} \mid H_{0}\right] \leq \alpha
\]

y definir la región crítica como

\[
W=\left\{T^{+}<t_{\alpha / 2}\right\} \cup\left\{T^{+}>t_{1-\alpha / 2}\right\}
\]

\subsubsection{Observaciones}\label{observaciones-3}

\begin{itemize}
\tightlist
\item
  Para valores grandes de \(n\) puede utilizarse el hecho de que, bajo \(H_{0}\), el estadístico \(T^{+}\) es asintóticamente normal:
\end{itemize}

\[
T^{+} \sim A N\left(\mu_{T^{+}}, \sigma_{T^{+}}\right), \quad \mu_{T^{+}}=\frac{n(n+1)}{4}, \quad \sigma_{T^{+}}^{2}=\frac{n(n+1)(2 n+1)}{24}
\]

y, por tanto, para muestras grandes podemos basarnos en el estadístico

\[
Z=\frac{T^{+}-n(n+1) / 4}{\sqrt{n(n+1)(2 n+1) / 24}} \sim N(0,1)
\]

\begin{itemize}
\tightlist
\item
  Una alternativa al estadístico de contraste anterior consiste en considerar el estadístico
\end{itemize}

\[
T=\min \left(T^{+}, T^{-}\right) .
\]

Si \(H_{0}\) es cierta, entonces \(T^{+}=T^{-}\). Si no lo es, se tendrá \(T^{+}>T^{-}\) o bien \(T^{+}<T^{-}\), de modo que el mínimo será un valor ``pequeño''. El test basado en este estadístico rechazará la hipótesis nula si \(T\) es menor que \(T_{\alpha}\), donde este valor crítico se obtiene a partir de una tabla diferente de la tabla de valores críticos para \(T^{+}\).

\subsubsection{Ejemplo 4}\label{ejemplo-4-1}

Dado que en el ejemplo 1 las notas son numéricas, podemos utilizar el test de los rangos con signo para contrastar \(H_{0}: M=66\) frente a \(H_{1}: M \neq 66\), con un nivel de significación del 0.05.

\textbf{Solución}:

Para calcular el estadístico \(T^{+}\) debemos asignar los rangos correspondientes a los valores positivos de las diferencias entre las observaciones y el valor 66 propuesto en la hipótesis nula.

En este ejemplo utilizaremos la función \texttt{wilcox.test} con el vector \texttt{notes} del ejemplo:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(notes,}\AttributeTok{mu=}\DecValTok{66}\NormalTok{,}\AttributeTok{alternative=}\StringTok{"two.sided"}\NormalTok{,}\AttributeTok{exact=}\NormalTok{F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  notes
## V = 465, p-value = 0.1726
## alternative hypothesis: true location is not equal to 66
\end{verbatim}

O bien, mediante una aproximación normal directa:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{z}\OtherTok{\textless{}{-}}\NormalTok{(}\DecValTok{465}\FloatTok{{-}0.5}\DecValTok{{-}38}\SpecialCharTok{*}\DecValTok{39}\SpecialCharTok{/}\DecValTok{4}\NormalTok{)}\SpecialCharTok{/}\FunctionTok{sqrt}\NormalTok{(}\DecValTok{38}\SpecialCharTok{*}\DecValTok{39}\SpecialCharTok{*}\DecValTok{77}\SpecialCharTok{/}\DecValTok{24}\NormalTok{);z}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.363214
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\DecValTok{2}\SpecialCharTok{*}\NormalTok{(}\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{pnorm}\NormalTok{(z)),}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.17
\end{verbatim}

Esta función calcula el estadístico \(T^{+}=465\) y su p-valor con corrección por continuidad.

En este problema existen, además de dos ceros, un número considerable de empates o \emph{ligaduras} (del inglés ``ties''), de modo que la función \texttt{wilcox.test} no puede calcular el p-valor exacto y por ello se le ha indicado \texttt{exact=F}.

El estadístico \(z\) que hemos calculado de forma directa y su p-valor, sin tener en cuenta las ligaduras, son bastante similares a los que calcula el algoritmo. Si no se indica nada sobre este parámetro, aparecen dos mensajes de advertencia relativos a este hecho.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(notes,}\AttributeTok{mu=}\DecValTok{66}\NormalTok{,}\AttributeTok{alternative=}\StringTok{"two.sided"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  notes
## V = 465, p-value = 0.1726
## alternative hypothesis: true location is not equal to 66
\end{verbatim}

\subsubsection{Ejemplo 5}\label{ejemplo-5-1}

Dado que en el ejemplo 2 las observaciones son numéricas y apareadas, podemos utilizar los valores de las diferencias con el test de los rangos con signo para contrastar si existen diferencias entre las dos máquinas.

\textbf{Solución}:

En este ejemplo se utiliza también la función \texttt{wilcox.test} con los dos vectores de datos del ejemplo y la opción \texttt{paired=TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{wilcox.test}\NormalTok{(maq1,maq2,}\AttributeTok{mu=}\DecValTok{0}\NormalTok{,}\AttributeTok{paired=}\NormalTok{T,}\AttributeTok{alternative=}\StringTok{"greater"}\NormalTok{,}\AttributeTok{exact=}\NormalTok{F)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Wilcoxon signed rank test with continuity correction
## 
## data:  maq1 and maq2
## V = 46.5, p-value = 0.02942
## alternative hypothesis: true location shift is greater than 0
\end{verbatim}

Observamos que en este caso hemos utilizado la opción \texttt{paired=T} para indicar que los datos son apareados. También hemos identificado correctamente la alternativa con \texttt{alternative="greater"}. Además, como en el ejemplo anterior, las ligaduras no permiten calcular el p-valor exacto. El p-valor aproximado 0.029 indica el rechazo de la hipótesis nula.

\subsection{\texorpdfstring{El test \(U\) de Mann-Whitney}{El test U de Mann-Whitney}}\label{el-test-u-de-mann-whitney}

Este test permite comparar dos poblaciones con muestras independientes:
\[
\left(x_{1}, \ldots, x_{n_{1}}\right),\left(y_{1}, \ldots, y_{n_{2}}\right)
\]

procedentes de dos poblaciones \(X, Y\) con funciones de distribución \(F_{X}, F_{Y}\) respectivamente. Queremos contrastar la hipótesis \(H_{0}: F_{X}=F_{Y}\) frente a alguna de las alternativas

\[
H_{1}: F_{X} \neq F_{Y} \quad H_{1}: F_{X}<F_{Y} \quad H_{1}: F_{X}>F_{Y}
\]

Si la hipótesis nula es cierta, entonces \(P(X<Y)=\frac{1}{2}\). Además, dado que existen \(n_{1} \cdot n_{2}\) pares posibles, el número de pares de observaciones \(\left(x_{i}, y_{j}\right)\) que se espera que verifiquen \(x_{i}<y_{j}\) estará alrededor de \(\frac{n_{1} \cdot n_{2}}{2}\).
Un estadístico de contraste razonable para decidir si aceptamos o rechazamos la hipótesis nula es el número de pares que verifican \(x_{i}<y_{j}\), que definimos como:

\[
U=\sum_{i=1}^{n_{1}} \sum_{j=1}^{n_{2}} I_{x_{i}<y_{j}}
\]

Una desviación significativa de \(U\) respecto al valor esperado \(\frac{n_{1} \cdot n_{2}}{2}\) conducirá al rechazo de la hipótesis nula. Para decidir si \(U\) es significativo se consulta la tabla de Mann-Whitney-Wilcoxon, que permite decidir el rechazo de \(H_{0}\) en función del nivel de significación elegido y de los tamaños muestrales \(n_{1}\) y \(n_{2}\).

\subsubsection{Observaciones}\label{observaciones-4}

\begin{itemize}
\tightlist
\item
  Un procedimiento alternativo para calcular \(U\), y a menudo más cómodo, consiste en formar la muestra conjunta reuniendo las dos muestras individuales y asignar los rangos \(1,2, \ldots, n_{1}+n_{2}\) a cada uno de los valores de la muestra ordenada. Puede calcularse \(U\) a partir de la relación:
\end{itemize}

\[
U=W-\frac{n_{2}\left(n_{2}+1\right)}{2}
\]

donde \(W\) es la suma de los rangos de las observaciones \(y_{j}\)

\[
W=\sum_{j=1}^{n_{2}} r\left(y_{j}\right)
\]

Este estadístico \(W\) para comparar dos poblaciones fue propuesto por Wilcoxon pero, por la relación anterior, es equivalente al estadístico \(U\) de Mann-Whitney.

\begin{itemize}
\tightlist
\item
  Si no existen ligaduras o empates, la relación entre el estadístico de Wilcoxon \(W\) (suma de rangos correspondientes a las observaciones \(Y\)) y el estadístico \(U\) de Mann-Whitney (número de veces que \(x_{i}<y_{j}\) en la muestra conjunta ordenada) es
\end{itemize}

\[
W=\frac{n_{2}\left(n_{2}+1\right)}{2}+U
\]

Si \(W^{\prime}\) es la suma de los rangos correspondientes a las observaciones \(X\), entonces

\[
W+W^{\prime}=\frac{\left(n_{1}+n_{2}\right)\left(n_{1}+n_{2}+1\right)}{2}
\]

De modo que, si \(U^{\prime}\) es el número de veces que \(y_{j}<x_{i}\), se obtiene

\[
U+U^{\prime}=n_{1} n_{2} \quad W^{\prime}=\frac{n_{1}\left(n_{1}+1\right)}{2}+U^{\prime}
\]

\begin{itemize}
\tightlist
\item
  Para muestras ``grandes'' puede utilizarse el hecho de que, bajo \(H_{0}\), el estadístico \(U\) es asintóticamente normal:
\end{itemize}

\[
U \sim A N\left(\mu_{U}, \sigma_{U}\right), \quad \mu_{U}=\frac{n_{1} n_{2}}{2}, \quad \sigma_{U}^{2}=\frac{n_{1} n_{2}\left(n_{1}+n_{2}+1\right)}{12}
\]

y, por tanto, para \(n_{1}>10\) o \(n_{2}>10\) podemos basarnos en el estadístico de contraste

\[
Z=\frac{U-n_{1} n_{2} / 2}{\sqrt{n_{1} n_{2}\left(n_{1}+n_{2}+1\right) / 12}} \sim N(0,1)
\]

\subsubsection{Ejemplo 6}\label{ejemplo-6-1}

Para comparar la resistencia en \(\mathrm{kg} / \mathrm{cm}^{2}\) de un material suministrado por dos proveedores se midieron dos muestras de varios elementos:

Proveedor A 202, 229, 215, 220, 223, 233, 208, 228, 209\\
Proveedor B 221, 207, 185, 203, 187, 190, 195, 204, 212

Con un nivel de significación del 0.05, indique si existen diferencias entre los materiales suministrados por los dos proveedores.

\textbf{Solución}:

Ahora utilizaremos la función \texttt{wilcox.test} con los dos vectores de datos, teniendo en cuenta que son independientes, que es la opción por defecto.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pro.A}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{202}\NormalTok{,}\DecValTok{229}\NormalTok{,}\DecValTok{215}\NormalTok{,}\DecValTok{220}\NormalTok{,}\DecValTok{223}\NormalTok{,}\DecValTok{233}\NormalTok{,}\DecValTok{208}\NormalTok{,}\DecValTok{228}\NormalTok{,}\DecValTok{209}\NormalTok{)}
\NormalTok{pro.B}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{221}\NormalTok{,}\DecValTok{207}\NormalTok{,}\DecValTok{185}\NormalTok{,}\DecValTok{203}\NormalTok{,}\DecValTok{187}\NormalTok{,}\DecValTok{190}\NormalTok{,}\DecValTok{195}\NormalTok{,}\DecValTok{204}\NormalTok{,}\DecValTok{212}\NormalTok{)}
\FunctionTok{wilcox.test}\NormalTok{(pro.A,pro.B,}\AttributeTok{alternative=}\StringTok{"two.sided"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Wilcoxon rank sum exact test
## 
## data:  pro.A and pro.B
## W = 70, p-value = 0.007775
## alternative hypothesis: true location shift is not equal to 0
\end{verbatim}

No debemos dejarnos confundir por la notación.

El estadístico calculado es el que hemos denominado \(U^{\prime}=70>n_{1} n_{2} / 2=40.5\). En cualquier caso, el p-valor es muy explícito e implica el rechazo de la hipótesis nula de equivalencia.

\subsection{Comparación de medianas}\label{comparaciuxf3n-de-medianas}

Consideremos una situación en la que se desea comparar dos poblaciones continuas con distribuciones de igual forma y tratar de detectar desplazamientos entre ambas distribuciones.
Sean \(x_{1}, \ldots, x_{n_{1}} \mathrm{i} y_{1}, \ldots, y_{n_{2}}\) dos muestras aleatorias correspondientes a cada población e independientes entre sí. Si se ordenan conjuntamente ambas muestras en orden creciente y se considera la mediana \(M\) de la muestra combinada, podemos calcular el estadístico

\[
T=\sum_{i=1}^{n_{1}} I_{x_{i}<M}
\]

que sirve para contrastar la hipótesis \(H_{0}: M_{X}=M_{Y}\).
Si ambas poblaciones tienen la misma distribución, es de esperar que \(T\) sea próximo a \(n_{1} / 2\). En cambio, si \(T\) resulta mucho mayor que \(n_{1} / 2\), es razonable suponer que la mediana \(M_{X}\) de la primera población es inferior a la de la segunda \(M_{Y}\); mientras que si \(T\) es mucho menor que \(n_{1} / 2\), ello parece indicar que \(M_{X}\) es superior a \(M_{Y}\). Las regiones críticas son:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}
  >{\raggedright\arraybackslash}p{(\linewidth - 2\tabcolsep) * \real{0.5000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Alternativa
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Región crítica
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(M_{X}<M_{Y}\) & \(\{T \geq k\}\) \\
\(M_{X}>M_{Y}\) & \(\left\{T \leq k^{\prime}\right\}\) \\
\(M_{X} \neq M_{Y}\) & \(\left\{T \leq k_{1}\right\} \cup\left\{T \geq k_{2}\right\}\) \\
\end{longtable}

Si la distribución de ambas poblaciones es la misma, la distribución de \(T\) puede obtenerse con facilidad. Dado que las \(n_{1}+n_{2}\) observaciones son independientes
e idénticamente distribuidas, las \(\binom{n_{1}+n_{2}}{n_{1}}\) formas de asignar \(n_{1}\) a la primera muestra (y las restantes \(n_{2}\) a la segunda) son equiprobables. Si \(p\) es la parte entera de \(\left(n_{1}+n_{2}\right) / 2\), existen \(p\) de las \(n_{1}+n_{2}\) observaciones inferiores a \(M\) y se tendrá \(T=t\) en todas aquellas asignaciones en las que resulten \(t\) observaciones de la primera muestra de entre las \(p\) primeras y \(n_{1}-t\) entre las \(n_{1}+n_{2}-p\) últimas. Así

\[
P(T=t)=\frac{\binom{p}{t}\binom{n_{1}+n_{2}-p}{n_{1}-t}}{\binom{n_{1}+n_{2}}{n_{1}}}
\]

donde \(t\) puede variar entre \(\max \left\{0, p-n_{2}\right\}\) y \(\min \left\{n_{1}, p\right\}\). Se trata, por tanto, de una distribución hipergeométrica que puede aproximarse, si \(n_{1}\) y \(n_{2}\) son grandes, por una \(N\left(n_{1} / 2, \sqrt{n_{1} n_{2} / 4\left(n_{1}+n_{2}\right)}\right)\).

\subsubsection{Ejemplo 7}\label{ejemplo-7-1}

Con los datos del ejemplo anterior, calcule el estadístico \(\chi^{2}\) y compare las medianas de las dos muestras.

\textbf{Solución}:

Como ya sabemos, la mediana común de las dos muestras es \(M=208.5\). Entonces la tabla para el test de homogeneidad es

\begin{longtable}[]{@{}lccc@{}}
\toprule\noalign{}
& Pro. A & Pro. B & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
valores inferiores & 2 & 7 & 9 \\
valores superiores & 7 & 2 & 9 \\
Total & 9 & 9 & \\
\end{longtable}

Así, debemos calcular el estadístico ji-cuadrado con la corrección de Yates

\[
\chi^{2}=\frac{(|2 \cdot 2-7 \cdot 7|-18 / 2)^{2}}{9 \cdot 9 \cdot 9 \cdot 9} 18=3.556
\]

Con un grado de libertad y para un nivel de significación del 0.05 , la región crítica comienza en \(\chi_{0.05}^{2}=3.841\), de modo que podemos aceptar la hipótesis nula.

Con tamaños muestrales grandes, el test ji-cuadrado es preferible si no se tiene constancia de que la forma de ambas distribuciones sea la misma, ya que el test \(T\) anterior tiende a aceptar la homogeneidad si \(M_{X}=M_{Y}\) aunque la forma de las distribuciones sea diferente.
Por la misma razón, es preferible el test de Kolmogorov-Smirnov que se explica en la sección siguiente.

Observemos el cálculo de la mediana conjunta con \texttt{median(c(pro.A,pro.B))}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T}\OtherTok{\textless{}{-}}\FunctionTok{length}\NormalTok{(pro.A[pro.A}\SpecialCharTok{\textless{}}\FunctionTok{median}\NormalTok{(}\FunctionTok{c}\NormalTok{(pro.A,pro.B))])}
\NormalTok{T}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{phyper}\NormalTok{(T,}\DecValTok{9}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02834225
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{1}\SpecialCharTok{{-}}\FunctionTok{phyper}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{9}\NormalTok{,}\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.02834225
\end{verbatim}

La distribución hipergeométrica permite encontrar los límites de la región crítica.

Si queremos hacerlo mediante el test ji-cuadrado, en primer lugar debemos introducir las frecuencias de la tabla.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{numero}\OtherTok{\textless{}{-}}\FunctionTok{cbind}\NormalTok{(}\FunctionTok{expand.grid}\NormalTok{(}\AttributeTok{M=}\FunctionTok{c}\NormalTok{(}\StringTok{"inferior a M"}\NormalTok{,}\StringTok{"superior a M"}\NormalTok{),}
\AttributeTok{grup=}\FunctionTok{c}\NormalTok{(}\StringTok{"A"}\NormalTok{,}\StringTok{"B"}\NormalTok{)))}
\NormalTok{fr}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{7}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\FunctionTok{attach}\NormalTok{(numero)}
\NormalTok{taula}\OtherTok{\textless{}{-}}\FunctionTok{table}\NormalTok{(M,grup)}\SpecialCharTok{*}\NormalTok{fr}
\NormalTok{taula}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               grup
## M              A B
##   inferior a M 2 7
##   superior a M 7 2
\end{verbatim}

Y con esta tabla calculamos el test de homogeneidad.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{chisq.test}\NormalTok{(taula)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  taula
## X-squared = 3.5556, df = 1, p-value = 0.05935
\end{verbatim}

El resultado es la aceptación de la igualdad de medianas. La discrepancia con el ejemplo anterior es posible debido al reducido número de observaciones.

\subsection{Test de Kolmogorov-Smirnov para la homogeneidad}\label{test-de-kolmogorov-smirnov-para-la-homogeneidad}

Cuando disponemos de dos muestras independientes \(x_{1}, x_{2}, \ldots, x_{n_{1}}\) e \(y_{1}, y_{2}, \ldots, y_{n_{2}}\) procedentes de dos poblaciones con distribuciones desconocidas \(F_{X}\) y \(F_{Y}\) respectivamente, y queremos contrastar su coincidencia, es decir, la hipótesis \(H_{0}: F_{X}=F_{Y}\), podemos comparar las distribuciones empíricas asociadas a cada muestra. Esto es posible si conocemos los valores exactos de las observaciones y, en este aspecto, esta comparación es preferible al test ji-cuadrado de homogeneidad, que utiliza frecuencias y necesita muchos datos de cada población.

Las distribuciones empíricas son:

\[
F_{n_{1}}(z)=\frac{1}{n_{1}} \sum_{i=1}^{n_{1}} I_{x_{i}<z} \quad
G_{n_{2}}(z)=\frac{1}{n_{2}} \sum_{i=1}^{n_{2}} I_{y_{i}<z}
\]

y el estadístico de Kolmogorov-Smirnov es

\[
\Delta_{n_{1}, n_{2}}=\sup _{z \in \mathbb{R}}\left|F_{n_{1}}(z)-G_{n_{2}}(z)\right|
\]

Si la hipótesis \(H_{0}\) es cierta, las dos distribuciones empíricas deben estar muy próximas y la medida global de discrepancia \(\Delta_{n_{1}, n_{2}}\) será pequeña. Por el contrario, cuando \(F_{X} \neq F_{Y}\), el valor de \(\Delta_{n_{1}, n_{2}}\) será mayor, de modo que la región crítica que debemos considerar es de la forma

\[
\left\{\Delta_{n_{1}, n_{2}}>a\right\}
\]

El test se basa en el Teorema de Smirnov, que afirma lo siguiente:

\emph{Si las distribuciones continuas de las dos poblaciones coinciden \(F_{X}=F_{Y}\) y \(n_{1} \rightarrow \infty, n_{2} \rightarrow \infty\), entonces para cada \(\lambda\)}

\[
P\left(\sqrt{\frac{n_{1} n_{2}}{n_{1}+n_{2}}} \Delta_{n_{1}, n_{2}} \leq \lambda\right)
\rightarrow
Q(\lambda)=\sum_{i=-\infty}^{\infty}(-1)^{i} e^{-2 i^{2} \lambda^{2}}
\]

\emph{donde \(Q(\lambda)\) es la distribución asintótica de Kolmogorov-Smirnov.}

\subsubsection{Ejemplo 8}\label{ejemplo-8-1}

Con los datos del ejemplo 6, calcule el estadístico de Kolmogorov-Smirnov y compare las distribuciones de las dos muestras.

\textbf{Solución}:

Los datos han sido introducidos en los vectores \texttt{pro.A} y \texttt{pro.B}, y el test se calcula mediante la función \texttt{ks.test}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ks.test}\NormalTok{(pro.A,pro.B,}\AttributeTok{alternative=}\StringTok{"two.sided"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Exact two-sample Kolmogorov-Smirnov test
## 
## data:  pro.A and pro.B
## D = 0.66667, p-value = 0.03357
## alternative hypothesis: two-sided
\end{verbatim}

En este caso, el p-valor indica el rechazo de la hipótesis nula.

\subsection{\texorpdfstring{Test \(H\) de Kruskal-Wallis}{Test H de Kruskal-Wallis}}\label{test-h-de-kruskal-wallis}

El test \(U\) es un test no paramétrico para decidir si dos muestras independientes proceden o no de la misma población. El test \(H\) de Kruskal-Wallis es una generalización para \(k\) muestras tomadas de \(k\) poblaciones. Así pues, \emph{es una versión no paramétrica de un ANOVA de un factor}.

Consideremos \(k\) muestras de tamaños \(n_{1}, n_{2}, \ldots, n_{k}\) recogidas en las \(k\) poblaciones, tales que \(n_{1}+n_{2}+\cdots+n_{k}=n\). Supongamos que ordenamos todas las observaciones de forma conjunta y calculamos las sumas de rangos para las \(k\) muestras \(R_{1}, R_{2}, \ldots, R_{k}\), respectivamente. Si definimos el estadístico

\[
H=\left(\frac{12}{n(n+1)} \sum_{i=1}^{k} \frac{R_{i}^{2}}{n_{i}}\right)-3(n+1)
\]

se demuestra que, si existe homogeneidad entre las distribuciones de los \(k\) grupos, su distribución muestral está muy próxima a una ji-cuadrado con \(k-1\) grados de libertad cuando los tamaños muestrales \(n_{i}\) son grandes.

Así, exigiremos siempre que \(n_{1}, n_{2}, \ldots, n_{k}\) sean todos ellos superiores a 5. Para valores pequeños es necesario consultar tablas especiales.

\subsubsection{Observaciones}\label{observaciones-5}

\begin{itemize}
\tightlist
\item
  El estadístico de Kruskal-Wallis puede escribirse en la forma
\end{itemize}

\[
H=\frac{12}{n(n+1)} \sum_{i=1}^{k} n_{i}\left(R_{\bullet i}-R_{\bullet \bullet}\right)^{2}
\]

donde \(R_{\bullet i}=R_{i} / n_{i}\) y \(R_{\bullet \bullet}=(n+1) / 2\). De esta forma, el test basado en \(H\) se asemeja mucho al test \(F\) en un diseño de un factor con réplicas.

\begin{itemize}
\tightlist
\item
  Si existen observaciones repetidas, el estadístico \(H\) se corrige mediante un factor, de forma que el nuevo estadístico es
\end{itemize}

\[
H^{\prime}=\frac{H}{1-\frac{\sum_{j=1}^{r}\left(t_{j}^{3}-t_{j}\right)}{n^{3}-n}}
\]

donde \(t_{j}\) es el número de observaciones repetidas para un rango dado en la muestra combinada y \(r\) es el número de repeticiones. Esta corrección tiene poco efecto sobre el valor de \(H\), incluso en presencia de muchas observaciones repetidas.

\subsubsection{Ejemplo 9}\label{ejemplo-9-1}

Se desea comparar el peso en gramos de un producto envasado por tres fabricantes, con muestras de tamaño 6 en los tres casos.

\begin{longtable}[]{@{}llllllll@{}}
\toprule\noalign{}
Fabr. \(A\) & 251 & 250 & 249 & 255 & 258 & 258 & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Fabr. \(B\) & 247 & 246 & 250 & 241 & 240 & 242 & \\
Fabr. \(C\) & 228 & 236 & 240 & 225 & 236 & 230 & \\
\end{longtable}

Estudie si existen diferencias entre los tres fabricantes utilizando el test de Kruskal-Wallis.

\textbf{Solución}:

Para realizar el test de Kruskal-Wallis utilizamos la función \texttt{kruskal.test}, que proporciona el estadístico \(H\) o, si es necesario, como en este caso, el estadístico corregido \(H^{\prime}\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pes}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{251}\NormalTok{,}\DecValTok{250}\NormalTok{,}\DecValTok{249}\NormalTok{,}\DecValTok{255}\NormalTok{,}\DecValTok{258}\NormalTok{,}\DecValTok{258}\NormalTok{,}\DecValTok{247}\NormalTok{,}\DecValTok{246}\NormalTok{,}\DecValTok{250}\NormalTok{,}\DecValTok{241}\NormalTok{,}\DecValTok{240}\NormalTok{,}\DecValTok{242}\NormalTok{,}
\DecValTok{228}\NormalTok{,}\DecValTok{236}\NormalTok{,}\DecValTok{240}\NormalTok{,}\DecValTok{225}\NormalTok{,}\DecValTok{236}\NormalTok{,}\DecValTok{230}\NormalTok{)}
\NormalTok{fabr}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{6}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{6}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{6}\NormalTok{))}
\FunctionTok{kruskal.test}\NormalTok{(pes,fabr)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Kruskal-Wallis rank sum test
## 
## data:  pes and fabr
## Kruskal-Wallis chi-squared = 14.396, df = 2, p-value = 0.0007482
\end{verbatim}

El p-valor es suficientemente significativo como para rechazar la hipótesis nula.

\subsection{Test de Friedman}\label{test-de-friedman}

Este test está pensado para comprobar si existen diferencias significativas entre \(k\) tratamientos o condiciones experimentales aplicados a \(n\) individuos.

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\linewidth - 12\tabcolsep) * \real{0.1429}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Tratamiento
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Individuo & 1 & 2 & \(\ldots\) & \(j\) & \(\ldots\) & \(k\) \\
1 & \(x_{11}\) & \(x_{12}\) & \(\ldots\) & \(x_{1 j}\) & \(\ldots\) & \(x_{1 k}\) \\
2 & \(x_{21}\) & \(x_{22}\) & \(\ldots\) & \(x_{2 j}\) & \(\ldots\) & \(x_{2 k}\) \\
\(\vdots\) & \(\vdots\) & \(\vdots\) & & \(\vdots\) & & \(\vdots\) \\
\(n\) & \(x_{n 1}\) & \(x_{n 2}\) & \(\ldots\) & \(x_{n j}\) & \(\ldots\) & \(x_{n k}\) \\
\end{longtable}

Los individuos deben escogerse al azar y de forma independiente, de modo que las filas son independientes entre sí. Sin embargo, como los individuos son los mismos, las columnas son dependientes.

El test de Friedman sirve para comprobar si existen diferencias entre los \(k\) tratamientos (efecto columna), en presencia de efectos individuales (efecto fila). \emph{Es una versión no paramétrica del diseño de dos factores sin interacción}.

La hipótesis nula es la igualdad de respuesta o de efecto de los diferentes tratamientos, mientras que la alternativa es que existen, al menos, dos tratamientos con respuesta diferente.

Para calcular el estadístico no paramétrico, para cada fila por separado se asignan los rangos correspondientes a los valores observados. Una vez convertida la tabla original en rangos, se calculan las sumas de rangos \(R_{j}\) para cada columna o tratamiento \(j=1, \ldots, k\). El estadístico es

\[
S=\frac{12}{n k(k+1)} \sum_{j=1}^{k} R_{j}^{2}-3 n(k+1)
\]

La distribución aproximada de \(S\) para valores grandes de \(n\) es una ji-cuadrado con \(k-1\) grados de libertad. Para valores muy pequeños de \(n\) (\(n<10\)) es necesario consultar tablas especiales. La región crítica es de la forma \(\{S \geq c\}\).

Cuando existen ligaduras en una fila, deben promediarse los rangos de los valores repetidos y calcular el estadístico de Friedman modificado mediante un factor de corrección

\[
S^{\prime}=\frac{12 \sum_{j=1}^{k} R_{j}^{2}-3 n^{2} k(k+1)^{2}}{n k(k+1)-\frac{1}{k-1} \sum_{i=1}^{n}\left\{\sum_{j=1}^{g_{i}} t_{i j}^{3}-k\right\}}
\]

donde \(g_{i}\) es el número de grupos de observaciones ligadas en la fila \(i\) y \(t_{i j}\) es el número de observaciones ligadas en el grupo \(j\) de la fila \(i\). Cuando no hay ligaduras se considera, por convenio, que \(g_{i}=k\) y \(t_{i j}=1\), y entonces el término de corrección para el individuo \(i\) es \(k-k=0\). Si esto ocurre en todas las filas, entonces \(S^{\prime}=S\).

\subsubsection{Ejemplo 10}\label{ejemplo-10-1}

Se ha consultado a un grupo de 12 personas para que opinen sobre cinco marcas de champú. En concreto, sus clasificaciones se recogen en la siguiente tabla.

\begin{longtable}[]{@{}cccccc@{}}
\toprule\noalign{}
& Champú & & & & \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Ind. & \(A\) & \(B\) & \(C\) & \(D\) & \(E\) \\
1 & 5 & 3 & 2 & 4 & 1 \\
2 & 4 & 3 & 5 & 2 & 1 \\
3 & 3 & 5 & 4 & 2 & 1 \\
4 & 4 & 5 & 1 & 2 & 3 \\
5 & 3 & 4 & 5 & 1 & 2 \\
6 & 5 & 3 & 4 & 2 & 1 \\
7 & 2 & 5 & 4 & 3 & 1 \\
8 & 3 & 5 & 4 & 1 & 2 \\
9 & 3 & 4 & 5 & 2 & 1 \\
10 & 4 & 5 & 3 & 1 & 2 \\
11 & 5 & 3 & 2 & 4 & 1 \\
12 & 5 & 4 & 3 & 2 & 1 \\
\end{longtable}

Determine si existen diferencias significativas entre las puntuaciones otorgadas a los champús.

\textbf{Solución}:

El test de Friedman se aplica mediante la función \texttt{friedman.test}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nota}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}
\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}
\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{,}
\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{individu}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{),}
\FunctionTok{rep}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{5}\NormalTok{),}
\FunctionTok{rep}\NormalTok{(}\DecValTok{7}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{9}\NormalTok{,}\DecValTok{5}\NormalTok{),}
\FunctionTok{rep}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{11}\NormalTok{,}\DecValTok{5}\NormalTok{),}\FunctionTok{rep}\NormalTok{(}\DecValTok{12}\NormalTok{,}\DecValTok{5}\NormalTok{))}
\NormalTok{xampu}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{5}\NormalTok{,}\DecValTok{1}\NormalTok{),}\DecValTok{12}\NormalTok{))}
\FunctionTok{friedman.test}\NormalTok{(nota,xampu,individu)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Friedman rank sum test
## 
## data:  nota, xampu and individu
## Friedman chi-squared = 25.533, df = 4, p-value = 3.929e-05
\end{verbatim}

El p-valor indica claramente la significación de las diferencias.

\subsubsection{Observaciones}\label{observaciones-6}

\begin{itemize}
\tightlist
\item
  Puede verse que
\end{itemize}

\[
S=\frac{12 n}{k(k+1)} \sum_{j=1}^{k}\left(R_{\bullet j}-R_{\bullet \bullet}\right)^{2}
\]

donde \(R_{\bullet j}=R_{j} / n\) y \(R_{\bullet \bullet}=(k+1) / 2\). Esto pone de manifiesto la relación de este test con el test \(F\) para detectar el efecto columna en el diseño de dos factores sin interacción.

\subsection{Coeficientes de correlación no paramétricos}\label{coeficientes-de-correlaciuxf3n-no-paramuxe9tricos}

En esta sección presentamos dos coeficientes no paramétricos que permiten medir la dependencia estocástica de dos muestras apareadas en poblaciones continuas.

También estamos interesados en los contrastes de independencia que pueden formularse a partir de estos coeficientes.

\subsubsection{\texorpdfstring{Coeficiente \(\tau\) de Kendall}{Coeficiente \textbackslash tau de Kendall}}\label{coeficiente-tau-de-kendall}

Consideremos una muestra aleatoria simple \((x_{1}, y_{1}), \ldots, (x_{n}, y_{n})\) procedente de una distribución bidimensional. Sabemos que la frecuencia relativa de los pares tales que \((x_{i}-x_{j})(y_{i}-y_{j})>0\) es un estimador del parámetro

\[
\pi_{+}=P\left\{(X-X^{\prime})(Y-Y^{\prime})>0\right\}
\]

donde \((X, Y)\) y \((X^{\prime}, Y^{\prime})\) son independientes y tienen la misma distribución conjunta poblacional.
La continuidad de las distribuciones implica que

\[
P\left\{(X-X^{\prime})(Y-Y^{\prime})=0\right\}=0
\]

de modo que

\[
\pi_{-}=P\left\{(X-X^{\prime})(Y-Y^{\prime})<0\right\}=1-\pi_{+}
\]

Entonces,

\[
\tau=\pi_{+}-\pi_{-}=2\pi_{+}-1
\]

es el llamado \textbf{coeficiente de asociación de Kendall}, y mide, en cierto modo, la dependencia entre las variables. De hecho, si \(X\) e \(Y\) son independientes,

\[
\begin{aligned}
\pi_{+} & =P(X<X^{\prime})P(Y<Y^{\prime})+P(X>X^{\prime})P(Y>Y^{\prime}) \\
& =P(X>X^{\prime})P(Y<Y^{\prime})+P(X<X^{\prime})P(Y>Y^{\prime})=\pi_{-}
\end{aligned}
\]

de forma que \(\tau=0\). El recíproco no es cierto: puede ocurrir que \(\tau=0\) sin que necesariamente las variables \(X\) e \(Y\) sean independientes.

Si \(P\) y \(N\) representan el número de pares tales que \((x_{i}-x_{j})(y_{i}-y_{j})>0\) y \((x_{i}-x_{j})(y_{i}-y_{j})<0\), respectivamente, entre las \(\binom{n}{2}\) posibles, el estimador natural de \(\tau\) es

\[
T=\frac{P}{\binom{n}{2}}-\frac{N}{\binom{n}{2}}=\frac{2}{n(n-1)}(P-N)
\]

Además, dado que \(P+N=\binom{n}{2}\), se obtiene

\[
T=\frac{4P}{n(n-1)}-1
\]

Para una muestra concreta, \(P\) se calcula fácilmente ordenando la muestra según la primera componente: es el número de pares con \(i<j\) tales que \(y_{i}<y_{j}\).

El estadístico \(T\) toma valores entre \(-1\) y \(1\), y un valor alejado de cero indica que \(\tau \neq 0\) y, por tanto, que las variables \(X\) e \(Y\) no son independientes.

La distribución exacta de \(T\) puede calcularse para valores moderados de \(n\). Para \(n \leq 10\) existen tablas de valores críticos tales que \(P(|T|>k_{\alpha}) \leq \alpha\). Para \(n>10\) puede considerarse la aproximación

\[
T \sim N\left(0, \sigma_K^2\right),
\]
dond \(\displaystyle{\sigma_K^2 =\frac{2(2n+5)}{9n(n-1)}}\) es la varianza asintótica del estadístico \(T\).

\subparagraph{Ejemplo 14}\label{ejemplo-14-1}

La longitud y la anchura de una muestra de 11 hojas de una determinada planta son:

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}
  >{\raggedleft\arraybackslash}p{(\linewidth - 22\tabcolsep) * \real{0.0833}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Hoja
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
1
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
2
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
3
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
4
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
5
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
6
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
7
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
8
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
9
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
10
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedleft
11
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Long. & 6.60 & 7.11 & 9.80 & 6.62 & 7.10 & 6.83 & 6.54 & 7.14 & 7.13 & 12.52 & 10.41 \\
Anch. & 4.24 & 5.41 & 5.26 & 5.53 & 3.25 & 4.22 & 3.98 & 3.29 & 3.43 & 5.57 & 6.01 \\
\end{longtable}

Calcule el coeficiente de correlación de Kendall y estudie si es significativo.

\textbf{Solución}:

Para el cálculo de los coeficientes de correlación se utiliza la función \texttt{cor.test} con el parámetro \texttt{method} y el valor \texttt{"pearson"}, \texttt{"kendall"} o \texttt{"spearman"}, según si deseamos el coeficiente clásico de Pearson, la \(\tau\) de Kendall o el coeficiente por rangos de Spearman.

Observemos, no obstante, que estrictamente esta función no sirve para calcular los coeficientes, sino para contrastar la hipótesis de que el coeficiente correspondiente es cero. Sin embargo, como el primer paso que realiza la función es el cálculo del coeficiente, se obtiene este como un efecto colateral.

Otra cuestión \textbf{muy importante}, y que muchos usuarios suelen olvidar, es que si estos tests resultan significativos, únicamente indican que la correlación, del tipo que sea, no es cero; en ningún caso garantizan que sea suficientemente alta como para hablar de una ``buena correlación''.

Volviendo a los datos del ejemplo:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{long}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\FloatTok{6.60}\NormalTok{,}\FloatTok{7.11}\NormalTok{,}\FloatTok{9.80}\NormalTok{,}\FloatTok{6.62}\NormalTok{,}\FloatTok{7.10}\NormalTok{,}\FloatTok{6.83}\NormalTok{,}\FloatTok{6.54}\NormalTok{,}\FloatTok{7.14}\NormalTok{,}\FloatTok{7.13}\NormalTok{,}\FloatTok{12.52}\NormalTok{,}\FloatTok{10.41}\NormalTok{)}
\NormalTok{ampl}\OtherTok{\textless{}{-}}\FunctionTok{c}\NormalTok{(}\FloatTok{4.24}\NormalTok{,}\FloatTok{5.41}\NormalTok{,}\FloatTok{5.26}\NormalTok{,}\FloatTok{5.53}\NormalTok{,}\FloatTok{3.25}\NormalTok{,}\FloatTok{4.22}\NormalTok{,}\FloatTok{3.98}\NormalTok{,}\FloatTok{3.29}\NormalTok{,}\FloatTok{3.43}\NormalTok{,}\FloatTok{5.57}\NormalTok{,}\FloatTok{6.01}\NormalTok{)}
\FunctionTok{cor.test}\NormalTok{(long, ampl, }\AttributeTok{method=}\StringTok{\textquotesingle{}kendall\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Kendall's rank correlation tau
## 
## data:  long and ampl
## T = 34, p-value = 0.3587
## alternative hypothesis: true tau is not equal to 0
## sample estimates:
##       tau 
## 0.2363636
\end{verbatim}

Observemos que el número de pares positivos es 34, estadístico que hemos denominado \(P\).
El procedimiento calcula el p-valor exacto para \(n<50\). En este caso, el p-valor indica que el estadístico no es significativo.

\subsubsection{Coeficiente de correlación por rangos de Spearman}\label{coeficiente-de-correlaciuxf3n-por-rangos-de-spearman}

El coeficiente de correlación de Spearman es el coeficiente de correlación ordinario (coeficiente de Pearson) aplicado a los rangos de las observaciones.

El resultado es

\[
r_{S}=1-\frac{6 \sum_{i=1}^{n} d_{i}^{2}}{n(n^{2}-1)}
\]

donde \(d_{i}=r(x_{i})-r(y_{i})\), \(i=1, \ldots, n\), son las diferencias entre los rangos.

Este coeficiente se utiliza cuando las variables están medidas en una escala ordinal y el orden muestral es la información más relevante.

\paragraph{Cálculo del coeficiente}\label{cuxe1lculo-del-coeficiente}

El coeficiente de correlación \(r_{S}\) de Spearman se obtiene sustituyendo los valores \((x_{i},y_{i})\) por sus rangos \((a_{i},b_{i})\), donde \(a_{i}=r(x_{i})\) y \(b_{i}=r(y_{i})\).

Así,

\[
r_{S}=\frac{\sum_{i=1}^{n}(a_{i}-\bar a)(b_{i}-\bar b)}{\sqrt{\sum_{i=1}^{n}(a_{i}-\bar a)^{2}\sum_{i=1}^{n}(b_{i}-\bar b)^{2}}}
\]

donde \(\bar a=\bar b=(n+1)/2\) y

\[
\sum_{i=1}^{n}(a_{i}-\bar a)^{2}=\sum_{i=1}^{n}(b_{i}-\bar b)^{2}=\frac{n(n^{2}-1)}{12}
\]

de modo que

\[
r_{S}=\frac{12}{n(n^{2}-1)}\sum_{i=1}^{n}(a_{i}-\bar a)(b_{i}-\bar b)
\]

Por otro lado,

\[
\sum_{i=1}^{n} d_{i}^{2}=\frac{n(n^{2}-1)}{6}(1-r_{S})
\]

lo que conduce a la expresión inicial de \(r_{S}\).

Bajo la hipótesis de independencia, puede obtenerse la distribución muestral de \(r_{S}\) y, por tanto, los puntos críticos del contraste para \(n\leq10\). Para \(n>10\), \(r_{S}\) es aproximadamente \(N(0,1/\sqrt{n-1})\).

\subparagraph{Ejemplo}\label{ejemplo-16}

Calcule el coeficiente de correlación por rangos de Spearman para los datos del ejemplo 14 y estudie si es significativo.

\textbf{Solución}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor.test}\NormalTok{(long,ampl,}\AttributeTok{method=}\StringTok{\textquotesingle{}spearman\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Spearman's rank correlation rho
## 
## data:  long and ampl
## S = 140, p-value = 0.2732
## alternative hypothesis: true rho is not equal to 0
## sample estimates:
##       rho 
## 0.3636364
\end{verbatim}

\subsubsection{El parámetro poblacional asociado a los coeficientes de correlación no paramétricos}\label{el-paruxe1metro-poblacional-asociado-a-los-coeficientes-de-correlaciuxf3n-no-paramuxe9tricos}

Si la distribución conjunta de \((X,Y)\) es \(F(x,y)\) y las distribuciones marginales son \(F_X(x)\) y \(F_Y(y)\), entonces \(\rho_S\) es el coeficiente de correlación ordinario entre las variables \(V_1=F_X(X)\) y \(V_2=F_Y(Y)\), ambas con distribución uniforme.

En consecuencia, puede demostrarse que

\[
\begin{aligned}
\rho_S &=12\iint_{\mathbb R^2}(F(x,y)-F_X(x)F_Y(y))\,dF_X(x)dF_Y(y)\\
&=12\iint_{\mathbb R^2}F(x,y)\,dF_X(x)dF_Y(y)-3
\end{aligned}
\]

La versión probabilística de la correlación \(\tau\) de Kendall es

\[
\tau=4\int_{\mathbb R^2}(F(x,y)-F_X(x)F_Y(y))\,dF(x,y)
\]

y se verifica la relación

\[
-1\leq 3\tau-2\rho_S\leq1
\]

Observemos que \(\rho_S=\tau=0\) si \(F(x,y)=F_X(x)F_Y(y)\), es decir, si \(X\) e \(Y\) son estocásticamente independientes.

Para contrastar la hipótesis nula \(H_0:\rho_S=0\), puede calcularse el estadístico

\[
t=\sqrt{n-2}\frac{r_S}{\sqrt{1-r_S^2}}
\]

que tiene aproximadamente una distribución \(t\) de Student con \(n-2\) grados de libertad, siempre que \(n\geq10\).

\newpage

\section{Bibliografia}\label{bibliografia}

\end{document}
