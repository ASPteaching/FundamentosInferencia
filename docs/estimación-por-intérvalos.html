<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 8 Estimación por intérvalos | Fundamentos de Inferencia Estadistica</title>
  <meta name="description" content="Capítulo 8 Estimación por intérvalos | Fundamentos de Inferencia Estadistica" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 8 Estimación por intérvalos | Fundamentos de Inferencia Estadistica" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 8 Estimación por intérvalos | Fundamentos de Inferencia Estadistica" />
  
  
  

<meta name="author" content="Alex Sanchez Pla y Santiago Pérez Hoyos" />


<meta name="date" content="2024-12-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimación-puntual.html"/>
<link rel="next" href="pruebas-de-hipótesis.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="blocks.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/docs/_main.pdf" title="Version en PDF" target="_blank"><img alt="Versión en pdf" src="./images(pdf.png)" width="12" height="15" />    </a>
</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisitos-y-organización-del-material"><i class="fa fa-check"></i>Prerequisitos y organización del material</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html"><i class="fa fa-check"></i>Agradecimiento y fuentes utilizadas</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#el-proyecto-statmedia"><i class="fa fa-check"></i>El proyecto Statmedia</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#otros-materiales-utilizados"><i class="fa fa-check"></i>Otros materiales utilizados</a></li>
<li class="chapter" data-level="0.1" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#materiales-complementarios"><i class="fa fa-check"></i><b>0.1</b> Materiales complementarios</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#complementos-matemáticos"><i class="fa fa-check"></i>Complementos matemáticos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html"><i class="fa fa-check"></i><b>1</b> Probabilidad y Experimentos aleatorios</a>
<ul>
<li class="chapter" data-level="1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducción"><i class="fa fa-check"></i><b>1.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#fenómenos-deterministas-y-fenómenos-aleatorios"><i class="fa fa-check"></i><b>1.1.1</b> Fenómenos deterministas y fenómenos aleatorios</a></li>
<li class="chapter" data-level="1.1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos"><i class="fa fa-check"></i><b>1.1.2</b> Sucesos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#función-de-probabilidad"><i class="fa fa-check"></i><b>1.2</b> Función de probabilidad</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#diferentes-funciones-de-probabilidad-para-una-misma-experiencia-aleatoria"><i class="fa fa-check"></i><b>1.2.1</b> ¿Diferentes funciones de probabilidad para una misma experiencia aleatoria?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#cómo-se-calculan-las-probabilidades"><i class="fa fa-check"></i><b>1.3</b> ¿Cómo se calculan las probabilidades?</a></li>
<li class="chapter" data-level="1.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-elementales-y-sucesos-observables"><i class="fa fa-check"></i><b>1.4</b> Sucesos elementales y sucesos observables</a></li>
<li class="chapter" data-level="1.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#propiedades-inmediatas-de-la-probabilidad"><i class="fa fa-check"></i><b>1.5</b> Propiedades inmediatas de la probabilidad</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#succeso-imposible"><i class="fa fa-check"></i><b>1.5.1</b> Succeso imposible</a></li>
<li class="chapter" data-level="1.5.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#suceso-implicado"><i class="fa fa-check"></i><b>1.5.2</b> Suceso implicado</a></li>
<li class="chapter" data-level="1.5.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#complementario-de-un-suceso"><i class="fa fa-check"></i><b>1.5.3</b> Complementario de un suceso</a></li>
<li class="chapter" data-level="1.5.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ocurrencia-de-algun-suceso"><i class="fa fa-check"></i><b>1.5.4</b> Ocurrencia de algun suceso</a></li>
<li class="chapter" data-level="1.5.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurra-algun-suceso"><i class="fa fa-check"></i><b>1.5.5</b> Probabilidad de que ocurra algun suceso</a></li>
<li class="chapter" data-level="1.5.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurran-dos-o-más-sucesos-a-la-vez"><i class="fa fa-check"></i><b>1.5.6</b> Probabilidad de que ocurran dos (o más) sucesos a la vez</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#espacios-de-probabilidad"><i class="fa fa-check"></i><b>1.6</b> Espacios de probabilidad</a></li>
<li class="chapter" data-level="1.7" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>1.7</b> Probabilidad condicionada</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-dependientes-y-sucesos-independientes"><i class="fa fa-check"></i><b>1.7.1</b> Sucesos dependientes y sucesos independientes</a></li>
<li class="chapter" data-level="1.7.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#incompatibilidad-e-independencia"><i class="fa fa-check"></i><b>1.7.2</b> Incompatibilidad e independencia</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#dos-teoremas-importantes"><i class="fa fa-check"></i><b>1.8</b> Dos Teoremas importantes</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-las-probabilidades-totales"><i class="fa fa-check"></i><b>1.8.1</b> Teorema de las probabilidades totales</a></li>
<li class="chapter" data-level="1.8.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-bayes"><i class="fa fa-check"></i><b>1.8.2</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducción-a-los-experimentos-múltiples"><i class="fa fa-check"></i><b>1.9</b> Introducción a los experimentos múltiples</a></li>
<li class="chapter" data-level="1.10" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinatoria"><i class="fa fa-check"></i><b>1.10</b> Combinatoria</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones"><i class="fa fa-check"></i><b>1.10.1</b> Permutaciones</a></li>
<li class="chapter" data-level="1.10.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones"><i class="fa fa-check"></i><b>1.10.2</b> Variaciones</a></li>
<li class="chapter" data-level="1.10.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones-con-repetición"><i class="fa fa-check"></i><b>1.10.3</b> Variaciones con repetición</a></li>
<li class="chapter" data-level="1.10.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinaciones"><i class="fa fa-check"></i><b>1.10.4</b> Combinaciones</a></li>
<li class="chapter" data-level="1.10.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones-con-repetición"><i class="fa fa-check"></i><b>1.10.5</b> Permutaciones con repetición</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#frecuencia-relativa-y-probabilidad"><i class="fa fa-check"></i><b>1.11</b> Frecuencia relativa y probabilidad</a></li>
<li class="chapter" data-level="1.12" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#caso-de-estudio-eficacia-de-una-prueba-diagnóstica"><i class="fa fa-check"></i><b>1.12</b> Caso de Estudio: Eficacia de una prueba diagnóstica</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#aplicación-del-teorema-de-bayes"><i class="fa fa-check"></i><b>1.12.1</b> Aplicación del Teorema de Bayes</a></li>
<li class="chapter" data-level="1.12.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ejemplo-numérico"><i class="fa fa-check"></i><b>1.12.2</b> Ejemplo numérico</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>2</b> Variables aleatorias y Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#el-espacio-muestral-y-sus-elementos"><i class="fa fa-check"></i><b>2.1</b> El espacio muestral y sus elementos</a></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representación-numérica-de-los-sucesos-elementales.-variables-aleatorias"><i class="fa fa-check"></i><b>2.2</b> Representación numérica de los sucesos elementales. Variables aleatorias</a></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterización-de-una-variable-aleatoria-a-través-de-la-probabilidad.-función-de-distribución"><i class="fa fa-check"></i><b>2.3</b> Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución</a></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-función-de-distribución"><i class="fa fa-check"></i><b>2.4</b> Propiedades de la función de distribución</a></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificación-de-las-variables-aleatorias"><i class="fa fa-check"></i><b>2.5</b> Clasificación de las variables aleatorias</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-discretas"><i class="fa fa-check"></i><b>2.5.1</b> Variables aleatorias discretas</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.5.2</b> Variables aleatorias continuas</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variable-aleatoria-discretas"><i class="fa fa-check"></i><b>2.6</b> Variable aleatoria discretas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterización-de-las-v.a.-discretas"><i class="fa fa-check"></i><b>2.6.1</b> Caracterización de las v.a. discretas</a></li>
<li class="chapter" data-level="2.6.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-función-de-densidad-discreta"><i class="fa fa-check"></i><b>2.6.2</b> Propiedades de la función de densidad discreta</a></li>
<li class="chapter" data-level="2.6.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-función-de-distribución-y-la-función-de-densidad-discreta.-probabilidad-de-intervalos."><i class="fa fa-check"></i><b>2.6.3</b> Relaciones entre la función de distribución y la función de densidad discreta. <br> Probabilidad de intervalos.</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>2.7</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#función-de-densidad-continua"><i class="fa fa-check"></i><b>2.7.1</b> Función de densidad continua</a></li>
<li class="chapter" data-level="2.7.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-función-de-distribución-y-la-función-de-densidad."><i class="fa fa-check"></i><b>2.7.2</b> Relaciones entre la función de distribución y la función de densidad.</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterización-de-una-variable-aleatoria-a-través-de-parámetros"><i class="fa fa-check"></i><b>2.8</b> Caracterización de una variable aleatoria a través de parámetros</a></li>
<li class="chapter" data-level="2.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-discreta"><i class="fa fa-check"></i><b>2.9</b> Esperanza de una variable aleatoria discreta</a></li>
<li class="chapter" data-level="2.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-continua"><i class="fa fa-check"></i><b>2.10</b> Esperanza de una variable aleatoria continua</a></li>
<li class="chapter" data-level="2.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-esperanza-matemática"><i class="fa fa-check"></i><b>2.11</b> Propiedades de la esperanza matemática</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#linealidad-de-la-esperanza-matemática"><i class="fa fa-check"></i><b>2.11.1</b> Linealidad de la esperanza matemática</a></li>
<li class="chapter" data-level="2.11.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-del-producto"><i class="fa fa-check"></i><b>2.11.2</b> Esperanza del producto</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.12</b> Varianza de una variable aleatoria</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-varianza"><i class="fa fa-check"></i><b>2.12.1</b> Propiedades de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#momentos-de-orden-k-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.13</b> Momentos (de orden <span class="math inline">\(k\)</span>) de una variable aleatoria</a></li>
<li class="chapter" data-level="2.14" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#definición-formal-de-variable-aleatoria"><i class="fa fa-check"></i><b>2.14</b> Definición formal de variable aleatoria</a></li>
<li class="chapter" data-level="2.15" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caso-práctico-lanzamiento-de-dos-dados"><i class="fa fa-check"></i><b>2.15</b> Caso práctico: Lanzamiento de dos dados</a>
<ul>
<li class="chapter" data-level="2.15.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#espacio-muestral"><i class="fa fa-check"></i><b>2.15.1</b> Espacio muestral</a></li>
<li class="chapter" data-level="2.15.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representación-numérica"><i class="fa fa-check"></i><b>2.15.2</b> Representación numérica</a></li>
<li class="chapter" data-level="2.15.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#algunas-probabilidades"><i class="fa fa-check"></i><b>2.15.3</b> Algunas probabilidades</a></li>
<li class="chapter" data-level="2.15.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#función-de-distribución"><i class="fa fa-check"></i><b>2.15.4</b> Función de distribución</a></li>
<li class="chapter" data-level="2.15.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificación-de-las-variables"><i class="fa fa-check"></i><b>2.15.5</b> Clasificación de las variables</a></li>
<li class="chapter" data-level="2.15.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#función-de-densidad-discreta"><i class="fa fa-check"></i><b>2.15.6</b> Función de densidad discreta</a></li>
<li class="chapter" data-level="2.15.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-intervalos-1"><i class="fa fa-check"></i><b>2.15.7</b> Probabilidad de intervalos</a></li>
<li class="chapter" data-level="2.15.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza"><i class="fa fa-check"></i><b>2.15.8</b> Esperanza</a></li>
<li class="chapter" data-level="2.15.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-un-juego"><i class="fa fa-check"></i><b>2.15.9</b> Esperanza de un juego</a></li>
<li class="chapter" data-level="2.15.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-con-recorrido-infinito"><i class="fa fa-check"></i><b>2.15.10</b> Esperanza con recorrido infinito</a></li>
<li class="chapter" data-level="2.15.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-infinita"><i class="fa fa-check"></i><b>2.15.11</b> Esperanza infinita</a></li>
<li class="chapter" data-level="2.15.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza"><i class="fa fa-check"></i><b>2.15.12</b> Varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html"><i class="fa fa-check"></i><b>3</b> Distribuciones Notables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-discretas"><i class="fa fa-check"></i><b>3.1</b> Distribuciones discretas</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-bernouilli"><i class="fa fa-check"></i><b>3.1.1</b> La distribución de Bernouilli</a></li>
<li class="chapter" data-level="3.1.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-binomial"><i class="fa fa-check"></i><b>3.1.2</b> La distribución Binomial</a></li>
<li class="chapter" data-level="3.1.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-poisson"><i class="fa fa-check"></i><b>3.1.3</b> La distribución de Poisson</a></li>
<li class="chapter" data-level="3.1.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-uniforme-discreta"><i class="fa fa-check"></i><b>3.1.4</b> La distribución Uniforme discreta</a></li>
<li class="chapter" data-level="3.1.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-hipergeométrica"><i class="fa fa-check"></i><b>3.1.5</b> La distribución Hipergeométrica</a></li>
<li class="chapter" data-level="3.1.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-geométrica-o-de-pascal"><i class="fa fa-check"></i><b>3.1.6</b> La distribución Geométrica o de Pascal</a></li>
<li class="chapter" data-level="3.1.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-binomial-negativa"><i class="fa fa-check"></i><b>3.1.7</b> La distribución Binomial negativa</a></li>
<li class="chapter" data-level="3.1.8" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-distribuciones-discretas-principales"><i class="fa fa-check"></i><b>3.1.8</b> Tabla resumen de las distribuciones discretas principales</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-continuas"><i class="fa fa-check"></i><b>3.2</b> Distribuciones Continuas</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-uniforme"><i class="fa fa-check"></i><b>3.2.1</b> La distribución Uniforme</a></li>
<li class="chapter" data-level="3.2.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-exponencial"><i class="fa fa-check"></i><b>3.2.2</b> La distribución Exponencial</a></li>
<li class="chapter" data-level="3.2.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-normal"><i class="fa fa-check"></i><b>3.2.3</b> La distribución Normal</a></li>
<li class="chapter" data-level="3.2.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-gamma"><i class="fa fa-check"></i><b>3.2.4</b> La distribución Gamma</a></li>
<li class="chapter" data-level="3.2.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-cauchy"><i class="fa fa-check"></i><b>3.2.5</b> La distribución de Cauchy</a></li>
<li class="chapter" data-level="3.2.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-weibull"><i class="fa fa-check"></i><b>3.2.6</b> La distribución de Weibull</a></li>
<li class="chapter" data-level="3.2.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-principales-distribuciones-continuas"><i class="fa fa-check"></i><b>3.2.7</b> Tabla resumen de las principales distribuciones continuas</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-con-r-y-python"><i class="fa fa-check"></i><b>3.3</b> Distribuciones con R (y Python)</a></li>
<li class="chapter" data-level="3.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-familia-exponencial-de-distribuciones"><i class="fa fa-check"></i><b>3.4</b> La familia exponencial de distribuciones</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#ejemplos-de-distribuciones-de-esta-familia"><i class="fa fa-check"></i><b>3.4.1</b> Ejemplos de distribuciones de esta familia</a></li>
<li class="chapter" data-level="3.4.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-binomial"><i class="fa fa-check"></i><b>3.4.2</b> Distribución Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#importancia-y-utilidad-de-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.3</b> Importancia y utilidad de la familia exponencial</a></li>
<li class="chapter" data-level="3.4.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#los-modelos-lineales-generalizados-glms"><i class="fa fa-check"></i><b>3.4.4</b> Los modelos lineales generalizados (GLMs)</a></li>
<li class="chapter" data-level="3.4.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#estimación-en-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.5</b> Estimación en la familia exponencial</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html"><i class="fa fa-check"></i><b>4</b> Distribuciones de probabilidad multidimensionales</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-conjuntas-de-probabilidades"><i class="fa fa-check"></i><b>4.1</b> Distribuciones conjuntas de probabilidades</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatoria-bivariante"><i class="fa fa-check"></i><b>4.1.1</b> Variable aleatoria bivariante</a></li>
<li class="chapter" data-level="4.1.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#función-de-distribución-bivariante"><i class="fa fa-check"></i><b>4.1.2</b> Función de distribución bivariante</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatorias-bivariantes-discretas"><i class="fa fa-check"></i><b>4.2</b> Variable aleatorias bivariantes discretas</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#función-de-masa-de-probabilidad-discreta-fmp"><i class="fa fa-check"></i><b>4.2.1</b> Función de masa de probabilidad discreta (fmp)</a></li>
<li class="chapter" data-level="4.2.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-fmp-bivariante"><i class="fa fa-check"></i><b>4.2.2</b> Propiedades de la fmp bivariante</a></li>
<li class="chapter" data-level="4.2.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejemplo-de-distribución-bivariante-discreta"><i class="fa fa-check"></i><b>4.2.3</b> Ejemplo de distribución bivariante discreta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribución-multinomial"><i class="fa fa-check"></i><b>4.3</b> La distribución multinomial</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#generación-de-las-observaciones"><i class="fa fa-check"></i><b>4.3.1</b> Generación de las observaciones</a></li>
<li class="chapter" data-level="4.3.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funcion-de-masa-de-probabilidad-de-la-distribución-multinomial"><i class="fa fa-check"></i><b>4.3.2</b> Funcion de masa de probabilidad de la distribución multinomial</a></li>
<li class="chapter" data-level="4.3.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relación-con-la-distribución-binomial"><i class="fa fa-check"></i><b>4.3.3</b> Relación con la distribución binomial</a></li>
<li class="chapter" data-level="4.3.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#un-caso-particular-la-distribución-trinomial"><i class="fa fa-check"></i><b>4.3.4</b> Un caso particular: La distribución trinomial</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-marginales"><i class="fa fa-check"></i><b>4.4</b> Distribuciones marginales</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#las-marginales-están-en-los-márgenes"><i class="fa fa-check"></i><b>4.4.1</b> Las marginales están en los márgenes</a></li>
<li class="chapter" data-level="4.4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-discretas"><i class="fa fa-check"></i><b>4.4.2</b> Densidades marginales discretas</a></li>
<li class="chapter" data-level="4.4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribuciones-marginales"><i class="fa fa-check"></i><b>4.4.3</b> Trinomial M(5; 0.6, 0.2): Distribuciones marginales</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales"><i class="fa fa-check"></i><b>4.5</b> Distribuciones condicionales</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional"><i class="fa fa-check"></i><b>4.5.1</b> Densidad condicional</a></li>
<li class="chapter" data-level="4.5.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribución-condicional"><i class="fa fa-check"></i><b>4.5.2</b> Trinomial M(5; 0.6, 0.2): Distribución condicional</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#vectores-aleatorios-absolutamente-continuos"><i class="fa fa-check"></i><b>4.6</b> Vectores aleatorios absolutamente continuos</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-función-de-densidad-conjunta"><i class="fa fa-check"></i><b>4.6.1</b> Propiedades de la función de densidad conjunta</a></li>
<li class="chapter" data-level="4.6.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.2</b> Densidades marginales en el caso continuo</a></li>
<li class="chapter" data-level="4.6.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.3</b> Densidad condicional en el caso continuo</a></li>
<li class="chapter" data-level="4.6.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribución-normal-bivariante"><i class="fa fa-check"></i><b>4.6.4</b> La Distribución Normal Bivariante</a></li>
<li class="chapter" data-level="4.6.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales-1"><i class="fa fa-check"></i><b>4.6.5</b> Distribuciones Condicionales</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#independencia-de-variables-aleatorias"><i class="fa fa-check"></i><b>4.7</b> Independencia de variables aleatorias</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#primera-caracterización-de-la-independencia"><i class="fa fa-check"></i><b>4.7.1</b> Primera caracterización de la independencia</a></li>
<li class="chapter" data-level="4.7.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-las-variables-independientes"><i class="fa fa-check"></i><b>4.7.2</b> Propiedades de las variables independientes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#momentos-de-vectores-aleatorios"><i class="fa fa-check"></i><b>4.8</b> Momentos de vectores aleatorios</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#esperanza-de-un-vector-aleatorio-o-vector-de-medias"><i class="fa fa-check"></i><b>4.8.1</b> Esperanza de un vector aleatorio o vector de medias</a></li>
<li class="chapter" data-level="4.8.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-entre-dos-variables-aleatorias"><i class="fa fa-check"></i><b>4.8.2</b> Covarianza entre dos variables aleatorias</a></li>
<li class="chapter" data-level="4.8.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-y-correlación"><i class="fa fa-check"></i><b>4.8.3</b> Covarianza y correlación</a></li>
<li class="chapter" data-level="4.8.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.4</b> Matriz de varianzas-covarianzas</a></li>
<li class="chapter" data-level="4.8.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>4.8.5</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="4.8.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#segunda-caracterización-de-la-independencia"><i class="fa fa-check"></i><b>4.8.6</b> Segunda caracterización de la independencia</a></li>
<li class="chapter" data-level="4.8.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relación-entre-incorrelación-e-independencia"><i class="fa fa-check"></i><b>4.8.7</b> Relación entre incorrelación e independencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="grandes-muestras.html"><a href="grandes-muestras.html"><i class="fa fa-check"></i><b>5</b> Grandes muestras</a>
<ul>
<li class="chapter" data-level="5.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#introducción-aproximaciones-asintóticas"><i class="fa fa-check"></i><b>5.1</b> Introducción: Aproximaciones asintóticas</a></li>
<li class="chapter" data-level="5.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ley-de-los-grandes-números-ley-débil"><i class="fa fa-check"></i><b>5.2</b> Ley de los Grandes Números (Ley débil)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ejemplo-3"><i class="fa fa-check"></i><b>5.2.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#el-teorema-central-del-límite"><i class="fa fa-check"></i><b>5.3</b> El teorema central del límite</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#sumas-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.3.1</b> Sumas de variables aleatorias</a></li>
<li class="chapter" data-level="5.3.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#definición-de-convergencia-en-ley"><i class="fa fa-check"></i><b>5.3.2</b> Definición de convergencia en ley</a></li>
<li class="chapter" data-level="5.3.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#enunciado-del-teorema-central-del-límite"><i class="fa fa-check"></i><b>5.3.3</b> Enunciado del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.4" data-path="grandes-muestras.html"><a href="grandes-muestras.html#algunos-ejemplos-de-aplicación-del-tcl"><i class="fa fa-check"></i><b>5.3.4</b> Algunos ejemplos de aplicación del TCL</a></li>
<li class="chapter" data-level="5.3.5" data-path="grandes-muestras.html"><a href="grandes-muestras.html#casos-particulares-más-notables"><i class="fa fa-check"></i><b>5.3.5</b> Casos particulares más notables</a></li>
<li class="chapter" data-level="5.3.6" data-path="grandes-muestras.html"><a href="grandes-muestras.html#interpretación-del-teorema-central-del-límite"><i class="fa fa-check"></i><b>5.3.6</b> Interpretación del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.7" data-path="grandes-muestras.html"><a href="grandes-muestras.html#acerca-de-las-variables-aproximadamente-normales"><i class="fa fa-check"></i><b>5.3.7</b> Acerca de las variables aproximadamente normales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html"><i class="fa fa-check"></i><b>6</b> Introducción a la inferencia estadística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#inferencia-estadística"><i class="fa fa-check"></i><b>6.1</b> Inferencia estadística</a></li>
<li class="chapter" data-level="6.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#problemas-de-inferencia-estadística"><i class="fa fa-check"></i><b>6.2</b> Problemas de inferencia estadística</a></li>
<li class="chapter" data-level="6.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-de-la-población"><i class="fa fa-check"></i><b>6.3</b> Distribución de la población</a></li>
<li class="chapter" data-level="6.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestra-aleatoria-simple"><i class="fa fa-check"></i><b>6.4</b> Muestra aleatoria simple</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición"><i class="fa fa-check"></i><b>6.4.1</b> Definición</a></li>
<li class="chapter" data-level="6.4.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-de-la-muestra"><i class="fa fa-check"></i><b>6.4.2</b> Distribución de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#estadísticos"><i class="fa fa-check"></i><b>6.5</b> Estadísticos</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición-1"><i class="fa fa-check"></i><b>6.5.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-en-el-muestreo-de-un-estadístico"><i class="fa fa-check"></i><b>6.6</b> Distribución en el muestreo de un estadístico</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#demostración"><i class="fa fa-check"></i><b>6.6.1</b> Demostración:</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribución-empírica"><i class="fa fa-check"></i><b>6.7</b> La distribución empírica</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición-2"><i class="fa fa-check"></i><b>6.7.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#los-momentos-muestrales"><i class="fa fa-check"></i><b>6.8</b> Los momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición-3"><i class="fa fa-check"></i><b>6.8.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-en-el-muestreo-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.9</b> Distribución en el muestreo de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#propiedades-asintóticas-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.10</b> Propiedades asintóticas de los momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#convergencia-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.10.1</b> Convergencia de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-asintótica"><i class="fa fa-check"></i><b>6.10.2</b> Distribución asintótica</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestreo-en-poblaciones-normales"><i class="fa fa-check"></i><b>6.11</b> Muestreo en poblaciones normales</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribución-chi-cuadrado"><i class="fa fa-check"></i><b>6.11.1</b> La distribución chi-cuadrado</a></li>
<li class="chapter" data-level="6.11.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-t-de-student"><i class="fa fa-check"></i><b>6.11.2</b> Distribución <span class="math inline">\(t\)</span> de Student</a></li>
<li class="chapter" data-level="6.11.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribución-f-de-fisher"><i class="fa fa-check"></i><b>6.11.3</b> La distribución <span class="math inline">\(F\)</span> de Fisher</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimación-puntual.html"><a href="estimación-puntual.html"><i class="fa fa-check"></i><b>7</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-problema-de-la-estimación-puntual"><i class="fa fa-check"></i><b>7.1</b> El problema de la estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#criterios-de-optimalidad-de-estimadores.-el-riesgo"><i class="fa fa-check"></i><b>7.1.1</b> Criterios de optimalidad de estimadores. El Riesgo</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-error-cuadrático-medio"><i class="fa fa-check"></i><b>7.1.2</b> El error cuadrático medio</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estudio-de-las-propiedades-deseables-de-los-estimadores"><i class="fa fa-check"></i><b>7.2</b> Estudio de las propiedades deseables de los estimadores</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-sesgo"><i class="fa fa-check"></i><b>7.2.1</b> El sesgo</a></li>
<li class="chapter" data-level="7.2.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#consistencia"><i class="fa fa-check"></i><b>7.2.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estimadores-consistentes"><i class="fa fa-check"></i><b>7.3</b> Propiedades de los estimadores consistentes</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#eficiencia"><i class="fa fa-check"></i><b>7.3.1</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="estimación-puntual.html"><a href="estimación-puntual.html#información-de-fisher-y-cota-de-cramerrao"><i class="fa fa-check"></i><b>7.4</b> Información de Fisher y cota de CramerRao</a></li>
<li class="chapter" data-level="7.5" data-path="estimación-puntual.html"><a href="estimación-puntual.html#información-y-verosimilitud-de-un-modelo-estadístico"><i class="fa fa-check"></i><b>7.5</b> Información y verosimilitud de un modelo estadístico</a></li>
<li class="chapter" data-level="7.6" data-path="estimación-puntual.html"><a href="estimación-puntual.html#información-de-fisher"><i class="fa fa-check"></i><b>7.6</b> Información de Fisher</a></li>
<li class="chapter" data-level="7.7" data-path="estimación-puntual.html"><a href="estimación-puntual.html#la-desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>7.7</b> La desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="7.8" data-path="estimación-puntual.html"><a href="estimación-puntual.html#caracterización-del-estimador-eficiente"><i class="fa fa-check"></i><b>7.8</b> Caracterización del estimador eficiente</a></li>
<li class="chapter" data-level="7.9" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estadísticos-suficientes"><i class="fa fa-check"></i><b>7.9</b> Estadísticos suficientes</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#definició-de-estadísticop-suficiente"><i class="fa fa-check"></i><b>7.9.1</b> Definició de estadísticop suficiente</a></li>
<li class="chapter" data-level="7.9.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#teorema-de-factorización"><i class="fa fa-check"></i><b>7.9.2</b> Teorema de factorización</a></li>
<li class="chapter" data-level="7.9.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estadísticos-suficientes"><i class="fa fa-check"></i><b>7.9.3</b> Propiedades de los estadísticos suficientes</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="estimación-puntual.html"><a href="estimación-puntual.html#obtención-de-estimadores"><i class="fa fa-check"></i><b>7.10</b> Obtención de estimadores</a></li>
<li class="chapter" data-level="7.11" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-método-de-los-momentos"><i class="fa fa-check"></i><b>7.11</b> El método de los momentos</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#observaciones"><i class="fa fa-check"></i><b>7.11.1</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-método-del-máximo-de-verosimilitud"><i class="fa fa-check"></i><b>7.12</b> El método del máximo de verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html"><i class="fa fa-check"></i><b>8</b> Estimación por intérvalos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#motivación-de-los-intervalos-de-confianza-la-estimación-puntual-casi-siempre-es-falsa"><i class="fa fa-check"></i><b>8.1</b> Motivación de los intervalos de confianza: la estimación puntual casi siempre es falsa</a></li>
<li class="chapter" data-level="8.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#definición-formal-de-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.2</b> Definición formal de intervalo de confianza</a></li>
<li class="chapter" data-level="8.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#un-ejemplo-de-construcción-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.3</b> Un ejemplo de construcción de un intervalo de confianza</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#planteamiento"><i class="fa fa-check"></i><b>8.3.1</b> Planteamiento</a></li>
<li class="chapter" data-level="8.3.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#desarrollo-de-la-construcción"><i class="fa fa-check"></i><b>8.3.2</b> Desarrollo de la construcción</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#por-qué-hablamos-de-confianza-y-no-de-probabilidad"><i class="fa fa-check"></i><b>8.4</b> ¿Por qué hablamos de confianza y no de probabilidad?</a></li>
<li class="chapter" data-level="8.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#elementos-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.5</b> Elementos de un intervalo de confianza</a></li>
<li class="chapter" data-level="8.6" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#método-del-pivote"><i class="fa fa-check"></i><b>8.6</b> Método del pivote</a></li>
<li class="chapter" data-level="8.7" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#algunos-estadísticos-pivote"><i class="fa fa-check"></i><b>8.7</b> Algunos estadísticos pivote</a></li>
<li class="chapter" data-level="8.8" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-media-de-una-distribución-normal"><i class="fa fa-check"></i><b>8.8</b> Intervalo de confianza para la media de una distribución Normal</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-conocida"><i class="fa fa-check"></i><b>8.8.1</b> Caso de varianza conocida</a></li>
<li class="chapter" data-level="8.8.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-desconocida"><i class="fa fa-check"></i><b>8.8.2</b> Caso de varianza desconocida</a></li>
<li class="chapter" data-level="8.8.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#calculo-con-r"><i class="fa fa-check"></i><b>8.8.3</b> Calculo con R</a></li>
<li class="chapter" data-level="8.8.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tamaño-de-muestra-para-la-media-de-una-distribución-normal"><i class="fa fa-check"></i><b>8.8.4</b> Tamaño de muestra para la media de una distribución Normal</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-varianza-de-una-distribución-normal"><i class="fa fa-check"></i><b>8.9</b> Intervalo de confianza para la varianza de una distribución Normal</a></li>
<li class="chapter" data-level="8.10" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-una-proporción"><i class="fa fa-check"></i><b>8.10</b> Intervalo de confianza para una proporción</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximación-asintótica"><i class="fa fa-check"></i><b>8.10.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.10.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto"><i class="fa fa-check"></i><b>8.10.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.10.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tamaño-muestral-para-una-proporción"><i class="fa fa-check"></i><b>8.10.3</b> Tamaño muestral para una proporción</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-parámetro-de-una-distribución-de-poisson"><i class="fa fa-check"></i><b>8.11</b> Intervalo de confianza para el parámetro de una distribución de Poisson</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximación-asintótica-1"><i class="fa fa-check"></i><b>8.11.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.11.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto-1"><i class="fa fa-check"></i><b>8.11.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.11.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tamaño-de-muestra-para-el-parámetro-de-una-distribución-de-poisson"><i class="fa fa-check"></i><b>8.11.3</b> Tamaño de muestra para el parámetro de una distribución de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes."><i class="fa fa-check"></i><b>8.12</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.12.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#varianza-común"><i class="fa fa-check"></i><b>8.12.1</b> Varianza común</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.-1"><i class="fa fa-check"></i><b>8.13</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.13.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#varianza-diferente"><i class="fa fa-check"></i><b>8.13.1</b> Varianza diferente</a></li>
<li class="chapter" data-level="8.13.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianzas-desconocidas-y-diferentes"><i class="fa fa-check"></i><b>8.13.2</b> Caso de varianzas desconocidas y diferentes</a></li>
<li class="chapter" data-level="8.13.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intérvalos-de-confianza-y-decisiones-estadísticas"><i class="fa fa-check"></i><b>8.13.3</b> Intérvalos de confianza y decisiones estadísticas</a></li>
</ul></li>
<li class="chapter" data-level="8.14" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-cociente-de-varianzas-de-distribuciones-normales-independientes"><i class="fa fa-check"></i><b>8.14</b> Intervalo de confianza para el cociente de varianzas de distribuciones normales independientes</a></li>
<li class="chapter" data-level="8.15" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#complementos"><i class="fa fa-check"></i><b>8.15</b> Complementos</a>
<ul>
<li class="chapter" data-level="8.15.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#interpretación-geométrica-de-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>8.15.1</b> Interpretación geométrica de los intervalos de confianza</a></li>
<li class="chapter" data-level="8.15.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-para-muestras-grandes"><i class="fa fa-check"></i><b>8.15.2</b> Intervalos para muestras grandes</a></li>
<li class="chapter" data-level="8.15.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-exactos-para-distribuciones-discretas"><i class="fa fa-check"></i><b>8.15.3</b> Intervalos exactos para distribuciones discretas</a></li>
<li class="chapter" data-level="8.15.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#una-aproximación-diferente-para-la-distribución-de-poisson"><i class="fa fa-check"></i><b>8.15.4</b> Una aproximación diferente para la distribución de Poisson</a></li>
<li class="chapter" data-level="8.15.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximación-mediante-chébishev"><i class="fa fa-check"></i><b>8.15.5</b> Aproximación mediante Chébishev</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>9</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#introducción-2"><i class="fa fa-check"></i><b>9.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#de-las-hipótesis-científicas-a-las-hipótesis-estadísticas"><i class="fa fa-check"></i><b>9.1.1</b> De las hipótesis científicas a las hipótesis estadísticas</a></li>
<li class="chapter" data-level="9.1.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#del-lenguaje-natural-a-la-hipótesis-estadística"><i class="fa fa-check"></i><b>9.1.2</b> Del lenguaje natural a la hipótesis estadística</a></li>
<li class="chapter" data-level="9.1.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-presentación"><i class="fa fa-check"></i><b>9.1.3</b> Caso 1: Presentación</a></li>
<li class="chapter" data-level="9.1.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-modelo-de-probabilidad"><i class="fa fa-check"></i><b>9.1.4</b> Caso 1: Modelo de probabilidad</a></li>
<li class="chapter" data-level="9.1.5" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-presentación"><i class="fa fa-check"></i><b>9.1.5</b> Caso 2: Presentación</a></li>
<li class="chapter" data-level="9.1.6" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-modelo-de-probabilidad"><i class="fa fa-check"></i><b>9.1.6</b> Caso 2: Modelo de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#las-hipótesis-del-contraste-de-hipótesis"><i class="fa fa-check"></i><b>9.2</b> Las hipótesis del contraste de hipótesis</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-hipótesis-para-dirimir-la-controversia-sobre-el-número-de-hembras"><i class="fa fa-check"></i><b>9.2.1</b> Caso 1: Hipótesis para dirimir la controversia sobre el número de hembras</a></li>
<li class="chapter" data-level="9.2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-hipótesis-a-contrastar-en-el-problema-de-la-tasa-de-statdrolona"><i class="fa fa-check"></i><b>9.2.2</b> Caso 2: Hipótesis a contrastar en el problema de la tasa de statdrolona</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#compatibilidad-de-resultados-e-hipótesis"><i class="fa fa-check"></i><b>9.3</b> Compatibilidad de resultados e hipótesis</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-compatibilidad-de-resultados-e-hipótesis"><i class="fa fa-check"></i><b>9.3.1</b> Caso 1: Compatibilidad de resultados e hipótesis</a></li>
<li class="chapter" data-level="9.3.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-compatibilidad-de-resultados-e-hipótesis"><i class="fa fa-check"></i><b>9.3.2</b> Caso 2: Compatibilidad de resultados e hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#no-todo-es-igualmente-probable"><i class="fa fa-check"></i><b>9.4</b> No todo es igualmente probable…</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-una-región-con-n.º-de-hembras-con-baja-probabilidad-bajo-mathrmh_0"><i class="fa fa-check"></i><b>9.4.1</b> Caso 1: Una región con n.º de hembras con baja probabilidad bajo <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
<li class="chapter" data-level="9.4.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-medias-de-las-tasas-de-statdrolona-improbables-si-se-cumple-mathrmh_0"><i class="fa fa-check"></i><b>9.4.2</b> Caso 2: Medias de las tasas de statdrolona improbables si se cumple <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#el-papel-privilegiado-de-la-hipótesis-nula-criterio-de-decisión"><i class="fa fa-check"></i><b>9.5</b> El papel privilegiado de la hipótesis nula: criterio de decisión</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-n.º-de-nidos-propuestos-ad-hoc-como-inicio-de-región-crítica.-regla-de-decisión-resultante"><i class="fa fa-check"></i><b>9.5.1</b> Caso 1: N.º de nidos propuestos ad hoc como inicio de región crítica. Regla de decisión resultante</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#hipótesis-nula-y-nivel-de-significación"><i class="fa fa-check"></i><b>9.6</b> Hipótesis nula y nivel de significación</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-nivel-de-significación"><i class="fa fa-check"></i><b>9.6.1</b> Caso 1: Nivel de significación</a></li>
<li class="chapter" data-level="9.6.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-elección-de-la-región-crítica"><i class="fa fa-check"></i><b>9.6.2</b> Caso 1: Elección de la región crítica</a></li>
<li class="chapter" data-level="9.6.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-elección-de-la-región-crítica"><i class="fa fa-check"></i><b>9.6.3</b> Caso 2: Elección de la región crítica</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#región-crítica-y-formalización-del-contraste"><i class="fa fa-check"></i><b>9.7</b> Región crítica y formalización del contraste</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-resumen-de-conceptos-asociados-al-contraste.-región-crítica"><i class="fa fa-check"></i><b>9.7.1</b> Caso 1: Resumen de conceptos asociados al contraste. Región crítica</a></li>
<li class="chapter" data-level="9.7.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-tabla-resumen-de-la-región-crítica-el-estadístico-de-test-y-del-criterio-de-decisión"><i class="fa fa-check"></i><b>9.7.2</b> Caso 2: Tabla resumen de la región crítica, el estadístico de test y del criterio de decisión</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tabla-de-decisión-del-contraste"><i class="fa fa-check"></i><b>9.8</b> Tabla de decisión del contraste</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-evaluación-de-los-dos-errores-asociados-al-contraste"><i class="fa fa-check"></i><b>9.8.1</b> Caso 1: Evaluación de los dos errores asociados al contraste</a></li>
<li class="chapter" data-level="9.8.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-cálculo-explícito-de-los-errores-de-primera-alpha-y-segunda-especie-1--beta"><i class="fa fa-check"></i><b>9.8.2</b> Caso 2: Cálculo explícito de los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#relación-entre-el-error-de-tipo-i-y-el-de-tipo-ii"><i class="fa fa-check"></i><b>9.9</b> Relación entre el error de tipo I y el de tipo II</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-evaluación-de-alpha-y-1--beta-para-diferentes-regiones-críticas"><i class="fa fa-check"></i><b>9.9.1</b> Caso 1: Evaluación de <span class="math inline">\(\alpha\)</span> y 1- <span class="math inline">\(\beta\)</span> para diferentes regiones críticas</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#potencia-y-test-más-potente"><i class="fa fa-check"></i><b>9.10</b> Potencia y test más potente</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-potencia-en-hipótesis-simple-vs-simple"><i class="fa fa-check"></i><b>9.10.1</b> Caso 1: Potencia en hipótesis simple vs simple</a></li>
<li class="chapter" data-level="9.10.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-potencia-en-hipótesis-simple-vs-simple"><i class="fa fa-check"></i><b>9.10.2</b> Caso 2: Potencia en hipótesis simple vs simple</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#efecto-del-tamaño-muestral"><i class="fa fa-check"></i><b>9.11</b> Efecto del tamaño muestral</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1"><i class="fa fa-check"></i><b>9.11.1</b> Caso 1</a></li>
<li class="chapter" data-level="9.11.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2"><i class="fa fa-check"></i><b>9.11.2</b> Caso 2</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#hipótesis-simples-vs.-hipótesis-compuestas"><i class="fa fa-check"></i><b>9.12</b> Hipótesis simples vs. hipótesis compuestas</a>
<ul>
<li class="chapter" data-level="9.12.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-hipótesis-compuestas"><i class="fa fa-check"></i><b>9.12.1</b> Caso 1: Hipótesis compuestas</a></li>
<li class="chapter" data-level="9.12.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-hipótesis-compuestas"><i class="fa fa-check"></i><b>9.12.2</b> Caso 2: Hipótesis compuestas</a></li>
</ul></li>
<li class="chapter" data-level="9.13" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#función-de-potencia"><i class="fa fa-check"></i><b>9.13</b> Función de potencia</a>
<ul>
<li class="chapter" data-level="9.13.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-función-de-potencia"><i class="fa fa-check"></i><b>9.13.1</b> Caso 1: Función de potencia</a></li>
<li class="chapter" data-level="9.13.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-función-de-potencia"><i class="fa fa-check"></i><b>9.13.2</b> Caso 2: Función de potencia</a></li>
</ul></li>
<li class="chapter" data-level="9.14" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tests-óptimos"><i class="fa fa-check"></i><b>9.14</b> Tests óptimos</a></li>
<li class="chapter" data-level="9.15" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-bilaterales-y-pruebas-unilaterales"><i class="fa fa-check"></i><b>9.15</b> Pruebas bilaterales y pruebas unilaterales</a>
<ul>
<li class="chapter" data-level="9.15.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-prueba-unilateral"><i class="fa fa-check"></i><b>9.15.1</b> Caso 1: Prueba unilateral</a></li>
<li class="chapter" data-level="9.15.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-prueba-unilateral"><i class="fa fa-check"></i><b>9.15.2</b> Caso 2: Prueba unilateral</a></li>
</ul></li>
<li class="chapter" data-level="9.16" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#elección-del-nivel-de-significación"><i class="fa fa-check"></i><b>9.16</b> Elección del nivel de significación</a></li>
<li class="chapter" data-level="9.17" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#el-p-valor"><i class="fa fa-check"></i><b>9.17</b> El p-valor</a>
<ul>
<li class="chapter" data-level="9.17.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-cálculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>9.17.1</b> Caso 1: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="9.17.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-cálculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>9.17.2</b> Caso 2: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="9.17.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-cálculo-del-p-valor-prueba-bilateral"><i class="fa fa-check"></i><b>9.17.3</b> Caso 2: Cálculo del p-valor (prueba bilateral)</a></li>
</ul></li>
<li class="chapter" data-level="9.18" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-exactas-y-pruebas-asintóticas"><i class="fa fa-check"></i><b>9.18</b> Pruebas exactas y pruebas asintóticas</a>
<ul>
<li class="chapter" data-level="9.18.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-test-asintótico"><i class="fa fa-check"></i><b>9.18.1</b> Caso 1: Test asintótico</a></li>
<li class="chapter" data-level="9.18.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-test-exacto"><i class="fa fa-check"></i><b>9.18.2</b> Caso 2: Test exacto</a></li>
</ul></li>
<li class="chapter" data-level="9.19" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#relación-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>9.19</b> Relación con los intervalos de confianza</a>
<ul>
<li class="chapter" data-level="9.19.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-relación-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>9.19.1</b> Caso 2: Relación con los intervalos de confianza</a></li>
</ul></li>
<li class="chapter" data-level="9.20" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tamaños-de-muestra.-diferencia-mínima-significativa"><i class="fa fa-check"></i><b>9.20</b> Tamaños de muestra. Diferencia mínima significativa</a>
<ul>
<li class="chapter" data-level="9.20.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-cálculo-del-tamaño-de-la-muestra"><i class="fa fa-check"></i><b>9.20.1</b> Caso 2: Cálculo del tamaño de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="9.21" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#esquema-de-un-contraste-correctamente-planteado"><i class="fa fa-check"></i><b>9.21</b> Esquema de un contraste correctamente planteado</a></li>
<li class="chapter" data-level="9.22" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#significación-estadística-y-significación-aplicada"><i class="fa fa-check"></i><b>9.22</b> Significación estadística y significación aplicada</a>
<ul>
<li class="chapter" data-level="9.22.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-significación-estadística-y-aplicada"><i class="fa fa-check"></i><b>9.22.1</b> Caso 2: Significación estadística y aplicada</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html"><i class="fa fa-check"></i><b>10</b> Inferencia Aplicada</a>
<ul>
<li class="chapter" data-level="10.1" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-normalidad.pruebas-gráficas.-el-test-de-shapiro-wilks"><i class="fa fa-check"></i><b>10.1</b> Pruebas de normalidad.Pruebas gráficas. El test de Shapiro-Wilks</a></li>
<li class="chapter" data-level="10.2" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-paramètricas-t-test-y-anova"><i class="fa fa-check"></i><b>10.2</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas paramètricas t-test y Anova</a></li>
<li class="chapter" data-level="10.3" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-de-hipótesis-no-paramétricas-de-wilcoxon-y-kruskal-wallis"><i class="fa fa-check"></i><b>10.3</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas de hipótesis no paramétricas de Wilcoxon y Kruskal-Wallis</a></li>
<li class="chapter" data-level="10.4" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#contrastes-para-datos-categóricos.-pruebas-binomiales-ji-cuadrado-y-test-de-fisher."><i class="fa fa-check"></i><b>10.4</b> Contrastes para datos categóricos. Pruebas binomiales, ji cuadrado y test de Fisher.</a></li>
<li class="chapter" data-level="10.5" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#riesgo-relativo-y-razón-de-odds"><i class="fa fa-check"></i><b>10.5</b> Riesgo relativo y razón de «odds»</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html"><i class="fa fa-check"></i><b>11</b> Computación Intensiva y <em>Multiple Testing</em></a>
<ul>
<li class="chapter" data-level="11.1" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#tests-de-permutaciones-qué-cuándo-cómo"><i class="fa fa-check"></i><b>11.1</b> Tests de permutaciones; ¿Qué?, ¿Cuándo?, ¿Cómo?</a></li>
<li class="chapter" data-level="11.2" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#el-bootstrap-en-contraste-de-hipótesis"><i class="fa fa-check"></i><b>11.2</b> El bootstrap en contraste de hipótesis</a></li>
<li class="chapter" data-level="11.3" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#el-problema-de-las-comparaciones-múltiples"><i class="fa fa-check"></i><b>11.3</b> El problema de las comparaciones múltiples</a></li>
<li class="chapter" data-level="11.4" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#métodos-de-control-de-error-fwer-y-fdr"><i class="fa fa-check"></i><b>11.4</b> Métodos de control de error: FWER y FDR</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferencia Estadistica</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimación-por-intérvalos" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Capítulo 8</span> Estimación por intérvalos<a href="estimación-por-intérvalos.html#estimación-por-intérvalos" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="motivación-de-los-intervalos-de-confianza-la-estimación-puntual-casi-siempre-es-falsa" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Motivación de los intervalos de confianza: la estimación puntual casi siempre es falsa<a href="estimación-por-intérvalos.html#motivación-de-los-intervalos-de-confianza-la-estimación-puntual-casi-siempre-es-falsa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como se ha visto en el capítulo anterior, un estimador puntual intenta proporcionar la mejor aproximación posible, en uno u otro sentido, al valor verdadero de los parámetros poblacionales que se desean estimar y que en realidad nos son desconocidos.</p>
<p>Sin embargo, ésto debe entenderse en el sentido de que no hemos de creer que el resultado de la estimación puntual ha de coincidir forzosamente con el valor verdadero del parámetro poblacional que queremos estimar. De hecho en muchas ocasiones de lo que podemos estar seguros es de la no-coincidencia. Baste considerar, por ejemplo, una variable Normal y una estimación de su esperanza a través de la media muestral. Como se trata de una variable continua se tiene:</p>
<p><span class="math display">\[
P\left(\bar{X}_{n}=\mu\right)=0.
\]</span></p>
<p>Esta expresión debe ser interpretada en el sentido de que la coincidencia del estimador con el parámetro verdadero es un suceso de probabilidad cero.</p>
<p>La estimación por intervalos de confianza nos proporciona <em>un rango de valores entre los que tendremos una cierta certeza o nivel de confianza de que se encuentre nuestro parámetro poblacional desconocido</em>.</p>
</div>
<div id="definición-formal-de-intervalo-de-confianza" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Definición formal de intervalo de confianza<a href="estimación-por-intérvalos.html#definición-formal-de-intervalo-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dada una muestra aleatoria simple, que podemos suponer se ha obtenido de una variable aleatoria (población) cuya distribución depende de un parámetro <span class="math inline">\(\theta\)</span>, diremos que los estadísticos <span class="math inline">\(L_{1}\)</span> y <span class="math inline">\(L_{2}\)</span> son un intervalo de confianza para <span class="math inline">\(\theta\)</span> con nivel de confianza <span class="math inline">\((1-\alpha) \cdot 100 \%\)</span>, si se verifica:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mathrm{L}_{1}&lt;\mathrm{L}_{2}\)</span> para toda muestra de tamaño <span class="math inline">\(n\)</span>.</li>
<li><span class="math inline">\(\mathrm{P}\left(\mathrm{L}_{1} \leq \theta \leq \mathrm{L}_{2}\right)=1-\alpha\)</span>.</li>
</ol>
<p>Hay que destacar que en la segunda condición, en nuestro contexto, el valor del parámetro es fijo, lo que es aleatorio son los estadísticos que delimitan el intervalo.</p>
</div>
<div id="un-ejemplo-de-construcción-de-un-intervalo-de-confianza" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Un ejemplo de construcción de un intervalo de confianza<a href="estimación-por-intérvalos.html#un-ejemplo-de-construcción-de-un-intervalo-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="planteamiento" class="section level3 hasAnchor" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Planteamiento<a href="estimación-por-intérvalos.html#planteamiento" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos que tenemos una variable aleatoria que sigue una distribución Normal N <span class="math inline">\((\mu ; \sigma)\)</span> donde la varianza es un valor fijo conocido <span class="math inline">\(\sigma^{2}=\sigma^2_0\)</span>. Nuestro objetivo es, dada una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> de la variable obtener un intervalo de confianza con nivel de confianza del <span class="math inline">\(95 \%\)</span> para el parámetro <span class="math inline">\(\mu\)</span> de la distribución.</p>
</div>
<div id="desarrollo-de-la-construcción" class="section level3 hasAnchor" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Desarrollo de la construcción<a href="estimación-por-intérvalos.html#desarrollo-de-la-construcción" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Utilizaremos la propiedad de que la media muestral sigue una distribución Normal de parámetros <span class="math inline">\((\mu ; \sigma/\sqrt{n})\)</span> y, por tanto, si construimos el estadístico</p>
<p><span class="math display">\[
z=\frac{\bar{X}-\mu}{\sigma_{0} / \sqrt{n}}
\]</span></p>
<p>su distribución es una Normal estándar <span class="math inline">\(\mathrm{N}(0,1)\)</span>.
El hecho de que sea una distribución conocida, que además no depende del parámetro que queremos estimar <span class="math inline">\(\mu\)</span>, nos permite, una vez construida la expresión siguiente</p>
<p><span class="math display">\[
P\left(-z_{\alpha / 2} \leq \frac{\bar{X}-\mu}{\sigma_{0} / \sqrt{n}} \leq z_{\alpha / 2}\right)=1-\alpha
\]</span></p>
<p>determinar, de manera independiente de <span class="math inline">\(\mu\)</span> el valor <span class="math inline">\(z_{\alpha / 2}\)</span> que delimita una probabilidad del <span class="math inline">\(95 \%\)</span> dentro del intervalo centrado en cero <span class="math inline">\(\left(-z_{\alpha / 2} ; z_{\alpha / 2}\right)\)</span>. En este caso, para la distribución <span class="math inline">\(\mathrm{N}(0,1)\)</span>, el valor es aproximadamente 1,96.</p>
<p><img src="images/dNormalQuantil975.png" width="90%" style="display: block; margin: auto;" /></p>
<p><span class="math display">\[
P\left(-1,96 \leq \frac{\bar{X}-\mu}{\sigma_{0} / \sqrt{n}} \leq 1,96\right)=0,95
\]</span></p>
<p>Sólo nos resta despejar <span class="math inline">\(\mu\)</span> de la expresión anterior para obtener el intervalo definitivo</p>
<p><span class="math display">\[
P\left(\bar{X}-1,96 \frac{\sigma_{0}}{\sqrt{n}} \leq \mu \leq \bar{X}+1,96 \frac{\sigma_{0}}{\sqrt{n}}\right)=0,95
\]</span></p>
</div>
</div>
<div id="por-qué-hablamos-de-confianza-y-no-de-probabilidad" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> ¿Por qué hablamos de confianza y no de probabilidad?<a href="estimación-por-intérvalos.html#por-qué-hablamos-de-confianza-y-no-de-probabilidad" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cuando ya hemos calculado el valor de los estadísticos que delimitan un intervalo solemos decir de que dicho intervalo <em>contiene el parámetro poblacional con un nivel de confianza, por ejemplo del 95 <span class="math inline">\(\%\)</span></em>. <strong>No decimos</strong> que la probabilidad de que el parámetro esté dentro del intervalo es de un <span class="math inline">\(95 \%\)</span>, puesto que esto no tiene sentido, ya que el parámetro es un valor fijo.</p>
<p>Por ejemplo, es correcto decir que el intervalo <span class="math inline">\((0,80 ; 0,86)\)</span> contiene el parámetro <span class="math inline">\(p\)</span> de una distribución Binomial con una confianza del <span class="math inline">\(95 \%\)</span>, pero sería incorrecto decir que la probabilidad de que el parámetro esté dentro del intervalo <span class="math inline">\((0,80 ; 0,86)\)</span> es del <span class="math inline">\(95 \%\)</span>.</p>
<p>En nuestro contexto, el parámetro poblacional es el que es, y no asociamos ninguna probabilidad ni fenómeno aleatorio al respecto. En otros enfoques estadísticos (estadística bayesiana) sí que se considera el parámetro como un valor aleatorio, pero no es nuestro caso.</p>
<p>La confianza del intervalo debe ser entendida como la fracción de intervalos calculados a partir de una gran serie de muestras de tamaño idéntico que contienen el valor verdadero del parámetro poblacional.</p>
<div class="software">
<p><strong>Simulación de intérvalos de confianza</strong></p>
<p><img src="images/simulaIC.png" width="90%" style="display: block; margin: auto;" /></p>
<p><a href="https://www.grbio.eu/statmedia/Statmedia_5/">https://www.grbio.eu/statmedia/Statmedia_5/</a></p>
</div>
<p>El enlace anterior apunta a una aplicación Shiny que permite simular un número determinado de intervalos de confianza para la media de una distribució Normal, basados en muestras del mismo tamaño, y comprobar en cuántas de las simulaciones el intervalo obtenido contiene el verdadero valor de la media poblacional a partir del cual se han simulado las muestras. El porcentaje de aciertos debería acercarse al nivel de confianza con el que se han construido los intervalos.</p>
<p>Manteniendo constante el tamaño muestral, incrementar el nivel de confianza del intervalo implica que la anchura de éste se incrementa. Es totalmente coherente con la lógica, puesto que al exigir mayor seguridad de que el parámetro esté incluido en el intervalo lo que hacemos es alejar los límites inferior y superior para incrementar la certeza de que incluya al parámetro.</p>
<p>Como veremos más adelante, la manera de disminuir la anchura del intervalo y mantener un nivel de confianza deseado es incrementar el tamaño de la muestra utilizada para la construcción del intervalo.</p>
</div>
<div id="elementos-de-un-intervalo-de-confianza" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Elementos de un intervalo de confianza<a href="estimación-por-intérvalos.html#elementos-de-un-intervalo-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A la hora de plantearnos la obtención de un intervalo de confianza hemos de adoptar una serie de decisiones previas.</p>
<ul>
<li><p>La primera y más importante es la elección del parámetro poblacional del cual deseamos obtener la estimación. Generalmente esta elección está relacionada la distribución que asumimos para la variable estudiada. De manera usual el parámetro poblacional se corresponde con alguna de las características de las distribuciones. Por ejemplo, si deseamos un intervalo de confianza para la probabilidad de un suceso trabajaríamos con el parámetro <span class="math inline">\(p\)</span> de la distribución Binomial. En algún caso, sin embargo, podemos estar interesados en la obtención de un intervalo de confianza para algún parámetro, por ejemplo, la media poblacional, sin hacer ninguna suposición sobre la distribución de la variable. Estaríamos dentro de la denominada estimación no paramétrica.</p></li>
<li><p>Una segunda elección es el nivel de confianza con el que deseamos trabajar. No es una elección sin importancia, puesto que del nivel de confianza dependerá la precisión de la estimación que obtengamos, es decir, la anchura del intervalo. A mayor nivel de confianza exigido, mayor será el radio del intervalo y por tanto menor la precisión en la estimación. Generalmente se trabaja con niveles de confianza del orden del <span class="math inline">\(90 \%\)</span> o <span class="math inline">\(95 \%\)</span>.</p></li>
<li><p>Relacionado con el punto anterior tenemos la elección del tamaño muestral utilizado para la construcción del intervalo. Hemos mencionado que aumentar la confianza significa aumentar la imprecisión de la estimación, sin embargo es posible ajustar una anchura del intervalo determinada para el nivel de confianza deseado jugando con el tamaño muestral utilizado.</p></li>
</ul>
<p>La aplicación mostrada en la sección anterior nos permite ilustrar estos conceptos y ver cual es el efecto de modificar el nivel de confianza o el tamaño muestral sin que cambien el resto de condiciones. Generalmente el investigador fijará el nivel de confianza con el que desea trabajar y la precisión deseada para la estimación.</p>
<p>Con estas premisas y basándose generalmente en la información adicional proporcionada por una muestra piloto obtenida con anterioridad <em>es posible determinar el tamaño muestral mínimo necesario para lograr los objetivos fijados</em>.</p>
<p>Si no se dispone de muestra piloto, es posible utilizar planteamientos alternativos, como los siguientes:</p>
<ul>
<li>Expresar la precisión en términos de fracciones de la desviación típica.</li>
<li>Utilizar las suposiciones más desfavorables posibles.</li>
</ul>
</div>
<div id="método-del-pivote" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Método del pivote<a href="estimación-por-intérvalos.html#método-del-pivote" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El método del pivote es uno de los principales métodos de construcción de intervalos de confianza. Generaliza la técnica empleada en la construcción del intervalo utilizado como primer ejemplo.</p>
<p>Se basa en la elección de una variable aleatoria que sea función de la muestra y del parámetro a estimar, con la condición de que sea una función continua y monótona del parámetro y que su distribución sea conocida e <strong>independiente del parámetro</strong>.</p>
<p>La expresión “distribución independiente del parámetro” puede generar cierta confusión porqué, uno no puede evitar observar el pivote y ver que el parámetro se encuentra incluido en la formma del mismo. Por ejemplo, si suponemos <span class="math inline">\(X\sim N(\mu, \sigma_0)\)</span>, hemos visto que <span class="math inline">\(Z=\frac{(X-\mu)}{\sigma/\sqrt{n}}\)</span> es el punto de partida para construir el intérvalo de confianza. Podemos decir que <span class="math inline">\(Z\)</span> es un pivote para <span class="math inline">\(\mu\)</span> porque <span class="math inline">\(Z=\frac{(X-\mu)}{\sigma/\sqrt{n}}\)</span> aunque contenga a <span class="math inline">\(\mu\)</span> en su expresión, sigue una distribución <span class="math inline">\(N(0,1)\)</span> <em>que es la misma sea cual sea el valor de <span class="math inline">\(\mu\)</span> por lo que no depende de éste</em>.</p>
<p>De forma más general denominaremos “estadístico pivote” a una función <span class="math inline">\(\varphi(\theta, X)\)</span> cuya distribución no depende del parámetro y que puede ser invertida para expresar el parámetro como la función (inversa), <span class="math inline">\(\phi^{-1}\)</span> de <span class="math inline">\(\phi\)</span>.</p>
<p>Bajo estas condiciones, fijado el nivel de confianza <span class="math inline">\((1-\alpha) \cdot 100 \%\)</span>, es posible encontrar los valores <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> tales que</p>
<p><span class="math display" id="eq:pivote">\[\begin{equation}
P(a \leq \varphi(\theta, X) \leq b)=1-\alpha
\tag{8.1}
\end{equation}\]</span></p>
<p>Por las condiciones exigidas sobre el estadístico, será posible despejar <span class="math inline">\(\theta\)</span> de la ecuación anterior <a href="estimación-por-intérvalos.html#eq:pivote">(8.1)</a> y obtener los límites para el intervalo.</p>
<p><span class="math display">\[
P\left(\varphi^{-1}(a, X) \leq \boldsymbol{\theta} \leq \varphi^{-1}(b, X)=1-\alpha\right.
\]</span></p>
<p>siendo <span class="math inline">\(\mathrm{L}_{1}=\varphi^{-1}(a, X)\)</span> i <span class="math inline">\(\mathrm{L}_{2}=\varphi^{-1}(b, X)\)</span> los límites del intervalo deseado.</p>
<p>Hemos de tener en cuenta que los valores <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span> que verifican <a href="estimación-por-intérvalos.html#eq:pivote">(8.1)</a> en general no son únicos. La elección se hace generalmente buscando que <em>el intervalo tenga la máxima precisión, es decir, la longitud mínima</em>. Para distribuciones simétricas y unimodales (Normal o <span class="math inline">\(t\)</span> de Student, por ejemplo) se consigue tomando el intervalo centrado, es decir, dejando una probabilidad de <span class="math inline">\(\alpha / 2\)</span> a cada lado.</p>
</div>
<div id="algunos-estadísticos-pivote" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Algunos estadísticos pivote<a href="estimación-por-intérvalos.html#algunos-estadísticos-pivote" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Estadistico pivote</th>
<th align="center">Distribución del estadístico pivote</th>
<th align="center">Observaciones</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">a) Poblaciones Normales</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(Z=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}\)</span></td>
<td align="center"><span class="math inline">\(\mathrm{N}(0,1)\)</span></td>
<td align="center">Varianza conocida</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(T=\frac{\bar{X}-\mu}{\hat{S} / \sqrt{n}}\)</span></td>
<td align="center">t de Student con n-1 grados de libertad</td>
<td align="center">Varianza desconocida</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\chi^{2}=\frac{(n-1) \hat{S}^{2}}{\sigma^{2}}\)</span></td>
<td align="center"><span class="math inline">\(\chi^{2} \text { con } n-1 \text { grados de }\)</span> <br> libertad</td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(T=\frac{\left(\bar{X}_{1}-\bar{X}_{2}\right)-\left(\mu_{1}-\mu_{2}\right)}{S_{T} \sqrt{1 / n_{1}+1 / n_{2}}}\)</span></td>
<td align="center">t de Student con <span class="math inline">\(\mathrm{n}_{1}+\mathrm{n}_{2}-2\)</span> grados de libertad</td>
<td align="center"><span class="math inline">\(\mathrm{S}_{\mathrm{T}}=\)</span> estimación de la <span class="math inline">\(\sigma\)</span> desconocida pero común a ambas poblaciones</td>
</tr>
<tr class="even">
<td align="center">b) Proporciones</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(T=\frac{\hat{p}-p}{\sqrt{\hat{p} \hat{q} / n}}\)</span></td>
<td align="center">N(0,1)</td>
<td align="center">Distribución asintótica</td>
</tr>
</tbody>
</table>
</div>
<div id="intervalo-de-confianza-para-la-media-de-una-distribución-normal" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Intervalo de confianza para la media de una distribución Normal<a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-media-de-una-distribución-normal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dada una variable aleatoria con distribución Normal <span class="math inline">\(\mathrm{N}(\mu, \sigma)\)</span>, el objetivo es la construcción de un intervalo de confianza para el parámetro <span class="math inline">\(\mu\)</span>, basado en una muestra de tamaño <span class="math inline">\(n\)</span> de la variable.</p>
<p>Desde el punto de vista didáctico hemos de considerar dos posibilidades sobre la desviación típica de la variable, que sea conocida o que sea desconocida y tengamos que estimarla a partir de la muestra. El caso de <span class="math inline">\(\sigma\)</span> conocida, ya comentado anteriormente, no pasa de ser un caso académico con poca aplicación en la práctica, sin embargo es útil desde del punto de vista didáctico.</p>
<div id="caso-de-varianza-conocida" class="section level3 hasAnchor" number="8.8.1">
<h3><span class="header-section-number">8.8.1</span> Caso de varianza conocida<a href="estimación-por-intérvalos.html#caso-de-varianza-conocida" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dada una muestra <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>, el estadístico</p>
<p><span class="math display">\[
z=\frac{\bar{X}-\mu}{\sigma / \sqrt{n}}
\]</span></p>
<p>se distribuye según una Normal estándar. Por tanto, aplicando el método del pivote podemos construir la expresión</p>
<p><span class="math display">\[
P\left(-z_{\alpha/ 2} \leq \frac{\bar{X}-\mu}{\sigma / \sqrt{n}} \leq z_{\alpha / / 2}\right)=1-\alpha
\]</span></p>
<p>donde <span class="math inline">\(z_{\alpha / 2}\)</span> es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>, de la que se deduce el intervalo de confianza</p>
<p><span class="math display">\[
\bar{X}-z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}+z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}
\]</span></p>
</div>
<div id="caso-de-varianza-desconocida" class="section level3 hasAnchor" number="8.8.2">
<h3><span class="header-section-number">8.8.2</span> Caso de varianza desconocida<a href="estimación-por-intérvalos.html#caso-de-varianza-desconocida" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dada una muestra <span class="math inline">\(X_{1}, \ldots, X_{n}\)</span>, el estadístico</p>
<p><span class="math display">\[
t=\frac{\bar{X}-\mu}{\hat{S} / \sqrt{n}}
\]</span></p>
<p>se distribuye según una <span class="math inline">\(t\)</span> de Student de <span class="math inline">\(\mathrm{n}-1\)</span> grados de libertad. Por tanto, y siguiendo pasos similares a los del apartado anterior, el intervalo de confianza resultante es</p>
<p><span class="math display">\[
\bar{X}-t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}} \leq \mu \leq \bar{X}+t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}}
\]</span></p>
<p>donde <span class="math inline">\(t_{\alpha / 2}\)</span> es el valor de una distribución t de Student con <span class="math inline">\(\mathrm{n}-1\)</span> grados de libertad que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
</div>
<div id="calculo-con-r" class="section level3 hasAnchor" number="8.8.3">
<h3><span class="header-section-number">8.8.3</span> Calculo con R<a href="estimación-por-intérvalos.html#calculo-con-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El lenguaje R contiene un gran número de procedimientos estadísticos implementados, pero los intérvalos de confianza no son uno de ellos. Es decir, apenas existen funciones de base para calcular intérvalos de confianza y estos aparecen ligados a las pruebas de hipótesis como es el caso de los intérvalos para la media, que tan sólo se pueden calcular con la función que realiza un test-t.</p>
<p>En esta sección mostraremos con algo de detalle cómo calcular un intervalo de confianza para la media de una muestra utilizando diferentes métodos:
1. Cálculo manual.
2. Uso de una función personalizada (<code>Calcula_IC_Media</code>).
3. Uso del paquete <code>DesctTols</code>.</p>
<div id="paso-a-paso-cálculo-manual-del-intervalo-de-confianza" class="section level4 hasAnchor" number="8.8.3.1">
<h4><span class="header-section-number">8.8.3.1</span> Paso a paso: Cálculo manual del intervalo de confianza<a href="estimación-por-intérvalos.html#paso-a-paso-cálculo-manual-del-intervalo-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="estimación-por-intérvalos.html#cb23-1" tabindex="-1"></a><span class="co"># Generar datos simulados</span></span>
<span id="cb23-2"><a href="estimación-por-intérvalos.html#cb23-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)  <span class="co"># Para reproducibilidad</span></span>
<span id="cb23-3"><a href="estimación-por-intérvalos.html#cb23-3" tabindex="-1"></a>muestra <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">30</span>, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)  <span class="co"># 30 observaciones con media 50 y desviación estándar 10</span></span>
<span id="cb23-4"><a href="estimación-por-intérvalos.html#cb23-4" tabindex="-1"></a></span>
<span id="cb23-5"><a href="estimación-por-intérvalos.html#cb23-5" tabindex="-1"></a><span class="co"># Tamaño de la muestra</span></span>
<span id="cb23-6"><a href="estimación-por-intérvalos.html#cb23-6" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(muestra)</span>
<span id="cb23-7"><a href="estimación-por-intérvalos.html#cb23-7" tabindex="-1"></a></span>
<span id="cb23-8"><a href="estimación-por-intérvalos.html#cb23-8" tabindex="-1"></a><span class="co"># Media muestral</span></span>
<span id="cb23-9"><a href="estimación-por-intérvalos.html#cb23-9" tabindex="-1"></a>media <span class="ot">&lt;-</span> <span class="fu">mean</span>(muestra)</span>
<span id="cb23-10"><a href="estimación-por-intérvalos.html#cb23-10" tabindex="-1"></a></span>
<span id="cb23-11"><a href="estimación-por-intérvalos.html#cb23-11" tabindex="-1"></a><span class="co"># Desviación estándar muestral</span></span>
<span id="cb23-12"><a href="estimación-por-intérvalos.html#cb23-12" tabindex="-1"></a>sd_muestra <span class="ot">&lt;-</span> <span class="fu">sd</span>(muestra)</span>
<span id="cb23-13"><a href="estimación-por-intérvalos.html#cb23-13" tabindex="-1"></a></span>
<span id="cb23-14"><a href="estimación-por-intérvalos.html#cb23-14" tabindex="-1"></a><span class="co"># Grados de libertad</span></span>
<span id="cb23-15"><a href="estimación-por-intérvalos.html#cb23-15" tabindex="-1"></a>gl <span class="ot">&lt;-</span> n <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb23-16"><a href="estimación-por-intérvalos.html#cb23-16" tabindex="-1"></a></span>
<span id="cb23-17"><a href="estimación-por-intérvalos.html#cb23-17" tabindex="-1"></a><span class="co"># Nivel de confianza</span></span>
<span id="cb23-18"><a href="estimación-por-intérvalos.html#cb23-18" tabindex="-1"></a>nivel_confianza <span class="ot">&lt;-</span> <span class="fl">0.95</span></span>
<span id="cb23-19"><a href="estimación-por-intérvalos.html#cb23-19" tabindex="-1"></a>alpha <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> nivel_confianza</span>
<span id="cb23-20"><a href="estimación-por-intérvalos.html#cb23-20" tabindex="-1"></a></span>
<span id="cb23-21"><a href="estimación-por-intérvalos.html#cb23-21" tabindex="-1"></a><span class="co"># Valor crítico t</span></span>
<span id="cb23-22"><a href="estimación-por-intérvalos.html#cb23-22" tabindex="-1"></a>t_critico <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> gl)</span>
<span id="cb23-23"><a href="estimación-por-intérvalos.html#cb23-23" tabindex="-1"></a></span>
<span id="cb23-24"><a href="estimación-por-intérvalos.html#cb23-24" tabindex="-1"></a><span class="co"># Margen de error</span></span>
<span id="cb23-25"><a href="estimación-por-intérvalos.html#cb23-25" tabindex="-1"></a>margen_error <span class="ot">&lt;-</span> t_critico <span class="sc">*</span> sd_muestra <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb23-26"><a href="estimación-por-intérvalos.html#cb23-26" tabindex="-1"></a></span>
<span id="cb23-27"><a href="estimación-por-intérvalos.html#cb23-27" tabindex="-1"></a><span class="co"># Límites del intervalo</span></span>
<span id="cb23-28"><a href="estimación-por-intérvalos.html#cb23-28" tabindex="-1"></a>limite_inferior <span class="ot">&lt;-</span> media <span class="sc">-</span> margen_error</span>
<span id="cb23-29"><a href="estimación-por-intérvalos.html#cb23-29" tabindex="-1"></a>limite_superior <span class="ot">&lt;-</span> media <span class="sc">+</span> margen_error</span>
<span id="cb23-30"><a href="estimación-por-intérvalos.html#cb23-30" tabindex="-1"></a></span>
<span id="cb23-31"><a href="estimación-por-intérvalos.html#cb23-31" tabindex="-1"></a><span class="co"># Mostrar resultados</span></span>
<span id="cb23-32"><a href="estimación-por-intérvalos.html#cb23-32" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Cálculo manual:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Cálculo manual:</code></pre>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="estimación-por-intérvalos.html#cb25-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Intervalo de confianza (95%): [&quot;</span>, limite_inferior, <span class="st">&quot;, &quot;</span>, limite_superior, <span class="st">&quot;]</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Intervalo de confianza (95%): [ 45.86573 ,  53.19219 ]</code></pre>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="estimación-por-intérvalos.html#cb27-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Media muestral: &quot;</span>, media, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Media muestral:  49.52896</code></pre>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="estimación-por-intérvalos.html#cb29-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Margen de error: &quot;</span>, margen_error, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Margen de error:  3.663229</code></pre>
</div>
<div id="uso-de-la-función-calcula_ic_media" class="section level4 hasAnchor" number="8.8.3.2">
<h4><span class="header-section-number">8.8.3.2</span> Uso de la función <code>Calcula_IC_Media</code><a href="estimación-por-intérvalos.html#uso-de-la-función-calcula_ic_media" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Dado lo extenso del cálculo podemos definir una función para automatizar los pasos anteriores:</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="estimación-por-intérvalos.html#cb31-1" tabindex="-1"></a>Calcula_IC_Media <span class="ot">&lt;-</span> <span class="cf">function</span>(muestra, <span class="at">nivel_confianza =</span> <span class="fl">0.95</span>) {</span>
<span id="cb31-2"><a href="estimación-por-intérvalos.html#cb31-2" tabindex="-1"></a>  <span class="co"># Tamaño de la muestra</span></span>
<span id="cb31-3"><a href="estimación-por-intérvalos.html#cb31-3" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">length</span>(muestra)</span>
<span id="cb31-4"><a href="estimación-por-intérvalos.html#cb31-4" tabindex="-1"></a>  </span>
<span id="cb31-5"><a href="estimación-por-intérvalos.html#cb31-5" tabindex="-1"></a>  <span class="co"># Media muestral</span></span>
<span id="cb31-6"><a href="estimación-por-intérvalos.html#cb31-6" tabindex="-1"></a>  media <span class="ot">&lt;-</span> <span class="fu">mean</span>(muestra)</span>
<span id="cb31-7"><a href="estimación-por-intérvalos.html#cb31-7" tabindex="-1"></a>  </span>
<span id="cb31-8"><a href="estimación-por-intérvalos.html#cb31-8" tabindex="-1"></a>  <span class="co"># Desviación estándar muestral</span></span>
<span id="cb31-9"><a href="estimación-por-intérvalos.html#cb31-9" tabindex="-1"></a>  sd_muestra <span class="ot">&lt;-</span> <span class="fu">sd</span>(muestra)</span>
<span id="cb31-10"><a href="estimación-por-intérvalos.html#cb31-10" tabindex="-1"></a>  </span>
<span id="cb31-11"><a href="estimación-por-intérvalos.html#cb31-11" tabindex="-1"></a>  <span class="co"># Grados de libertad</span></span>
<span id="cb31-12"><a href="estimación-por-intérvalos.html#cb31-12" tabindex="-1"></a>  gl <span class="ot">&lt;-</span> n <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb31-13"><a href="estimación-por-intérvalos.html#cb31-13" tabindex="-1"></a>  </span>
<span id="cb31-14"><a href="estimación-por-intérvalos.html#cb31-14" tabindex="-1"></a>  <span class="co"># Valor crítico t</span></span>
<span id="cb31-15"><a href="estimación-por-intérvalos.html#cb31-15" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> nivel_confianza</span>
<span id="cb31-16"><a href="estimación-por-intérvalos.html#cb31-16" tabindex="-1"></a>  t_critico <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="dv">1</span> <span class="sc">-</span> alpha <span class="sc">/</span> <span class="dv">2</span>, <span class="at">df =</span> gl)</span>
<span id="cb31-17"><a href="estimación-por-intérvalos.html#cb31-17" tabindex="-1"></a>  </span>
<span id="cb31-18"><a href="estimación-por-intérvalos.html#cb31-18" tabindex="-1"></a>  <span class="co"># Margen de error</span></span>
<span id="cb31-19"><a href="estimación-por-intérvalos.html#cb31-19" tabindex="-1"></a>  margen_error <span class="ot">&lt;-</span> t_critico <span class="sc">*</span> sd_muestra <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb31-20"><a href="estimación-por-intérvalos.html#cb31-20" tabindex="-1"></a>  </span>
<span id="cb31-21"><a href="estimación-por-intérvalos.html#cb31-21" tabindex="-1"></a>  <span class="co"># Límites del intervalo</span></span>
<span id="cb31-22"><a href="estimación-por-intérvalos.html#cb31-22" tabindex="-1"></a>  limite_inferior <span class="ot">&lt;-</span> media <span class="sc">-</span> margen_error</span>
<span id="cb31-23"><a href="estimación-por-intérvalos.html#cb31-23" tabindex="-1"></a>  limite_superior <span class="ot">&lt;-</span> media <span class="sc">+</span> margen_error</span>
<span id="cb31-24"><a href="estimación-por-intérvalos.html#cb31-24" tabindex="-1"></a>  </span>
<span id="cb31-25"><a href="estimación-por-intérvalos.html#cb31-25" tabindex="-1"></a>  <span class="co"># Resultado como lista</span></span>
<span id="cb31-26"><a href="estimación-por-intérvalos.html#cb31-26" tabindex="-1"></a>  <span class="fu">return</span>(<span class="fu">list</span>(</span>
<span id="cb31-27"><a href="estimación-por-intérvalos.html#cb31-27" tabindex="-1"></a>    <span class="at">media =</span> media,</span>
<span id="cb31-28"><a href="estimación-por-intérvalos.html#cb31-28" tabindex="-1"></a>    <span class="at">margen_error =</span> margen_error,</span>
<span id="cb31-29"><a href="estimación-por-intérvalos.html#cb31-29" tabindex="-1"></a>    <span class="at">limite_inferior =</span> limite_inferior,</span>
<span id="cb31-30"><a href="estimación-por-intérvalos.html#cb31-30" tabindex="-1"></a>    <span class="at">limite_superior =</span> limite_superior,</span>
<span id="cb31-31"><a href="estimación-por-intérvalos.html#cb31-31" tabindex="-1"></a>    <span class="at">nivel_confianza =</span> nivel_confianza</span>
<span id="cb31-32"><a href="estimación-por-intérvalos.html#cb31-32" tabindex="-1"></a>  ))</span>
<span id="cb31-33"><a href="estimación-por-intérvalos.html#cb31-33" tabindex="-1"></a>}</span></code></pre></div>
<p>Si ahora la aplicamos a los datos anteriores, obtendremos el mismo resultado con una llamada mucho más compacta.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="estimación-por-intérvalos.html#cb32-1" tabindex="-1"></a><span class="co"># Calcular el intervalo con la función</span></span>
<span id="cb32-2"><a href="estimación-por-intérvalos.html#cb32-2" tabindex="-1"></a>resultado_funcion <span class="ot">&lt;-</span> <span class="fu">Calcula_IC_Media</span>(muestra, <span class="at">nivel_confianza =</span> <span class="fl">0.95</span>)</span>
<span id="cb32-3"><a href="estimación-por-intérvalos.html#cb32-3" tabindex="-1"></a></span>
<span id="cb32-4"><a href="estimación-por-intérvalos.html#cb32-4" tabindex="-1"></a><span class="co"># Mostrar resultados</span></span>
<span id="cb32-5"><a href="estimación-por-intérvalos.html#cb32-5" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Cálculo con la función:</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Cálculo con la función:</code></pre>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="estimación-por-intérvalos.html#cb34-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Intervalo de confianza (95%): [&quot;</span>, resultado_funcion<span class="sc">$</span>limite_inferior, <span class="st">&quot;, &quot;</span>, resultado_funcion<span class="sc">$</span>limite_superior, <span class="st">&quot;]</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Intervalo de confianza (95%): [ 45.86573 ,  53.19219 ]</code></pre>
<div class="sourceCode" id="cb36"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb36-1"><a href="estimación-por-intérvalos.html#cb36-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Media muestral: &quot;</span>, resultado_funcion<span class="sc">$</span>media, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Media muestral:  49.52896</code></pre>
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb38-1"><a href="estimación-por-intérvalos.html#cb38-1" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;Margen de error: &quot;</span>, resultado_funcion<span class="sc">$</span>margen_error, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<pre><code>## Margen de error:  3.663229</code></pre>
</div>
<div id="uso-del-paquete-descttols" class="section level4 hasAnchor" number="8.8.3.3">
<h4><span class="header-section-number">8.8.3.3</span> Uso del paquete <code>DesctTols</code><a href="estimación-por-intérvalos.html#uso-del-paquete-descttols" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El paquete <code>Desctools</code> simplifica el cálculo e interpretación de intervalos de confianza.</p>
<div class="sourceCode" id="cb40"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb40-1"><a href="estimación-por-intérvalos.html#cb40-1" tabindex="-1"></a><span class="co"># Usar DescTools para intervalos de confianza</span></span>
<span id="cb40-2"><a href="estimación-por-intérvalos.html#cb40-2" tabindex="-1"></a><span class="fu">library</span>(DescTools)</span>
<span id="cb40-3"><a href="estimación-por-intérvalos.html#cb40-3" tabindex="-1"></a><span class="fu">MeanCI</span>(muestra, <span class="at">conf.level =</span> <span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##     mean   lwr.ci   upr.ci 
## 49.52896 45.86573 53.19219</code></pre>
<p>Como puede verse los tres métodos proporcionan el mismo resultado por lo que, en aras de la simplificación, siempre que se disponga de una función incorporada en un paquete utilizaremos ésta.</p>
</div>
</div>
<div id="tamaño-de-muestra-para-la-media-de-una-distribución-normal" class="section level3 hasAnchor" number="8.8.4">
<h3><span class="header-section-number">8.8.4</span> Tamaño de muestra para la media de una distribución Normal<a href="estimación-por-intérvalos.html#tamaño-de-muestra-para-la-media-de-una-distribución-normal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La fórmula para el intervalo de confianza</p>
<p><span class="math display">\[
\bar{X}-t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}} \leq \mu \leq \bar{X}+t_{\alpha / 2} \frac{\hat{S}}{\sqrt{n}}
\]</span></p>
<p>nos da la expresión que permite calcular el tamaño muestral para conseguir una precisión determinada:</p>
<p><span class="math display">\[
n=\frac{t_{a / 2}^{2} \hat{S}^{2}}{d^{2}}
\]</span></p>
<p>donde <span class="math inline">\(d\)</span> es el radio máximo deseado para el intervalo y <span class="math inline">\(t_{\alpha / 2}\)</span> es el valor de una distribución <span class="math inline">\(t\)</span> de Student, con <span class="math inline">\(\mathrm{n}-1\)</span> grados de libertad que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
<p>Para aplicar la fórmula es necesario conocer el valor estimado para la desviación típica. Tenemos varias opciones:</p>
<ul>
<li>Obtener una muestra piloto de un tamaño arbitrario, no necesariamente grande, y obtenida la estimación de la desviación típica sustituirla en la expresión anterior. El número de grados de libertad de la t de Student debe ser <span class="math inline">\(n_{1}-1\)</span>, donde <span class="math inline">\(n_{1}\)</span> es el tamaño muestral de la muestra piloto. Una vez obtenido el intervalo basado en la nueva muestra, se debe comprobar que se ha logrado la precisión deseada para dar por definitivo el resultado.</li>
<li>Si no es posible la obtención de una muestra piloto, todavía es posible el cálculo del tamaño muestral si definimos el radio del intervalo como una fracción de la desviación típica de la población,</li>
</ul>
<p><span class="math display">\[
d=K \sigma
\]</span></p>
<p>y utilizamos como fórmula para calcular el tamaño muestral</p>
<p><span class="math display">\[
n=\frac{z_{a / 2}^{2} \sigma^{2}}{d^{2}}
\]</span></p>
<p>donde <span class="math inline">\(z_{\alpha / 2}\)</span> es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
<p>La fórmula final que resulta es:</p>
<p><span class="math display">\[
n=\frac{z_{\alpha / 2}^{2}}{K^{2}}
\]</span></p>
<ul>
<li>La última posibilidad es sustituir en la expresión (1) el valor de la desviación típica por el valor máximo que se considere que pueda tomar basado en datos bibliográficos previos o en el criterio del investigador.</li>
</ul>
<div id="calculo-del-tamaño-muestral-usando-r" class="section level4 hasAnchor" number="8.8.4.1">
<h4><span class="header-section-number">8.8.4.1</span> Calculo del tamaño muestral usando R<a href="estimación-por-intérvalos.html#calculo-del-tamaño-muestral-usando-r" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como en el caso anterior es posible implementar las fórmulas directamente con R o usar algún paquete específico <code>samplesize</code>o el mismo <code>DescTools</code> que incorpora la función <code>MeanCIn</code> que, a partir del intérvalo de confianza centrado en la media y la desviación retorna el tamaño necesario para alcanzar una precisión determinada.</p>
<p>Por ejemplo si en el ejemplo anterior, con una media de 49.53 y una desviación de 9,81 se desa una precisión (anchura del intérvalo entre dos) de 3 con confianza del 90%:</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="estimación-por-intérvalos.html#cb42-1" tabindex="-1"></a><span class="fu">library</span>(DescTools)</span>
<span id="cb42-2"><a href="estimación-por-intérvalos.html#cb42-2" tabindex="-1"></a>prec<span class="ot">&lt;-</span> <span class="dv">3</span></span>
<span id="cb42-3"><a href="estimación-por-intérvalos.html#cb42-3" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="fl">49.53</span></span>
<span id="cb42-4"><a href="estimación-por-intérvalos.html#cb42-4" tabindex="-1"></a>conf <span class="ot">=</span><span class="fl">0.9</span></span>
<span id="cb42-5"><a href="estimación-por-intérvalos.html#cb42-5" tabindex="-1"></a><span class="fu">MeanCIn</span>(<span class="at">ci=</span><span class="fu">c</span>(m<span class="sc">-</span>prec, m<span class="sc">+</span>prec), <span class="at">sd=</span><span class="fl">9.8</span>, <span class="at">conf.level=</span>conf) </span></code></pre></div>
<pre><code>## [1] 30.75626</code></pre>
<div class="sourceCode" id="cb44"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb44-1"><a href="estimación-por-intérvalos.html#cb44-1" tabindex="-1"></a>conf <span class="ot">=</span><span class="fl">0.95</span></span>
<span id="cb44-2"><a href="estimación-por-intérvalos.html#cb44-2" tabindex="-1"></a><span class="fu">MeanCIn</span>(<span class="at">ci=</span><span class="fu">c</span>(m<span class="sc">-</span>prec, m<span class="sc">+</span>prec), <span class="at">sd=</span><span class="fl">9.8</span>, <span class="at">conf.level=</span>conf) </span></code></pre></div>
<pre><code>## [1] 43.43345</code></pre>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="estimación-por-intérvalos.html#cb46-1" tabindex="-1"></a>conf <span class="ot">=</span><span class="fl">0.99</span></span>
<span id="cb46-2"><a href="estimación-por-intérvalos.html#cb46-2" tabindex="-1"></a><span class="fu">MeanCIn</span>(<span class="at">ci=</span><span class="fu">c</span>(m<span class="sc">-</span>prec, m<span class="sc">+</span>prec), <span class="at">sd=</span><span class="fl">9.8</span>, <span class="at">conf.level=</span>conf) </span></code></pre></div>
<pre><code>## [1] 74.61462</code></pre>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="estimación-por-intérvalos.html#cb48-1" tabindex="-1"></a>prec <span class="ot">&lt;-</span> <span class="dv">2</span>; conf <span class="ot">&lt;-</span> <span class="fl">0.95</span></span>
<span id="cb48-2"><a href="estimación-por-intérvalos.html#cb48-2" tabindex="-1"></a><span class="fu">MeanCIn</span>(<span class="at">ci=</span><span class="fu">c</span>(m<span class="sc">-</span>prec, m<span class="sc">+</span>prec), <span class="at">sd=</span><span class="fl">9.8</span>, <span class="at">conf.level=</span>conf) </span></code></pre></div>
<pre><code>## [1] 94.66357</code></pre>
</div>
</div>
</div>
<div id="intervalo-de-confianza-para-la-varianza-de-una-distribución-normal" class="section level2 hasAnchor" number="8.9">
<h2><span class="header-section-number">8.9</span> Intervalo de confianza para la varianza de una distribución Normal<a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-varianza-de-una-distribución-normal" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dada una variable aleatoria con distribución Normal <span class="math inline">\(\mathrm{N}(\mu ; \sigma)\)</span>, el objetivo es la construcción de un intervalo de confianza para el parámetro <span class="math inline">\(\sigma\)</span>, basado en una muestra de tamaño <span class="math inline">\(n\)</span> de la variable.</p>
<p>A partir del estadístico</p>
<p><span class="math display">\[
\mathrm{X}^{2}=\frac{(n-1) \hat{S}^{2}}{\sigma^{2}}
\]</span></p>
<p>la fórmula para el intervalo de confianza, con nivel de confianza <span class="math inline">\(1-\alpha\)</span> es la siguiente</p>
<p><span class="math display">\[
\frac{(n-1) \hat{S}^{2}}{\chi_{\alpha a / 2}^{2}} \leq \sigma^{2} \leq \frac{(n-1) \hat{S}^{2}}{\chi_{1-\alpha / 2}^{2}}
\]</span></p>
<p>Donde <span class="math inline">\(\chi_{\alpha / 2}^{2}\)</span> es el valor de una distribución Ji al cuadrado con <span class="math inline">\(n-1\)</span> grados de libertad que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
<p>Por ejemplo, dados los datos siguientes:</p>
<ul>
<li>Distribución poblacional: Normal</li>
<li>Tamaño de muestra: 10</li>
<li>Confianza deseada para el intervalo: <span class="math inline">\(95 \%\)</span></li>
<li>Varianza muestral corregida: 38,5</li>
</ul>
<p>Un intervalo de confianza al <span class="math inline">\(95 \%\)</span> para la varianza de la distribución viene dado por:</p>
<p><span class="math display">\[
\frac{9 \cdot 38,5}{19,031} \leq \sigma^{2} \leq \frac{9 \cdot 38,5}{2,699}
\]</span></p>
<p>que resulta, finalmente</p>
<p><span class="math display">\[
\sigma^{2} \in(18.207 ; 128,381)
\]</span></p>
</div>
<div id="intervalo-de-confianza-para-una-proporción" class="section level2 hasAnchor" number="8.10">
<h2><span class="header-section-number">8.10</span> Intervalo de confianza para una proporción<a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-una-proporción" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dada una variable aleatoria con distribución Binomial <span class="math inline">\(\mathrm{B}(n, p)\)</span>, el objetivo es la construcción de un intervalo de confianza para el parámetro <span class="math inline">\(p\)</span>, basada en una observación de la variable que ha dado como valor <span class="math inline">\(x\)</span>. El mismo caso se aplica si estudiamos una Binomial <span class="math inline">\(\mathrm{B}(1, p)\)</span> y consideramos el número de veces que ocurre el suceso que define la variable al repetir el experimento <span class="math inline">\(n\)</span> veces en condiciones de independencia.</p>
<p>Existen dos alternativas a la hora de construir un intervalo de confianza para <span class="math inline">\(p\)</span> :</p>
<ul>
<li>Considerar la aproximación asintótica de la distribución Binomial en la distribución Normal.</li>
<li>Utilizar un método exacto.</li>
</ul>
<div id="aproximación-asintótica" class="section level3 hasAnchor" number="8.10.1">
<h3><span class="header-section-number">8.10.1</span> Aproximación asintótica<a href="estimación-por-intérvalos.html#aproximación-asintótica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Tiene la ventaja de la simplicidad en la expresión y en los cálculos, y es la más referenciada en la mayoría de textos de estadística. Se basa en la aproximación</p>
<p><span class="math display">\[
X \sim B(n, p) \rightarrow N(n p, \sqrt{n p q)}
\]</span></p>
<p>que, trasladada a la frecuencia relativa, resulta</p>
<p><span class="math display">\[
\hat{p}=X / n \rightarrow N(p, \sqrt{p q / n})
\]</span></p>
<p>Tomando como estadístico pivote</p>
<p><span class="math display">\[
Z=\frac{\hat{p}-p}{\sqrt{\hat{p} \hat{q} / n}}
\]</span></p>
<p>que sigue una distribución <span class="math inline">\(\mathrm{N}(0,1)\)</span>, y añadiendo una corrección por continuidad al pasar de una variable discreta a una continua, se obtiene el intervalo de confianza asintótico:</p>
<p><span class="math display">\[
\hat{p} \pm z_{c / 2 / 2} \sqrt{\frac{\hat{p} \hat{q}}{n}}+\frac{1}{2 n}
\]</span></p>
<p>donde <span class="math inline">\(z_{\alpha / 2}\)</span> es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span> para un intervalo de confianza de <span class="math inline">\((1-\alpha) \cdot 100 \%\)</span>. Las condiciones generalmente aceptadas para considerar válida la aproximación asintótica anterior son:</p>
<p><span class="math display">\[
n \geq 30 \quad ; \quad n \hat{p} \geq 5 \quad ; \quad n \hat{q} \geq 5
\]</span></p>
<p>El intervalo obtenido es un intervalo asintótico y por tanto condicionado a la validez de la aproximación utilizada. Una información más general sobre los intervalos de confianza asintóticos puede encontrase aquí.</p>
<div id="cálculo-con-r" class="section level4 hasAnchor" number="8.10.1.1">
<h4><span class="header-section-number">8.10.1.1</span> Cálculo con R<a href="estimación-por-intérvalos.html#cálculo-con-r" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para ver como calcular un intervalo de confianza asintótico puede consultarse el ejemplo en <a href="r-tutor.com">R-Tutor</a>: <a href="https://www.r-tutor.com/elementary-statistics/interval-estimation/interval-estimate-population-proportion">interval-estimate-population-proportion</a></p>
</div>
</div>
<div id="intervalo-exacto" class="section level3 hasAnchor" number="8.10.2">
<h3><span class="header-section-number">8.10.2</span> Intervalo exacto<a href="estimación-por-intérvalos.html#intervalo-exacto" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Aun cuando las condiciones anteriores no se verifiquen, es posible la construcción de un intervalo exacto, válido siempre pero algo más complicado en los cálculos. Es posible demostrar que un intervalo exacto para el parámetro <span class="math inline">\(p\)</span> viene dado por los valores siguientes:</p>
<p><span class="math display">\[
p_{1}=\frac{X}{(n-X+1) F_{\alpha(2,2(n-X+1), 2 X}+X} ; p_{2}=\frac{(X+1) F_{\alpha(2), 2(X+1), 2(n-X)}}{(n-X)+(X+1) F_{\alpha(2,2,(X+1), 2(n-R)}}
\]</span></p>
<p>donde <span class="math inline">\(F_{\alpha / 2, a, b}\)</span> es el valor de una distribución <span class="math inline">\(F\)</span> de Fisher-Snedecor con a y b grados de libertad que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span> para un intervalo de confianza de <span class="math inline">\((1-\alpha) \cdot 100 \%\)</span>.</p>
<p>Una justificación de los intervalos de confianza exactos para distribuciones discretas puede encontrarse aquí.</p>
<div id="cálculo-con-r-1" class="section level4 hasAnchor" number="8.10.2.1">
<h4><span class="header-section-number">8.10.2.1</span> Cálculo con R<a href="estimación-por-intérvalos.html#cálculo-con-r-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En general los paquetes de R implementan múltiples métodos exactos. Este es el caso de <code>DescTools</code>que implementa más de una docena de métodos (podéis hacer <code>? DescTools::BinomCI</code> para aprender cuales son).</p>
<p>Por ejemplo si hemos obtenido un valor de 37 con un tamaño muestral de 43 (es decir una estimación puntual de 37/43 = ``0.8604651) el intervalo de confianza se calculará como:</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="estimación-por-intérvalos.html#cb50-1" tabindex="-1"></a><span class="fu">BinomCI</span>(<span class="at">x=</span><span class="dv">37</span>, <span class="at">n=</span><span class="dv">43</span>, </span>
<span id="cb50-2"><a href="estimación-por-intérvalos.html#cb50-2" tabindex="-1"></a>        <span class="at">method=</span><span class="fu">eval</span>(<span class="fu">formals</span>(BinomCI)<span class="sc">$</span>method))   <span class="co"># return all methods</span></span></code></pre></div>
<pre><code>##                         est    lwr.ci    upr.ci
## wilson            0.8604651 0.7273641 0.9344428
## wald              0.8604651 0.7568980 0.9640322
## waldcc            0.8604651 0.7452701 0.9756601
## agresti-coull     0.8604651 0.7235600 0.9382469
## jeffreys          0.8604651 0.7348110 0.9395927
## modified wilson   0.8604651 0.7273641 0.9344428
## wilsoncc          0.8604651 0.7137335 0.9419725
## modified jeffreys 0.8604651 0.7348110 0.9395927
## clopper-pearson   0.8604651 0.7206752 0.9470234
## arcsine           0.8604651 0.7346862 0.9424696
## logit             0.8604651 0.7224337 0.9359412
## witting           0.8604651 0.7493378 0.9273288
## pratt             0.8604651 0.7661306 0.9472522
## midp              0.8604651 0.7321815 0.9414281
## lik               0.8604651 0.7372546 0.9420472
## blaker            0.8604651 0.7255152 0.9374534</code></pre>
<p>Ante la duda de que método usar lo mejor es usar el métod por defecto (el primero de la lista anterior).</p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="estimación-por-intérvalos.html#cb52-1" tabindex="-1"></a><span class="fu">BinomCI</span>(<span class="at">x=</span><span class="dv">37</span>, <span class="at">n=</span><span class="dv">43</span>) </span></code></pre></div>
<pre><code>##            est    lwr.ci    upr.ci
## [1,] 0.8604651 0.7273641 0.9344428</code></pre>
</div>
</div>
<div id="tamaño-muestral-para-una-proporción" class="section level3 hasAnchor" number="8.10.3">
<h3><span class="header-section-number">8.10.3</span> Tamaño muestral para una proporción<a href="estimación-por-intérvalos.html#tamaño-muestral-para-una-proporción" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A partir de la fórmula para el intervalo de confianza</p>
<p><span class="math display">\[
\hat{p} \pm z_{a / 2 / 2} \sqrt{\frac{\hat{p} \hat{q}}{n}}+\frac{1}{2 n}
\]</span></p>
<p>podemos determinar el tamaño muestral necesario con el fin de que la precisión de la estimación sea la deseada con antelación. La fórmula que resulta es</p>
<p><span class="math display">\[
n=\frac{z_{\alpha / 2}^{2} p q}{d^{2}}
\]</span></p>
<p>donde <span class="math inline">\(d\)</span> es el radio máximo deseado para el intervalo y <span class="math inline">\(z_{\alpha / 2}\)</span> tiene el significado habitual. Nótese que no hemos tenido en cuenta el último término de la primera expresión.</p>
<p>La aplicación efectiva de la fórmula obtenida requiere el conocimiento de <span class="math inline">\(p\)</span> y de <span class="math inline">\(q=(1-p)\)</span>, valores que nos son desconocidos en la práctica. Para solventar este problema tenemos dos alternativas:</p>
<ul>
<li>Considerar el caso más desfavorable posible, es decir, aquel que verifique que <span class="math inline">\(p \cdot q\)</span> da el valor máximo posible. Es fácil verificar que esto sucede si <span class="math inline">\(p=0,5\)</span>. En este caso el producto es <span class="math inline">\(p \cdot q=\)</span> 0,25.</li>
<li>Utilizar un valor de referencia obtenido a partir de una muestra piloto o a partir de datos bibliográficos y utilizar el valor compatible con la información más cercano a <span class="math inline">\(p=0,5\)</span>.</li>
</ul>
<p>A partir de la fórmula puede comprobarse que el tamaño muestral requerido, una vez fijada <span class="math inline">\(p\)</span>, crece al incrementarse la confianza del intervalo y crece también al incrementarse la precisión (al disminuir el radio).</p>
<div id="cálculo-con-r-2" class="section level4 hasAnchor" number="8.10.3.1">
<h4><span class="header-section-number">8.10.3.1</span> Cálculo con R<a href="estimación-por-intérvalos.html#cálculo-con-r-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para ver como determinar el tamaño muestral necesario para construir un intervalo de confianza para una proporción, pueden consultarse los mismos recursos</p>
<ul>
<li>Para el cálculo del tamaño muestral asociado a un intérvalo de confianza asintótico tótico puede consultarse <a href="r-tutor.com">R-Tutor</a>: <a href="https://www.r-tutor.com/elementary-statistics/interval-estimation/sampling-size-population-proportion">sampling-size-population-proportion</a></li>
</ul>
</div>
</div>
</div>
<div id="intervalo-de-confianza-para-el-parámetro-de-una-distribución-de-poisson" class="section level2 hasAnchor" number="8.11">
<h2><span class="header-section-number">8.11</span> Intervalo de confianza para el parámetro de una distribución de Poisson<a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-parámetro-de-una-distribución-de-poisson" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dada una variable aleatoria con distribución de Poisson <span class="math inline">\(\mathrm{P}(\lambda)\)</span>, el objetivo es la construcción de un intervalo de confianza para el parámetro <span class="math inline">\(\lambda\)</span>, basado en una muestra de tamaño <span class="math inline">\(n\)</span> de la variable.</p>
<p>Del mismo modo que para una proporción, existe una solución exacta y una aproximación asintótica al intervalo de confianza para el parámetro <span class="math inline">\(\lambda\)</span>.</p>
<div id="aproximación-asintótica-1" class="section level3 hasAnchor" number="8.11.1">
<h3><span class="header-section-number">8.11.1</span> Aproximación asintótica<a href="estimación-por-intérvalos.html#aproximación-asintótica-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para valores del parámetro <span class="math inline">\(\lambda\)</span> grandes, la distribución de Poisson puede aproximarse a una distribución Normal según:</p>
<p><span class="math display">\[
P(\lambda) \rightarrow N(\lambda, \sqrt{\lambda})
\]</span></p>
<p>Dada una muestra de <span class="math inline">\(n\)</span> observaciones independientes distribuidas según una Poisson de parámetro <span class="math inline">\(\lambda, X_{\mathrm{i}}\)</span> <span class="math inline">\(\sim \mathrm{P}(\lambda)\)</span>, como la distribución de Poisson es aditiva en <span class="math inline">\(\lambda\)</span> se cumple que <span class="math inline">\(\sum X_{i} \sim P(n \lambda)\)</span>. Esta última distribución, si procede, podrá aproximarse a una distribución Normal:</p>
<p><span class="math display">\[
\sum_{i=1}^{n} X_{i} \rightarrow N(n \lambda \sqrt{n \lambda})
\]</span></p>
<p>Por tanto, es inmediato comprobar que:</p>
<p><span class="math display">\[
P\left(-z_{\alpha / 2} \sqrt{\lambda / n}&lt;\bar{X}-\lambda&lt;z_{\alpha / 2} \sqrt{\lambda / n}\right)=1-\alpha
\]</span></p>
<p>donde <span class="math inline">\(z_{\alpha / 2}\)</span> es el valor de una distribución Normal standard que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
<p>La desigualdad es equivalente a</p>
<p><span class="math display">\[
\bar{X}^{2}-2 \lambda \bar{X}+\lambda^{2}&lt;\frac{\lambda}{n} z_{a / 2}^{2}
\]</span></p>
<p>El valor de <span class="math inline">\(\lambda\)</span> estará comprendido entre las dos raíces de la ecuación de segundo grado</p>
<p><span class="math display">\[
\lambda^{2}+\lambda\left(-2 \bar{X}-\frac{z_{\alpha z / 2}^{2}}{n}\right)+\bar{X}^{2}=0
\]</span></p>
<p>Y, finalmente, se obtiene el intervalo de confianza</p>
<p><span class="math display">\[
\lambda \in\left(\bar{X}+\frac{z_{\alpha / 2}^{2}}{2 n} \mp \sqrt{\bar{X} \frac{z_{\alpha / 2}^{2}}{n}+\frac{z_{\alpha / 2}^{4}}{4 n^{2}}}\right)
\]</span></p>
</div>
<div id="intervalo-exacto-1" class="section level3 hasAnchor" number="8.11.2">
<h3><span class="header-section-number">8.11.2</span> Intervalo exacto<a href="estimación-por-intérvalos.html#intervalo-exacto-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si no son aplicables las condiciones para utilizar la aproximación asintótica puede utilizarse la solución exacta, válida siempre. Puede demostrarse que el intervalo exacto para el parámetro <span class="math inline">\(\lambda\)</span> viene dado por</p>
<p><span class="math display">\[
\lambda_{1}=\frac{1}{2 n} \chi_{1-a / 2}^{2}\left(2 \cdot \sum_{i=1}^{n} \chi_{i}\right) ; \lambda_{2}=\frac{1}{2 n} \chi_{a / 2}^{2}\left(2 \cdot \sum_{i=1}^{n} \chi_{i}+2\right)
\]</span></p>
<p>donde <span class="math inline">\(\chi_{\alpha / 2}^{2}(n)\)</span> es el valor de una distribución Ji al cuadrado con <span class="math inline">\(n\)</span> grados de libertad que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
</div>
<div id="tamaño-de-muestra-para-el-parámetro-de-una-distribución-de-poisson" class="section level3 hasAnchor" number="8.11.3">
<h3><span class="header-section-number">8.11.3</span> Tamaño de muestra para el parámetro de una distribución de Poisson<a href="estimación-por-intérvalos.html#tamaño-de-muestra-para-el-parámetro-de-una-distribución-de-poisson" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para determinar el tamaño muestral, se parte de la aproximación</p>
<p><span class="math display">\[
P(\lambda) \rightarrow N(\lambda, \sqrt{\lambda})
\]</span></p>
<p>La expresión que resulta para el tamaño muestral es:</p>
<p><span class="math display">\[
n=\frac{z_{a / 2}^{2} \lambda}{d^{2}}
\]</span></p>
<p>Como suele ocurrir, la fórmula depende del parámetro desconocido y las alternativas vuelven a ser:</p>
<ul>
<li>Utilizar una muestra piloto o datos externos para estimar <span class="math inline">\(\lambda\)</span> y tomar el valor máximo que se considere que puede valer.</li>
<li>Conformarse con una precisión del tipo <span class="math inline">\(d^{2}=K^{2} \lambda\)</span>, de manera que la fórmula queda reducida a</li>
</ul>
<p><span class="math display">\[
n=z_{a / 2}^{2} / K^{2}
\]</span></p>
</div>
</div>
<div id="intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes." class="section level2 hasAnchor" number="8.12">
<h2><span class="header-section-number">8.12</span> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.<a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes." class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="varianza-común" class="section level3 hasAnchor" number="8.12.1">
<h3><span class="header-section-number">8.12.1</span> Varianza común<a href="estimación-por-intérvalos.html#varianza-común" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="caso-de-varianza-desconocida-y-común" class="section level4 hasAnchor" number="8.12.1.1">
<h4><span class="header-section-number">8.12.1.1</span> Caso de varianza desconocida y común<a href="estimación-por-intérvalos.html#caso-de-varianza-desconocida-y-común" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supondremos la existencia de dos poblaciones sobre las que una variable determinada sigue una distribución Normal con idéntica varianza en las dos. Sobre la población 1, la variable sigue una distribución <span class="math inline">\(\mathrm{N}\left(\mu_{1}, \sigma\right)\)</span> y, sobre la población 2 , sigue una distribución <span class="math inline">\(N\left(\mu_{2}, \sigma\right)\)</span>. Igualmente supondremos que disponemos de dos muestras aleatorias independientes, una para cada población, de tamaños muestrales <span class="math inline">\(n_{1}\)</span> y <span class="math inline">\(n_{2}\)</span> respectivamente.</p>
<p>El objetivo es construir un intervalo de confianza, con nivel de confianza ( <span class="math inline">\(1-\alpha\)</span> ) <span class="math inline">\(100 \%\)</span>, para la diferencia de medias</p>
<p><span class="math display">\[
\mu_{1}-\mu_{2}
\]</span></p>
<p>El método se basa en la construcción de una nueva variable <span class="math inline">\(D\)</span>, definida como la diferencia de las medias muestrales para cada población</p>
<p><span class="math display">\[
D=\bar{X}_{1}-\bar{X}_{2}
\]</span></p>
<p>Esta variable, bajo la hipótesis de independencia de las muestras, sigue una distribución Normal de esperanza</p>
<p><span class="math display">\[
\mu_{1}-\mu_{2}
\]</span></p>
<p>y de varianza</p>
<p><span class="math display">\[
\operatorname{Var}(D)=\sigma^{2}\left(\frac{1}{n_{1}}+\frac{1}{n_{2}}\right)
\]</span></p>
<p>La estimación conjunta, a partir de las dos muestras, de la varianza común viene dada por la expresión</p>
<p><span class="math display">\[
\hat{S}_{T}^{2}=\frac{\left(n_{1}-1\right) \cdot \hat{S}_{1}^{2}+\left(n_{2}-1\right) \cdot \hat{S}_{2}^{2}}{n_{1}+n_{2}-2}
\]</span></p>
<p><span class="math inline">\(y\)</span>, utilizando la propiedad de que la variable</p>
<p><span class="math display">\[
\frac{\left(n_{1}+n_{2}-2\right) \hat{S}_{T}^{2}}{\sigma^{2}}
\]</span></p>
<p>sigue una distribución <span class="math inline">\(\chi^{2}\)</span> con <span class="math inline">\(\mathrm{n}_{1}+\mathrm{n}_{2}-2\)</span> grados de libertad, podemos construir un estadístico pivote que siga una distribución <span class="math inline">\(t\)</span> de Student y que nos proporciona la fórmula siguiente para el intervalo de
confianza para la diferencia de medias:</p>
<p><span class="math display">\[
\left(\bar{X}_{1}-\bar{X}_{2}\right)-t_{a / 2} \cdot \hat{S}_{T} \cdot \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}} \leq \mu_{1}-\mu_{2} \leq\left(\bar{X}_{1}-\bar{X}_{2}\right)+t_{a k 2} \cdot \hat{S}_{T} \cdot \sqrt{\frac{1}{n_{1}}+\frac{1}{n_{2}}}
\]</span></p>
<p>donde <span class="math inline">\(t_{\alpha / 2}\)</span> es el valor de una distribución <span class="math inline">\(t\)</span> de Student con <span class="math inline">\(\mathrm{n}_{1}+\mathrm{n}_{2}-2\)</span> grados de libertad que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
</div>
</div>
</div>
<div id="intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.-1" class="section level2 hasAnchor" number="8.13">
<h2><span class="header-section-number">8.13</span> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.<a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="varianza-diferente" class="section level3 hasAnchor" number="8.13.1">
<h3><span class="header-section-number">8.13.1</span> Varianza diferente<a href="estimación-por-intérvalos.html#varianza-diferente" class="anchor-section" aria-label="Anchor link to header"></a></h3>
</div>
<div id="caso-de-varianzas-desconocidas-y-diferentes" class="section level3 hasAnchor" number="8.13.2">
<h3><span class="header-section-number">8.13.2</span> Caso de varianzas desconocidas y diferentes<a href="estimación-por-intérvalos.html#caso-de-varianzas-desconocidas-y-diferentes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cuando tenemos razones para suponer que la varianza no es común, no podemos utilizar el estadístico anterior. Hemos de destacar que, en esta situación, no existe un método exacto que permita obtener el intervalo de confianza deseado. Lo más que tenemos son aproximaciones a la solución. Un intervalo aproximado con nivel de confianza <span class="math inline">\((1-\alpha) \cdot 100 \%\)</span> es</p>
<p><span class="math display">\[
\left(\bar{X}_{1}-\bar{X}_{2}\right)-t_{\alpha / 2} \cdot \sqrt{\frac{\hat{S_{1}}}{n_{1}}+\frac{\hat{S}_{2}}{n_{2}}} \leq \mu_{1}-\mu_{2} \leq\left(\bar{X}_{1}-\bar{X}_{2}\right)+t_{\alpha / 2} \cdot \sqrt{\frac{\hat{S_{1}}}{n_{1}}+\frac{\hat{S}_{2}}{n_{2}}},
\]</span></p>
<p>donde <span class="math inline">\(\hat{S}_{1}\)</span> y <span class="math inline">\(\hat{S}_{2}\)</span> son las varianzas muestrales corregidas para cada población y donde <span class="math inline">\(t_{\alpha / 2}\)</span> es el valor de una distribución <span class="math inline">\(t\)</span> de Student con <span class="math inline">\(g\)</span> grados de libertad, donde</p>
<p><span class="math display">\[
g=\frac{\left(\hat{S}_{1}^{2} / n_{1}+\hat{S}_{2}^{2} / n_{2}\right)^{2}}{\frac{\left(\hat{S}_{1}^{2} / n_{1}\right)^{2}}{n_{1}+1}+\frac{\left(\hat{S}_{2}^{2} / n_{2}\right)^{2}}{n_{2}+1}}-2
\]</span></p>
<p>Si los grados de libertad resultantes son decimales, puede optarse por hacer una interpolación entre los dos valores enteros más cercanos o bien por tomar el valor más desfavorable, aquel que suponga un radio mayor para el intervalo de confianza y que coincide con el redondeo a la baja de los grados de libertad.</p>
</div>
<div id="intérvalos-de-confianza-y-decisiones-estadísticas" class="section level3 hasAnchor" number="8.13.3">
<h3><span class="header-section-number">8.13.3</span> Intérvalos de confianza y decisiones estadísticas<a href="estimación-por-intérvalos.html#intérvalos-de-confianza-y-decisiones-estadísticas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Es, por tanto, importante, antes de proceder a la obtención del intervalo de confianza para la diferencia de medias, verificar si la suposición de homogeneidad de varianzas es razonable o no. Una manera de verificarlo consiste en la construcción del intervalo para el cociente de varianzas, tal como se explica más adelante, y comprobar si en dicho intervalo está incluido el valor 1. La inclusión de la unidad dentro del intervalo resultante, la debemos interpretar en el sentido de que la muestra no proporciona evidencia suficiente para afirmar que las varianzas son diferentes y, por tanto, no es incorrecta la utilización del intervalo para varianza común. De manera análoga, el intervalo de confianza para la diferencia de medias nos puede servir para verificar la suposición de que las medias son iguales o diferentes; en este caso, si el valor 0 está incluido en el intervalo, la conclusión es que la muestra no proporciona evidencia suficiente para afirmar que las medias son diferentes.</p>
<p>Nota importante: El párrafo anterior nos introduce en la posibilidad de utilizar intervalos de confianza para verificar o rechazar ciertas suposiciones sobre el parámetro o los parámetros de las distribuciones. La técnica específica para la verificación de dichas suposiciones o hipótesis a partir de muestras aleatorias se verá en los temas siguientes, donde se introduce el concepto de contraste de hipótesis, sin embargo no podemos dejar de mencionar aquí que los intervalos de confianza nos pueden proporcionar una técnica alternativa o complementaria para la resolución de contrastes.</p>
</div>
</div>
<div id="intervalo-de-confianza-para-el-cociente-de-varianzas-de-distribuciones-normales-independientes" class="section level2 hasAnchor" number="8.14">
<h2><span class="header-section-number">8.14</span> Intervalo de confianza para el cociente de varianzas de distribuciones normales independientes<a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-cociente-de-varianzas-de-distribuciones-normales-independientes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Supondremos la existencia de dos poblaciones sobre las que una determinada variable sigue una distribución Normal. Sobre la población 1 la variable sigue una distribución <span class="math inline">\(N\left(\mu_{1}, \sigma_{1}\right)\)</span> y sobre la población 2 sigue una distribución <span class="math inline">\(\mathrm{N}\left(\mu_{2}, \sigma_{2}\right)\)</span>. Igualmente supondremos que disponemos de dos muestras aleatorias independientes, una para cada población, de tamaños muestrales <span class="math inline">\(n_{1}\)</span> y <span class="math inline">\(n_{2}\)</span> respectivamente.</p>
<p>El objetivo es construir un intervalo de confianza, con nivel de confianza ( <span class="math inline">\(1-\alpha\)</span> ) • <span class="math inline">\(100 \%\)</span>, para el cociente de varianzas</p>
<p><span class="math display">\[
\frac{\sigma_{1}^{2}}{\sigma_{2}^{2}}
\]</span></p>
<p>El estadístico pivote utilizado es</p>
<p><span class="math display">\[
F=\frac{\hat{S}_{1}^{2} / \sigma_{1}^{2}}{\hat{S}_{2}^{2} / \sigma_{2}^{2}}
\]</span></p>
<p>que sigue una distribución <span class="math inline">\(F\)</span> de Fisher con <span class="math inline">\(n_{1}-1\)</span> y <span class="math inline">\(n_{2}-1\)</span> grados de libertad.
El intervalo de confianza que resulta es</p>
<p><span class="math display">\[
\frac{\hat{S}_{1}^{2} / \hat{S}_{2}^{2}}{F_{\alpha / 2}} \leq \frac{\sigma_{1}^{2}}{\sigma_{2}^{2}} \leq \frac{\hat{S}_{1}^{2} / \hat{S}_{2}^{2}}{F_{1-\alpha / 2}}
\]</span></p>
<p>donde <span class="math inline">\(F_{\alpha / 2}\)</span> es el valor de una distribución <span class="math inline">\(F\)</span> de Fisher-Snedecor con <span class="math inline">\(n_{1}-1\)</span> y <span class="math inline">\(n_{2}-1\)</span> grados de libertad que deja a su derecha una probabilidad de <span class="math inline">\(\alpha / 2\)</span>.</p>
</div>
<div id="complementos" class="section level2 hasAnchor" number="8.15">
<h2><span class="header-section-number">8.15</span> Complementos<a href="estimación-por-intérvalos.html#complementos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="interpretación-geométrica-de-los-intervalos-de-confianza" class="section level3 hasAnchor" number="8.15.1">
<h3><span class="header-section-number">8.15.1</span> Interpretación geométrica de los intervalos de confianza<a href="estimación-por-intérvalos.html#interpretación-geométrica-de-los-intervalos-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Es posible tener una visión gráfica de los intervalos de confianza, los límites del intervalo pueden ser representados por curvas en el plano formado por el parámetro que queremos estimar y el estadístico utilizado para construir el pivote. Esta visión nos puede ayudar en la interpretación y la comprensión de los intervalos o de sus propiedades.</p>
<p>Por ejemplo, el intervalo del <span class="math inline">\(95 \%\)</span> para la esperanza de una distribución Normal con varianza conocida y para una muestra de tamaño <span class="math inline">\(n=9\)</span>, de fórmula</p>
<p><span class="math display">\[
\bar{X}-z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}+z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}
\]</span></p>
<p>puede representarse por medio de la figura siguiente:</p>
<p><img src="images/interpretacionGeometrica.png" width="80%" style="display: block; margin: auto;" /></p>
<p>El eje horizontal representa la media muestral y el eje vertical el valor del intervalo para el parámetro <span class="math inline">\(\mu\)</span>. Como puede observarse los límites son líneas rectas y la anchura del intervalo es la misma para cualquier valor de la media.</p>
<p>Veamos ahora la representación gráfica del intervalo para una proporción. La fórmula es</p>
<p><span class="math display">\[
\hat{p} \pm z_{c / 2 / 2} \sqrt{\frac{\hat{p} \hat{q}}{n}}+\frac{1}{2 n}
\]</span></p>
<p>y, para una muestra de tamaño <span class="math inline">\(n=9\)</span> y un intervalo de confianza del <span class="math inline">\(95 \%\)</span>, la gráfica resultante es:</p>
<p><img src="images/freqVsprop.png" width="80%" style="display: block; margin: auto;" /></p>
<p>El eje horizontal es la frecuencia relativa observada y el eje vertical el intervalo de confianza para la proporción. Podemos notar que la anchura del intervalo varía y que, en el caso más desfavorable, la máxima amplitud se da para una frecuencia observada de 0,5.</p>
</div>
<div id="intervalos-para-muestras-grandes" class="section level3 hasAnchor" number="8.15.2">
<h3><span class="header-section-number">8.15.2</span> Intervalos para muestras grandes<a href="estimación-por-intérvalos.html#intervalos-para-muestras-grandes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bajo ciertas condiciones de regularidad, es posible construir intervalos de confianza asintóticos de una manera bastante general.</p>
<p>Si suponemos que un parámetro <span class="math inline">\(\theta\)</span> tiene una estimación máximo verosímil <span class="math inline">\(\theta^{*}\)</span>, la distribución asintótica del estimador, bajo condiciones generales de regularidad, es Normal, de media el valor verdadero del parámetro <span class="math inline">\(\theta\)</span> y varianza igual a la cota de Cramér-Rao <span class="math inline">\(\sigma^{2}\left(\theta^{*}\right)\)</span>.</p>
<p><span class="math display">\[
1 / \sqrt{n \mathrm{E}\left(\frac{\partial}{\partial \theta} \ln f(X, \theta)\right)^{2}}=\sigma\left(\theta^{*}\right)
\]</span></p>
<p>Bajo las suposiciones anteriores, es posible construir un intervalo de confianza asintótico y con nivel de confianza <span class="math inline">\((1-\alpha) \cdot 100 \%\)</span> a partir de</p>
<p><span class="math display">\[
P\left(-z_{\alpha / 2} \leq \frac{\theta^{*}-\theta}{1 / \sqrt{n \mathrm{E}\left(\frac{\partial}{\partial \theta} \ln f(X, \theta)\right)^{2}}} \leq z_{\alpha / 2}\right)=1-\alpha
\]</span></p>
<p>donde los valores de <span class="math inline">\(z_{\alpha / 2}\)</span> se calculan a partir de la distribución <span class="math inline">\(N(0,1)\)</span> de forma que <span class="math inline">\(P\left(|Z|&gt;z_{\alpha / 2}\right)=\alpha\)</span>.
Es decir, se utiliza como estadístico pivote</p>
<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="33%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Estadístico pivote</th>
<th align="center">Distribución del estadístico pivote</th>
<th align="center">Observaciones</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(Z=\frac{\theta^{*}-\theta}{\sigma\left(\theta^{*}\right)}\)</span></td>
<td align="center">N( 0,1 )</td>
<td align="center">Distribución asintótica, <span class="math inline">\(\theta^{*}\)</span> es la estimación máximo verosimil del parámetro y <span class="math inline">\(\sigma\left(\theta^{*}\right)\)</span> es la cota de Crámer-Rao</td>
</tr>
</tbody>
</table>
<p>El intervalo de confianza aproximado que resulta es:</p>
<p><span class="math display">\[
\theta^{*}-z_{a / 2} \sigma\left(\theta^{*}\right) \leq \theta \leq \theta^{*}+z_{a / 2} \sigma\left(\theta^{*}\right)
\]</span></p>
</div>
<div id="intervalos-exactos-para-distribuciones-discretas" class="section level3 hasAnchor" number="8.15.3">
<h3><span class="header-section-number">8.15.3</span> Intervalos exactos para distribuciones discretas<a href="estimación-por-intérvalos.html#intervalos-exactos-para-distribuciones-discretas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El procedimiento que permite obtener los intervalos exactos para los parámetros de las distribuciones discretas, por ejemplo los parámetros <span class="math inline">\(\lambda\)</span> de la distribución de Poisson o <span class="math inline">\(p\)</span> de la Binomial, se explica a continuación.</p>
<p>Consideramos que la variable aleatoria discreta tiene por recorrido <span class="math inline">\(\{0,1,2, \ldots\}\)</span> y depende de un parámetro desconocido <span class="math inline">\(\theta\)</span>. Si suponemos que se ha obtenido una muestra de tamaño 1 y de valor <span class="math inline">\(k\)</span> (donde <span class="math inline">\(k\)</span> puede ser, por ejemplo, la frecuencia con que se ha presentado un suceso en <span class="math inline">\(n\)</span> experiencias o la suma de <span class="math inline">\(n\)</span> observaciones distribuidas según una distribución de Poisson), se trata de resolver las ecuaciones siguientes:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \sum_{\substack{i=k \\
k}}^{\infty} P(x=i / \theta)=\alpha / 2 \\
&amp; \sum_{i=0}^{k} P(x=i / \theta)=\alpha / 2
\end{aligned}
\]</span></p>
<p>Las soluciones <span class="math inline">\(\theta_{1}\)</span> y <span class="math inline">\(\theta_{2}\)</span> constituyen el intervalo de confianza de nivel de confianza <span class="math inline">\((1-\alpha) \cdot 100 \%\)</span> buscado.</p>
<p>Veamos un ejemplo:
Supongamos que tenemos una variable Binomial con <span class="math inline">\(n=4\)</span> y que una observación nos ha dado <span class="math inline">\(x=2\)</span>. ¿Cuál es el intervalo de confianza del <span class="math inline">\(95 \%\)</span> para el parámetro <span class="math inline">\(p\)</span> ?</p>
<p>Hemos de resolver las ecuaciones siguientes:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; P(X=0)+P(X=1)+P(X=2)=\binom{4}{0}(1-p)^{4}+\binom{4}{1} p(1-p)^{3}+\binom{4}{2} p^{2}(1-p)^{2}=0,025 \\
&amp; P(X=2)+P(X=3)+P(X=4)=\binom{4}{2} p^{2}(1-p)^{2}+\binom{4}{3} p^{3}(1-p)+\binom{4}{4} p^{4}=0,025
\end{aligned}
\]</span></p>
<p>Utilizando un programa de cálculo numérico (el Mathematica, por ejemplo) obtenemos como soluciones significativas <span class="math inline">\(p_{1}=0,932414\)</span>, para la primera, y <span class="math inline">\(p_{2}=0,067586\)</span>, para la segunda; quedando finalmente el intervalo ( 0,<span class="math inline">\(067586 ; 0,932414\)</span> ).</p>
<p>Podéis comprobar el resultado aquí, tomando <span class="math inline">\(n=4\)</span> y <span class="math inline">\(x=2\)</span>.</p>
<p>En la bibliografia existen numerosas tablas para el cálculo de dichos intervalos, pero también son aplicables las fórmulas presentadas para la Binomial y la Poisson.</p>
</div>
<div id="una-aproximación-diferente-para-la-distribución-de-poisson" class="section level3 hasAnchor" number="8.15.4">
<h3><span class="header-section-number">8.15.4</span> Una aproximación diferente para la distribución de Poisson<a href="estimación-por-intérvalos.html#una-aproximación-diferente-para-la-distribución-de-poisson" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hemos visto con anterioridad la construcción del intervalo de confianza para el parámetro <span class="math inline">\(\lambda\)</span> de una distribución de Poisson. Los cálculos y la fórmula del intervalo eran algo complejos, sin embargo, si en lugar de trabajar directamente con la variable, efectuamos una transformación previa, en particular, si trabajamos con la raíz cuadrada de la variable, el problema puede simplificarse notablemente.</p>
<p>Puede demostrarse que</p>
<p><span class="math display">\[
X \rightarrow P(\lambda) \Rightarrow \sqrt{X} \rightarrow N(\sqrt{\lambda} ; 1 / 2)
\]</span></p>
<p>La transformación de la raíz cuadrada es una transformación estabilizadora de la varianza, la ventaja es que la varianza resultante <span class="math inline">\((0,25)\)</span> no depende del parámetro <span class="math inline">\(\lambda\)</span> que se ha de estimar, facilitando la obtención de resultados. En nuestro caso,</p>
<p><span class="math display">\[
\sqrt{\sum_{i=1}^{n} X_{i}} \rightarrow N\left(\sqrt{n \lambda_{3}} 1 / 2\right)
\]</span></p>
<p>y se obtiene fácilmente el intervalo de confianza</p>
<p><span class="math display">\[
\sqrt{\sum_{i=1}^{n} X_{i}}-\frac{z_{\alpha / 2}}{2}&lt;\sqrt{n \lambda}&lt;\sqrt{\sum_{i=1}^{n} X_{i}}+\frac{z_{\alpha / 2}}{2}
\]</span></p>
<p>donde <span class="math inline">\(z_{\alpha}\)</span> es el valor de una distribución Normal estándar que deja a su derecha una probabilidad de <span class="math inline">\(\alpha\)</span>.
Y, si despejamos,</p>
<p><span class="math display">\[
\lambda \in \frac{1}{n}\left(\frac{z_{\alpha / 2}}{2} \pm \sqrt{\sum_{i=1}^{n} X_{i}}\right)^{2}
\]</span></p>
<p>Comparad la fórmula obtenida con la desarrollada en el caso de no utilizar la transformación.</p>
</div>
<div id="aproximación-mediante-chébishev" class="section level3 hasAnchor" number="8.15.5">
<h3><span class="header-section-number">8.15.5</span> Aproximación mediante Chébishev<a href="estimación-por-intérvalos.html#aproximación-mediante-chébishev" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El teorema de Chébishev nos proporciona una aproximación al problema de construcción de intervalos de confianza para los valores de una variable aleatoria independientemente de su distribución. No es por tanto una estimación paramétrica a través de intervalos de confianza, sino únicamente una manera de acotar la probabilidad de una variable aleatoria alrededor de su esperanza.</p>
<p>La ventaja del enfoque basado en Chébishev es que no es necesaria ninguna suposición sobre la distribución de la variable, la única condición es la existencia de esperanza y de varianza finita para la variable aleatoria.</p>
<p>El inconveniente es la falta de precisión de la estimación, puesto que trabajamos con una cota superior para la probabilidad de desviación de una variable aleatoria respecto a su esperanza.</p>
<p>La fórmula utilizada es</p>
<p><span class="math display">\[
P(|X-E(X)| \geq h) \leq \frac{\operatorname{Var}(X)}{h^{2}}
\]</span></p>
<p>donde <span class="math inline">\(h&gt;0\)</span>.
Una vez que se dispone de los valores de la esperanza y de la varianza de la variable, es posible fijar la probabilidad deseada y despejar el valor de <span class="math inline">\(h\)</span> que nos proporciona el radio del intervalo centrado en la esperanza.</p>
<p><span class="math display">\[
h^{2}=\frac{\operatorname{Var}(X)}{1-\text { Probabilidad deseada del intervalo }}
\]</span></p>
<p>El resultado final se interpreta en el sentido de que la probabilidad de que la variable se encuentre dentro del intervalo construido es mayor o igual que la probabilidad fijada.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimación-puntual.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="pruebas-de-hipótesis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ASPteaching/FundamentosInferencia/edit/BRANCH/08-estimacionIntervalos.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/08-estimacionIntervalos.Rmd",
"text": null
},
"download": "https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/docs/_main.pdf",
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
