<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 8 MÉTODOS DE OBTENCIÓN DE ESTIMADORES | Fundamentos de Inferencia Estadistica</title>
  <meta name="description" content="Capítulo 8 MÉTODOS DE OBTENCIÓN DE ESTIMADORES | Fundamentos de Inferencia Estadistica" />
  <meta name="generator" content="bookdown 0.41 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 8 MÉTODOS DE OBTENCIÓN DE ESTIMADORES | Fundamentos de Inferencia Estadistica" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 8 MÉTODOS DE OBTENCIÓN DE ESTIMADORES | Fundamentos de Inferencia Estadistica" />
  
  
  

<meta name="author" content="Alex Sanchez Pla y Santiago Pérez Hoyos" />


<meta name="date" content="2024-11-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimación-puntual.html"/>
<link rel="next" href="estimación-puntual-1.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="blocks.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/docs/_main.pdf" title="Version en PDF" target="_blank"><img alt="Versión en pdf" src="./images(pdf.png)" width="12" height="15" />    </a>
</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisitos-y-organización-del-material"><i class="fa fa-check"></i>Prerequisitos y organización del material</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#referencias"><i class="fa fa-check"></i>Referencias</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html"><i class="fa fa-check"></i>Agradecimiento y fuentes utilizadas</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#el-proyecto-statmedia"><i class="fa fa-check"></i>El proyecto Statmedia</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#otros-materiales-utilizados"><i class="fa fa-check"></i>Otros materiales utilizados</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html"><i class="fa fa-check"></i><b>1</b> Probabilidad y Experimentos aleatorios</a>
<ul>
<li class="chapter" data-level="1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducción"><i class="fa fa-check"></i><b>1.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#fenómenos-deterministas-y-fenómenos-aleatorios"><i class="fa fa-check"></i><b>1.1.1</b> Fenómenos deterministas y fenómenos aleatorios</a></li>
<li class="chapter" data-level="1.1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos"><i class="fa fa-check"></i><b>1.1.2</b> Sucesos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#función-de-probabilidad"><i class="fa fa-check"></i><b>1.2</b> Función de probabilidad</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#diferentes-funciones-de-probabilidad-para-una-misma-experiencia-aleatoria"><i class="fa fa-check"></i><b>1.2.1</b> ¿Diferentes funciones de probabilidad para una misma experiencia aleatoria?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#cómo-se-calculan-las-probabilidades"><i class="fa fa-check"></i><b>1.3</b> ¿Cómo se calculan las probabilidades?</a></li>
<li class="chapter" data-level="1.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-elementales-y-sucesos-observables"><i class="fa fa-check"></i><b>1.4</b> Sucesos elementales y sucesos observables</a></li>
<li class="chapter" data-level="1.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#propiedades-inmediatas-de-la-probabilidad"><i class="fa fa-check"></i><b>1.5</b> Propiedades inmediatas de la probabilidad</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#succeso-imposible"><i class="fa fa-check"></i><b>1.5.1</b> Succeso imposible</a></li>
<li class="chapter" data-level="1.5.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#suceso-implicado"><i class="fa fa-check"></i><b>1.5.2</b> Suceso implicado</a></li>
<li class="chapter" data-level="1.5.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#complementario-de-un-suceso"><i class="fa fa-check"></i><b>1.5.3</b> Complementario de un suceso</a></li>
<li class="chapter" data-level="1.5.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ocurrencia-de-algun-suceso"><i class="fa fa-check"></i><b>1.5.4</b> Ocurrencia de algun suceso</a></li>
<li class="chapter" data-level="1.5.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurra-algun-suceso"><i class="fa fa-check"></i><b>1.5.5</b> Probabilidad de que ocurra algun suceso</a></li>
<li class="chapter" data-level="1.5.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurran-dos-o-más-sucesos-a-la-vez"><i class="fa fa-check"></i><b>1.5.6</b> Probabilidad de que ocurran dos (o más) sucesos a la vez</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#espacios-de-probabilidad"><i class="fa fa-check"></i><b>1.6</b> Espacios de probabilidad</a></li>
<li class="chapter" data-level="1.7" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>1.7</b> Probabilidad condicionada</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-dependientes-y-sucesos-independientes"><i class="fa fa-check"></i><b>1.7.1</b> Sucesos dependientes y sucesos independientes</a></li>
<li class="chapter" data-level="1.7.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#incompatibilidad-e-independencia"><i class="fa fa-check"></i><b>1.7.2</b> Incompatibilidad e independencia</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#dos-teoremas-importantes"><i class="fa fa-check"></i><b>1.8</b> Dos Teoremas importantes</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-las-probabilidades-totales"><i class="fa fa-check"></i><b>1.8.1</b> Teorema de las probabilidades totales</a></li>
<li class="chapter" data-level="1.8.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-bayes"><i class="fa fa-check"></i><b>1.8.2</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducción-a-los-experimentos-múltiples"><i class="fa fa-check"></i><b>1.9</b> Introducción a los experimentos múltiples</a></li>
<li class="chapter" data-level="1.10" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinatoria"><i class="fa fa-check"></i><b>1.10</b> Combinatoria</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones"><i class="fa fa-check"></i><b>1.10.1</b> Permutaciones</a></li>
<li class="chapter" data-level="1.10.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones"><i class="fa fa-check"></i><b>1.10.2</b> Variaciones</a></li>
<li class="chapter" data-level="1.10.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones-con-repetición"><i class="fa fa-check"></i><b>1.10.3</b> Variaciones con repetición</a></li>
<li class="chapter" data-level="1.10.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinaciones"><i class="fa fa-check"></i><b>1.10.4</b> Combinaciones</a></li>
<li class="chapter" data-level="1.10.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones-con-repetición"><i class="fa fa-check"></i><b>1.10.5</b> Permutaciones con repetición</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#frecuencia-relativa-y-probabilidad"><i class="fa fa-check"></i><b>1.11</b> Frecuencia relativa y probabilidad</a></li>
<li class="chapter" data-level="1.12" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#caso-de-estudio-eficacia-de-una-prueba-diagnóstica"><i class="fa fa-check"></i><b>1.12</b> Caso de Estudio: Eficacia de una prueba diagnóstica</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#aplicación-del-teorema-de-bayes"><i class="fa fa-check"></i><b>1.12.1</b> Aplicación del Teorema de Bayes</a></li>
<li class="chapter" data-level="1.12.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ejemplo-numérico"><i class="fa fa-check"></i><b>1.12.2</b> Ejemplo numérico</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>2</b> Variables aleatorias y Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#el-espacio-muestral-y-sus-elementos"><i class="fa fa-check"></i><b>2.1</b> El espacio muestral y sus elementos</a></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representación-numérica-de-los-sucesos-elementales.-variables-aleatorias"><i class="fa fa-check"></i><b>2.2</b> Representación numérica de los sucesos elementales. Variables aleatorias</a></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterización-de-una-variable-aleatoria-a-través-de-la-probabilidad.-función-de-distribución"><i class="fa fa-check"></i><b>2.3</b> Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución</a></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-función-de-distribución"><i class="fa fa-check"></i><b>2.4</b> Propiedades de la función de distribución</a></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificación-de-las-variables-aleatorias"><i class="fa fa-check"></i><b>2.5</b> Clasificación de las variables aleatorias</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-discretas"><i class="fa fa-check"></i><b>2.5.1</b> Variables aleatorias discretas</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.5.2</b> Variables aleatorias continuas</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variable-aleatoria-discretas"><i class="fa fa-check"></i><b>2.6</b> Variable aleatoria discretas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterización-de-las-v.a.-discretas"><i class="fa fa-check"></i><b>2.6.1</b> Caracterización de las v.a. discretas</a></li>
<li class="chapter" data-level="2.6.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-función-de-densidad-discreta"><i class="fa fa-check"></i><b>2.6.2</b> Propiedades de la función de densidad discreta</a></li>
<li class="chapter" data-level="2.6.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-función-de-distribución-y-la-función-de-densidad-discreta.-probabilidad-de-intervalos."><i class="fa fa-check"></i><b>2.6.3</b> Relaciones entre la función de distribución y la función de densidad discreta. <br> Probabilidad de intervalos.</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>2.7</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#función-de-densidad-continua"><i class="fa fa-check"></i><b>2.7.1</b> Función de densidad continua</a></li>
<li class="chapter" data-level="2.7.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-función-de-distribución-y-la-función-de-densidad."><i class="fa fa-check"></i><b>2.7.2</b> Relaciones entre la función de distribución y la función de densidad.</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterización-de-una-variable-aleatoria-a-través-de-parámetros"><i class="fa fa-check"></i><b>2.8</b> Caracterización de una variable aleatoria a través de parámetros</a></li>
<li class="chapter" data-level="2.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-discreta"><i class="fa fa-check"></i><b>2.9</b> Esperanza de una variable aleatoria discreta</a></li>
<li class="chapter" data-level="2.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-continua"><i class="fa fa-check"></i><b>2.10</b> Esperanza de una variable aleatoria continua</a></li>
<li class="chapter" data-level="2.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-esperanza-matemática"><i class="fa fa-check"></i><b>2.11</b> Propiedades de la esperanza matemática</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#linealidad-de-la-esperanza-matemática"><i class="fa fa-check"></i><b>2.11.1</b> Linealidad de la esperanza matemática</a></li>
<li class="chapter" data-level="2.11.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-del-producto"><i class="fa fa-check"></i><b>2.11.2</b> Esperanza del producto</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.12</b> Varianza de una variable aleatoria</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-varianza"><i class="fa fa-check"></i><b>2.12.1</b> Propiedades de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#momentos-de-orden-k-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.13</b> Momentos (de orden <span class="math inline">\(k\)</span>) de una variable aleatoria</a></li>
<li class="chapter" data-level="2.14" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#definición-formal-de-variable-aleatoria"><i class="fa fa-check"></i><b>2.14</b> Definición formal de variable aleatoria</a></li>
<li class="chapter" data-level="2.15" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caso-práctico-lanzamiento-de-dos-dados"><i class="fa fa-check"></i><b>2.15</b> Caso práctico: Lanzamiento de dos dados</a>
<ul>
<li class="chapter" data-level="2.15.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#espacio-muestral"><i class="fa fa-check"></i><b>2.15.1</b> Espacio muestral</a></li>
<li class="chapter" data-level="2.15.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representación-numérica"><i class="fa fa-check"></i><b>2.15.2</b> Representación numérica</a></li>
<li class="chapter" data-level="2.15.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#algunas-probabilidades"><i class="fa fa-check"></i><b>2.15.3</b> Algunas probabilidades</a></li>
<li class="chapter" data-level="2.15.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#función-de-distribución"><i class="fa fa-check"></i><b>2.15.4</b> Función de distribución</a></li>
<li class="chapter" data-level="2.15.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificación-de-las-variables"><i class="fa fa-check"></i><b>2.15.5</b> Clasificación de las variables</a></li>
<li class="chapter" data-level="2.15.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#función-de-densidad-discreta"><i class="fa fa-check"></i><b>2.15.6</b> Función de densidad discreta</a></li>
<li class="chapter" data-level="2.15.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-intervalos-1"><i class="fa fa-check"></i><b>2.15.7</b> Probabilidad de intervalos</a></li>
<li class="chapter" data-level="2.15.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza"><i class="fa fa-check"></i><b>2.15.8</b> Esperanza</a></li>
<li class="chapter" data-level="2.15.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-un-juego"><i class="fa fa-check"></i><b>2.15.9</b> Esperanza de un juego</a></li>
<li class="chapter" data-level="2.15.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-con-recorrido-infinito"><i class="fa fa-check"></i><b>2.15.10</b> Esperanza con recorrido infinito</a></li>
<li class="chapter" data-level="2.15.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-infinita"><i class="fa fa-check"></i><b>2.15.11</b> Esperanza infinita</a></li>
<li class="chapter" data-level="2.15.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza"><i class="fa fa-check"></i><b>2.15.12</b> Varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html"><i class="fa fa-check"></i><b>3</b> Distribuciones Notables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-discretas"><i class="fa fa-check"></i><b>3.1</b> Distribuciones discretas</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-bernouilli"><i class="fa fa-check"></i><b>3.1.1</b> La distribución de Bernouilli</a></li>
<li class="chapter" data-level="3.1.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-binomial"><i class="fa fa-check"></i><b>3.1.2</b> La distribución Binomial</a></li>
<li class="chapter" data-level="3.1.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-poisson"><i class="fa fa-check"></i><b>3.1.3</b> La distribución de Poisson</a></li>
<li class="chapter" data-level="3.1.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-uniforme-discreta"><i class="fa fa-check"></i><b>3.1.4</b> La distribución Uniforme discreta</a></li>
<li class="chapter" data-level="3.1.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-hipergeométrica"><i class="fa fa-check"></i><b>3.1.5</b> La distribución Hipergeométrica</a></li>
<li class="chapter" data-level="3.1.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-geométrica-o-de-pascal"><i class="fa fa-check"></i><b>3.1.6</b> La distribución Geométrica o de Pascal</a></li>
<li class="chapter" data-level="3.1.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-binomial-negativa"><i class="fa fa-check"></i><b>3.1.7</b> La distribución Binomial negativa</a></li>
<li class="chapter" data-level="3.1.8" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-distribuciones-discretas-principales"><i class="fa fa-check"></i><b>3.1.8</b> Tabla resumen de las distribuciones discretas principales</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-continuas"><i class="fa fa-check"></i><b>3.2</b> Distribuciones Continuas</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-uniforme"><i class="fa fa-check"></i><b>3.2.1</b> La distribución Uniforme</a></li>
<li class="chapter" data-level="3.2.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-exponencial"><i class="fa fa-check"></i><b>3.2.2</b> La distribución Exponencial</a></li>
<li class="chapter" data-level="3.2.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-normal"><i class="fa fa-check"></i><b>3.2.3</b> La distribución Normal</a></li>
<li class="chapter" data-level="3.2.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-gamma"><i class="fa fa-check"></i><b>3.2.4</b> La distribución Gamma</a></li>
<li class="chapter" data-level="3.2.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-cauchy"><i class="fa fa-check"></i><b>3.2.5</b> La distribución de Cauchy</a></li>
<li class="chapter" data-level="3.2.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribución-de-weibull"><i class="fa fa-check"></i><b>3.2.6</b> La distribución de Weibull</a></li>
<li class="chapter" data-level="3.2.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-principales-distribuciones-continuas"><i class="fa fa-check"></i><b>3.2.7</b> Tabla resumen de las principales distribuciones continuas</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-con-r-y-python"><i class="fa fa-check"></i><b>3.3</b> Distribuciones con R (y Python)</a></li>
<li class="chapter" data-level="3.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-familia-exponencial-de-distribuciones"><i class="fa fa-check"></i><b>3.4</b> La familia exponencial de distribuciones</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#ejemplos-de-distribuciones-de-esta-familia"><i class="fa fa-check"></i><b>3.4.1</b> Ejemplos de distribuciones de esta familia</a></li>
<li class="chapter" data-level="3.4.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribución-binomial"><i class="fa fa-check"></i><b>3.4.2</b> Distribución Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#importancia-y-utilidad-de-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.3</b> Importancia y utilidad de la familia exponencial</a></li>
<li class="chapter" data-level="3.4.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#los-modelos-lineales-generalizados-glms"><i class="fa fa-check"></i><b>3.4.4</b> Los modelos lineales generalizados (GLMs)</a></li>
<li class="chapter" data-level="3.4.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#estimación-en-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.5</b> Estimación en la familia exponencial</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html"><i class="fa fa-check"></i><b>4</b> Distribuciones de probabilidad multidimensionales</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-conjuntas-de-probabilidades"><i class="fa fa-check"></i><b>4.1</b> Distribuciones conjuntas de probabilidades</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatoria-bivariante"><i class="fa fa-check"></i><b>4.1.1</b> Variable aleatoria bivariante</a></li>
<li class="chapter" data-level="4.1.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#función-de-distribución-bivariante"><i class="fa fa-check"></i><b>4.1.2</b> Función de distribución bivariante</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatorias-bivariantes-discretas"><i class="fa fa-check"></i><b>4.2</b> Variable aleatorias bivariantes discretas</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#función-de-masa-de-probabilidad-discreta-fmp"><i class="fa fa-check"></i><b>4.2.1</b> Función de masa de probabilidad discreta (fmp)</a></li>
<li class="chapter" data-level="4.2.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-fmp-bivariante"><i class="fa fa-check"></i><b>4.2.2</b> Propiedades de la fmp bivariante</a></li>
<li class="chapter" data-level="4.2.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejemplo-de-distribución-bivariante-discreta"><i class="fa fa-check"></i><b>4.2.3</b> Ejemplo de distribución bivariante discreta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribución-multinomial"><i class="fa fa-check"></i><b>4.3</b> La distribución multinomial</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#generación-de-las-observaciones"><i class="fa fa-check"></i><b>4.3.1</b> Generación de las observaciones</a></li>
<li class="chapter" data-level="4.3.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funcion-de-masa-de-probabilidad-de-la-distribución-multinomial"><i class="fa fa-check"></i><b>4.3.2</b> Funcion de masa de probabilidad de la distribución multinomial</a></li>
<li class="chapter" data-level="4.3.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relación-con-la-distribución-binomial"><i class="fa fa-check"></i><b>4.3.3</b> Relación con la distribución binomial</a></li>
<li class="chapter" data-level="4.3.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#un-caso-particular-la-distribución-trinomial"><i class="fa fa-check"></i><b>4.3.4</b> Un caso particular: La distribución trinomial</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-marginales"><i class="fa fa-check"></i><b>4.4</b> Distribuciones marginales</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#las-marginales-están-en-los-márgenes"><i class="fa fa-check"></i><b>4.4.1</b> Las marginales están en los márgenes</a></li>
<li class="chapter" data-level="4.4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-discretas"><i class="fa fa-check"></i><b>4.4.2</b> Densidades marginales discretas</a></li>
<li class="chapter" data-level="4.4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribuciones-marginales"><i class="fa fa-check"></i><b>4.4.3</b> Trinomial M(5; 0.6, 0.2): Distribuciones marginales</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales"><i class="fa fa-check"></i><b>4.5</b> Distribuciones condicionales</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional"><i class="fa fa-check"></i><b>4.5.1</b> Densidad condicional</a></li>
<li class="chapter" data-level="4.5.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribución-condicional"><i class="fa fa-check"></i><b>4.5.2</b> Trinomial M(5; 0.6, 0.2): Distribución condicional</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#vectores-aleatorios-absolutamente-continuos"><i class="fa fa-check"></i><b>4.6</b> Vectores aleatorios absolutamente continuos</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-función-de-densidad-conjunta"><i class="fa fa-check"></i><b>4.6.1</b> Propiedades de la función de densidad conjunta</a></li>
<li class="chapter" data-level="4.6.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.2</b> Densidades marginales en el caso continuo</a></li>
<li class="chapter" data-level="4.6.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.3</b> Densidad condicional en el caso continuo</a></li>
<li class="chapter" data-level="4.6.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribución-normal-bivariante"><i class="fa fa-check"></i><b>4.6.4</b> La Distribución Normal Bivariante</a></li>
<li class="chapter" data-level="4.6.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales-1"><i class="fa fa-check"></i><b>4.6.5</b> Distribuciones Condicionales</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#independencia-de-variables-aleatorias"><i class="fa fa-check"></i><b>4.7</b> Independencia de variables aleatorias</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#primera-caracterización-de-la-independencia"><i class="fa fa-check"></i><b>4.7.1</b> Primera caracterización de la independencia</a></li>
<li class="chapter" data-level="4.7.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-las-variables-independientes"><i class="fa fa-check"></i><b>4.7.2</b> Propiedades de las variables independientes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#momentos-de-vectores-aleatorios"><i class="fa fa-check"></i><b>4.8</b> Momentos de vectores aleatorios</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#esperanza-de-un-vector-aleatorio-o-vector-de-medias"><i class="fa fa-check"></i><b>4.8.1</b> Esperanza de un vector aleatorio o vector de medias</a></li>
<li class="chapter" data-level="4.8.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-entre-dos-variables-aleatorias"><i class="fa fa-check"></i><b>4.8.2</b> Covarianza entre dos variables aleatorias</a></li>
<li class="chapter" data-level="4.8.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-y-correlación"><i class="fa fa-check"></i><b>4.8.3</b> Covarianza y correlación</a></li>
<li class="chapter" data-level="4.8.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.4</b> Matriz de varianzas-covarianzas</a></li>
<li class="chapter" data-level="4.8.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>4.8.5</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="4.8.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#segunda-caracterización-de-la-independencia"><i class="fa fa-check"></i><b>4.8.6</b> Segunda caracterización de la independencia</a></li>
<li class="chapter" data-level="4.8.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relación-entre-incorrelación-e-independencia"><i class="fa fa-check"></i><b>4.8.7</b> Relación entre incorrelación e independencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="grandes-muestras.html"><a href="grandes-muestras.html"><i class="fa fa-check"></i><b>5</b> Grandes muestras</a>
<ul>
<li class="chapter" data-level="5.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#introducción-aproximaciones-asintóticas"><i class="fa fa-check"></i><b>5.1</b> Introducción: Aproximaciones asintóticas</a></li>
<li class="chapter" data-level="5.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ley-de-los-grandes-números-ley-débil"><i class="fa fa-check"></i><b>5.2</b> Ley de los Grandes Números (Ley débil)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ejemplo-3"><i class="fa fa-check"></i><b>5.2.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#el-teorema-central-del-límite"><i class="fa fa-check"></i><b>5.3</b> El teorema central del límite</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#sumas-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.3.1</b> Sumas de variables aleatorias</a></li>
<li class="chapter" data-level="5.3.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#definición-de-convergencia-en-ley"><i class="fa fa-check"></i><b>5.3.2</b> Definición de convergencia en ley</a></li>
<li class="chapter" data-level="5.3.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#enunciado-del-teorema-central-del-límite"><i class="fa fa-check"></i><b>5.3.3</b> Enunciado del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.4" data-path="grandes-muestras.html"><a href="grandes-muestras.html#algunos-ejemplos-de-aplicación-del-tcl"><i class="fa fa-check"></i><b>5.3.4</b> Algunos ejemplos de aplicación del TCL</a></li>
<li class="chapter" data-level="5.3.5" data-path="grandes-muestras.html"><a href="grandes-muestras.html#casos-particulares-más-notables"><i class="fa fa-check"></i><b>5.3.5</b> Casos particulares más notables</a></li>
<li class="chapter" data-level="5.3.6" data-path="grandes-muestras.html"><a href="grandes-muestras.html#interpretación-del-teorema-central-del-límite"><i class="fa fa-check"></i><b>5.3.6</b> Interpretación del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.7" data-path="grandes-muestras.html"><a href="grandes-muestras.html#acerca-de-las-variables-aproximadamente-normales"><i class="fa fa-check"></i><b>5.3.7</b> Acerca de las variables aproximadamente normales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html"><i class="fa fa-check"></i><b>6</b> Introducción a la inferencia estadística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#inferencia-estadística"><i class="fa fa-check"></i><b>6.1</b> Inferencia estadística</a></li>
<li class="chapter" data-level="6.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#problemas-de-inferencia-estadística"><i class="fa fa-check"></i><b>6.2</b> Problemas de inferencia estadística</a></li>
<li class="chapter" data-level="6.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-de-la-población"><i class="fa fa-check"></i><b>6.3</b> Distribución de la población</a></li>
<li class="chapter" data-level="6.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestra-aleatoria-simple"><i class="fa fa-check"></i><b>6.4</b> Muestra aleatoria simple</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición"><i class="fa fa-check"></i><b>6.4.1</b> Definición</a></li>
<li class="chapter" data-level="6.4.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-de-la-muestra"><i class="fa fa-check"></i><b>6.4.2</b> Distribución de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#estadísticos"><i class="fa fa-check"></i><b>6.5</b> Estadísticos</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición-1"><i class="fa fa-check"></i><b>6.5.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-en-el-muestreo-de-un-estadístico"><i class="fa fa-check"></i><b>6.6</b> Distribución en el muestreo de un estadístico</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#demostración"><i class="fa fa-check"></i><b>6.6.1</b> Demostración:</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribución-empírica"><i class="fa fa-check"></i><b>6.7</b> La distribución empírica</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición-2"><i class="fa fa-check"></i><b>6.7.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#los-momentos-muestrales"><i class="fa fa-check"></i><b>6.8</b> Los momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definición-3"><i class="fa fa-check"></i><b>6.8.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-en-el-muestreo-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.9</b> Distribución en el muestreo de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#propiedades-asintóticas-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.10</b> Propiedades asintóticas de los momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#convergencia-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.10.1</b> Convergencia de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-asintótica"><i class="fa fa-check"></i><b>6.10.2</b> Distribución asintótica</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestreo-en-poblaciones-normales"><i class="fa fa-check"></i><b>6.11</b> Muestreo en poblaciones normales</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribución-chi-cuadrado"><i class="fa fa-check"></i><b>6.11.1</b> La distribución chi-cuadrado</a></li>
<li class="chapter" data-level="6.11.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribución-t-de-student"><i class="fa fa-check"></i><b>6.11.2</b> Distribución <span class="math inline">\(t\)</span> de Student</a></li>
<li class="chapter" data-level="6.11.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribución-f-de-fisher"><i class="fa fa-check"></i><b>6.11.3</b> La distribución <span class="math inline">\(F\)</span> de Fisher</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimación-puntual.html"><a href="estimación-puntual.html"><i class="fa fa-check"></i><b>7</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-problema-de-la-estimación-puntual"><i class="fa fa-check"></i><b>7.1</b> El problema de la estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#criterios-de-optimalidad-de-estimadores.-el-riesgo"><i class="fa fa-check"></i><b>7.1.1</b> Criterios de optimalidad de estimadores. El Riesgo</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-error-cuadrático-medio"><i class="fa fa-check"></i><b>7.1.2</b> El error cuadrático medio</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estudio-de-las-propiedades-deseables-de-los-estimadores"><i class="fa fa-check"></i><b>7.2</b> Estudio de las propiedades deseables de los estimadores</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-sesgo"><i class="fa fa-check"></i><b>7.2.1</b> El sesgo</a></li>
<li class="chapter" data-level="7.2.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#consistencia"><i class="fa fa-check"></i><b>7.2.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estimadores-consistentes"><i class="fa fa-check"></i><b>7.3</b> Propiedades de los estimadores consistentes</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#eficiencia"><i class="fa fa-check"></i><b>7.3.1</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="estimación-puntual.html"><a href="estimación-puntual.html#información-de-fisher-y-cota-de-cramerrao"><i class="fa fa-check"></i><b>7.4</b> Información de Fisher y cota de CramerRao</a></li>
<li class="chapter" data-level="7.5" data-path="estimación-puntual.html"><a href="estimación-puntual.html#información-y-verosimilitud-de-un-modelo-estadístico"><i class="fa fa-check"></i><b>7.5</b> Información y verosimilitud de un modelo estadístico</a></li>
<li class="chapter" data-level="7.6" data-path="estimación-puntual.html"><a href="estimación-puntual.html#información-de-fisher"><i class="fa fa-check"></i><b>7.6</b> Información de Fisher</a></li>
<li class="chapter" data-level="7.7" data-path="estimación-puntual.html"><a href="estimación-puntual.html#la-desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>7.7</b> La desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="7.8" data-path="estimación-puntual.html"><a href="estimación-puntual.html#caracterización-del-estimador-eficiente"><i class="fa fa-check"></i><b>7.8</b> Caracterización del estimador eficiente</a></li>
<li class="chapter" data-level="7.9" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estadísticos-suficientes"><i class="fa fa-check"></i><b>7.9</b> Estadísticos suficientes</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#definició-de-estadísticop-suficiente"><i class="fa fa-check"></i><b>7.9.1</b> Definició de estadísticop suficiente</a></li>
<li class="chapter" data-level="7.9.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#teorema-de-factorización"><i class="fa fa-check"></i><b>7.9.2</b> Teorema de factorización</a></li>
<li class="chapter" data-level="7.9.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estadísticos-suficientes"><i class="fa fa-check"></i><b>7.9.3</b> Propiedades de los estadísticos suficientes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="métodos-de-obtención-de-estimadores.html"><a href="métodos-de-obtención-de-estimadores.html"><i class="fa fa-check"></i><b>8</b> MÉTODOS DE OBTENCIÓN DE ESTIMADORES</a>
<ul>
<li class="chapter" data-level="8.1" data-path="métodos-de-obtención-de-estimadores.html"><a href="métodos-de-obtención-de-estimadores.html#el-método-de-los-momentos"><i class="fa fa-check"></i><b>8.1</b> El método de los momentos</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="métodos-de-obtención-de-estimadores.html"><a href="métodos-de-obtención-de-estimadores.html#observaciones"><i class="fa fa-check"></i><b>8.1.1</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="métodos-de-obtención-de-estimadores.html"><a href="métodos-de-obtención-de-estimadores.html#el-método-del-máximo-de-verosimilitud"><i class="fa fa-check"></i><b>8.2</b> El método del máximo de verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html"><i class="fa fa-check"></i><b>9</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="9.1" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html#preliminares-estimación-del-error-estándar-e-introducción-al-bootstrap"><i class="fa fa-check"></i><b>9.1</b> Preliminares: estimación del error estándar e Introducción al bootstrap</a></li>
<li class="chapter" data-level="9.2" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html#estimadores-por-intervalo-intervalos-de-confianza"><i class="fa fa-check"></i><b>9.2</b> Estimadores por intervalo: intervalos de confianza</a></li>
<li class="chapter" data-level="9.3" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html#intervalos-de-confianza-para-características-de-una-población-normal-media-varianza"><i class="fa fa-check"></i><b>9.3</b> Intervalos de confianza para características de una población normal (media, varianza),</a></li>
<li class="chapter" data-level="9.4" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html#intervalos-de-confianza-bootstrap."><i class="fa fa-check"></i><b>9.4</b> Intervalos de confianza bootstrap.</a></li>
<li class="chapter" data-level="9.5" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html#intervalos-de-confianza-para-proporciones-binomiales"><i class="fa fa-check"></i><b>9.5</b> Intervalos de confianza para proporciones binomiales</a></li>
<li class="chapter" data-level="9.6" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html#intervalos-de-confianza-para-parámetros-en-muestra-grandes-y-para-casos-generales-tasas-or"><i class="fa fa-check"></i><b>9.6</b> Intervalos de confianza para parámetros en muestra grandes y para casos generales (tasas, OR, …)</a></li>
<li class="chapter" data-level="9.7" data-path="estimación-puntual-1.html"><a href="estimación-puntual-1.html#aplicaciones-cálculo-del-tamaño-muestral"><i class="fa fa-check"></i><b>9.7</b> Aplicaciones: cálculo del tamaño muestral</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>10</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#conceptos-básicos-pruebas-de-hipótesis-y-de-significación-pruebas-unilaterales-y-bilaterales-tipos-de-error-valores-críticos-de-test-y-p-valores"><i class="fa fa-check"></i><b>10.1</b> Conceptos básicos: pruebas de hipótesis y de significación, pruebas unilaterales y bilaterales, tipos de error, valores críticos de test y p-valores</a></li>
<li class="chapter" data-level="10.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#potencia-de-un-test.-cálculos-de-potencia-y-de-tamaño-de-la-muestra.-tamaño-del-efecto."><i class="fa fa-check"></i><b>10.2</b> Potencia de un test. Cálculos de potencia y de tamaño de la muestra. Tamaño del efecto.</a></li>
<li class="chapter" data-level="10.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#métodos-de-construcción-de-tests."><i class="fa fa-check"></i><b>10.3</b> Métodos de construcción de tests.</a></li>
<li class="chapter" data-level="10.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#problemas-asociados-al-uso-de-tests-estadísticos.-la-crisis-de-la-significación"><i class="fa fa-check"></i><b>10.4</b> Problemas asociados al uso de tests estadísticos. La crisis de la significación</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html"><i class="fa fa-check"></i><b>11</b> Inferencia Aplicada</a>
<ul>
<li class="chapter" data-level="11.1" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-normalidad.pruebas-gráficas.-el-test-de-shapiro-wilks"><i class="fa fa-check"></i><b>11.1</b> Pruebas de normalidad.Pruebas gráficas. El test de Shapiro-Wilks</a></li>
<li class="chapter" data-level="11.2" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-paramètricas-t-test-y-anova"><i class="fa fa-check"></i><b>11.2</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas paramètricas t-test y Anova</a></li>
<li class="chapter" data-level="11.3" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-hipótesis-para-constrastar-variables-cuantitativas-pruebas-de-hipótesis-no-paramétricas-de-wilcoxon-y-kruskal-wallis"><i class="fa fa-check"></i><b>11.3</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas de hipótesis no paramétricas de Wilcoxon y Kruskal-Wallis</a></li>
<li class="chapter" data-level="11.4" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#contrastes-para-datos-categóricos.-pruebas-binomiales-ji-cuadrado-y-test-de-fisher."><i class="fa fa-check"></i><b>11.4</b> Contrastes para datos categóricos. Pruebas binomiales, ji cuadrado y test de Fisher.</a></li>
<li class="chapter" data-level="11.5" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#riesgo-relativo-y-razón-de-odds"><i class="fa fa-check"></i><b>11.5</b> Riesgo relativo y razón de «odds»</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html"><i class="fa fa-check"></i><b>12</b> Computación Intensiva y <em>Multiple Testing</em></a>
<ul>
<li class="chapter" data-level="12.1" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#tests-de-permutaciones-qué-cuándo-cómo"><i class="fa fa-check"></i><b>12.1</b> Tests de permutaciones; ¿Qué?, ¿Cuándo?, ¿Cómo?</a></li>
<li class="chapter" data-level="12.2" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#el-bootstrap-en-contraste-de-hipótesis"><i class="fa fa-check"></i><b>12.2</b> El bootstrap en contraste de hipótesis</a></li>
<li class="chapter" data-level="12.3" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#el-problema-de-las-comparaciones-múltiples"><i class="fa fa-check"></i><b>12.3</b> El problema de las comparaciones múltiples</a></li>
<li class="chapter" data-level="12.4" data-path="computación-intensiva-y-multiple-testing.html"><a href="computación-intensiva-y-multiple-testing.html#métodos-de-control-de-error-fwer-y-fdr"><i class="fa fa-check"></i><b>12.4</b> Métodos de control de error: FWER y FDR</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferencia Estadistica</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="métodos-de-obtención-de-estimadores" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Capítulo 8</span> MÉTODOS DE OBTENCIÓN DE ESTIMADORES<a href="métodos-de-obtención-de-estimadores.html#métodos-de-obtención-de-estimadores" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>En el capítulo anterior hemos analizado el problema de la estimación puntual desde el punto de vista de, dado un estimador, ver ?qué tan bueno es? para estimar un parámetro.
Otra cuestión que nos podemos plantear, de hecho la primera cuestión que hay que plantearse en la práctica, es cómo obtener un estimador ?razonablemente bueno? de un parámetro. De hecho, desde el punto de vista práctico parece razonable empezar por ver cómo se obtiene un estimador y, una vez obtenido, analizar ?cuán bueno resulta?.
Existen muchos métodos para obtener estimadores, cada uno de los cuales puede llevarnos a unos resultados de diferente calidad.
Los principales métodos de estimación son:</p>
<ol style="list-style-type: decimal">
<li>Método de los momentos</li>
<li>Método de la máxima verosimilitud</li>
<li>Método de Bayes</li>
<li>Otros métodos</li>
</ol>
<div id="el-método-de-los-momentos" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> El método de los momentos<a href="métodos-de-obtención-de-estimadores.html#el-método-de-los-momentos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este método fue introducido por K. Pearson a finales del siglo XIX y es el principio en que nos basamos cuando hacemos una estimación de la media o de la varianza poblacional a partir de la media o la varianza muestrales.
La idea del método de los momentos es bastante intuitiva. Si lo que queremos estimar (uno o varios parámetros) es una función de los momentos
poblacionales, entonces una estimación razonable puede consistir en tomar como estimador la misma función en la que los momentos poblacionales han sido sustituidos por los momentos muestrales.
Dado que estos últimos son estimadores consistentes de los momentos poblacionales, en condiciones bastante generales se puede garantizar que los estimadores obtenidos serán estimadores consistentes para las funciones de los momentos poblacionales estimadas.
Algunos ejemplos típicos de estimadores basados en el método de los momentos son:</p>
<p><span class="math display">\[
\widehat{\mu}=\bar{X}_{n} \quad \widehat{\sigma}=\sqrt{S^{2}} \quad \widehat{\sigma^{2}}=S^{2}
\]</span></p>
<p>Sea un modelo estadístico, <span class="math inline">\(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\)</span>, y <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> una muestra aleatoria simple de <span class="math inline">\(X\)</span>. Sean <span class="math inline">\(m_{1}, m_{2}, ?, m_{k}\)</span> los momentos poblacionales de orden <span class="math inline">\(1,2, ?, k\)</span> de <span class="math inline">\(X\)</span>, que suponemos que existen,</p>
<p><span class="math display">\[
m_{k}=E\left(X^{k}\right)
\]</span></p>
<p>y <span class="math inline">\(a_{1}, a_{2}, ?, a_{k}\)</span> los momentos muestrales respectivos</p>
<p><span class="math display">\[
a_{k}\left(X_{1}, X_{2}, \ldots, X_{n}\right)=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}
\]</span></p>
<p>Suponemos que estamos interesados en estimar:</p>
<p><span class="math display">\[
\theta=h\left(m_{1}, m_{2}, \ldots, m_{p}\right),
\]</span></p>
<p>donde <span class="math inline">\(h\)</span> es una función conocida.
Definició 3.1 El método de los momentos consiste en estimar <span class="math inline">\(\theta\)</span> por el estadístico</p>
<p><span class="math display">\[
T(\mathbf{X})=h\left(a_{1}, a_{2}, \ldots, a_{p}\right)
\]</span></p>
<div id="observaciones" class="section level3 hasAnchor" number="8.1.1">
<h3><span class="header-section-number">8.1.1</span> Observaciones<a href="métodos-de-obtención-de-estimadores.html#observaciones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li>El método se extiende de forma sencilla a la estimación de momentos conjuntos. Podemos usar <span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n} X_{i} Y_{i}\)</span> para estimar <span class="math inline">\(E(X Y)\)</span>, etc.</li>
<li>Por la ley débil de los grandes números,</li>
</ul>
<p><span class="math display">\[
a_{k}\left(X_{1}, X_{2}, \ldots, X_{n}\right)=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k} \xrightarrow{P} E\left(X^{k}\right),
\]</span></p>
<p>de modo que si lo que queremos es estimar los momentos muestrales, el método garantiza que los estimadores son consistentes y sin sesgo.</p>
<p>En este caso, además, los estimadores son asintóticamente normales. Si lo que se desea estimar es una función <span class="math inline">\(h\)</span> continua de los momentos, entonces el método garantiza que el estimador <span class="math inline">\(T(\mathbf{X})\)</span> es consistente y, bajo ciertas condiciones de regularidad, también es asintóticamente normal.</p>
<p>Ejemplo 3.1.1 Sea <span class="math inline">\(X \sim \Gamma(p, \alpha)\)</span>. Queremos estimar <span class="math inline">\(p\)</span> y <span class="math inline">\(\alpha\)</span>. En lugar de conocer la función <span class="math inline">\(h\left(\theta_{1}, \theta_{2}\right)\)</span> sabemos que:</p>
<p><span class="math display">\[
\begin{aligned}
m_{1} &amp; =\frac{p}{\alpha}=E(X) \\
m_{2} &amp; =\frac{p(p+1)}{\alpha^{2}}=E\left(X^{2}\right) \\
&amp; =V(X)+[E(X)]^{2}=\frac{p}{\alpha^{2}}+\left(\frac{p}{\alpha}\right)^{2}=\frac{p^{2}+p}{\alpha^{2}}=
\end{aligned}
\]</span></p>
<p>De modo que podemos obtener las funciones deseadas ?aislando? p y <span class="math inline">\(\alpha\)</span> como funciones de <span class="math inline">\(m_{1}\)</span> y <span class="math inline">\(m_{2}\)</span> :</p>
<p><span class="math display">\[
\begin{aligned}
\alpha^{2} &amp; =\frac{p^{2}}{m_{1}^{2}} \\
\alpha^{2} &amp; =\frac{p(p+1)}{m_{2}}
\end{aligned}
\]</span></p>
<p>Procediendo por igualación:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \frac{p^{2}}{m_{1}^{2}}=\frac{p(p+1)}{m_{2}} \\
&amp; \frac{p}{m_{1}}=\frac{p+1}{m_{2}} \\
&amp; p m_{2}=p m_{1}^{2}+m_{1}^{2} \\
&amp; p\left(m_{2}-m_{1}^{2}\right)=m_{1}^{2} \\
&amp; p=\frac{m_{1}^{2}}{m_{2}-m_{1}^{2}} \\
&amp; \alpha=\frac{m_{1}^{2}}{m_{2}-m_{1}^{2}} \\
&amp; m_{1}
\end{aligned} \frac{m_{1}}{m_{2}-m_{1}^{2}} .
\]</span></p>
<p>Los estimadores por el método de los momentos se obtendrán ahora sustituyendo <span class="math inline">\(p\)</span> y <span class="math inline">\(\alpha\)</span> por <span class="math inline">\(\hat{p}\)</span> y <span class="math inline">\(\hat{\alpha}\)</span> en la expresión anterior, es decir:</p>
<p><span class="math display">\[
\widehat{p}=\frac{a_{1}^{2}}{a_{2}-a_{1}^{2}}
\]</span></p>
<p>Hacemos lo mismo para el parámetro <span class="math inline">\(\alpha\)</span> :</p>
<p><span class="math display">\[
\widehat{\alpha}=\frac{a_{1}}{a_{2}-a_{1}^{2}}
\]</span></p>
</div>
</div>
<div id="el-método-del-máximo-de-verosimilitud" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> El método del máximo de verosimilitud<a href="métodos-de-obtención-de-estimadores.html#el-método-del-máximo-de-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introducción-1" class="section level4 hasAnchor" number="8.2.0.1">
<h4><span class="header-section-number">8.2.0.1</span> Introducción<a href="métodos-de-obtención-de-estimadores.html#introducción-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El método de la máxima verosimilitud, introducido por Fisher, es un método de estimación que se basa en la función de verosimilitud, presentada en el capítulo anterior. Básicamente consiste en tomar como estimadores de los parámetros aquellos valores que hagan más probable observar precisamente lo que se ha observado, es decir, que hagan que la muestra observada resulte más verosímil.</p>
<p>Ejemplo 3.2.1 Tomemos 5 papeles. En cada uno de ellos ponemos o bien un ?+? o bien un ?-?, sin que se sepa qué hay en cada papel, y los guardamos en una bolsa. Nuestro objetivo es estimar el número de papeles con el signo ?? escrito. Extraemos tres papeles, devolviéndolos a la bolsa después de cada extracción, y observamos que ha salido lo siguiente: ?++-?. Los valores posibles para la probabilidad de ?-?, llamémosla p, son:</p>
<table>
<thead>
<tr class="header">
<th align="center">En la bolsa hay</th>
<th align="center"><span class="math inline">\(p\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(4 ?+\)</span> ?, 1 ?-?</td>
<td align="center">0,2</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(3 ?+\)</span> ?, 2 ?-?</td>
<td align="center">0,4</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(2 ?+\)</span> ?, 3 ?-?</td>
<td align="center">0,6</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(1 ?+\)</span> ?, 4 ?-?</td>
<td align="center">0,8</td>
</tr>
</tbody>
</table>
<p>Supongamos que la variable <span class="math inline">\(X\)</span> mide el número de ?-? en tres extracciones consecutivas y que, por tanto, sigue una distribución binomial:</p>
<p><span class="math display">\[
X \sim B(3, p(?-?))
\]</span></p>
<p>La probabilidad de sacar un ?-? es:</p>
<p><span class="math display">\[
P_{p}[X=1]=\binom{3}{1} \cdot p^{1}(1-p)^{2}
\]</span></p>
<p>Para cada uno de los valores de p, las probabilidades quedan asi:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(p\)</span></th>
<th align="center"><span class="math inline">\(P_{p}[X=1]\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0.2</td>
<td align="center"><span class="math inline">\(3 \cdot 0.2 \cdot 0.8^{2}=0.384\)</span></td>
</tr>
<tr class="even">
<td align="center">0.4</td>
<td align="center"><span class="math inline">\(3 \cdot 0.4 \cdot 0.6^{2}=0.432\)</span></td>
</tr>
<tr class="odd">
<td align="center">0.6</td>
<td align="center"><span class="math inline">\(3 \cdot 0.6 \cdot 0.4^{2}=0.288\)</span></td>
</tr>
<tr class="even">
<td align="center">0.8</td>
<td align="center"><span class="math inline">\(3 \cdot 0.8 \cdot 0.2^{2}=0.096\)</span></td>
</tr>
</tbody>
</table>
<p>El valor de p que da una probabilidad mayor a la muestra, es decir, que la hace más verosímil, es <span class="math inline">\(p=0.4\)</span>. El método del máximo de verosimilitud consiste precisamente en tomar este valor como estimación de <span class="math inline">\(p\)</span>.</p>
</div>
<div id="la-función-de-verosimilitud" class="section level4 hasAnchor" number="8.2.0.2">
<h4><span class="header-section-number">8.2.0.2</span> La función de verosimilitud<a href="métodos-de-obtención-de-estimadores.html#la-función-de-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Una vez introducido el método con un ejemplo, podemos pasar a definirlo con mayor precisión. Para ello, comenzaremos con el concepto de función de verosimilitud.
En el capítulo anterior presentamos la función de verosimilitud como la función que resulta de considerar que, en la función de probabilidad de la muestra, el parámetro es variable y la muestra queda fija. Es decir:</p>
<p><span class="math display">\[
\underbrace{f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)}_{\mathbf{x} \text { variable, } \theta \text { fijo }} \longrightarrow \underbrace{L\left(\theta ; x_{1}, x_{2}, \ldots, x_{n}\right)}_{\mathbf{x} \text { fija, } \theta \text { variable }}
\]</span></p>
<p>Esta definición es básicamente correcta. En el caso de las variables discretas, donde <span class="math inline">\(f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)\)</span> representa la probabilidad de la muestra, fijado <span class="math inline">\(\theta\)</span>, resulta intuitivamente claro decir que la verosimilitud representa la ?probabilidad de la muestra para cada valor del parámetro?.
Refiriéndonos al ejemplo introductorio, resulta sencillo ver que se trata de ?dos puntos de vista? sobre la misma función. Fijado un valor del parámetro, por ejemplo, 0.4 , podemos considerar la probabilidad de diversas muestras posibles, como <span class="math inline">\(x=0, x=1, \ldots\)</span>, hasta <span class="math inline">\(x=3\)</span> :</p>
<p><span class="math display">\[
\begin{aligned}
f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right) &amp; =P_{0.4}[X=x], x=0,1, \ldots, 3 \\
&amp; =\binom{3}{x} \cdot 0.4^{x}(0.6)^{3-x} .
\end{aligned}
\]</span></p>
<p>Análogamente, fijada una muestra, por ejemplo, <span class="math inline">\(x=1\)</span>, podemos considerar la probabilidad de esta para diversos valores del parámetro, <span class="math inline">\(p=0,0.2, \ldots, 1\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
L\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right) &amp; =P_{p}[X=1], x=0,0.2,0.4, \ldots, 1 \\
&amp; =3 \cdot p(1-p)^{2} .
\end{aligned}
\]</span></p>
<p>En el caso de las distribuciones absolutamente continuas, el significado de la función de verosimilitud ya no es intuitivamente tan claro como en el caso de las discretas. En este caso, la función de densidad de la muestra ya no representa la probabilidad de esta como en el caso de las discretas. Algunos autores intentan solucionar esto explicando que existe una conocida aproximación en que la función de densidad es la probabilidad de un suceso ?infinitesimal?.
Lo que es importante en la función de verosimilitud, a la hora de hacer inferencias, es la parte que es función del parámetro. Esto hace que a menudo se considere que la expresión de la función de verosimilitud mantenga solo aquella parte de <span class="math inline">\(f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)\)</span> que depende de <span class="math inline">\(\theta\)</span>, ignorando la parte que dependa solo de la muestra. Es decir, si podemos factorizar <span class="math inline">\(f\left(x_{1}, x_{2}, \ldots, x_{n} ; \theta\right)\)</span> como</p>
<p><span class="math display">\[
f(\mathbf{x} ; \theta)=c(\mathbf{x}) \cdot g(\mathbf{x} ; \theta)
\]</span></p>
<p>podremos prescindir de la ?constante? <span class="math inline">\(c(x)\)</span> (constante porque no depende de <span class="math inline">\(\theta\)</span> ) al considerar la verosimilitud.</p>
<p><span class="math display">\[
L(\theta ; \mathbf{x})=g(\mathbf{x} ; \theta) \propto f(\mathbf{x} ; \theta)
\]</span></p>
<p>Esto implica que <span class="math inline">\(L(\theta ; \mathbf{x})\)</span> no tiene por qué integrar a 1 , como en el caso de las probabilidades, y que depende de las unidades de medida.</p>
<p>Ejemplo 3.2.2 Si <span class="math inline">\(X\)</span> es discreta, <span class="math inline">\(X \sim \mathcal{P}(\lambda)\)</span>, y suponemos <span class="math inline">\(n=1\)</span> (muestras de tamaño 1), tenemos que la f.d.p. de la muestra es:</p>
<p><span class="math display">\[
P[x ; \lambda]=e^{-\lambda} \frac{\lambda^{x}}{x!}
\]</span></p>
<p>con <span class="math inline">\(x=0,1, \ldots\)</span> Ahora, si hemos observado <span class="math inline">\(x=5\)</span>, la función de verosimilitud vale:</p>
<p><span class="math display">\[
L(\lambda ; 5)=e^{-\lambda} \lambda^{5}\left[\frac{1}{5!}\right]
\]</span></p>
<p>Como solo nos interesa la parte que es función de <span class="math inline">\(\lambda\)</span>, podemos ignorar <span class="math inline">\(\frac{1}{5!}\)</span>, es decir:</p>
<p><span class="math display">\[
L(\lambda ; 5)=e^{-\lambda} \lambda^{5} \propto P[\mathbf{x} ; \lambda] .
\]</span></p>
<p>Ejemplo 3.2.3 Si dada una muestra de tamaño 1, por ejemplo, <span class="math inline">\(x=2\)</span>, de una ley de Poisson <span class="math inline">\(\mathcal{P}(\lambda)\)</span> queremos comparar sus verosimilitudes respecto de los valores del parámetro <span class="math inline">\(\lambda=1.5\)</span> o <span class="math inline">\(\lambda=3\)</span>, lo que haremos será basarnos en la razón de verosimilitudes:</p>
<p><span class="math display">\[
\begin{aligned}
\Lambda(\mathbf{x}) &amp; =\frac{L\left(\lambda_{1} ; x\right)}{L\left(\lambda_{2} ; x\right)}=\frac{L(1.5 ; 2)}{L(3 ; 2)} \\
&amp; =\frac{e^{-1.5} 1.5^{2}\left[\frac{1}{2!}\right]}{e^{-3} 3^{2}\left[\frac{1}{2!}\right]}=\frac{e^{-1.5} 1.5^{2}}{e^{-3} 3^{2}}=\frac{0.5020}{0.4481}=1.12 .
\end{aligned}
\]</span></p>
<p>Como se observa, al basarnos en la razón de verosimilitudes, la parte correspondiente solo a la muestra no se toma en cuenta. La razón de verosimilitudes sugiere que el valor <span class="math inline">\(\lambda=1.5\)</span> hace la muestra más verosímil.</p>
</div>
<div id="el-método-del-máximo-de-verosimilitud-1" class="section level4 hasAnchor" number="8.2.0.3">
<h4><span class="header-section-number">8.2.0.3</span> El método del máximo de verosimilitud<a href="métodos-de-obtención-de-estimadores.html#el-método-del-máximo-de-verosimilitud-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Si partimos de las dos ideas que hemos visto en la introducción:</p>
<ul>
<li>Escoger como estimación el valor que maximice la probabilidad de la muestra observada.</li>
<li>La verosimilitud de la muestra es una aproximación a la probabilidad de esta como función del valor del parámetro.</li>
</ul>
<p>Una forma razonable de definir el EMV es entonces como aquel que maximice la verosimilitud.</p>
<p>Definició 3.2 Un estimador <span class="math inline">\(T: \Omega \longrightarrow \Theta\)</span> es un estimador del máximo de verosimilitud para el parámetro <span class="math inline">\(\theta\)</span> si cumple:</p>
<p><span class="math display">\[
L(T(\mathbf{x}) ; \mathbf{x})=\sup _{\theta \in \Theta} L(\theta ; \mathbf{x})
\]</span></p>
<p>Como suele ocurrir en problemas de maximización, este valor ni existe necesariamente ni tiene por qué ser único. Ahora bien, bajo ciertas condiciones (las habituales para los problemas de máximos y mínimos) el problema se podrá reducir a buscar un máximo para la función de verosimilitud.</p>
<p>Ejemplo 3.2.4 Supongamos que <span class="math inline">\(x_{1}, \ldots, x_{n}\)</span> es una muestra de una población de Bernouilli, <span class="math inline">\(X \sim B e(p)\)</span>, donde queremos estimar p. La función de masa de la probabilidad de <span class="math inline">\(X\)</span> es:</p>
<p><span class="math display">\[
P\left[X=x_{i}\right]=P\left(x_{i} ; p\right)=p^{x_{i}}(1-p)^{1-x_{i}} \text { donde } x_{i} \in\{0,1\} ; i=1, \ldots, n
\]</span></p>
<p>La función de verosimilitud es:</p>
<p><span class="math display">\[
L(p ; \mathbf{x})=\prod_{i=1}^{n} p^{x_{i}}(1-p)^{1-x_{i}}=p^{\sum_{i=1}^{n} x_{i}}(1-p)^{\sum_{i=1}^{n}\left(1-x_{i}\right)}
\]</span></p>
<p>Debemos buscar el máximo de <span class="math inline">\(L(p ; \mathbf{x})\)</span>. En este caso, como en otros, es más sencillo buscar el máximo de su logaritmo, que, dado que es una función monótona, es el mismo que el máximo de <span class="math inline">\(L\)</span></p>
<p><span class="math display">\[
\ln L(p ; x)=\left(\sum_{i=1}^{n} x_{i}\right) \cdot \ln p+\left(n-\sum_{i=1}^{n} x_{i}\right) \cdot \ln (1-p)
\]</span></p>
<p>Derivamos respecto a p:</p>
<p><span class="math display">\[
\frac{\partial \ln L(p ; x)}{\partial p}=\frac{\sum_{i=1}^{n} x_{i}}{p}-\frac{n-\sum_{i=1}^{n} x_{i}}{1-p}
\]</span></p>
<p>e igualamos a cero la derivada, planteando lo que se denomina la ecuación de verosimilitud, cuyas soluciones nos conducirán eventualmente al estimador del máximo de verosimilitud.</p>
<p><span class="math display">\[
\frac{\sum_{i=1}^{n} x_{i}-n \hat{p}}{\hat{p}(1-\hat{p})}=0 \Rightarrow \hat{p}=\frac{\sum_{i=1}^{n} x_{i}}{n}
\]</span></p>
<p>Si la segunda derivada es negativa en <span class="math inline">\(\widehat{p}\)</span> entonces será un máximo:</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial^{2} \ln L(p ; x)}{\partial p^{2}} &amp; =\frac{\partial}{\partial p}\left(\frac{\sum_{i=1}^{n} x_{i}-n p}{p(1-p)}\right)=\frac{-n[p(1-p)]-\left(\sum_{i=1}^{n} x_{i}-n p\right) \cdot(1-2 p)}{p^{2}\left(1-p^{2}\right)}= \\
&amp; =\frac{-n p+n p^{2}-\sum_{i=1}^{n} x_{i}-n p-2 p \sum_{i=1}^{n} x_{i}-2 n p^{2}}{p^{2}(1-p)^{2}}= \\
&amp; =\frac{\left[\sum_{i=1}^{n} x_{i}(1+2 p)-n p^{2}\right]}{p^{2} \cdot(1-p)^{2}}
\end{aligned}
\]</span></p>
<p>que es negativa cuando <span class="math inline">\(p=\hat{p}\)</span>, de forma que <span class="math inline">\(\hat{p}\)</span> es efectivamente un máximo.
El método analítico expuesto en el ejemplo anterior, consistente en el cálculo de un extremo de una función, no se puede aplicar en todas las situaciones. En estos casos, una alternativa puede ser estudiar directamente la función de verosimilitud. Veamos un ejemplo:</p>
<p>Ejemplo 3.2.5 Sea <span class="math inline">\(X_{1}, \ldots, X_{n} \stackrel{i i d}{\sim} X \sim U(0, \theta) \quad \theta&gt;0\)</span> desconocido. Sabemos que:</p>
<p><span class="math display">\[
f(x ; \theta)=\left\{\begin{array}{c}
\frac{1}{\theta} \text { si } 0&lt;\min \left\{x_{i}\right\} \leq \max \left\{x_{i}\right\} \leq \theta \\
0 \quad \text { en caso contrario }
\end{array}\right\}
\]</span></p>
<p>La derivada respecto a <span class="math inline">\(\theta\)</span> es <span class="math inline">\(-\frac{n}{\theta^{n-1}}\)</span>, que se anula cuando <span class="math inline">\(\theta \underset{n \rightarrow \infty}{\longrightarrow} \infty\)</span> que lleva a una solución sin sentido de la ecuación de verosimilitud. Una inspección de la gráfica de la función de verosimilitud revela que el EMV, en este caso,</p>
<p>Figura 3.1: Función de verosimilitud para una distribución uniforme
es <span class="math inline">\(\max \left\{X_{i}, \ldots, X_{n}\right\}\)</span>. Efectivamente, consideremos cualquier otro valor <span class="math inline">\(\theta^{*}\)</span> diferente del máximo:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text { Si } \theta^{*}&gt;X_{(n)} \Rightarrow \frac{1}{\left(\theta^{*}\right)^{n}}&lt;\frac{1}{\left(X_{n}\right)^{n}}, \\
&amp; \text { Si } \theta^{*}&lt;X_{(n)} \Rightarrow L\left(\theta^{*} ; \mathbf{x}\right)=0
\end{aligned}
\]</span></p>
<p>ya que si un estimador toma un valor inferior al máximo de la muestra habrá algún valor muestral, <span class="math inline">\(x_{i}\)</span> para el cual se verificará que <span class="math inline">\(\theta^{*}&lt;x_{i}\)</span>, lo que hace la muestra inverosímil, y por tanto el estimador no es admisible.
A la vista de lo anterior, deducimos que el valor que maximiza <span class="math inline">\(L(\theta ; \mathbf{x})\)</span> es el máximo de la muestra.</p>
<p>Ejemplo 3.2.6 El método del máximo de verosimilitud se extiende de forma inmediata a los parámetros <span class="math inline">\(K\)</span>-dimensionales. Consideremos el caso de la
ley normal <span class="math inline">\(X \sim N\left(\mu, \sigma^{2}\right)\)</span>. Aquí el parámetro <span class="math inline">\(\theta\)</span> es bidimensional, es decir: <span class="math inline">\(\theta=\left(\mu, \sigma^{2}\right) \in \Theta=\mathbb{R} \times \mathbb{R}^{+}\)</span></p>
<ol style="list-style-type: decimal">
<li>La función de verosimilitud de una muestra de tamaño <span class="math inline">\(n\)</span> es:</li>
</ol>
<p><span class="math display">\[
L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)=\prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi \sigma^{2}}} e^{-\frac{\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}=\frac{1}{(2 \pi)^{n / 2}\left(\sigma^{2}(n / 2\right.} e^{-\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Sacando logaritmos</li>
</ol>
<p><span class="math display">\[
\log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)=-\frac{n}{2} \log (2 \pi)-\frac{n}{2} \log \left(\sigma^{2}\right)-\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{2}}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>La derivada de <span class="math inline">\(L()\)</span> es la matriz de derivadas:</li>
</ol>
<p><span class="math display">\[
D \log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)=\binom{\frac{\partial \log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)}{\partial \mu}}{\frac{\partial \log L\left(\left(\mu, \sigma^{2}\right) ; \mathbf{x}\right)}{\partial \sigma^{2}}}=\left\{\begin{array}{c}
\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)}{\sigma^{2}} \\
\frac{\sum_{i=1}^{n}\left(x_{i}-\mu\right)^{2}}{2 \sigma^{4}}-\frac{n}{2 \sigma^{2}}
\end{array}\right.
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>Planteando y resolviendo la ecuación de verosimilitud tenemos:</li>
</ol>
<p><span class="math display">\[
D \log L\left(\left(\hat{\mu}, \hat{\sigma}^{2}\right) ; \mathbf{x}\right)=\left\{\begin{array}{c}
\frac{\sum_{i=1}^{n}\left(x_{i}-\hat{\mu}\right)}{\hat{\sigma}^{2}}=0 \\
\frac{\sum_{i=1}^{n}\left(x_{i}-\hat{\mu}\right)^{2}}{2 \hat{\sigma}^{4}}=\frac{n}{2 \hat{\sigma}^{2}}
\end{array}\right.
\]</span></p>
<p>de donde las raíces de la ecuación de verosimilitud son:</p>
<p><span class="math display">\[
\hat{m} u=\bar{x}, \quad \hat{\sigma}^{2}=\frac{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}}{n}=s^{2} .
\]</span></p>
<ol start="5" style="list-style-type: decimal">
<li>Para decidir si las raíces de la ecuación de verosimilitud corresponden a un máximo, analizamos la matriz de derivadas segundas, denominada Hessiana.</li>
</ol>
<p><span class="math display">\[
H=\left(\begin{array}{cc}
\frac{\partial^{2} z}{\partial x^{2}} &amp; \frac{\partial^{2} z}{\partial x \partial y} \\
\frac{\partial^{2} z}{\partial y \partial x} &amp; \frac{\partial^{2} z}{\partial y^{2}}
\end{array}\right)
\]</span></p>
<p>Una condición suficiente para que un punto <span class="math inline">\(\left(x_{0}, y_{0}\right)\)</span> sea un máximo es que el determinante de <span class="math inline">\(H\)</span> sea positivo y el menor en la posición ?11? negativo, es decir:
<span class="math inline">\(S i|H|&gt;\left.0 y \frac{\partial^{2} z}{\partial x^{2}}\right|_{\left(x_{0}, y_{0}\right)}&lt;0 \Longrightarrow\)</span> Hay un máximo relativo en <span class="math inline">\(\left(x_{0}, y_{0}\right)\)</span>.
Si evaluamos el Hessiano en el punto <span class="math inline">\(\left(\bar{x}, s^{2}\right)\)</span> tenemos:</p>
<p><span class="math display">\[
H=\left(\begin{array}{cc}
-\frac{n}{s^{2}} &amp; 0 \\
0 &amp; -\frac{n}{2 s^{4}}
\end{array}\right) .
\]</span></p>
<p>Las condiciones de extremo que hemos dado más arriba se verifican: <span class="math inline">\(H_{11}&lt;0 y|H|&gt;0\)</span>, de manera que podemos concluir que el estimador del máximo de verosimilitud de <span class="math inline">\(\left(\mu, \sigma^{2}\right)\)</span> es, efectivamente, <span class="math inline">\(\left(\bar{x}, s^{2}\right)\)</span>.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimación-puntual.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimación-puntual-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/ASPteaching/FundamentosInferencia/edit/BRANCH/07-estimacionPuntual.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/07-estimacionPuntual.Rmd",
"text": null
},
"download": "https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/docs/_main.pdf",
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
