<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 14 Métodos de computación intensiva: El Bootstrap | Fundamentos de Inferencia Estadistica</title>
  <meta name="description" content="Capítulo 14 Métodos de computación intensiva: El Bootstrap | Fundamentos de Inferencia Estadistica" />
  <meta name="generator" content="bookdown 0.45 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 14 Métodos de computación intensiva: El Bootstrap | Fundamentos de Inferencia Estadistica" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 14 Métodos de computación intensiva: El Bootstrap | Fundamentos de Inferencia Estadistica" />
  
  
  

<meta name="author" content="Alex Sanchez Pla y Santiago Pérez Hoyos" />


<meta name="date" content="2026-01-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estadística-no-paramétrica.html"/>
<link rel="next" href="capítulo-2.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="blocks.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<div style="margin:0 0 10px 15px;">
  <a href="FundamentosInferenciaEstadistica.pdf" target="_blank"
     title="Descargar PDF"
     style="display:flex;align-items:center;gap:6px;text-decoration:none;">
    <img src="images/aPDF.png" alt="PDF" width="16" height="20">
    <span style="font-weight:bold;">Descargar versión PDF</span>
  </a>
</div>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisitos-y-organizaci%C3%B3n-del-material"><i class="fa fa-check"></i>Prerequisitos y organización del material</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html"><i class="fa fa-check"></i>Agradecimiento y fuentes utilizadas</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#el-proyecto-statmedia"><i class="fa fa-check"></i>El proyecto Statmedia</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#otros-materiales-utilizados"><i class="fa fa-check"></i>Otros materiales utilizados</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#materiales-complementarios"><i class="fa fa-check"></i>Materiales complementarios</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#complementos-matem%C3%A1ticos"><i class="fa fa-check"></i>Complementos matemáticos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html"><i class="fa fa-check"></i><b>1</b> Probabilidad y Experimentos aleatorios</a>
<ul>
<li class="chapter" data-level="1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducci%C3%B3n"><i class="fa fa-check"></i><b>1.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#fen%C3%B3menos-deterministas-y-fen%C3%B3menos-aleatorios"><i class="fa fa-check"></i><b>1.1.1</b> Fenómenos deterministas y fenómenos aleatorios</a></li>
<li class="chapter" data-level="1.1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos"><i class="fa fa-check"></i><b>1.1.2</b> Sucesos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#funci%C3%B3n-de-probabilidad"><i class="fa fa-check"></i><b>1.2</b> Función de probabilidad</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#diferentes-funciones-de-probabilidad-para-una-misma-experiencia-aleatoria"><i class="fa fa-check"></i><b>1.2.1</b> ¿Diferentes funciones de probabilidad para una misma experiencia aleatoria?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#c%C3%B3mo-se-calculan-las-probabilidades"><i class="fa fa-check"></i><b>1.3</b> ¿Cómo se calculan las probabilidades?</a></li>
<li class="chapter" data-level="1.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-elementales-y-sucesos-observables"><i class="fa fa-check"></i><b>1.4</b> Sucesos elementales y sucesos observables</a></li>
<li class="chapter" data-level="1.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#propiedades-inmediatas-de-la-probabilidad"><i class="fa fa-check"></i><b>1.5</b> Propiedades inmediatas de la probabilidad</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#succeso-imposible"><i class="fa fa-check"></i><b>1.5.1</b> Succeso imposible</a></li>
<li class="chapter" data-level="1.5.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#suceso-implicado"><i class="fa fa-check"></i><b>1.5.2</b> Suceso implicado</a></li>
<li class="chapter" data-level="1.5.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#complementario-de-un-suceso"><i class="fa fa-check"></i><b>1.5.3</b> Complementario de un suceso</a></li>
<li class="chapter" data-level="1.5.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ocurrencia-de-algun-suceso"><i class="fa fa-check"></i><b>1.5.4</b> Ocurrencia de algun suceso</a></li>
<li class="chapter" data-level="1.5.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurra-algun-suceso"><i class="fa fa-check"></i><b>1.5.5</b> Probabilidad de que ocurra algun suceso</a></li>
<li class="chapter" data-level="1.5.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurran-dos-o-m%C3%A1s-sucesos-a-la-vez"><i class="fa fa-check"></i><b>1.5.6</b> Probabilidad de que ocurran dos (o más) sucesos a la vez</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#espacios-de-probabilidad"><i class="fa fa-check"></i><b>1.6</b> Espacios de probabilidad</a></li>
<li class="chapter" data-level="1.7" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>1.7</b> Probabilidad condicionada</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#la-probabilidad-condicionada-es-una-medida-de-probabilidad"><i class="fa fa-check"></i><b>1.7.1</b> La probabilidad condicionada es una medida de probabilidad</a></li>
<li class="chapter" data-level="1.7.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-dependientes-y-sucesos-independientes"><i class="fa fa-check"></i><b>1.7.2</b> Sucesos dependientes y sucesos independientes</a></li>
<li class="chapter" data-level="1.7.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#incompatibilidad-e-independencia"><i class="fa fa-check"></i><b>1.7.3</b> Incompatibilidad e independencia</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#dos-teoremas-importantes"><i class="fa fa-check"></i><b>1.8</b> Dos Teoremas importantes</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-las-probabilidades-totales"><i class="fa fa-check"></i><b>1.8.1</b> Teorema de las probabilidades totales</a></li>
<li class="chapter" data-level="1.8.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-bayes"><i class="fa fa-check"></i><b>1.8.2</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducci%C3%B3n-a-los-experimentos-m%C3%BAltiples"><i class="fa fa-check"></i><b>1.9</b> Introducción a los experimentos múltiples</a></li>
<li class="chapter" data-level="1.10" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinatoria"><i class="fa fa-check"></i><b>1.10</b> Combinatoria</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones"><i class="fa fa-check"></i><b>1.10.1</b> Permutaciones</a></li>
<li class="chapter" data-level="1.10.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones"><i class="fa fa-check"></i><b>1.10.2</b> Variaciones</a></li>
<li class="chapter" data-level="1.10.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones-con-repetici%C3%B3n"><i class="fa fa-check"></i><b>1.10.3</b> Variaciones con repetición</a></li>
<li class="chapter" data-level="1.10.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinaciones"><i class="fa fa-check"></i><b>1.10.4</b> Combinaciones</a></li>
<li class="chapter" data-level="1.10.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones-con-repetici%C3%B3n"><i class="fa fa-check"></i><b>1.10.5</b> Permutaciones con repetición</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#frecuencia-relativa-y-probabilidad"><i class="fa fa-check"></i><b>1.11</b> Frecuencia relativa y probabilidad</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ilustraci%C3%B3n-por-simulaci%C3%B3n"><i class="fa fa-check"></i><b>1.11.1</b> Ilustración por simulación</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#caso-de-estudio-eficacia-de-una-prueba-diagn%C3%B3stica"><i class="fa fa-check"></i><b>1.12</b> Caso de Estudio: Eficacia de una prueba diagnóstica</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#aplicaci%C3%B3n-del-teorema-de-bayes"><i class="fa fa-check"></i><b>1.12.1</b> Aplicación del Teorema de Bayes</a></li>
<li class="chapter" data-level="1.12.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ejemplo-num%C3%A9rico"><i class="fa fa-check"></i><b>1.12.2</b> Ejemplo numérico</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>2</b> Variables aleatorias y Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#el-espacio-muestral-y-sus-elementos"><i class="fa fa-check"></i><b>2.1</b> El espacio muestral y sus elementos</a></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representaci%C3%B3n-num%C3%A9rica-de-los-sucesos-elementales.-variables-aleatorias"><i class="fa fa-check"></i><b>2.2</b> Representación numérica de los sucesos elementales. Variables aleatorias</a></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterizaci%C3%B3n-de-una-variable-aleatoria-a-trav%C3%A9s-de-la-probabilidad.-funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.3</b> Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución</a></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.4</b> Propiedades de la función de distribución</a></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificaci%C3%B3n-de-las-variables-aleatorias"><i class="fa fa-check"></i><b>2.5</b> Clasificación de las variables aleatorias</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-discretas"><i class="fa fa-check"></i><b>2.5.1</b> Variables aleatorias discretas</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.5.2</b> Variables aleatorias continuas</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variable-aleatoria-discretas"><i class="fa fa-check"></i><b>2.6</b> Variable aleatoria discretas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterizaci%C3%B3n-de-las-v.a.-discretas"><i class="fa fa-check"></i><b>2.6.1</b> Caracterización de las v.a. discretas</a></li>
<li class="chapter" data-level="2.6.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-funci%C3%B3n-de-densidad-discreta"><i class="fa fa-check"></i><b>2.6.2</b> Propiedades de la función de densidad discreta</a></li>
<li class="chapter" data-level="2.6.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-funci%C3%B3n-de-distribuci%C3%B3n-y-la-funci%C3%B3n-de-densidad-discreta.-probabilidad-de-intervalos."><i class="fa fa-check"></i><b>2.6.3</b> Relaciones entre la función de distribución y la función de densidad discreta. <br> Probabilidad de intervalos.</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>2.7</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#funci%C3%B3n-de-densidad-continua"><i class="fa fa-check"></i><b>2.7.1</b> Función de densidad continua</a></li>
<li class="chapter" data-level="2.7.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-funci%C3%B3n-de-distribuci%C3%B3n-y-la-funci%C3%B3n-de-densidad."><i class="fa fa-check"></i><b>2.7.2</b> Relaciones entre la función de distribución y la función de densidad.</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterizaci%C3%B3n-de-una-variable-aleatoria-a-trav%C3%A9s-de-par%C3%A1metros"><i class="fa fa-check"></i><b>2.8</b> Caracterización de una variable aleatoria a través de parámetros</a></li>
<li class="chapter" data-level="2.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-discreta"><i class="fa fa-check"></i><b>2.9</b> Esperanza de una variable aleatoria discreta</a></li>
<li class="chapter" data-level="2.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-continua"><i class="fa fa-check"></i><b>2.10</b> Esperanza de una variable aleatoria continua</a></li>
<li class="chapter" data-level="2.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-esperanza-matem%C3%A1tica"><i class="fa fa-check"></i><b>2.11</b> Propiedades de la esperanza matemática</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#linealidad-de-la-esperanza-matem%C3%A1tica"><i class="fa fa-check"></i><b>2.11.1</b> Linealidad de la esperanza matemática</a></li>
<li class="chapter" data-level="2.11.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-del-producto"><i class="fa fa-check"></i><b>2.11.2</b> Esperanza del producto</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.12</b> Varianza de una variable aleatoria</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-varianza"><i class="fa fa-check"></i><b>2.12.1</b> Propiedades de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#momentos-de-orden-k-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.13</b> Momentos (de orden <span class="math inline">\(k\)</span>) de una variable aleatoria</a></li>
<li class="chapter" data-level="2.14" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#definici%C3%B3n-formal-de-variable-aleatoria"><i class="fa fa-check"></i><b>2.14</b> Definición formal de variable aleatoria</a></li>
<li class="chapter" data-level="2.15" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caso-pr%C3%A1ctico-lanzamiento-de-dos-dados"><i class="fa fa-check"></i><b>2.15</b> Caso práctico: Lanzamiento de dos dados</a>
<ul>
<li class="chapter" data-level="2.15.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#espacio-muestral"><i class="fa fa-check"></i><b>2.15.1</b> Espacio muestral</a></li>
<li class="chapter" data-level="2.15.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representaci%C3%B3n-num%C3%A9rica"><i class="fa fa-check"></i><b>2.15.2</b> Representación numérica</a></li>
<li class="chapter" data-level="2.15.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#algunas-probabilidades"><i class="fa fa-check"></i><b>2.15.3</b> Algunas probabilidades</a></li>
<li class="chapter" data-level="2.15.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.15.4</b> Función de distribución</a></li>
<li class="chapter" data-level="2.15.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificaci%C3%B3n-de-las-variables"><i class="fa fa-check"></i><b>2.15.5</b> Clasificación de las variables</a></li>
<li class="chapter" data-level="2.15.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#funci%C3%B3n-de-densidad-discreta"><i class="fa fa-check"></i><b>2.15.6</b> Función de densidad discreta</a></li>
<li class="chapter" data-level="2.15.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-intervalos-1"><i class="fa fa-check"></i><b>2.15.7</b> Probabilidad de intervalos</a></li>
<li class="chapter" data-level="2.15.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza"><i class="fa fa-check"></i><b>2.15.8</b> Esperanza</a></li>
<li class="chapter" data-level="2.15.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-un-juego"><i class="fa fa-check"></i><b>2.15.9</b> Esperanza de un juego</a></li>
<li class="chapter" data-level="2.15.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-con-recorrido-infinito"><i class="fa fa-check"></i><b>2.15.10</b> Esperanza con recorrido infinito</a></li>
<li class="chapter" data-level="2.15.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-infinita"><i class="fa fa-check"></i><b>2.15.11</b> Esperanza infinita</a></li>
<li class="chapter" data-level="2.15.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza"><i class="fa fa-check"></i><b>2.15.12</b> Varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html"><i class="fa fa-check"></i><b>3</b> Distribuciones Notables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-discretas"><i class="fa fa-check"></i><b>3.1</b> Distribuciones discretas</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-bernouilli"><i class="fa fa-check"></i><b>3.1.1</b> La distribución de Bernouilli</a></li>
<li class="chapter" data-level="3.1.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>3.1.2</b> La distribución Binomial</a></li>
<li class="chapter" data-level="3.1.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>3.1.3</b> La distribución de Poisson</a></li>
<li class="chapter" data-level="3.1.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-uniforme-discreta"><i class="fa fa-check"></i><b>3.1.4</b> La distribución Uniforme discreta</a></li>
<li class="chapter" data-level="3.1.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-hipergeom%C3%A9trica"><i class="fa fa-check"></i><b>3.1.5</b> La distribución Hipergeométrica</a></li>
<li class="chapter" data-level="3.1.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-geom%C3%A9trica-o-de-pascal"><i class="fa fa-check"></i><b>3.1.6</b> La distribución Geométrica o de Pascal</a></li>
<li class="chapter" data-level="3.1.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-binomial-negativa"><i class="fa fa-check"></i><b>3.1.7</b> La distribución Binomial negativa</a></li>
<li class="chapter" data-level="3.1.8" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-distribuciones-discretas-principales"><i class="fa fa-check"></i><b>3.1.8</b> Tabla resumen de las distribuciones discretas principales</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-continuas"><i class="fa fa-check"></i><b>3.2</b> Distribuciones Continuas</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-uniforme"><i class="fa fa-check"></i><b>3.2.1</b> La distribución Uniforme</a></li>
<li class="chapter" data-level="3.2.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-exponencial"><i class="fa fa-check"></i><b>3.2.2</b> La distribución Exponencial</a></li>
<li class="chapter" data-level="3.2.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>3.2.3</b> La distribución Normal</a></li>
<li class="chapter" data-level="3.2.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-gamma"><i class="fa fa-check"></i><b>3.2.4</b> La distribución Gamma</a></li>
<li class="chapter" data-level="3.2.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-cauchy"><i class="fa fa-check"></i><b>3.2.5</b> La distribución de Cauchy</a></li>
<li class="chapter" data-level="3.2.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-weibull"><i class="fa fa-check"></i><b>3.2.6</b> La distribución de Weibull</a></li>
<li class="chapter" data-level="3.2.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-principales-distribuciones-continuas"><i class="fa fa-check"></i><b>3.2.7</b> Tabla resumen de las principales distribuciones continuas</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-con-r-y-python"><i class="fa fa-check"></i><b>3.3</b> Distribuciones con R (y Python)</a></li>
<li class="chapter" data-level="3.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-familia-exponencial-de-distribuciones"><i class="fa fa-check"></i><b>3.4</b> La familia exponencial de distribuciones</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#ejemplos-de-distribuciones-de-esta-familia"><i class="fa fa-check"></i><b>3.4.1</b> Ejemplos de distribuciones de esta familia</a></li>
<li class="chapter" data-level="3.4.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>3.4.2</b> Distribución Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#importancia-y-utilidad-de-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.3</b> Importancia y utilidad de la familia exponencial</a></li>
<li class="chapter" data-level="3.4.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#los-modelos-lineales-generalizados-glms"><i class="fa fa-check"></i><b>3.4.4</b> Los modelos lineales generalizados (GLMs)</a></li>
<li class="chapter" data-level="3.4.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#estimaci%C3%B3n-en-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.5</b> Estimación en la familia exponencial</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html"><i class="fa fa-check"></i><b>4</b> Distribuciones de probabilidad multidimensionales</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-conjuntas-de-probabilidades"><i class="fa fa-check"></i><b>4.1</b> Distribuciones conjuntas de probabilidades</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatoria-bivariante"><i class="fa fa-check"></i><b>4.1.1</b> Variable aleatoria bivariante</a></li>
<li class="chapter" data-level="4.1.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funci%C3%B3n-de-distribuci%C3%B3n-bivariante"><i class="fa fa-check"></i><b>4.1.2</b> Función de distribución bivariante</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatorias-bivariantes-discretas"><i class="fa fa-check"></i><b>4.2</b> Variable aleatorias bivariantes discretas</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funci%C3%B3n-de-masa-de-probabilidad-discreta-fmp"><i class="fa fa-check"></i><b>4.2.1</b> Función de masa de probabilidad discreta (fmp)</a></li>
<li class="chapter" data-level="4.2.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-fmp-bivariante"><i class="fa fa-check"></i><b>4.2.2</b> Propiedades de la fmp bivariante</a></li>
<li class="chapter" data-level="4.2.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejemplo-de-distribuci%C3%B3n-bivariante-discreta"><i class="fa fa-check"></i><b>4.2.3</b> Ejemplo de distribución bivariante discreta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribuci%C3%B3n-multinomial"><i class="fa fa-check"></i><b>4.3</b> La distribución multinomial</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#generaci%C3%B3n-de-las-observaciones"><i class="fa fa-check"></i><b>4.3.1</b> Generación de las observaciones</a></li>
<li class="chapter" data-level="4.3.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funcion-de-masa-de-probabilidad-de-la-distribuci%C3%B3n-multinomial"><i class="fa fa-check"></i><b>4.3.2</b> Funcion de masa de probabilidad de la distribución multinomial</a></li>
<li class="chapter" data-level="4.3.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relaci%C3%B3n-con-la-distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>4.3.3</b> Relación con la distribución binomial</a></li>
<li class="chapter" data-level="4.3.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#un-caso-particular-la-distribuci%C3%B3n-trinomial"><i class="fa fa-check"></i><b>4.3.4</b> Un caso particular: La distribución trinomial</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-marginales"><i class="fa fa-check"></i><b>4.4</b> Distribuciones marginales</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#las-marginales-est%C3%A1n-en-los-m%C3%A1rgenes"><i class="fa fa-check"></i><b>4.4.1</b> Las marginales están en los márgenes</a></li>
<li class="chapter" data-level="4.4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-discretas"><i class="fa fa-check"></i><b>4.4.2</b> Densidades marginales discretas</a></li>
<li class="chapter" data-level="4.4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribuciones-marginales"><i class="fa fa-check"></i><b>4.4.3</b> Trinomial M(5; 0.6, 0.2): Distribuciones marginales</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales"><i class="fa fa-check"></i><b>4.5</b> Distribuciones condicionales</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional"><i class="fa fa-check"></i><b>4.5.1</b> Densidad condicional</a></li>
<li class="chapter" data-level="4.5.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribuci%C3%B3n-condicional"><i class="fa fa-check"></i><b>4.5.2</b> Trinomial M(5; 0.6, 0.2): Distribución condicional</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#vectores-aleatorios-absolutamente-continuos"><i class="fa fa-check"></i><b>4.6</b> Vectores aleatorios absolutamente continuos</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-funci%C3%B3n-de-densidad-conjunta"><i class="fa fa-check"></i><b>4.6.1</b> Propiedades de la función de densidad conjunta</a></li>
<li class="chapter" data-level="4.6.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.2</b> Densidades marginales en el caso continuo</a></li>
<li class="chapter" data-level="4.6.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.3</b> Densidad condicional en el caso continuo</a></li>
<li class="chapter" data-level="4.6.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribuci%C3%B3n-normal-bivariante"><i class="fa fa-check"></i><b>4.6.4</b> La Distribución Normal Bivariante</a></li>
<li class="chapter" data-level="4.6.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales-1"><i class="fa fa-check"></i><b>4.6.5</b> Distribuciones Condicionales</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#independencia-de-variables-aleatorias"><i class="fa fa-check"></i><b>4.7</b> Independencia de variables aleatorias</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#primera-caracterizaci%C3%B3n-de-la-independencia"><i class="fa fa-check"></i><b>4.7.1</b> Primera caracterización de la independencia</a></li>
<li class="chapter" data-level="4.7.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-las-variables-independientes"><i class="fa fa-check"></i><b>4.7.2</b> Propiedades de las variables independientes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#momentos-de-vectores-aleatorios"><i class="fa fa-check"></i><b>4.8</b> Momentos de vectores aleatorios</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#esperanza-de-un-vector-aleatorio-o-vector-de-medias"><i class="fa fa-check"></i><b>4.8.1</b> Esperanza de un vector aleatorio o vector de medias</a></li>
<li class="chapter" data-level="4.8.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-entre-dos-variables-aleatorias"><i class="fa fa-check"></i><b>4.8.2</b> Covarianza entre dos variables aleatorias</a></li>
<li class="chapter" data-level="4.8.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-y-correlaci%C3%B3n"><i class="fa fa-check"></i><b>4.8.3</b> Covarianza y correlación</a></li>
<li class="chapter" data-level="4.8.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.4</b> Matriz de varianzas-covarianzas</a></li>
<li class="chapter" data-level="4.8.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>4.8.5</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="4.8.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#segunda-caracterizaci%C3%B3n-de-la-independencia"><i class="fa fa-check"></i><b>4.8.6</b> Segunda caracterización de la independencia</a></li>
<li class="chapter" data-level="4.8.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relaci%C3%B3n-entre-incorrelaci%C3%B3n-e-independencia"><i class="fa fa-check"></i><b>4.8.7</b> Relación entre incorrelación e independencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="grandes-muestras.html"><a href="grandes-muestras.html"><i class="fa fa-check"></i><b>5</b> Grandes muestras</a>
<ul>
<li class="chapter" data-level="5.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#introducci%C3%B3n-aproximaciones-asint%C3%B3ticas"><i class="fa fa-check"></i><b>5.1</b> Introducción: Aproximaciones asintóticas</a></li>
<li class="chapter" data-level="5.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ley-de-los-grandes-n%C3%BAmeros-ley-d%C3%A9bil"><i class="fa fa-check"></i><b>5.2</b> Ley de los Grandes Números (Ley débil)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ejemplo-3"><i class="fa fa-check"></i><b>5.2.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#el-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3</b> El teorema central del límite</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#sumas-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.3.1</b> Sumas de variables aleatorias</a></li>
<li class="chapter" data-level="5.3.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#definici%C3%B3n-de-convergencia-en-ley"><i class="fa fa-check"></i><b>5.3.2</b> Definición de convergencia en ley</a></li>
<li class="chapter" data-level="5.3.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#enunciado-del-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3.3</b> Enunciado del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.4" data-path="grandes-muestras.html"><a href="grandes-muestras.html#algunos-ejemplos-de-aplicaci%C3%B3n-del-tcl"><i class="fa fa-check"></i><b>5.3.4</b> Algunos ejemplos de aplicación del TCL</a></li>
<li class="chapter" data-level="5.3.5" data-path="grandes-muestras.html"><a href="grandes-muestras.html#casos-particulares-m%C3%A1s-notables"><i class="fa fa-check"></i><b>5.3.5</b> Casos particulares más notables</a></li>
<li class="chapter" data-level="5.3.6" data-path="grandes-muestras.html"><a href="grandes-muestras.html#interpretaci%C3%B3n-del-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3.6</b> Interpretación del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.7" data-path="grandes-muestras.html"><a href="grandes-muestras.html#acerca-de-las-variables-aproximadamente-normales"><i class="fa fa-check"></i><b>5.3.7</b> Acerca de las variables aproximadamente normales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html"><i class="fa fa-check"></i><b>6</b> Introducción a la inferencia estadística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#inferencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>6.1</b> Inferencia estadística</a></li>
<li class="chapter" data-level="6.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#problemas-de-inferencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>6.2</b> Problemas de inferencia estadística</a></li>
<li class="chapter" data-level="6.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-de-la-poblaci%C3%B3n"><i class="fa fa-check"></i><b>6.3</b> Distribución de la población</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-4"><i class="fa fa-check"></i><b>6.3.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestra-aleatoria-simple"><i class="fa fa-check"></i><b>6.4</b> Muestra aleatoria simple</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definici%C3%B3n-muestra-aleatoria-simple"><i class="fa fa-check"></i><b>6.4.1</b> Definición (Muestra aleatoria simple)</a></li>
<li class="chapter" data-level="6.4.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-de-la-muestra"><i class="fa fa-check"></i><b>6.4.2</b> Distribución de la muestra</a></li>
<li class="chapter" data-level="6.4.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#casos-particulares"><i class="fa fa-check"></i><b>6.4.3</b> Casos particulares</a></li>
<li class="chapter" data-level="6.4.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-5"><i class="fa fa-check"></i><b>6.4.4</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#estad%C3%ADsticos"><i class="fa fa-check"></i><b>6.5</b> Estadísticos</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definici%C3%B3n"><i class="fa fa-check"></i><b>6.5.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-en-el-muestreo-de-un-estad%C3%ADstico"><i class="fa fa-check"></i><b>6.6</b> Distribución en el muestreo de un estadístico</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-6"><i class="fa fa-check"></i><b>6.6.1</b> Ejemplo</a></li>
<li class="chapter" data-level="6.6.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-7"><i class="fa fa-check"></i><b>6.6.2</b> Ejemplo</a></li>
<li class="chapter" data-level="6.6.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-8"><i class="fa fa-check"></i><b>6.6.3</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-emp%C3%ADrica"><i class="fa fa-check"></i><b>6.7</b> La distribución empírica</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-9"><i class="fa fa-check"></i><b>6.7.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#momentos-muestrales"><i class="fa fa-check"></i><b>6.8</b> Momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#observaciones"><i class="fa fa-check"></i><b>6.8.1</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-en-el-muestreo-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.9</b> Distribución en el muestreo de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestreo-en-poblaciones-normales"><i class="fa fa-check"></i><b>6.10</b> Muestreo en poblaciones normales</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-chi-cuadrado-y-la-varianza-muestral"><i class="fa fa-check"></i><b>6.10.1</b> La distribución chi-cuadrado y la varianza muestral</a></li>
<li class="chapter" data-level="6.10.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-t-de-student-y-el-estad%C3%ADstico-t"><i class="fa fa-check"></i><b>6.10.2</b> La distribución t de Student y el estadístico <span class="math inline">\(T\)</span></a></li>
<li class="chapter" data-level="6.10.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-f-de-fisher-y-la-raz%C3%B3n-de-varianzas."><i class="fa fa-check"></i><b>6.10.3</b> La distribución F de Fisher y la razón de varianzas.</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ap%C3%A9ndice-t%C3%A9cnico-opcional"><i class="fa fa-check"></i><b>6.11</b> Apéndice técnico (opcional)</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#funci%C3%B3n-generadora-de-momentos-de-la-media-muestral"><i class="fa fa-check"></i><b>6.11.1</b> Función generadora de momentos de la media muestral</a></li>
<li class="chapter" data-level="6.11.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#momentos-centrales-y-relaci%C3%B3n-con-la-varianza-muestral"><i class="fa fa-check"></i><b>6.11.2</b> Momentos centrales y relación con la varianza muestral</a></li>
<li class="chapter" data-level="6.11.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#propiedades-asint%C3%B3ticas-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.11.3</b> Propiedades asintóticas de los momentos muestrales</a></li>
<li class="chapter" data-level="6.11.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#recordatorio-propiedades-%C3%BAtiles-de-la-distribuci%C3%B3n-gamma"><i class="fa fa-check"></i><b>6.11.4</b> Recordatorio: propiedades útiles de la distribución Gamma</a></li>
<li class="chapter" data-level="6.11.5" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#derivaci%C3%B3n-estructurada-de-chi2-t-y-f"><i class="fa fa-check"></i><b>6.11.5</b> Derivación estructurada de <span class="math inline">\(\chi^2\)</span>, <span class="math inline">\(t\)</span> y <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="6.11.6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#asint%C3%B3tica-%C3%BAtil-para-inferencia"><i class="fa fa-check"></i><b>6.11.6</b> Asintótica útil para inferencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimación-puntual.html"><a href="estimación-puntual.html"><i class="fa fa-check"></i><b>7</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-problema-de-la-estimaci%C3%B3n-puntual"><i class="fa fa-check"></i><b>7.1</b> El problema de la estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#criterios-de-optimalidad-de-estimadores.-el-riesgo"><i class="fa fa-check"></i><b>7.1.1</b> Criterios de optimalidad de estimadores. El Riesgo</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-error-cuadr%C3%A1tico-medio"><i class="fa fa-check"></i><b>7.1.2</b> El error cuadrático medio</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estudio-de-las-propiedades-deseables-de-los-estimadores"><i class="fa fa-check"></i><b>7.2</b> Estudio de las propiedades deseables de los estimadores</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-sesgo"><i class="fa fa-check"></i><b>7.2.1</b> El sesgo</a></li>
<li class="chapter" data-level="7.2.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#consistencia"><i class="fa fa-check"></i><b>7.2.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estimadores-consistentes"><i class="fa fa-check"></i><b>7.3</b> Propiedades de los estimadores consistentes</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#eficiencia"><i class="fa fa-check"></i><b>7.3.1</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="estimación-puntual.html"><a href="estimación-puntual.html#informaci%C3%B3n-de-fisher-y-cota-de-cramerrao"><i class="fa fa-check"></i><b>7.4</b> Información de Fisher y cota de CramerRao</a></li>
<li class="chapter" data-level="7.5" data-path="estimación-puntual.html"><a href="estimación-puntual.html#informaci%C3%B3n-y-verosimilitud-de-un-modelo-estad%C3%ADstico"><i class="fa fa-check"></i><b>7.5</b> Información y verosimilitud de un modelo estadístico</a></li>
<li class="chapter" data-level="7.6" data-path="estimación-puntual.html"><a href="estimación-puntual.html#informaci%C3%B3n-de-fisher"><i class="fa fa-check"></i><b>7.6</b> Información de Fisher</a></li>
<li class="chapter" data-level="7.7" data-path="estimación-puntual.html"><a href="estimación-puntual.html#la-desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>7.7</b> La desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="7.8" data-path="estimación-puntual.html"><a href="estimación-puntual.html#caracterizaci%C3%B3n-del-estimador-eficiente"><i class="fa fa-check"></i><b>7.8</b> Caracterización del estimador eficiente</a></li>
<li class="chapter" data-level="7.9" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estad%C3%ADsticos-suficientes"><i class="fa fa-check"></i><b>7.9</b> Estadísticos suficientes</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#definici%C3%B3-de-estad%C3%ADsticop-suficiente"><i class="fa fa-check"></i><b>7.9.1</b> Definició de estadísticop suficiente</a></li>
<li class="chapter" data-level="7.9.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#teorema-de-factorizaci%C3%B3n"><i class="fa fa-check"></i><b>7.9.2</b> Teorema de factorización</a></li>
<li class="chapter" data-level="7.9.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estad%C3%ADsticos-suficientes"><i class="fa fa-check"></i><b>7.9.3</b> Propiedades de los estadísticos suficientes</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="estimación-puntual.html"><a href="estimación-puntual.html#obtenci%C3%B3n-de-estimadores"><i class="fa fa-check"></i><b>7.10</b> Obtención de estimadores</a></li>
<li class="chapter" data-level="7.11" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-m%C3%A9todo-de-los-momentos"><i class="fa fa-check"></i><b>7.11</b> El método de los momentos</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#observaciones-1"><i class="fa fa-check"></i><b>7.11.1</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-m%C3%A9todo-del-m%C3%A1ximo-de-verosimilitud"><i class="fa fa-check"></i><b>7.12</b> El método del máximo de verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html"><i class="fa fa-check"></i><b>8</b> Estimación por intérvalos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#motivaci%C3%B3n-de-los-intervalos-de-confianza-la-estimaci%C3%B3n-puntual-casi-siempre-es-falsa"><i class="fa fa-check"></i><b>8.1</b> Motivación de los intervalos de confianza: la estimación puntual casi siempre es falsa</a></li>
<li class="chapter" data-level="8.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#definici%C3%B3n-formal-de-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.2</b> Definición formal de intervalo de confianza</a></li>
<li class="chapter" data-level="8.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#un-ejemplo-de-construcci%C3%B3n-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.3</b> Un ejemplo de construcción de un intervalo de confianza</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#planteamiento"><i class="fa fa-check"></i><b>8.3.1</b> Planteamiento</a></li>
<li class="chapter" data-level="8.3.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#desarrollo-de-la-construcci%C3%B3n"><i class="fa fa-check"></i><b>8.3.2</b> Desarrollo de la construcción</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#por-qu%C3%A9-hablamos-de-confianza-y-no-de-probabilidad"><i class="fa fa-check"></i><b>8.4</b> ¿Por qué hablamos de confianza y no de probabilidad?</a></li>
<li class="chapter" data-level="8.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#elementos-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.5</b> Elementos de un intervalo de confianza</a></li>
<li class="chapter" data-level="8.6" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#m%C3%A9todo-del-pivote"><i class="fa fa-check"></i><b>8.6</b> Método del pivote</a></li>
<li class="chapter" data-level="8.7" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#algunos-estad%C3%ADsticos-pivote"><i class="fa fa-check"></i><b>8.7</b> Algunos estadísticos pivote</a></li>
<li class="chapter" data-level="8.8" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-media-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.8</b> Intervalo de confianza para la media de una distribución Normal</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-conocida"><i class="fa fa-check"></i><b>8.8.1</b> Caso de varianza conocida</a></li>
<li class="chapter" data-level="8.8.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-desconocida"><i class="fa fa-check"></i><b>8.8.2</b> Caso de varianza desconocida</a></li>
<li class="chapter" data-level="8.8.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#calculo-con-r"><i class="fa fa-check"></i><b>8.8.3</b> Calculo con R</a></li>
<li class="chapter" data-level="8.8.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tama%C3%B1o-de-muestra-para-la-media-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.8.4</b> Tamaño de muestra para la media de una distribución Normal</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-varianza-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.9</b> Intervalo de confianza para la varianza de una distribución Normal</a></li>
<li class="chapter" data-level="8.10" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>8.10</b> Intervalo de confianza para una proporción</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximaci%C3%B3n-asint%C3%B3tica"><i class="fa fa-check"></i><b>8.10.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.10.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto"><i class="fa fa-check"></i><b>8.10.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.10.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tama%C3%B1o-muestral-para-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>8.10.3</b> Tamaño muestral para una proporción</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-par%C3%A1metro-de-una-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.11</b> Intervalo de confianza para el parámetro de una distribución de Poisson</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximaci%C3%B3n-asint%C3%B3tica-1"><i class="fa fa-check"></i><b>8.11.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.11.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto-1"><i class="fa fa-check"></i><b>8.11.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.11.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tama%C3%B1o-de-muestra-para-el-par%C3%A1metro-de-una-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.11.3</b> Tamaño de muestra para el parámetro de una distribución de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes."><i class="fa fa-check"></i><b>8.12</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.12.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#varianza-com%C3%BAn"><i class="fa fa-check"></i><b>8.12.1</b> Varianza común</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.-1"><i class="fa fa-check"></i><b>8.13</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.13.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#varianza-diferente"><i class="fa fa-check"></i><b>8.13.1</b> Varianza diferente</a></li>
<li class="chapter" data-level="8.13.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianzas-desconocidas-y-diferentes"><i class="fa fa-check"></i><b>8.13.2</b> Caso de varianzas desconocidas y diferentes</a></li>
<li class="chapter" data-level="8.13.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#int%C3%A9rvalos-de-confianza-y-decisiones-estad%C3%ADsticas"><i class="fa fa-check"></i><b>8.13.3</b> Intérvalos de confianza y decisiones estadísticas</a></li>
</ul></li>
<li class="chapter" data-level="8.14" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-cociente-de-varianzas-de-distribuciones-normales-independientes"><i class="fa fa-check"></i><b>8.14</b> Intervalo de confianza para el cociente de varianzas de distribuciones normales independientes</a></li>
<li class="chapter" data-level="8.15" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#complementos"><i class="fa fa-check"></i><b>8.15</b> Complementos</a>
<ul>
<li class="chapter" data-level="8.15.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#interpretaci%C3%B3n-geom%C3%A9trica-de-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>8.15.1</b> Interpretación geométrica de los intervalos de confianza</a></li>
<li class="chapter" data-level="8.15.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-para-muestras-grandes"><i class="fa fa-check"></i><b>8.15.2</b> Intervalos para muestras grandes</a></li>
<li class="chapter" data-level="8.15.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-exactos-para-distribuciones-discretas"><i class="fa fa-check"></i><b>8.15.3</b> Intervalos exactos para distribuciones discretas</a></li>
<li class="chapter" data-level="8.15.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#una-aproximaci%C3%B3n-diferente-para-la-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.15.4</b> Una aproximación diferente para la distribución de Poisson</a></li>
<li class="chapter" data-level="8.15.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximaci%C3%B3n-mediante-ch%C3%A9bishev"><i class="fa fa-check"></i><b>8.15.5</b> Aproximación mediante Chébishev</a></li>
</ul></li>
<li class="chapter" data-level="8.16" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#introducci%C3%B3n-2"><i class="fa fa-check"></i><b>8.16</b> Introducción</a>
<ul>
<li class="chapter" data-level="8.16.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#de-las-hip%C3%B3tesis-cient%C3%ADficas-a-las-hip%C3%B3tesis-estad%C3%ADsticas"><i class="fa fa-check"></i><b>8.16.1</b> De las hipótesis científicas a las hipótesis estadísticas</a></li>
<li class="chapter" data-level="8.16.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#del-lenguaje-natural-a-la-hip%C3%B3tesis-estad%C3%ADstica"><i class="fa fa-check"></i><b>8.16.2</b> Del lenguaje natural a la hipótesis estadística</a></li>
<li class="chapter" data-level="8.16.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-presentaci%C3%B3n"><i class="fa fa-check"></i><b>8.16.3</b> Caso 1: Presentación</a></li>
<li class="chapter" data-level="8.16.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-modelo-de-probabilidad"><i class="fa fa-check"></i><b>8.16.4</b> Caso 1: Modelo de probabilidad</a></li>
<li class="chapter" data-level="8.16.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-presentaci%C3%B3n"><i class="fa fa-check"></i><b>8.16.5</b> Caso 2: Presentación</a></li>
<li class="chapter" data-level="8.16.6" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-modelo-de-probabilidad"><i class="fa fa-check"></i><b>8.16.6</b> Caso 2: Modelo de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="8.17" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#las-hip%C3%B3tesis-del-contraste-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>8.17</b> Las hipótesis del contraste de hipótesis</a>
<ul>
<li class="chapter" data-level="8.17.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-hip%C3%B3tesis-para-dirimir-la-controversia-sobre-el-n%C3%BAmero-de-hembras"><i class="fa fa-check"></i><b>8.17.1</b> Caso 1: Hipótesis para dirimir la controversia sobre el número de hembras</a></li>
<li class="chapter" data-level="8.17.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-hip%C3%B3tesis-a-contrastar-en-el-problema-de-la-tasa-de-statdrolona"><i class="fa fa-check"></i><b>8.17.2</b> Caso 2: Hipótesis a contrastar en el problema de la tasa de statdrolona</a></li>
</ul></li>
<li class="chapter" data-level="8.18" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>8.18</b> Compatibilidad de resultados e hipótesis</a>
<ul>
<li class="chapter" data-level="8.18.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>8.18.1</b> Caso 1: Compatibilidad de resultados e hipótesis</a></li>
<li class="chapter" data-level="8.18.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>8.18.2</b> Caso 2: Compatibilidad de resultados e hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="8.19" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#no-todo-es-igualmente-probable"><i class="fa fa-check"></i><b>8.19</b> No todo es igualmente probable…</a>
<ul>
<li class="chapter" data-level="8.19.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-una-regi%C3%B3n-con-n%C3%BAmero-de-hembras-con-baja-probabilidad-bajo-mathrmh_0"><i class="fa fa-check"></i><b>8.19.1</b> Caso 1: Una región con número de hembras con baja probabilidad bajo <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
<li class="chapter" data-level="8.19.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-medias-de-las-tasas-de-statdrolona-improbables-si-se-cumple-mathrmh_0"><i class="fa fa-check"></i><b>8.19.2</b> Caso 2: Medias de las tasas de statdrolona improbables si se cumple <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.20" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#el-papel-privilegiado-de-la-hip%C3%B3tesis-nula-criterio-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>8.20</b> El papel privilegiado de la hipótesis nula: criterio de decisión</a>
<ul>
<li class="chapter" data-level="8.20.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-n.%C2%BA-de-nidos-propuestos-ad-hoc-como-inicio-de-regi%C3%B3n-cr%C3%ADtica.-regla-de-decisi%C3%B3n-resultante"><i class="fa fa-check"></i><b>8.20.1</b> Caso 1: N.º de nidos propuestos ad hoc como inicio de región crítica. Regla de decisión resultante</a></li>
</ul></li>
<li class="chapter" data-level="8.21" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#hip%C3%B3tesis-nula-y-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>8.21</b> Hipótesis nula y nivel de significación</a>
<ul>
<li class="chapter" data-level="8.21.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>8.21.1</b> Caso 1: Nivel de significación</a></li>
<li class="chapter" data-level="8.21.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>8.21.2</b> Caso 1: Elección de la región crítica</a></li>
<li class="chapter" data-level="8.21.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>8.21.3</b> Caso 2: Elección de la región crítica</a></li>
</ul></li>
<li class="chapter" data-level="8.22" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#regi%C3%B3n-cr%C3%ADtica-y-formalizaci%C3%B3n-del-contraste"><i class="fa fa-check"></i><b>8.22</b> Región crítica y formalización del contraste</a>
<ul>
<li class="chapter" data-level="8.22.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-resumen-de-conceptos-asociados-al-contraste.-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>8.22.1</b> Caso 1: Resumen de conceptos asociados al contraste. Región crítica</a></li>
<li class="chapter" data-level="8.22.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-tabla-resumen-de-la-regi%C3%B3n-cr%C3%ADtica-el-estad%C3%ADstico-de-test-y-del-criterio-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>8.22.2</b> Caso 2: Tabla resumen de la región crítica, el estadístico de test y del criterio de decisión</a></li>
<li class="chapter" data-level="8.22.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#regi%C3%B3n-cr%C3%ADtica-frente-a-estad%C3%ADstico-de-test"><i class="fa fa-check"></i><b>8.22.3</b> Región crítica frente a Estadístico de Test</a></li>
</ul></li>
<li class="chapter" data-level="8.23" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tabla-de-decisi%C3%B3n-del-contraste"><i class="fa fa-check"></i><b>8.23</b> Tabla de decisión del contraste</a>
<ul>
<li class="chapter" data-level="8.23.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-evaluaci%C3%B3n-de-los-dos-errores-asociados-al-contraste"><i class="fa fa-check"></i><b>8.23.1</b> Caso 1: Evaluación de los dos errores asociados al contraste</a></li>
<li class="chapter" data-level="8.23.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-c%C3%A1lculo-expl%C3%ADcito-de-los-errores-de-primera-alpha-y-segunda-especie-1--beta"><i class="fa fa-check"></i><b>8.23.2</b> Caso 2: Cálculo explícito de los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )</a></li>
</ul></li>
<li class="chapter" data-level="8.24" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#relaci%C3%B3n-entre-el-error-de-tipo-i-y-el-de-tipo-ii"><i class="fa fa-check"></i><b>8.24</b> Relación entre el error de tipo I y el de tipo II</a>
<ul>
<li class="chapter" data-level="8.24.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-evaluaci%C3%B3n-de-alpha-y-1--beta-para-diferentes-regiones-cr%C3%ADticas"><i class="fa fa-check"></i><b>8.24.1</b> Caso 1: Evaluación de <span class="math inline">\(\alpha\)</span> y 1- <span class="math inline">\(\beta\)</span> para diferentes regiones críticas</a></li>
<li class="chapter" data-level="8.24.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-relaci%C3%B3n-entre-los-errores-de-primera-alpha-y-segunda-especie-1--beta"><i class="fa fa-check"></i><b>8.24.2</b> Caso 2: Relación entre los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )</a></li>
</ul></li>
<li class="chapter" data-level="8.25" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#potencia-y-test-m%C3%A1s-potente"><i class="fa fa-check"></i><b>8.25</b> Potencia y test más potente</a>
<ul>
<li class="chapter" data-level="8.25.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-potencia-en-hip%C3%B3tesis-simple-vs-simple"><i class="fa fa-check"></i><b>8.25.1</b> Caso 1: Potencia en hipótesis simple vs simple</a></li>
<li class="chapter" data-level="8.25.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-potencia-en-hip%C3%B3tesis-simple-vs-simple"><i class="fa fa-check"></i><b>8.25.2</b> Caso 2: Potencia en hipótesis simple vs simple</a></li>
</ul></li>
<li class="chapter" data-level="8.26" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#efecto-del-tama%C3%B1o-muestral"><i class="fa fa-check"></i><b>8.26</b> Efecto del tamaño muestral</a>
<ul>
<li class="chapter" data-level="8.26.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1"><i class="fa fa-check"></i><b>8.26.1</b> Caso 1</a></li>
<li class="chapter" data-level="8.26.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2"><i class="fa fa-check"></i><b>8.26.2</b> Caso 2</a></li>
</ul></li>
<li class="chapter" data-level="8.27" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#hip%C3%B3tesis-simples-vs.-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>8.27</b> Hipótesis simples vs. hipótesis compuestas</a>
<ul>
<li class="chapter" data-level="8.27.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>8.27.1</b> Caso 1: Hipótesis compuestas</a></li>
<li class="chapter" data-level="8.27.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>8.27.2</b> Caso 2: Hipótesis compuestas</a></li>
</ul></li>
<li class="chapter" data-level="8.28" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>8.28</b> Función de potencia</a>
<ul>
<li class="chapter" data-level="8.28.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>8.28.1</b> Caso 1: Función de potencia</a></li>
<li class="chapter" data-level="8.28.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>8.28.2</b> Caso 2: Función de potencia</a></li>
</ul></li>
<li class="chapter" data-level="8.29" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tests-%C3%B3ptimos"><i class="fa fa-check"></i><b>8.29</b> Tests óptimos</a></li>
<li class="chapter" data-level="8.30" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#pruebas-bilaterales-y-pruebas-unilaterales"><i class="fa fa-check"></i><b>8.30</b> Pruebas bilaterales y pruebas unilaterales</a>
<ul>
<li class="chapter" data-level="8.30.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-prueba-unilateral"><i class="fa fa-check"></i><b>8.30.1</b> Caso 1: Prueba unilateral</a></li>
<li class="chapter" data-level="8.30.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-prueba-unilateral"><i class="fa fa-check"></i><b>8.30.2</b> Caso 2: Prueba unilateral</a></li>
</ul></li>
<li class="chapter" data-level="8.31" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#elecci%C3%B3n-del-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>8.31</b> Elección del nivel de significación</a></li>
<li class="chapter" data-level="8.32" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#el-p-valor"><i class="fa fa-check"></i><b>8.32</b> El p-valor</a>
<ul>
<li class="chapter" data-level="8.32.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-c%C3%A1lculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>8.32.1</b> Caso 1: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="8.32.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-c%C3%A1lculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>8.32.2</b> Caso 2: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="8.32.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-c%C3%A1lculo-del-p-valor-prueba-bilateral"><i class="fa fa-check"></i><b>8.32.3</b> Caso 2: Cálculo del p-valor (prueba bilateral)</a></li>
</ul></li>
<li class="chapter" data-level="8.33" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#pruebas-exactas-y-pruebas-asint%C3%B3ticas"><i class="fa fa-check"></i><b>8.33</b> Pruebas exactas y pruebas asintóticas</a>
<ul>
<li class="chapter" data-level="8.33.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-1-test-asint%C3%B3tico"><i class="fa fa-check"></i><b>8.33.1</b> Caso 1: Test asintótico</a></li>
<li class="chapter" data-level="8.33.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-test-exacto"><i class="fa fa-check"></i><b>8.33.2</b> Caso 2: Test exacto</a></li>
</ul></li>
<li class="chapter" data-level="8.34" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#relaci%C3%B3n-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>8.34</b> Relación con los intervalos de confianza</a>
<ul>
<li class="chapter" data-level="8.34.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-relaci%C3%B3n-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>8.34.1</b> Caso 2: Relación con los intervalos de confianza</a></li>
</ul></li>
<li class="chapter" data-level="8.35" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tama%C3%B1os-de-muestra.-diferencia-m%C3%ADnima-significativa"><i class="fa fa-check"></i><b>8.35</b> Tamaños de muestra. Diferencia mínima significativa</a>
<ul>
<li class="chapter" data-level="8.35.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-c%C3%A1lculo-del-tama%C3%B1o-de-la-muestra"><i class="fa fa-check"></i><b>8.35.1</b> Caso 2: Cálculo del tamaño de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="8.36" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#esquema-de-un-contraste-correctamente-planteado"><i class="fa fa-check"></i><b>8.36</b> Esquema de un contraste correctamente planteado</a></li>
<li class="chapter" data-level="8.37" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#significaci%C3%B3n-estad%C3%ADstica-y-significaci%C3%B3n-aplicada"><i class="fa fa-check"></i><b>8.37</b> Significación estadística y significación aplicada</a>
<ul>
<li class="chapter" data-level="8.37.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-2-significaci%C3%B3n-estad%C3%ADstica-y-aplicada"><i class="fa fa-check"></i><b>8.37.1</b> Caso 2: Significación estadística y aplicada</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>9</b> Construcción de contrastes de hipótesis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#qu%C3%A9-significa-construir-un-contraste-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.1</b> ¿Qué significa “construir” un contraste de hipótesis?</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#el-contraste-como-regla-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>9.1.1</b> El contraste como regla de decisión</a></li>
<li class="chapter" data-level="9.1.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#nivel-de-significaci%C3%B3n-como-restricci%C3%B3n-b%C3%A1sica"><i class="fa fa-check"></i><b>9.1.2</b> Nivel de significación como restricción básica</a></li>
<li class="chapter" data-level="9.1.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#primer-ejemplo-distintos-contrastes-con-el-mismo-nivel"><i class="fa fa-check"></i><b>9.1.3</b> Primer ejemplo: distintos contrastes con el mismo nivel</a></li>
<li class="chapter" data-level="9.1.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#potencia-como-criterio-de-comparaci%C3%B3n"><i class="fa fa-check"></i><b>9.1.4</b> Potencia como criterio de comparación</a></li>
<li class="chapter" data-level="9.1.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#segundo-ejemplo-misma-alpha-distinta-potencia"><i class="fa fa-check"></i><b>9.1.5</b> Segundo ejemplo: misma alpha, distinta potencia</a></li>
<li class="chapter" data-level="9.1.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#de-contrastes-razonables-a-contrastes-%C3%B3ptimos"><i class="fa fa-check"></i><b>9.1.6</b> De contrastes razonables a contrastes óptimos</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#evidencia-y-decisi%C3%B3n-dos-enfoques-cl%C3%A1sicos"><i class="fa fa-check"></i><b>9.2</b> Evidencia y decisión: dos enfoques clásicos</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#el-enfoque-de-fisher-tests-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>9.2.1</b> El enfoque de Fisher: tests de significación</a></li>
<li class="chapter" data-level="9.2.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#el-enfoque-de-neymanpearson-contraste-como-regla-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>9.2.2</b> El enfoque de Neyman–Pearson: contraste como regla de decisión</a></li>
<li class="chapter" data-level="9.2.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#diferencias-conceptuales-clave"><i class="fa fa-check"></i><b>9.2.3</b> Diferencias conceptuales clave</a></li>
<li class="chapter" data-level="9.2.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#convivencia-de-ambos-enfoques-en-la-pr%C3%A1ctica"><i class="fa fa-check"></i><b>9.2.4</b> Convivencia de ambos enfoques en la práctica</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#tests-%C3%B3ptimos-el-lema-de-neymanpearson"><i class="fa fa-check"></i><b>9.3</b> Tests óptimos: el lema de Neyman–Pearson</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#hip%C3%B3tesis-simples-y-raz%C3%B3n-de-verosimilitudes"><i class="fa fa-check"></i><b>9.3.1</b> Hipótesis simples y razón de verosimilitudes</a></li>
<li class="chapter" data-level="9.3.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#enunciado-del-lema-de-neymanpearson"><i class="fa fa-check"></i><b>9.3.2</b> Enunciado del lema de Neyman–Pearson</a></li>
<li class="chapter" data-level="9.3.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-modelo-normal-con-varianza-conocida"><i class="fa fa-check"></i><b>9.3.3</b> Ejemplo: modelo normal con varianza conocida</a></li>
<li class="chapter" data-level="9.3.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-modelo-de-poisson"><i class="fa fa-check"></i><b>9.3.4</b> Ejemplo: modelo de Poisson</a></li>
<li class="chapter" data-level="9.3.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#extensiones-del-lema-de-neymanpearson"><i class="fa fa-check"></i><b>9.3.5</b> Extensiones del lema de Neyman–Pearson</a></li>
<li class="chapter" data-level="9.3.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#l%C3%ADmites-del-enfoque"><i class="fa fa-check"></i><b>9.3.6</b> Límites del enfoque</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#contrastes-de-raz%C3%B3n-de-verosimilitudes-generalizados"><i class="fa fa-check"></i><b>9.4</b> Contrastes de razón de verosimilitudes generalizados</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#definici%C3%B3n-del-estad%C3%ADstico-de-raz%C3%B3n-de-verosimilitudes"><i class="fa fa-check"></i><b>9.4.1</b> Definición del estadístico de razón de verosimilitudes</a></li>
<li class="chapter" data-level="9.4.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#regla-de-decisi%C3%B3n-y-aproximaci%C3%B3n-asint%C3%B3tica"><i class="fa fa-check"></i><b>9.4.2</b> Regla de decisión y aproximación asintótica</a></li>
<li class="chapter" data-level="9.4.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-comparaci%C3%B3n-de-par%C3%A1metros-en-un-modelo-de-poisson"><i class="fa fa-check"></i><b>9.4.3</b> Ejemplo: comparación de parámetros en un modelo de Poisson</a></li>
<li class="chapter" data-level="9.4.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-contraste-en-un-modelo-exponencial"><i class="fa fa-check"></i><b>9.4.4</b> Ejemplo: contraste en un modelo exponencial</a></li>
<li class="chapter" data-level="9.4.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-contraste-en-un-modelo-trinomial"><i class="fa fa-check"></i><b>9.4.5</b> Ejemplo: contraste en un modelo trinomial</a></li>
<li class="chapter" data-level="9.4.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#del-contraste-de-raz%C3%B3n-de-verosimilitudes-al-test-ji-cuadrado"><i class="fa fa-check"></i><b>9.4.6</b> Del contraste de razón de verosimilitudes al test ji-cuadrado</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#tests-de-permutaciones"><i class="fa fa-check"></i><b>9.5</b> Tests de permutaciones</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#idea-b%C3%A1sica"><i class="fa fa-check"></i><b>9.5.1</b> Idea básica</a></li>
<li class="chapter" data-level="9.5.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-1-test-de-permutaciones-con-enumeraci%C3%B3n-completa"><i class="fa fa-check"></i><b>9.5.2</b> Ejemplo 1: test de permutaciones con enumeración completa</a></li>
<li class="chapter" data-level="9.5.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#valor-observado-del-estad%C3%ADstico"><i class="fa fa-check"></i><b>9.5.3</b> Valor observado del estadístico</a></li>
<li class="chapter" data-level="9.5.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#distribuci%C3%B3n-exacta-por-permutaciones"><i class="fa fa-check"></i><b>9.5.4</b> Distribución exacta por permutaciones</a></li>
<li class="chapter" data-level="9.5.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-2-test-de-permutaciones-mediante-simulaci%C3%B3n"><i class="fa fa-check"></i><b>9.5.5</b> Ejemplo 2: test de permutaciones mediante simulación</a></li>
<li class="chapter" data-level="9.5.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#comentario-final"><i class="fa fa-check"></i><b>9.5.6</b> Comentario final</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html"><i class="fa fa-check"></i><b>10</b> Pruebas de una muestra</a>
<ul>
<li class="chapter" data-level="10.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-a-los-contrastes-de-una-muestra."><i class="fa fa-check"></i><b>10.1</b> Introducción a los contrastes de una muestra.</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#esquema-de-los-contrastes-presentados"><i class="fa fa-check"></i><b>10.1.1</b> Esquema de los contrastes presentados</a></li>
<li class="chapter" data-level="10.1.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contrastes-sobre-los-par%C3%A1metros-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>10.1.2</b> Contrastes sobre los parámetros de una distribución Normal</a></li>
<li class="chapter" data-level="10.1.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contrastes-sobre-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>10.1.3</b> Contrastes sobre una proporción</a></li>
<li class="chapter" data-level="10.1.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#esquema-general-de-los-contrastes-presentados"><i class="fa fa-check"></i><b>10.1.4</b> Esquema general de los contrastes presentados</a></li>
<li class="chapter" data-level="10.1.5" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contrastes-param%C3%A9tricos-frente-a-no-param%C3%A9tricos"><i class="fa fa-check"></i><b>10.1.5</b> Contrastes paramétricos frente a no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida-z-test."><i class="fa fa-check"></i><b>10.2</b> Contraste de hipótesis para la media de una distribución Normal con varianza conocida: <span class="math inline">\(Z\)</span>-test.</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-3"><i class="fa fa-check"></i><b>10.2.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida."><i class="fa fa-check"></i><b>10.2.2</b> Resolución del contraste para la media de una distribución Normal con varianza conocida.</a></li>
<li class="chapter" data-level="10.2.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida."><i class="fa fa-check"></i><b>10.2.3</b> Intervalo de confianza para la media de una distribución Normal con varianza conocida.</a></li>
<li class="chapter" data-level="10.2.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#c%C3%A1lculo-del-tama%C3%B1o-muestral-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida."><i class="fa fa-check"></i><b>10.2.4</b> Cálculo del tamaño muestral para la media de una distribución Normal con varianza conocida.</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida-t-test."><i class="fa fa-check"></i><b>10.3</b> Contraste de hipótesis para la media de una distribución Normal con varianza desconocida: <span class="math inline">\(T\)</span>-test.</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-4"><i class="fa fa-check"></i><b>10.3.1</b> Introducción</a></li>
<li class="chapter" data-level="10.3.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida."><i class="fa fa-check"></i><b>10.3.2</b> Resolución del contraste para la media de una distribución Normal con varianza desconocida.</a></li>
<li class="chapter" data-level="10.3.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida."><i class="fa fa-check"></i><b>10.3.3</b> Intervalo de confianza para la media de una distribución Normal con varianza desconocida.</a></li>
<li class="chapter" data-level="10.3.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#c%C3%A1lculo-del-tama%C3%B1o-muestral-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida."><i class="fa fa-check"></i><b>10.3.4</b> Cálculo del tamaño muestral para la media de una distribución Normal con varianza desconocida.</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-varianza-de-una-distribuci%C3%B3n-normal."><i class="fa fa-check"></i><b>10.4</b> Contraste de hipótesis para la varianza de una distribución Normal.</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-5"><i class="fa fa-check"></i><b>10.4.1</b> Introducción</a></li>
<li class="chapter" data-level="10.4.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#informaci%C3%B3n-previa-premisas"><i class="fa fa-check"></i><b>10.4.2</b> Información previa (premisas)</a></li>
<li class="chapter" data-level="10.4.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-varianza-de-una-distribuci%C3%B3n-normal."><i class="fa fa-check"></i><b>10.4.3</b> Resolución del contraste para la varianza de una distribución Normal.</a></li>
<li class="chapter" data-level="10.4.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-varianza-de-una-distribuci%C3%B3n-normal."><i class="fa fa-check"></i><b>10.4.4</b> Intervalo de confianza para la varianza de una distribución Normal.</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>10.5</b> Contraste de hipótesis para la proporción.</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-6"><i class="fa fa-check"></i><b>10.5.1</b> Introducción:</a></li>
<li class="chapter" data-level="10.5.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#informaci%C3%B3n-previa-premisas-1"><i class="fa fa-check"></i><b>10.5.2</b> Información previa (premisas)</a></li>
<li class="chapter" data-level="10.5.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>10.5.3</b> Resolución del contraste para la proporción.</a></li>
<li class="chapter" data-level="10.5.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>10.5.4</b> Intervalo de confianza para la proporción.</a></li>
<li class="chapter" data-level="10.5.5" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#c%C3%A1lculo-del-tama%C3%B1o-muestral-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>10.5.5</b> Cálculo del tamaño muestral para la proporción.</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#tabla-resumen-para-una-muestra."><i class="fa fa-check"></i><b>10.6</b> Tabla resumen para una muestra.</a></li>
<li class="chapter" data-level="10.7" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#la-importancia-de-elegir-correctamente-la-hip%C3%B3tesis-nula."><i class="fa fa-check"></i><b>10.7</b> La importancia de elegir correctamente la hipótesis nula.</a></li>
<li class="chapter" data-level="10.8" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#relaci%C3%B3n-con-los-intervalos-de-confianza-1"><i class="fa fa-check"></i><b>10.8</b> Relación con los intervalos de confianza</a></li>
<li class="chapter" data-level="10.9" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#relaci%C3%B3n-entre-el-intervalo-y-el-contraste"><i class="fa fa-check"></i><b>10.9</b> Relación entre el intervalo y el contraste</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-varianza-de-una-distribuci%C3%B3n-normal-1"><i class="fa fa-check"></i><b>10.9.1</b> Intervalo de confianza para la varianza de una distribución Normal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html"><i class="fa fa-check"></i><b>11</b> Contrastes con dos muestras</a>
<ul>
<li class="chapter" data-level="11.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#introducci%C3%B3n-7"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-independencia-vs-datos-apareados"><i class="fa fa-check"></i><b>11.2</b> Premisas: independencia vs datos apareados</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#ejemplo-datos-independientes-vs-apareados"><i class="fa fa-check"></i><b>11.2.1</b> Ejemplo: Datos independientes vs apareados</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis-en-comparaciones-de-medias-de-datos-normales-independientes."><i class="fa fa-check"></i><b>11.3</b> Premisas e hipótesis en comparaciones de medias de datos normales independientes.</a></li>
<li class="chapter" data-level="11.4" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaci%C3%B3n-de-medias-de-datos-normales-independientes."><i class="fa fa-check"></i><b>11.4</b> Comparación de medias de datos normales independientes.</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#estad%C3%ADstico-de-test-y-valores-cr%C3%ADticos"><i class="fa fa-check"></i><b>11.4.1</b> Estadístico de test y valores críticos</a></li>
<li class="chapter" data-level="11.4.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#intervalo-de-confianza-para-la-diferencia-de-medias."><i class="fa fa-check"></i><b>11.4.2</b> Intervalo de confianza para la diferencia de medias.</a></li>
<li class="chapter" data-level="11.4.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#c%C3%A1lculo-del-tama%C3%B1o-de-muestra"><i class="fa fa-check"></i><b>11.4.3</b> Cálculo del tamaño de muestra</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaci%C3%B3n-de-varianzas-de-datos-normales-independientes."><i class="fa fa-check"></i><b>11.5</b> Comparación de varianzas de datos normales independientes.</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis-en"><i class="fa fa-check"></i><b>11.5.1</b> Premisas e hipótesis en</a></li>
<li class="chapter" data-level="11.5.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#estad%C3%ADstico-de-test-y-valores-cr%C3%ADticos-1"><i class="fa fa-check"></i><b>11.5.2</b> Estadístico de test y valores críticos</a></li>
<li class="chapter" data-level="11.5.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#intervalo-de-confianza-para-la-raz%C3%B3n-de-varianzas"><i class="fa fa-check"></i><b>11.5.3</b> Intervalo de confianza para la razón de varianzas</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaciones-de-medias-de-datos-normales-apareados"><i class="fa fa-check"></i><b>11.6</b> Comparaciones de medias de datos normales apareados</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.6.1</b> Premisas e hipótesis</a></li>
<li class="chapter" data-level="11.6.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#relaci%C3%B3n-entre-el-contraste-de-datos-apareados-y-el-de-una-media-datos-normales."><i class="fa fa-check"></i><b>11.6.2</b> Relación entre el contraste de datos apareados y el de una media (datos normales).</a></li>
<li class="chapter" data-level="11.6.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#int%C3%A9rvalos-de-confianza-para-la-diferencia"><i class="fa fa-check"></i><b>11.6.3</b> Intérvalos de confianza para la diferencia</a></li>
<li class="chapter" data-level="11.6.4" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#tama%C3%B1o-muestral"><i class="fa fa-check"></i><b>11.6.4</b> Tamaño muestral</a></li>
<li class="chapter" data-level="11.6.5" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#ejemplo-efecto-de-una-intervenci%C3%B3n-sobre-el-colesterol-hdl"><i class="fa fa-check"></i><b>11.6.5</b> Ejemplo: efecto de una intervención sobre el colesterol HDL</a></li>
<li class="chapter" data-level="11.6.6" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#resumen-datos-independientes-frente-a-datos-apareados"><i class="fa fa-check"></i><b>11.6.6</b> Resumen: Datos independientes frente a datos apareados</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaciones-de-2-proporciones-datos-independientes"><i class="fa fa-check"></i><b>11.7</b> Comparaciones de 2 proporciones (datos independientes)</a>
<ul>
<li class="chapter" data-level="11.7.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis-1"><i class="fa fa-check"></i><b>11.7.1</b> Premisas e hipótesis</a></li>
<li class="chapter" data-level="11.7.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#estad%C3%ADstico-de-test-y-valores-cr%C3%ADticos-2"><i class="fa fa-check"></i><b>11.7.2</b> Estadístico de test y valores críticos</a></li>
<li class="chapter" data-level="11.7.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#condiciones-de-aplicaci%C3%B3n-del-test"><i class="fa fa-check"></i><b>11.7.3</b> Condiciones de aplicación del test</a></li>
<li class="chapter" data-level="11.7.4" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#intervalo-de-confianza-para-la-diferencia-de-proporciones-datos-independientes."><i class="fa fa-check"></i><b>11.7.4</b> Intervalo de confianza para la diferencia de proporciones (datos independientes).</a></li>
<li class="chapter" data-level="11.7.5" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#c%C3%A1lculo-del-tama%C3%B1o-de-muestra-en-el-contraste-de-proporciones-de-datos-independientes."><i class="fa fa-check"></i><b>11.7.5</b> Cálculo del tamaño de muestra en el contraste de proporciones de datos independientes.</a></li>
</ul></li>
<li class="chapter" data-level="11.8" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaciones-de-dos-muestras-tabla-resumen"><i class="fa fa-check"></i><b>11.8</b> Comparaciones de dos muestras: Tabla resumen</a></li>
<li class="chapter" data-level="11.9" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#complementos-efecto-de-las-transformaciones-de-los-datos-en-el-test-t"><i class="fa fa-check"></i><b>11.9</b> Complementos: efecto de las transformaciones de los datos en el test t</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#efecto-del-cambi-de-posici%C3%B3n"><i class="fa fa-check"></i><b>11.9.1</b> Efecto del cambi de posición</a></li>
<li class="chapter" data-level="11.9.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#efecto-de-un-cambio-de-escala"><i class="fa fa-check"></i><b>11.9.2</b> Efecto de un cambio de escala</a></li>
</ul></li>
<li class="chapter" data-level="11.10" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#presentaci%C3%B3n-del-caso-1"><i class="fa fa-check"></i><b>11.10</b> Presentación del caso 1</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html"><i class="fa fa-check"></i><b>12</b> Las pruebas “Chi-cuadrado”</a>
<ul>
<li class="chapter" data-level="12.1" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#introducci%C3%B3n-8"><i class="fa fa-check"></i><b>12.1</b> Introducción</a></li>
<li class="chapter" data-level="12.2" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#pruebas-chi2-de-bondad-de-ajuste"><i class="fa fa-check"></i><b>12.2</b> Pruebas <span class="math inline">\(\chi^2\)</span> de bondad de ajuste</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#hip%C3%B3tesis-simples"><i class="fa fa-check"></i><b>12.2.1</b> Hipótesis simples</a></li>
<li class="chapter" data-level="12.2.2" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#estad%C3%ADstico-de-pearson"><i class="fa fa-check"></i><b>12.2.2</b> Estadístico de Pearson</a></li>
<li class="chapter" data-level="12.2.3" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#observaciones-pr%C3%A1cticas"><i class="fa fa-check"></i><b>12.2.3</b> Observaciones prácticas</a></li>
<li class="chapter" data-level="12.2.4" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-1-bondad-de-ajuste"><i class="fa fa-check"></i><b>12.2.4</b> Ejemplo 1: Bondad de ajuste</a></li>
<li class="chapter" data-level="12.2.5" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-2-ajuste-de-modelo-gen%C3%A9tico"><i class="fa fa-check"></i><b>12.2.5</b> Ejemplo 2: Ajuste de modelo genético</a></li>
<li class="chapter" data-level="12.2.6" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>12.2.6</b> Hipótesis compuestas</a></li>
<li class="chapter" data-level="12.2.7" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-3-ajuste-de-modelo-gen%C3%A9tico-con-probabilidades-desconocidas"><i class="fa fa-check"></i><b>12.2.7</b> Ejemplo 3: Ajuste de modelo genético con probabilidades desconocidas</a></li>
<li class="chapter" data-level="12.2.8" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-4-ajuste-a-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>12.2.8</b> Ejemplo 4: Ajuste a una distribución normal</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#pruebas-de-independencia-en-tablas-de-contingencia"><i class="fa fa-check"></i><b>12.3</b> Pruebas de independencia en tablas de contingencia</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-5-relaci%C3%B3n-entre-nivel-de-estudios-y-preferencias"><i class="fa fa-check"></i><b>12.3.1</b> Ejemplo 5: Relación entre nivel de estudios y preferencias</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#pruebas-de-homogeneidad"><i class="fa fa-check"></i><b>12.4</b> Pruebas de homogeneidad</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-6-homogeneidad-en-los-grupos-sangu%C3%ADneos"><i class="fa fa-check"></i><b>12.4.1</b> Ejemplo 6: Homogeneidad en los grupos sanguíneos</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplos-resueltos-en-r"><i class="fa fa-check"></i><b>12.5</b> Ejemplos resueltos en R</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-1-bondad-de-ajuste-1"><i class="fa fa-check"></i><b>12.5.1</b> Ejemplo 1: Bondad de ajuste</a></li>
<li class="chapter" data-level="12.5.2" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-2-ajuste-de-modelo-gen%C3%A9tico-1"><i class="fa fa-check"></i><b>12.5.2</b> Ejemplo 2: Ajuste de modelo genético</a></li>
<li class="chapter" data-level="12.5.3" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-3-ajuste-de-modelo-gen%C3%A9tico-con-probabilidades-desconocidas-1"><i class="fa fa-check"></i><b>12.5.3</b> Ejemplo 3: Ajuste de modelo genético con probabilidades desconocidas</a></li>
<li class="chapter" data-level="12.5.4" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-4-ajuste-a-una-distribuci%C3%B3n-normal-1"><i class="fa fa-check"></i><b>12.5.4</b> Ejemplo 4: Ajuste a una distribución normal</a></li>
<li class="chapter" data-level="12.5.5" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-5-relaci%C3%B3n-entre-nivel-de-estudios-y-preferencias-1"><i class="fa fa-check"></i><b>12.5.5</b> Ejemplo 5: Relación entre nivel de estudios y preferencias</a></li>
<li class="chapter" data-level="12.5.6" data-path="las-pruebas-chi-cuadrado.html"><a href="las-pruebas-chi-cuadrado.html#ejemplo-6-homogeneidad-en-los-grupos-sangu%C3%ADneos-1"><i class="fa fa-check"></i><b>12.5.6</b> Ejemplo 6: Homogeneidad en los grupos sanguíneos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html"><i class="fa fa-check"></i><b>13</b> Estadística no paramétrica</a>
<ul>
<li class="chapter" data-level="13.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#introducci%C3%B3n-9"><i class="fa fa-check"></i><b>13.1</b> Introducción</a></li>
<li class="chapter" data-level="13.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-de-los-signos"><i class="fa fa-check"></i><b>13.2</b> Test de los signos</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-para-la-mediana"><i class="fa fa-check"></i><b>13.2.1</b> Test para la mediana</a></li>
<li class="chapter" data-level="13.2.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-de-los-signos-para-datos-apareados"><i class="fa fa-check"></i><b>13.2.2</b> Test de los signos para datos apareados</a></li>
<li class="chapter" data-level="13.2.3" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-para-datos-binarios"><i class="fa fa-check"></i><b>13.2.3</b> Test para datos binarios</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-de-mcnemar"><i class="fa fa-check"></i><b>13.3</b> Test de McNemar</a></li>
<li class="chapter" data-level="13.4" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-de-los-rangos-con-signo-de-wilcoxon"><i class="fa fa-check"></i><b>13.4</b> Test de los rangos con signo de Wilcoxon</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#observaciones-3"><i class="fa fa-check"></i><b>13.4.1</b> Observaciones</a></li>
<li class="chapter" data-level="13.4.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ejemplo-4-1"><i class="fa fa-check"></i><b>13.4.2</b> Ejemplo 4</a></li>
<li class="chapter" data-level="13.4.3" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ejemplo-5-1"><i class="fa fa-check"></i><b>13.4.3</b> Ejemplo 5</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#el-test-u-de-mann-whitney"><i class="fa fa-check"></i><b>13.5</b> El test <span class="math inline">\(U\)</span> de Mann-Whitney</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#observaciones-4"><i class="fa fa-check"></i><b>13.5.1</b> Observaciones</a></li>
<li class="chapter" data-level="13.5.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ejemplo-6-1"><i class="fa fa-check"></i><b>13.5.2</b> Ejemplo 6</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#comparaci%C3%B3n-de-medianas"><i class="fa fa-check"></i><b>13.6</b> Comparación de medianas</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ejemplo-7-1"><i class="fa fa-check"></i><b>13.6.1</b> Ejemplo 7</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-de-kolmogorov-smirnov-para-la-homogeneidad"><i class="fa fa-check"></i><b>13.7</b> Test de Kolmogorov-Smirnov para la homogeneidad</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ejemplo-8-1"><i class="fa fa-check"></i><b>13.7.1</b> Ejemplo 8</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-h-de-kruskal-wallis"><i class="fa fa-check"></i><b>13.8</b> Test <span class="math inline">\(H\)</span> de Kruskal-Wallis</a>
<ul>
<li class="chapter" data-level="13.8.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#observaciones-5"><i class="fa fa-check"></i><b>13.8.1</b> Observaciones</a></li>
<li class="chapter" data-level="13.8.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ejemplo-9-1"><i class="fa fa-check"></i><b>13.8.2</b> Ejemplo 9</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#test-de-friedman"><i class="fa fa-check"></i><b>13.9</b> Test de Friedman</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#ejemplo-10"><i class="fa fa-check"></i><b>13.9.1</b> Ejemplo 10</a></li>
<li class="chapter" data-level="13.9.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#observaciones-6"><i class="fa fa-check"></i><b>13.9.2</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="13.10" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#coeficientes-de-correlaci%C3%B3n-no-param%C3%A9tricos"><i class="fa fa-check"></i><b>13.10</b> Coeficientes de correlación no paramétricos</a>
<ul>
<li class="chapter" data-level="13.10.1" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#coeficiente-tau-de-kendall"><i class="fa fa-check"></i><b>13.10.1</b> Coeficiente <span class="math inline">\(\tau\)</span> de Kendall</a></li>
<li class="chapter" data-level="13.10.2" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#coeficiente-de-correlaci%C3%B3n-por-rangos-de-spearman"><i class="fa fa-check"></i><b>13.10.2</b> Coeficiente de correlación por rangos de Spearman</a></li>
<li class="chapter" data-level="13.10.3" data-path="estadística-no-paramétrica.html"><a href="estadística-no-paramétrica.html#el-par%C3%A1metro-poblacional-asociado-a-los-coeficientes-de-correlaci%C3%B3n-no-param%C3%A9tricos"><i class="fa fa-check"></i><b>13.10.3</b> El parámetro poblacional asociado a los coeficientes de correlación no paramétricos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html"><i class="fa fa-check"></i><b>14</b> Métodos de computación intensiva: El <em>Bootstrap</em></a>
<ul>
<li class="chapter" data-level="14.1" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#introducci%C3%B3n-precisi%C3%B3n-de-un-estimador"><i class="fa fa-check"></i><b>14.1</b> Introducción: Precisión de un estimador</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#ejemplos-de-introducci%C3%B3n"><i class="fa fa-check"></i><b>14.1.1</b> Ejemplos de introducción</a></li>
<li class="chapter" data-level="14.1.2" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#estimaci%C3%B3n-del-error-est%C3%A1ndar-soluciones-cl%C3%A1sica-y-bootstrap"><i class="fa fa-check"></i><b>14.1.2</b> Estimación del error estándar: soluciones clásica y bootstrap</a></li>
<li class="chapter" data-level="14.1.3" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#estimadores-de-substituci%C3%B3n-plug-in-y-funcionales-estad%C3%ADsticos"><i class="fa fa-check"></i><b>14.1.3</b> Estimadores de substitución (“plug-in”) y Funcionales estadísticos</a></li>
<li class="chapter" data-level="14.1.4" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#el-bootstrap"><i class="fa fa-check"></i><b>14.1.4</b> El bootstrap</a></li>
<li class="chapter" data-level="14.1.5" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#ejemplo-1-continuaci%C3%B3n"><i class="fa fa-check"></i><b>14.1.5</b> Ejemplo 1 (continuación)</a></li>
<li class="chapter" data-level="14.1.6" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#resumen-del-mundo-real-al-mundo-bootstrap"><i class="fa fa-check"></i><b>14.1.6</b> Resumen: del mundo real al mundo bootstrap</a></li>
<li class="chapter" data-level="14.1.7" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#otros-aspectos"><i class="fa fa-check"></i><b>14.1.7</b> Otros aspectos</a></li>
<li class="chapter" data-level="14.1.8" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#ejercicios"><i class="fa fa-check"></i><b>14.1.8</b> Ejercicios</a></li>
<li class="chapter" data-level="14.1.9" data-path="métodos-de-computación-intensiva-el-bootstrap.html"><a href="métodos-de-computación-intensiva-el-bootstrap.html#practicas"><i class="fa fa-check"></i><b>14.1.9</b> Practicas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="capítulo-2.html"><a href="capítulo-2.html"><i class="fa fa-check"></i><b>15</b> Capítulo 2</a>
<ul>
<li class="chapter" data-level="15.1" data-path="capítulo-2.html"><a href="capítulo-2.html#estimaci%C3%B3n-y-correcci%C3%B3n-del-sesgo-de-un-estimador"><i class="fa fa-check"></i><b>15.1</b> Estimación y corrección del sesgo de un estimador</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="capítulo-2.html"><a href="capítulo-2.html#introducci%C3%B3n-10"><i class="fa fa-check"></i><b>15.1.1</b> Introducción</a></li>
<li class="chapter" data-level="15.1.2" data-path="capítulo-2.html"><a href="capítulo-2.html#estimaci%C3%B3n-bootstrap-del-sesgo"><i class="fa fa-check"></i><b>15.1.2</b> Estimación bootstrap del sesgo</a></li>
<li class="chapter" data-level="15.1.3" data-path="capítulo-2.html"><a href="capítulo-2.html#ejemplo-1.-estimaci%C3%B3n-del-sesgo-del-estimador-de-la-varianza"><i class="fa fa-check"></i><b>15.1.3</b> Ejemplo 1. Estimación del sesgo del estimador de la varianza</a></li>
<li class="chapter" data-level="15.1.4" data-path="capítulo-2.html"><a href="capítulo-2.html#correcci%C3%B3n-del-sesgo-de-un-estimador"><i class="fa fa-check"></i><b>15.1.4</b> Corrección del sesgo de un estimador</a></li>
<li class="chapter" data-level="15.1.5" data-path="capítulo-2.html"><a href="capítulo-2.html#el-jackknife"><i class="fa fa-check"></i><b>15.1.5</b> El jackknife</a></li>
<li class="chapter" data-level="15.1.6" data-path="capítulo-2.html"><a href="capítulo-2.html#ejercicios-1"><i class="fa fa-check"></i><b>15.1.6</b> Ejercicios</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="capítulo-3.html"><a href="capítulo-3.html"><i class="fa fa-check"></i><b>16</b> Capítulo 3</a>
<ul>
<li class="chapter" data-level="16.1" data-path="capítulo-3.html"><a href="capítulo-3.html#intervalos-de-confianza-bootstrap"><i class="fa fa-check"></i><b>16.1</b> Intervalos de confianza bootstrap</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="capítulo-3.html"><a href="capítulo-3.html#introducci%C3%B3n-11"><i class="fa fa-check"></i><b>16.1.1</b> Introducción</a></li>
<li class="chapter" data-level="16.1.2" data-path="capítulo-3.html"><a href="capítulo-3.html#intervalos-de-confianza-est%C3%A1ndar"><i class="fa fa-check"></i><b>16.1.2</b> Intervalos de confianza estándar</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="capítulo-4.html"><a href="capítulo-4.html"><i class="fa fa-check"></i><b>17</b> Capítulo 4</a>
<ul>
<li class="chapter" data-level="17.1" data-path="capítulo-4.html"><a href="capítulo-4.html#intervalos-de-confianza-basados-en-tablas-bootstrap"><i class="fa fa-check"></i><b>17.1</b> Intervalos de confianza basados en tablas bootstrap</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="capítulo-4.html"><a href="capítulo-4.html#el-caso-de-la-t-de-student"><i class="fa fa-check"></i><b>17.1.1</b> El caso de la t de Student</a></li>
<li class="chapter" data-level="17.1.2" data-path="capítulo-4.html"><a href="capítulo-4.html#intervalos-de-confianza-basados-en-tablas-bootstrap-1"><i class="fa fa-check"></i><b>17.1.2</b> Intervalos de confianza basados en tablas bootstrap</a></li>
<li class="chapter" data-level="17.1.3" data-path="capítulo-4.html"><a href="capítulo-4.html#el-bootstrap-t-y-las-transformaciones"><i class="fa fa-check"></i><b>17.1.3</b> El bootstrap-t y las transformaciones</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="capítulo-5.html"><a href="capítulo-5.html"><i class="fa fa-check"></i><b>18</b> Capítulo 5</a>
<ul>
<li class="chapter" data-level="18.1" data-path="capítulo-5.html"><a href="capítulo-5.html#intervalos-de-confianza-basados-en-percentiles-bootstrap"><i class="fa fa-check"></i><b>18.1</b> Intervalos de confianza basados en percentiles bootstrap</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="capítulo-5.html"><a href="capítulo-5.html#intervalos-basados-en-percentiles-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>18.1.1</b> Intervalos basados en percentiles de una distribución normal</a></li>
<li class="chapter" data-level="18.1.2" data-path="capítulo-5.html"><a href="capítulo-5.html#los-intervalos-percentil"><i class="fa fa-check"></i><b>18.1.2</b> Los intervalos percentil</a></li>
<li class="chapter" data-level="18.1.3" data-path="capítulo-5.html"><a href="capítulo-5.html#ejercicios-2"><i class="fa fa-check"></i><b>18.1.3</b> Ejercicios</a></li>
<li class="chapter" data-level="18.1.4" data-path="capítulo-5.html"><a href="capítulo-5.html#pr%C3%A1cticas"><i class="fa fa-check"></i><b>18.1.4</b> Prácticas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="capítulo-6.html"><a href="capítulo-6.html"><i class="fa fa-check"></i><b>19</b> Capítulo 6</a>
<ul>
<li class="chapter" data-level="19.1" data-path="capítulo-6.html"><a href="capítulo-6.html#contraste-de-hip%C3%B3tesis-mediante-bootstrap"><i class="fa fa-check"></i><b>19.1</b> Contraste de hipótesis mediante bootstrap</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="capítulo-6.html"><a href="capítulo-6.html#introducci%C3%B3n-12"><i class="fa fa-check"></i><b>19.1.1</b> Introducción</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="capítulo-6.html"><a href="capítulo-6.html#elecci%C3%B3n-del-estad%C3%ADstico-de-test"><i class="fa fa-check"></i><b>19.2</b> Elección del estadístico de test</a></li>
<li class="chapter" data-level="19.3" data-path="capítulo-6.html"><a href="capítulo-6.html#c%C3%A1lculo-del-p-valor-1"><i class="fa fa-check"></i><b>19.3</b> Cálculo del p-valor</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="capítulo-6.html"><a href="capítulo-6.html#contrastes-de-hip%C3%B3tesis-bootstrap"><i class="fa fa-check"></i><b>19.3.1</b> Contrastes de hipótesis bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="capítulo-6.html"><a href="capítulo-6.html#ejemplo-1-comparaci%C3%B3n-de-medias"><i class="fa fa-check"></i><b>19.4</b> Ejemplo 1: Comparación de medias</a></li>
<li class="chapter" data-level="19.5" data-path="capítulo-6.html"><a href="capítulo-6.html#ejemplo-2-prueba-de-independencia"><i class="fa fa-check"></i><b>19.5</b> Ejemplo 2: Prueba de independencia</a>
<ul>
<li class="chapter" data-level="19.5.1" data-path="capítulo-6.html"><a href="capítulo-6.html#relaci%C3%B3n-entre-contrastes-de-hip%C3%B3tesis-intervalos-de-confianza-y-el-bootstrap"><i class="fa fa-check"></i><b>19.5.1</b> Relación entre contrastes de hipótesis, intervalos de confianza y el bootstrap</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="capítulo-7.html"><a href="capítulo-7.html"><i class="fa fa-check"></i><b>20</b> Capítulo 7</a>
<ul>
<li class="chapter" data-level="20.1" data-path="capítulo-7.html"><a href="capítulo-7.html#validez-de-los-m%C3%A9todos-bootstrap"><i class="fa fa-check"></i><b>20.1</b> Validez de los métodos bootstrap</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="capítulo-7.html"><a href="capítulo-7.html#introducci%C3%B3n-13"><i class="fa fa-check"></i><b>20.1.1</b> Introducción</a></li>
<li class="chapter" data-level="20.1.2" data-path="capítulo-7.html"><a href="capítulo-7.html#teorema-central-del-l%C3%ADmite-bootstrap"><i class="fa fa-check"></i><b>20.1.2</b> Teorema central del límite bootstrap</a></li>
<li class="chapter" data-level="20.1.3" data-path="capítulo-7.html"><a href="capítulo-7.html#validaci%C3%B3n-del-bootstrap-mediante-simulaci%C3%B3n"><i class="fa fa-check"></i><b>20.1.3</b> Validación del bootstrap mediante simulación</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="capítulo-7.html"><a href="capítulo-7.html#bibliograf%C3%ADa"><i class="fa fa-check"></i><b>20.2</b> Bibliografía</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografia.html"><a href="bibliografia.html"><i class="fa fa-check"></i>Bibliografia</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferencia Estadistica</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="métodos-de-computación-intensiva-el-bootstrap" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">Capítulo 14</span> Métodos de computación intensiva: El <em>Bootstrap</em><a href="métodos-de-computación-intensiva-el-bootstrap.html#m%C3%A9todos-de-computaci%C3%B3n-intensiva-el-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introducción-precisión-de-un-estimador" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Introducción: Precisión de un estimador<a href="métodos-de-computación-intensiva-el-bootstrap.html#introducci%C3%B3n-precisi%C3%B3n-de-un-estimador" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los métodos bootstrap que se expondrán a continuación son un conjunto de técnicas introducidas por Bradley Efron de la universidad de Stanford a finales de los años 70 ([7,9,12]) y que se han revelado como una poderosa herramienta de gran utilidad en diversos campos de la estadística.</p>
<div id="ejemplos-de-introducción" class="section level3 hasAnchor" number="14.1.1">
<h3><span class="header-section-number">14.1.1</span> Ejemplos de introducción<a href="métodos-de-computación-intensiva-el-bootstrap.html#ejemplos-de-introducci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Empezaremos por considerar algunas situaciones aparentemente sencillas en donde se nos presentarán algunos problemas difíciles de resolver mediante las técnicas “clásicas” de la inferencia estadística (convendremos en denominar así al conjunto de métodos paramétricos y no paramétricos que constituyen el soporte usual de la inferencia estadística).</p>
<div id="problema-1-tiempo-de-supervivencia" class="section level4 hasAnchor" number="14.1.1.1">
<h4><span class="header-section-number">14.1.1.1</span> Problema 1: Tiempo de supervivencia<a href="métodos-de-computación-intensiva-el-bootstrap.html#problema-1-tiempo-de-supervivencia" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Supongamos que estamos interesados en estudiar el tiempo de vida, en años, de unos enfermos después de un trasplante de riñón. El parámetro que nos interesa estimar es el tiempo medio de vida tras la intervención. Para estimarlo podemos utilizar la media muestral, <span class="math inline">\(\bar{X}\)</span> o la mediana muestral <span class="math inline">\(\widehat{\operatorname{Med}}(X)\)</span>. Los datos de que disponemos <span class="math inline">\((n=9)\)</span> son los siguientes:</p>
<p>Tabla 1
Tiempos de supervivencia
| .14 | .18 | .25 | .26 | .37 |
| :— | :— | :— | :— | :— |
| .43 | .51 | .61 | .71 | |</p>
<p>El valor de los estimadores seleccionados, calculados sobre la muestra es:</p>
<ul>
<li>Media muestral, <span class="math inline">\(\bar{X}=0,384\)</span>,</li>
<li>Mediana muestral, <span class="math inline">\(\widehat{\operatorname{Med}}(X)=0,37\)</span></li>
</ul>
</div>
<div id="problema-2-coeficiente-de-correlación" class="section level4 hasAnchor" number="14.1.1.2">
<h4><span class="header-section-number">14.1.1.2</span> Problema 2: Coeficiente de correlación<a href="métodos-de-computación-intensiva-el-bootstrap.html#problema-2-coeficiente-de-correlaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Disponemos de las notas de C.O.U. y de selectividad de un grupo de 15 alumnos de primer curso de la universidad y deseamos determinar cuán relacionadas se hallan las dos. Puesto que se trata de medidas numéricas podemos medir el grado de relación entre ambas mediante el coeficiente de correlación de Pearson:
<span class="math inline">\(\hat{\rho}=\frac{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right)}{\sqrt{\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}} \sqrt{\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}\right)^{2}}}, \quad\left(\bar{X}=\sum_{i=1}^{n} X_{i} / n, \bar{Y}=\sum_{i=1}^{n} Y_{i} / n\right)\)</span>.
La muestra de 15 estudiantes que utilizaremos para el estudio es la siguiente:</p>
<p>Tabla 2
Notas de COU y de selectividad de 15 estudiantes
| Estudiante núm: | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |
| :— | :—: | :—: | :—: | :—: | :—: | :—: | :—: | :—: |
| Selectividad | 5.76 | 6.35 | 5.58 | 5.78 | 6.66 | 5.8 | 5.55 | 6.61 |
| COU | 6.78 | 6.6 | 5.62 | 6.06 | 6.88 | 6.14 | 6 | 6.86 |
| Estudiante núm: | 9 | 10 | 11 | 12 | 13 | 14 | 15 | |
| Selectividad | 6.51 | 6.05 | 6.53 | 5.75 | 5.45 | 5.72 | 5.94 | |
| COU | 6.72 | 6.26 | 6.24 | 5.48 | 5.52 | 5.76 | 5.92 | |</p>
<p>El valor del coeficiente de correlación sobre esta muestra es:</p>
<p><span class="math display">\[
\hat{\rho}=0,776
\]</span></p>
</div>
</div>
<div id="estimación-del-error-estándar-soluciones-clásica-y-bootstrap" class="section level3 hasAnchor" number="14.1.2">
<h3><span class="header-section-number">14.1.2</span> Estimación del error estándar: soluciones clásica y bootstrap<a href="métodos-de-computación-intensiva-el-bootstrap.html#estimaci%C3%B3n-del-error-est%C3%A1ndar-soluciones-cl%C3%A1sica-y-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez calculadas las estimaciones sobre la muestra suele interesar disponer de alguna medida de su fiabilidad.</p>
<p>En el caso de la media muestral podemos calcular su error estándar</p>
<p><span class="math display">\[
\hat{\sigma}_{\bar{X}}=\frac{\sqrt{\sum\left(X_{i}-\bar{X}\right)^{2}}}{n}
\]</span></p>
<p>pero para la mediana y el coeficiente de correlación, no existe una fórmula de validez tan general -es decir rápida de calcular y libre de suposiciones sobre la distribución de la variable o variables- como la anterior.</p>
<p>Antes de pasar a buscar una solución general para el tipo de problema planteado vamos a establecer una formalización que nos permita tratar ambas situaciones de forma unificada:</p>
<ul>
<li>Partimos de unos datos, es decir una muestra de una variable aleatoria, unidimensional o multidimensional, que sigue una distribución <span class="math inline">\(F\)</span>.</li>
</ul>
<p><span class="math display">\[
\mathbf{X}=\left(X_{1}, X_{2}, \ldots, X_{n}\right), \quad \mathbf{X} \sim F
\]</span></p>
<ul>
<li>Existe un parámetro de interés <span class="math inline">\(\theta\)</span>, que, como en los ejemplos anteriores, puede ser el valor medio, la mediana o el coeficiente de correlación poblacionales. (Estamos pues suponiendo un modelo estadístico paramétrico <span class="math inline">\(\left(\Omega, \mathcal{A},\left\{P_{\theta}, \theta \in \Theta\right\}\right)\)</span> o abreviadamente <span class="math inline">\(\mathbf{X} \sim F_{\theta}, \theta \in \Theta\)</span> ).</li>
<li>Deseamos estimar <span class="math inline">\(\theta\)</span> a partir de la muestra.</li>
</ul>
<p>En las circunstancias anteriores se nos plantean usualmente dos cuestiones básicas:</p>
<ol style="list-style-type: decimal">
<li>Qué estadístico <span class="math inline">\(\hat{\theta}(\mathbf{X})\)</span> resulta el (más) adecuado para estimar <span class="math inline">\(\theta\)</span> ?</li>
<li>Qué tan “preciso” es <span class="math inline">\(\hat{\theta}\)</span> como estimador de <span class="math inline">\(\theta\)</span> ?</li>
</ol>
<p>Una primera aproximación para responder a estas dos preguntas consiste en acudir a la teoría clásica de la estimación máximo-verosímil, que sugiere como solución a la primera pregunta el uso del estimador máximo-verosímil de <span class="math inline">\(\theta\)</span>, llamémosle <span class="math inline">\(\hat{\theta}_{M V}\)</span>.</p>
<p>Bajo condiciones bastante generales esta teoría establece que el estimador máximo verosímil, <span class="math inline">\(\hat{\theta}_{M V}\)</span>, es asintóticamente normal de media igual al valor del parámetro <span class="math inline">\(\theta\)</span> y de varianza asintótica <span class="math inline">\(\frac{1}{I(\theta)}\)</span>, donde <span class="math inline">\(I(\theta)\)</span> representa la información de Fisher del modelo.</p>
<p><span class="math display">\[
\hat{\theta}_{M V} \simeq A N\left(\theta, \frac{1}{I(\theta)}\right)
\]</span></p>
<p>Como es habitual en estos casos error estándar de <span class="math inline">\(\hat{\theta}_{M V}\)</span> se puede aproximar, en muestras grandes, por</p>
<p><span class="math display">\[
\hat{\sigma}_{\hat{\theta}_{M V}} \simeq \frac{1}{\sqrt{I(\hat{\theta})}}
\]</span></p>
<p>donde <span class="math inline">\(I(\hat{\theta})\)</span> suele denominarse información observada del modelo, frente a <span class="math inline">\(I(\theta)\)</span> que se denomina al hacer esta distinción, información esperada.</p>
<p>La aplicación del método de la máxima verosimilitud al caso de <span class="math inline">\(\theta= E_{F}(X)\)</span> nos conduce a</p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta}_{M V} &amp; =\bar{X} \\
\hat{\sigma}_{\hat{\theta}_{M V}} &amp; =\sqrt{\frac{1}{n^{2}} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}}
\end{aligned}
\]</span></p>
<p>En el caso de la mediana y el coeficiente de correlación la respuesta no es tan inmediata. Antes de considerar el enfoque bootstrap</p>
</div>
<div id="estimadores-de-substitución-plug-in-y-funcionales-estadísticos" class="section level3 hasAnchor" number="14.1.3">
<h3><span class="header-section-number">14.1.3</span> Estimadores de substitución (“plug-in”) y Funcionales estadísticos<a href="métodos-de-computación-intensiva-el-bootstrap.html#estimadores-de-substituci%C3%B3n-plug-in-y-funcionales-estad%C3%ADsticos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="la-distribución-muestral-o-empírica" class="section level4 hasAnchor" number="14.1.3.1">
<h4><span class="header-section-number">14.1.3.1</span> La distribución muestral (o empírica)<a href="métodos-de-computación-intensiva-el-bootstrap.html#la-distribuci%C3%B3n-muestral-o-emp%C3%ADrica" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Sea <span class="math inline">\(\left(x_{1}, x_{2}, \ldots, x_{n}\right)\)</span> una realización de una muestra aleatoria simple <span class="math inline">\(\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span> de una v.a. <span class="math inline">\(X\)</span>. Podemos asociar una distribución a las observaciones <span class="math inline">\(\left(x_{1}, x_{2}, \ldots, x_{n}\right)\)</span> con la pretensión de que, en tanto que la muestra “emula” a la población, <span class="math inline">\(X\)</span>, la distribución de la muestra <span class="math inline">\(F_{n}(x)\)</span> emule la distribución de la población. Esta distribución se denomina distribución empírica o distribució muestral y se representa por:</p>
<p><span class="math display">\[
F_{n}(x)=F^{*}(x)=F_{n}^{*}(x)=\frac{\sharp d^{\prime} \text { elementos muestrales }}{n}
\]</span></p>
<p>En la práctica se construye ordenando la muestra</p>
<p><span class="math display">\[
x_{1}, x_{2}, \ldots, x_{n} \longrightarrow x_{(1)}&lt;x_{(2)} \ldots&lt;x_{(n)}
\]</span></p>
<p>definiendo:</p>
<p><span class="math display">\[
F_{n}(x)=\left\{\begin{array}{ll}
0 &amp; \text { si } x&lt;x_{(1)} \\
\frac{k}{n} &amp; \text { si } x_{(k)} \leq x&lt;x_{(k+1)} \\
1 &amp; \text { si } x \geq x_{(n)}
\end{array}\right\}
\]</span></p>
<p>Ejemplo 1 Extraemos una muestra y obtenemos:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x_{1}\)</span></th>
<th align="left"><span class="math inline">\(x_{2}\)</span></th>
<th align="left"><span class="math inline">\(x_{3}\)</span></th>
<th align="center"><span class="math inline">\(x_{4}\)</span></th>
<th align="left"><span class="math inline">\(x_{5}\)</span></th>
<th align="center"><span class="math inline">\(x_{6}\)</span></th>
<th align="left"><span class="math inline">\(x_{7}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">5.1</td>
<td align="left">3.4</td>
<td align="left">1.2</td>
<td align="center">17.6</td>
<td align="left">2.1</td>
<td align="center">16.4</td>
<td align="left">4.3</td>
</tr>
</tbody>
</table>
<p>Una vez ordenada queda:</p>
<p><span class="math display">\[
\begin{array}{lllllll}
x_{(3)} &amp; x_{(5)} &amp; x_{(2)} &amp; x_{(7)} &amp; x_{(1)} &amp; x_{(6)} &amp; x_{(4)}
\end{array}
\]</span></p>
<p>y si hacemos la representación gráfica:</p>
<p>La distribución muestral refleja exclusivamente los valores contenidos en la muestra y por lo tanto no se relaciona directamente ni con la distribución (conjunta) de la muestra <span class="math inline">\(G\left(\left(X_{1}, X_{2}, \ldots, X_{n}\right)\right)\)</span> ni con la distribución de la población: <span class="math inline">\(F\)</span>. Sin embargo, como es razonable esperar <span class="math inline">\(F_{n}(x)\)</span> proporciona una imagen aproximada de la distribución de la población de donde se ha extraido la muestra. Pueden repasarse las propiedades de la distribución empírica en Velez y García (1993,[23]).</p>
</div>
<div id="estimadores-de-substitución" class="section level4 hasAnchor" number="14.1.3.2">
<h4><span class="header-section-number">14.1.3.2</span> Estimadores de substitución<a href="métodos-de-computación-intensiva-el-bootstrap.html#estimadores-de-substituci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El principio de substitución es un método de estimación, o más bien una idea subyacente en algunos métodos de estimación. El estimador de substitución de un parámetro <span class="math inline">\(\theta=T(F)\)</span> se define como</p>
<p><span class="math display">\[
\hat{\theta}=T\left(F_{n}\right) .
\]</span></p>
<p>En otras palabras, estimamos la función <span class="math inline">\(\theta=T(F)\)</span> por la misma función de la función de distribución empírica, <span class="math inline">\(F_{n}\)</span>, o, en general, por la misma función de algún estimador de la función de distribución, <span class="math inline">\(\hat{F}\)</span>.</p>
<p>Un enfoque algo más formal que el anterior consiste en introducir los el concepto de funcional estadístico. Este concepto ha resultado de gran utilidad en diversas áreas de la estadística -como el de la robustez- y que permite
utilizar una notación que arroja considerable luz sobre el significado del bootstrap .</p>
<p>Consideremos la situación introducida en el párrafo anterior donde se tiene una muestra de observaciones iid de una cierta función de distribución <span class="math inline">\(F\)</span>, siendo <span class="math inline">\(F_{n}\)</span> la función de distribución empírica de la muestra. Como hemos indicado, muchos estadísticos importantes pueden representarse como funciones de la función de distribución empírica, llamémosles <span class="math inline">\(T\left(F_{n}\right)\)</span>. Obsérvese que esto significa que <span class="math inline">\(T\)</span> es una función de algún conjunto <span class="math inline">\(\mathcal{F}\)</span> de funciones de distribución -al que pertenecen <span class="math inline">\(F_{n}\)</span> y <span class="math inline">\(F\)</span> - en <span class="math inline">\(\mathbf{R}\)</span> :</p>
<p><span class="math display">\[
\begin{aligned}
T: \mathcal{F} &amp; \longrightarrow \mathbf{R} \\
G &amp; \longrightarrow T(G) .
\end{aligned}
\]</span></p>
<p>(Es habitual denominar funcional a aquellas funciones en que el conjunto origen es, a su vez, un conjunto de funciones).</p>
<p>Por ejemplo para la varianza de <span class="math inline">\(F, \sigma^{2}\)</span>, el funcional relevante es:</p>
<p><span class="math display">\[
T(F)=\int\left[x-\int x d F(x)\right]^{2} d F(x)
\]</span></p>
<p>donde la integral <span class="math inline">\(\int() d F(x)\)</span> se puede tomar en el sentido de Riemann-Stieltjes, con lo que <span class="math inline">\(T\left(F_{n}\right)\)</span> es la varianza muestral</p>
<p><span class="math display">\[
T\left(F_{n}\right)=S^{2}=1 / n \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}
\]</span></p>
<p>La idea central del uso de estimadores que son funcionales estadísticos y que, por tanto se basan en el principio de substitución es la siguiente: dado que <span class="math inline">\(F_{n}\)</span> es un estimador razonable de <span class="math inline">\(F\)</span> puede esperarse que <span class="math inline">\(T\left(F_{n}\right)\)</span> se relacione con <span class="math inline">\(T(F)\)</span> de forma similar siempre que el funcional <span class="math inline">\(T(\cdot)\)</span> se comporte “suficientemente bien” en una entorno de <span class="math inline">\(F\)</span>. Esta idea conduce a la consideración de <span class="math inline">\(F\)</span> como un punto en una colección <span class="math inline">\(\mathcal{F}\)</span> de funciones de distribución y a nociones de continuidad, diferenciabilidad y otras propiedades de regularidad que no discutiremos aquí dado que escapan de nuestro objetivo. Para un estudio de los funcionales estadísticos puede consultarse p.ej. Serfling (1980, [20]).</p>
<p>Veamos la utilidad de este enfoque en el problema que nos ocupa:</p>
<ul>
<li>Como hemos indicado en la sección anterior nuestro objetivo es estimar algún parámetro <span class="math inline">\(\theta\)</span>, que generalmente podrá expresarse como <span class="math inline">\(\theta(F)\)</span> siendo <span class="math inline">\(F\)</span> la función de distribución de cada <span class="math inline">\(X_{i}\)</span> en <span class="math inline">\(\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span>. Por ejemplo:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; \theta=E_{F}(X)=\theta(F) \\
&amp; \theta=\operatorname{Med}(X)=\left\{m: P_{F}(X \leq m)=1 / 2\right\}=\theta(F)
\end{aligned}
\]</span></p>
<ul>
<li>Para estimar <span class="math inline">\(\theta\)</span> utilizaremos un estimador de substitución <span class="math inline">\(\hat{\theta}\)</span> ( <span class="math inline">\(\hat{\theta}\)</span> es un funcional de <span class="math inline">\(F_{n}\)</span> ), es decir <span class="math inline">\(\hat{\theta}=\theta\left(F_{n}\right)\)</span>. Por ejemplo:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
&amp; \hat{\theta}=\bar{X}=\int X d F_{n}(x)=\frac{1}{n} \sum_{i=1}^{n} x_{i}=\theta\left(F_{n}\right) \\
&amp; \hat{\theta}=\widehat{\operatorname{Med}}(X)=\left\{m: \frac{\# x_{i} \leq m}{n}=1 / 2\right\}=\theta\left(F_{n}\right)
\end{aligned}
\]</span></p>
<ul>
<li>Centrándonos en <span class="math inline">\(\hat{\theta}=\bar{X}\)</span> podemos ver como la medida de precisión que deseamos obtener, su error estándar, también es un funcional de <span class="math inline">\(F\)</span> :</li>
</ul>
<p><span class="math display">\[
\sigma_{\bar{X}}=\frac{\sigma(X)}{\sqrt{n}}=\frac{\sqrt{\int\left[x-\int x d F(x)\right]^{2} d F(x)}}{\sqrt{n}}=\sigma_{\bar{X}}(F)
\]</span></p>
<p>y que el estimador de su varianza es el mismo funcional aplicado sobre <span class="math inline">\(F_{n}\)</span> es decir:</p>
<p><span class="math display">\[
\hat{\sigma}_{\bar{X}}=\frac{\hat{\sigma}(X)}{\sqrt{n}}=\frac{\sqrt{1 / n \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}}}{\sqrt{n}}=\sigma_{\bar{X}}\left(F_{n}\right) .
\]</span></p>
<p>Vemos pues que una forma de obtener una estimación del error estándar de un estimador, <span class="math inline">\(\hat{\sigma}_{\hat{\theta}}\)</span> consiste en substituir <span class="math inline">\(F\)</span> por <span class="math inline">\(F_{n}\)</span> en la expresión del error estándar “poblacional” de <span class="math inline">\(\hat{\theta}, \sigma_{\hat{\theta}}=\sigma_{\hat{\theta}}(F)\)</span>, siempre que ésta sea conocida. De forma esquemática el proceso consistirá en:</p>
<p><span class="math display">\[
\sigma_{\hat{\theta}}=\sigma_{\hat{\theta}}(F) \Longrightarrow \sigma_{\hat{\theta}}\left(F_{n}\right)=\widehat{\sigma}_{\hat{\theta}} .
\]</span></p>
<p>El método anterior presenta el inconveniente obvio de que cuando la forma (el funcional) de <span class="math inline">\(\sigma_{\hat{\theta}}(F)\)</span> es desconocida no es posible realizar la substitución de <span class="math inline">\(F\)</span> por <span class="math inline">\(F_{n}\)</span>. Este es por ejemplo el caso del error estándar de la mediana o el coeficiente de correlación. En el apartado siguiente se presenta el método bootstrap a partir del cual es posible realizar la aproximación que nos interesa</p>
<p><span class="math display">\[
\hat{\sigma}_{\hat{\theta}} \simeq \sigma_{\hat{\theta}}\left(F_{n}\right)
\]</span></p>
<p>sin que sea necesario conocer la forma de <span class="math inline">\(\sigma_{\hat{\theta}}(F)\)</span>.</p>
</div>
</div>
<div id="el-bootstrap" class="section level3 hasAnchor" number="14.1.4">
<h3><span class="header-section-number">14.1.4</span> El bootstrap<a href="métodos-de-computación-intensiva-el-bootstrap.html#el-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="estimación-de-la-distribución-en-el-muestreo" class="section level4 hasAnchor" number="14.1.4.1">
<h4><span class="header-section-number">14.1.4.1</span> Estimación de la distribución en el muestreo<a href="métodos-de-computación-intensiva-el-bootstrap.html#estimaci%C3%B3n-de-la-distribuci%C3%B3n-en-el-muestreo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En la sección anterior se ha propuesto el principio de substitución para estimar el error estándar de un estimador, es decir:</p>
<p><span class="math display">\[
\widehat{\sigma_{\hat{\theta}}(F)}=\sigma_{\hat{\theta}}(\hat{F}),
\]</span></p>
<p>supuesta conocida la forma del funcional <span class="math inline">\(\sigma_{\hat{\theta}}(F)\)</span> y dado un estimador <span class="math inline">\(\hat{F}\)</span> de <span class="math inline">\(F\)</span>, que suele ser la función de distribución empírica <span class="math inline">\(F_{n}\)</span>.</p>
<p>Sea <span class="math inline">\(\mathbf{X} \stackrel{\text { i.i.d. }}{\sim} F\)</span> una muestra aleatoria simple y <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)\)</span> una función medible de la muestra que por tanto depende también de <span class="math inline">\(F\)</span> y de <span class="math inline">\(n\)</span>. El estimador <span class="math inline">\(\hat{\theta}\)</span>, considerado hasta el momento, es un caso particular de tal función. Llamemos <span class="math inline">\(H_{F, n}(x)\)</span> a la función de distribución de <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)\)</span>, es decir:</p>
<p><span class="math display">\[
H_{F, n}(x)=P\left\{\mathcal{R}_{n}(\mathbf{X}, F) \leq x\right\}
\]</span></p>
<p>En general nos referiremos a ella simplemente como <span class="math inline">\(H_{F}(x)\)</span>, omitiendo la dependencia de <span class="math inline">\(n\)</span>.</p>
<p>Cuando <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)=\hat{\theta}\)</span> entonces el error estándar de <span class="math inline">\(\hat{\theta}\)</span> coincide con la desviación típica de <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)\)</span> es decir:</p>
<p><span class="math display">\[
\sigma_{F}(\hat{\theta})=\sqrt{\operatorname{var}_{H}\left(\mathcal{R}_{n}(\mathbf{X}, F)\right)}
\]</span></p>
<p>Una alternativa al conocimiento de la forma de <span class="math inline">\(\sigma_{\hat{\theta}}(F)\)</span> consiste en estimar directamente la distribución <span class="math inline">\(H_{F}(x)\)</span> y tomar su varianza como un estimador de <span class="math inline">\(\operatorname{var}_{H}\left(\mathcal{R}_{n}(\mathbf{X}, F)\right)\)</span>, es decir:</p>
<p><span class="math display">\[
\begin{aligned}
P_{F}\left\{\mathcal{R}_{n}(\mathbf{X}, F) \leq x\right\}=H_{F}(x) &amp; \doteq H_{F_{n}}(x)=P_{F_{n}}\left\{\mathcal{R}_{n}\left(\mathbf{X}^{*}, F_{n}\right) \leq x\right\} \\
\sigma_{\hat{\theta}}^{2}(F)=\operatorname{var}_{H_{F}}(\hat{\theta}) &amp; \doteq \operatorname{var}_{H_{F_{n}}}(\hat{\theta})=\sigma_{\hat{\theta}}^{2}\left(F_{n}\right)
\end{aligned}
\]</span></p>
<p>La notación <span class="math inline">\(\mathbf{X}^{*}\)</span> hace referencia al hecho de que la muestra proviene de la distribución <span class="math inline">\(F_{n}\)</span> en vez de <span class="math inline">\(F\)</span>.</p>
<ul>
<li><span class="math inline">\(\mathbf{X}^{*}\)</span> recibe el nombre de muestra bootstrap o remuestra.</li>
<li>La distribución <span class="math inline">\(H_{F_{n}}(x)\)</span> se denominará la distribución bootstrap de <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)\)</span>.</li>
</ul>
<p>El principio bootstrap consistirá en utilizar la distribución bootstrap como base para realizar inferencias sobre <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)\)</span>.</p>
<p>Esta aproximación resulta muy atractiva de entrada, en tanto que permite prescindir de suposiciones previas -como la normalidad de los datos- para hacer inferencia. Existe sin embargo un problema importante y es que, en la mayoria de los casos de interés, no es posible obtener analíticamente la distribución bootstrap de <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)\)</span>, con lo que aparentemente, el método bootstrap no tendrá ningún interés práctico.</p>
<p>Resulta sin embargo que, en muchos casos, es posible aproximar de forma, razonablemente buena la distribución bootstrap mediante simulación de Monte Carlo. Esto determina que, en la práctica, la situación haya sido la contraria de la descrita en el parrafo anterior, es decir el método ha adquirido una gran popularidad dada la posibilidad que ofrece de realizar inferencia de forma relativamente automática.</p>
<p>Ejemplo 1 Sea <span class="math inline">\(X\)</span> una variable discreta con distribución de Bernouilli,</p>
<p><span class="math display">\[
X \sim b(1, p), \quad\left\{\begin{array}{l}
P(X=1)=\theta \\
P(X=0)=1-\theta
\end{array}\right.
\]</span></p>
<p>Sea <span class="math inline">\(\theta(F)=P(X=1)\)</span> el parámetro de interés cuyo estimador de substitución es <span class="math inline">\(\widehat{\theta(F)}=\theta\left(F_{n}\right)=\bar{X}\)</span>. Sea</p>
<p><span class="math display">\[
\mathcal{R}_{n}(\mathbf{X}, F)=\bar{X}-\hat{\theta}(F)
\]</span></p>
<p>el error de estimación. Dada una muestra <span class="math inline">\(\mathbf{x}=\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span> la probabilidat, condicional, de que en una muestra de <span class="math inline">\(F_{n}, \mathbf{x}^{*}\)</span>, un valor valga 1 será <span class="math inline">\(\bar{x}\)</span> :</p>
<p><span class="math display">\[
P\left(X_{i}^{*}=1\right)=\bar{x} \Leftrightarrow X^{*} \sim b(1, \bar{x}) .
\]</span></p>
<p>Esto permitirá estimar <span class="math inline">\(\mathcal{R}_{n}(\mathbf{X}, F)=\bar{X}-\hat{\theta}(F)\)</span> por</p>
<p><span class="math display">\[
\mathcal{R}_{n}\left(\mathbf{X}^{*}, F_{n}\right)=\bar{X}^{*}-\hat{\theta}\left(F_{n}\right)=\bar{X}^{*}-\bar{x}
\]</span></p>
<p>El cálculo exacto de las características de la distribución bootstrap de <span class="math inline">\(\mathcal{R}_{n}\left(\mathbf{X}^{*}, F_{n}\right)\)</span> puede ahora realizarse, simplemente teniendo en cuenta que, para cualquier remuestra, el valor <span class="math inline">\(\bar{x}\)</span> es fijo: entre las remuestras <span class="math inline">\(\bar{x}\)</span> hace el papel de parámetro que correspondia a <span class="math inline">\(\theta\)</span> entre las muestras. Tenemos pues que, si denominamos <span class="math inline">\(\operatorname{var}_{B}\left(\mathcal{R}^{*}\right)\)</span> a la varianza bajo la distribución bootstrap de <span class="math inline">\(\mathcal{R}_{n}\left(\mathbf{X}^{*}, F_{n}\right)\)</span> :</p>
<p><span class="math display">\[
\begin{aligned}
\operatorname{var}_{H_{n}}\left(\mathcal{R}_{n}\left(\mathbf{X}^{*}, F_{n}\right)\right) &amp; =\operatorname{var}_{B}\left(\mathcal{R}^{*}\right)=\operatorname{var}_{B}\left(\bar{X}^{*}-\bar{x}\right)=\operatorname{var}_{B}\left(\bar{X}^{*}\right)+0= \\
&amp; =n \frac{\bar{x}}{n} \frac{1-\bar{x}}{n}=\frac{\bar{x}(1-\bar{x})}{n}
\end{aligned}
\]</span></p>
<p>El ejemplo anterior refleja una situación, poco habitual, en que es posible obtener el estimador bootstrap de la varianza, analíticamente. Otro ejemplo, correspondiente a la distribución bootstrap de la mediana se encuentra en Efron ([9]). Otra forma de plantear el estudio de la distribución bootstrap consiste en construirla por enumeración de todas las muestras posibles. Excepto en los casos en que el tamaño de la muestra es muy pequeño el problema es difícil de abordar computacionalmente. Holmes ([14]) discute brevemente este problema en <a href="http://www-stat.stanford.edu/~susan/courses/s208/node12.html" class="uri">http://www-stat.stanford.edu/~susan/courses/s208/node12.html</a>.</p>
</div>
<div id="muestreo-bootstrap-de-monte-carlo" class="section level4 hasAnchor" number="14.1.4.2">
<h4><span class="header-section-number">14.1.4.2</span> Muestreo bootstrap de Monte Carlo<a href="métodos-de-computación-intensiva-el-bootstrap.html#muestreo-bootstrap-de-monte-carlo" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como se ha discutido en la sección anterior la idea básica del bootstrap consiste en estimar el error estándar - u otra característica de la distribución-
a partir de muestras bootstrap de <span class="math inline">\(F_{n}\)</span>, que se obtienen substituyendo <span class="math inline">\(F_{n}\)</span> por <span class="math inline">\(F\)</span> en la etapa de muestreo (en vez de hacerlo en la cálculo de <span class="math inline">\(\sigma_{\hat{\theta}}(F)\)</span> ). Es decir en vez de realizar el muestreo:</p>
<p><span class="math display">\[
F \xrightarrow{\text { m.a.s. }} \mathbf{X}=\left(X_{1}, X_{2}, \ldots, X_{n}\right)
\]</span></p>
<p>se hace</p>
<p><span class="math display">\[
F_{n} \xrightarrow{\text { m.a.s. }} \mathrm{X}^{*}=\left(X_{1}^{*}, X_{2}^{*}, \ldots, X_{n}^{*}\right) .
\]</span></p>
<p>Esto significa que muestreamos extrayendo muestras de tamaño <span class="math inline">\(n\)</span> de <span class="math inline">\(F_{n}\)</span>, es decir que <span class="math inline">\(\mathrm{X}^{*}=\left(X_{1}^{*}, X_{2}^{*}, \ldots, X_{n}^{*}\right)\)</span> es una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> obtenida con reemplazamiento de la muestra original ( <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> ).</p>
<p>La muestra resultante del muestreo bootstrap, <span class="math inline">\(\mathbf{X}^{*}\)</span>, recibe el nombre de muestra bootstrap o remuestra.</p>
<p>El cálculo del error estándar a partir de las remuestras debe de aproximarse habitualmente mediante un algoritmo de Monte Carlo, dado que no suele conocerse explícitamente la forma de la distribución bootstrap . Este algoritmo consiste en:</p>
<ol style="list-style-type: decimal">
<li>Extraer <span class="math inline">\(B\)</span> muestras, <span class="math inline">\(\mathbf{x}_{1}^{*}, \mathbf{x}_{2}^{*}, \ldots, \mathbf{x}_{B}^{*}\)</span> de <span class="math inline">\(F_{n}\)</span></li>
<li>Calcular <span class="math inline">\(\hat{\theta}\left(\mathrm{x}_{1}^{*}\right), \ldots, \hat{\theta}\left(\mathrm{x}_{B}^{*}\right)\)</span></li>
<li>Sea</li>
</ol>
<p><span class="math display">\[
\overline{\hat{\theta}} \equiv \frac{1}{B} \sum_{b=1}^{B} \hat{\theta}\left(\mathrm{x}_{b}^{*}\right)
\]</span></p>
<p>entonces el el error estándar bootstrap de <span class="math inline">\(\hat{\theta}, \sigma_{B}(\hat{\theta})\)</span> se puede aproximar por:</p>
<p><span class="math display">\[
\hat{\sigma}_{B}(\hat{\theta})=\sqrt{\frac{1}{(B-1)} \sum_{b=1}^{B}\left(\hat{\theta}\left(\mathbf{x}_{\mathbf{i}}^{*}\right)-\overline{\hat{\theta}}\right)^{2}}
\]</span></p>
<p>Cuando</p>
<p><span class="math display">\[
B \rightarrow \infty \quad \Longrightarrow \hat{\sigma}_{B}(\hat{\theta}) \rightarrow \hat{\sigma}_{\infty}(\hat{\theta})=\sigma_{B}(\hat{\theta})=\hat{\sigma}_{\hat{\theta}}\left(F_{n}\right)
\]</span></p>
</div>
</div>
<div id="ejemplo-1-continuación" class="section level3 hasAnchor" number="14.1.5">
<h3><span class="header-section-number">14.1.5</span> Ejemplo 1 (continuación)<a href="métodos-de-computación-intensiva-el-bootstrap.html#ejemplo-1-continuaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como hemos visto anteriormente el muestreo bootstrap equivale a tomar muestras con reemplazamiento de la muestra original -es decir extraer <span class="math inline">\(n\)</span> valores de la muestra original con probabilidad <span class="math inline">\(1 / n\)</span> para cada uno de ellossobre las que se calcula el estimador del parámetro de interés. En los listados
siguientes <span class="math inline">\({ }^{1}\)</span> se puede ver el aspecto de las primeras remuestras de un muestreo bootstrap con <span class="math inline">\(B=100\)</span> y el valor del parámetro calculado sobre cada una de ellas.</p>
<p>Ejemplo núm 1: Muestra inicial de 9 tiempos de supervivencia y 5 remuestras extraídas de ella.</p>
<pre><code>Muestra original
Datos para calcular el error estándar bootstrap de la mediana.
    0.14 0.18 0.25 0.26 0.37 0.44 0.51 0.61 0.71
El valor del parámetro sobre la muestra original es: 0.37
Remuestra numero: 1
    0.14 0.26 0.37 0.44 0.51 0.51 0.61 0.61 0.71
El valor del parámetro sobre la remuestra n : 1 es: 0.51
Remuestra numero: 2
    0.14 0.18 0.18 0.26 0.37 0.61 0.71 0.71 0.71
El valor del parámetro sobre la remuestra n : 2 es: 0.37
Remuestra numero: 3
    0.18 0.18 0.18 0.25 0.26 0.26 0.26 0.37 0.44
El valor del parámetro sobre la remuestra n : 3 es: 0.26
Remuestra numero: 4
    0.14 0.18 0.18 0.25 0.26 0.44 0.51 0.51 0.71
El valor del parámetro sobre la remuestra n : 4 es: 0.26
Remuestra numero: 5
    0.18 0.26 0.26 0.26 0.37 0.37 0.44 0.51 0.71
El valor del parámetro sobre la remuestra n : 5 es: 0.37</code></pre>
<p>Ejemplo núm 2: Muestra de notas de COU y selectividad de 15 estudiantes de primer curso de universidad</p>
<p>[^0]Un hecho que merece la pena comentar, en tanto que en una primera aproximación puede generar dudas, es como se realiza el remuestreo en variables bidimensionales o <span class="math inline">\(k\)</span>-dimensionales. La respuesta es, evidentemente, que en una muestra de tamaño <span class="math inline">\(n\)</span> deben sacarse <span class="math inline">\(n\)</span> pares, en variables bidimensionales, o <span class="math inline">\(k\)</span>-tuplas, en variables <span class="math inline">\(k\)</span>-dimensionales, con reemplazamiento, manteniendo siempre juntos las coordenadas originales en cada punto.</p>
<pre><code>Muestra inicial Datos para calcular el error estándar bootstrap
del coeficiente de correlaci\&#39;on.
(5.76, 6.78)( 6.35, 6.60)( 5.58, 5.62)( 5.78, 6.06)
( 6.66, 6.88)( 5.80, 6.14)( 5.55, 6.00) ( 6.61, 6.86)
( 6.51, 6.72) ( 6.05, 6.26) ( 6.53, 6.24) ( 5.75, 5.48)
( 5.45, 5.52) ( 5.72, 5.76) ( 5.94, 5.92)
El valor del parámetro sobre la muestra original es: 0.776
Remuestra no 1:(5.55, 6.00)( 6.66, 6.88)( 5.72, 5.76)
( 6.51, 6.72) ( 6.53, 6.24) ( 5.75, 5.48) ( 5.72, 5.76)
(5.78, 6.06)( 5.58, 5.62)( 5.94, 5.92)( 6.35, 6.60)
( 6.05, 6.26)( 5.78, 6.06)( 5.76, 6.78)( 5.80, 6.14)
El valor del parámetro sobre la remuestra n : 1 es: 0.71
Remuestra numero: 2 ( 6.61, 6.86) ( 6.35, 6.60) ( 6.61,
6.86) ( 6.66, 6.88)( 6.61, 6.86)( 5.75, 5.48)( 6.53,
6.24) ( 5.72, 5.76) ( 5.80, 6.14) ( 6.35, 6.60) ( 5.72,
5.76) ( 6.35, 6.60) ( 5.45, 5.52) ( 5.55, 6.00) ( 5.80,
6.14) El valor del parámetro sobre la remuestra no: 2 es: 0.91
Remuestra numero: 3( 5.76, 6.78)( 5.45, 5.52)( 5.58,
5.62) ( 5.45, 5.52) ( 5.80, 6.14) ( 6.61, 6.86) ( 6.35,
6.60) ( 6.66, 6.88)( 5.76, 6.78)( 5.94, 5.92)(5.55,
6.00) ( 5.75, 5.48)( 5.45, 5.52)( 6.05, 6.26)( 5.55,
6.00) El valor del parámetro sobre la remuestra no: 3 es: 0.75</code></pre>
<p>Realizado el remuestreo se obtienen los siguientes resultados:</p>
<ul>
<li>Media muestral
<span class="math inline">\(\hat{\sigma}_{100}=0,156, \quad \sigma_{\infty}=, 155\)</span>
<span class="math inline">\(\left(\hat{\sigma}_{\infty}=\frac{1}{n^{2}}\left[\sum\left(X_{i}-\bar{X}\right)^{2}\right]^{1 / 2}\right)\)</span>
El ajuste entre la estimación bootstrap y el valor teórico es muy bueno.</li>
<li>Mediana muestral
<span class="math inline">\(\hat{\sigma}_{100}=, 106\)</span></li>
<li>Coeficiente de correlación
<span class="math inline">\(\hat{\sigma}_{100}=, 130 \quad \sigma_{\infty}=, 114\)</span>
( <span class="math inline">\(\hat{\sigma}_{\infty}\)</span> representa el error estándar del coeficiente de correlación según la teoría normal).</li>
</ul>
<p>En general para estimar errores estándares basta con <span class="math inline">\(B=100\)</span>. P.ej. en el caso de la mediana del ejemplo anterior se obtiene:</p>
<table>
<thead>
<tr class="header">
<th align="left">B</th>
<th align="center">25</th>
<th align="center">50</th>
<th align="center">100</th>
<th align="center">250</th>
<th align="center">1000</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><span class="math inline">\(\widehat{\sigma_{B}}\)</span></td>
<td align="center">.087</td>
<td align="center">.109</td>
<td align="center">.106</td>
<td align="center">.102</td>
<td align="center">.102</td>
</tr>
</tbody>
</table>
</div>
<div id="resumen-del-mundo-real-al-mundo-bootstrap" class="section level3 hasAnchor" number="14.1.6">
<h3><span class="header-section-number">14.1.6</span> Resumen: del mundo real al mundo bootstrap<a href="métodos-de-computación-intensiva-el-bootstrap.html#resumen-del-mundo-real-al-mundo-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Podemos resumir lo visto hasta aquí en las ideas siguientes:</p>
<ul>
<li>La mayoría de los métodos usuales para obtener errores estándares son versiones aproximadas de:</li>
</ul>
<p><span class="math display">\[
\hat{\sigma}=\sigma\left(F_{n}\right)
\]</span></p>
<ul>
<li>El bootstrap permite evaluar <span class="math inline">\(\sigma\left(F_{n}\right)\)</span> directamente a base de “fuerza bruta” (método de Monte Carlo).</li>
</ul>
<p>Esquemáticamente se puede considerar que al aplicar el bootstrap disponemos de alguna forma de estimación del modelo completo de probabilidad <span class="math inline">\(P=P_{F}\)</span>, a partir de los datos observados <span class="math inline">\(\mathbf{X}\)</span>, y sabemos como producir un modelo estimado <span class="math inline">\(\hat{P}=P_{F_{n}}\)</span>. Este el paso crucial del método.</p>
<p>Una vez disponemos del modelo estimado <span class="math inline">\(\hat{P}\)</span> podemos utilizar el método de Monte Carlo para generar remuestras, <span class="math inline">\(\mathbf{X}^{*}\)</span>, según las mismas reglas por las que los datos originales son generados de <span class="math inline">\(P\)</span>. La variable bootstrap, <span class="math inline">\(\hat{\theta}\left(\mathbf{X}^{*}\right)\)</span>, es observable dado que conocemos <span class="math inline">\(\hat{P}\)</span> y <span class="math inline">\(\mathbf{X}^{*}\)</span> con lo que el muestreo de Monte Carlo nos permitirá conocer la distribución de <span class="math inline">\(\hat{\theta}\left(\mathbf{X}^{*}\right)\)</span>. De esta forma podremos sobre ella estimar las características que nos interesen como, en nuestro ejemplo, el error estándar, que será <span class="math inline">\(\operatorname{Var}_{\hat{P}}\left[\hat{\theta}\left(\mathbf{X}^{*}\right)\right]\)</span>.</p>
<!-- ![](https://cdn.mathpix.com/cropped/836c905e-932d-4fa3-ba7e-9be0ed67ca89-18.jpg?height=330&width=1227&top_left_y=431&top_left_x=484) -->
</div>
<div id="otros-aspectos" class="section level3 hasAnchor" number="14.1.7">
<h3><span class="header-section-number">14.1.7</span> Otros aspectos<a href="métodos-de-computación-intensiva-el-bootstrap.html#otros-aspectos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="bootstrap-paramétrico-y-no-paramétrico" class="section level4 hasAnchor" number="14.1.7.1">
<h4><span class="header-section-number">14.1.7.1</span> Bootstrap paramétrico y no paramétrico<a href="métodos-de-computación-intensiva-el-bootstrap.html#bootstrap-param%C3%A9trico-y-no-param%C3%A9trico" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En ocasiones puede disponerse de información sobre la forma de <span class="math inline">\(F\)</span>. Por ejemplo, se puede aceptar razonablemente que el tiempo de vida sigue una distribución exponencial. Si esta suposición se considera válida, la distribución dependerá tan solo del parámetro <span class="math inline">\(\alpha=\left(E_{F} X\right)^{-1}\)</span>.</p>
<p>En vez de estimar <span class="math inline">\(F\)</span> por <span class="math inline">\(F_{n}\)</span> y generar las remuestras a partir de ésta, un procedimiento alternativo consiste en estimar el parámetro -p.ej. mediante su estimador máximo-verosímil, llamémosle <span class="math inline">\(\hat{\alpha}_{M V}-\)</span> y obtener las remuestras generando muestras de una distribución exponencial de parámetro <span class="math inline">\(\hat{\alpha}_{M V}\)</span>.</p>
<p>Es decir en vez de remuestrear aproximando <span class="math inline">\(F=F_{\alpha}\)</span> por <span class="math inline">\(F_{n}\)</span> y extrayendo muestras con reemplazamiento de la muestra original:</p>
<p><span class="math display">\[
F_{\alpha} \simeq F_{n} \quad \xrightarrow{\text { m.a.s. }} \mathbf{X}^{*}=\left(X_{1}^{*}, X_{2}^{*}, \ldots, X_{n}^{*}\right) .
\]</span></p>
<p>lo haremos aproximando <span class="math inline">\(F_{\alpha}\)</span> por <span class="math inline">\(F_{\hat{\alpha}_{M V}}\)</span> y generando mediante métodos de Monte Carlo, muestras a partir de esta distribución.</p>
<p><span class="math display">\[
F_{\alpha} \simeq F_{\hat{\alpha}_{M V}} \quad \xrightarrow{\text { m.a.s. }} \quad \mathbf{Y}^{*}=\left(Y_{1}^{*}, Y_{2}^{*}, \ldots, Y_{n}^{*}\right)
\]</span></p>
<p>Este procedimiento se conoce como Bootstrap paramétrico. Una diferencia obvia con el procedimiento anterior es que, en general, los elementos de la remuestra no pertenecerán a la muestra original.</p>
<p>Ejemplo 1 Si en el ejemplo número 1, en donde considerábamos los tiempos de supervivencia, realizamos la suposición, razonable, de que éstos se distribuyen según una distribución exponencial</p>
<p><span class="math display">\[
f(x ; \alpha)=\alpha \exp (-\alpha x), x&gt;0, \alpha&gt;0
\]</span></p>
<p>podemos utilizar el estimador <span class="math inline">\(F_{\alpha} \simeq F_{\hat{\alpha}_{M V}}\)</span>, en donde</p>
<p><span class="math display">\[
\hat{\alpha}_{M V}=\frac{1}{\bar{x}}
\]</span></p>
<p>Para generar muestras según la distribución exponencial nos podemos basar en el procedimiento de inversión que, aplicado a la función de distribución de la ley exponencial, garantiza que la variable</p>
<p><span class="math display">\[
X=-\frac{1}{\alpha} \ln (1-U), \quad U \sim \operatorname{Unif.}(0,1),
\]</span></p>
<p>sigue una distribución exponencial <span class="math inline">\({ }^{2}\)</span>.</p>
</div>
<div id="numero-de-remuestras-necesario" class="section level4 hasAnchor" number="14.1.7.2">
<h4><span class="header-section-number">14.1.7.2</span> Numero de remuestras necesario<a href="métodos-de-computación-intensiva-el-bootstrap.html#numero-de-remuestras-necesario" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Como ya hemos comentado suele ser necesario recurrir a algún tipo de muestreo de Monte Carlo para evaluar los estimadores bootstrap. Una pregunta de inminente interés práctico es cuantas remuestras deben realizarse para que la aproximación de Monte Carlo del estimador bootstrap se aproxime “razonablemente” al auténtico valor del estimador bootstrap. Si llamamos:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\sigma_{F}(\hat{\theta})\)</span> al error estándar de <span class="math inline">\(\hat{\theta}\)</span>,</li>
<li><span class="math inline">\(\sigma_{\hat{F}}(\hat{\theta})=\sigma_{B}(\hat{\theta})\)</span> al estimador bootstrap del error estándar de <span class="math inline">\(\hat{\theta}\)</span>, y</li>
<li><span class="math inline">\(\hat{\sigma}_{\hat{F}}(\hat{\theta})=\hat{\sigma}_{B}(\hat{\theta})\)</span> a la aproximación de Monte Carlo del estimador bootstrap del error estándar de <span class="math inline">\(\hat{\theta}\)</span>,
la pregunta relevante es cuan mayor es el error cometido para estimar <span class="math inline">\(\sigma_{F}(\hat{\theta})\)</span> si, en vez de basarnos en <span class="math inline">\(\sigma_{B}(\hat{\theta})\)</span> lo hacemos en <span class="math inline">\(\hat{\sigma}_{B}(\hat{\theta})\)</span> ?</li>
</ol>
<p>Efron ([11])deduce una fórmula para el coeficiente de variación (es decir el cociente entre la desviación típica y la esperanza) de <span class="math inline">\(\hat{\sigma}_{B}(\hat{\theta})\)</span>, condicional sobre una muestra dada:</p>
<p><span class="math display">\[
C V\left(\hat{\sigma}_{B}(\hat{\theta}) \mid \mathbf{x}\right)=\left[\frac{\hat{\Delta}+2}{4 B}\right]^{1 / 2}
\]</span></p>
<p>donde <span class="math inline">\(\hat{\Delta}\)</span> es la curtosis de la distribución (bootstrap) de <span class="math inline">\(\hat{\theta}\)</span>. La notación indica que los datos observados, <span class="math inline">\(\mathbf{x}\)</span>, se consideran fijos en esta expresión. Cuando <span class="math inline">\(B \rightarrow \infty\)</span> la expresión anterior <span class="math inline">\(\rightarrow 0\)</span> y <span class="math inline">\(\sigma_{B} \rightarrow \hat{\sigma}\)</span> el estimador bootstrap del error estándar, “ideal”. Sean ahora <span class="math inline">\(C V\left(\sigma_{B}(\hat{\theta})\right)\)</span> y <span class="math inline">\(C V\left(\hat{\sigma}_{B}(\hat{\theta})\right)\)</span> los coeficientes de variación incondicionales (es decir los CV condicionales promediados sobre</p>
<p>[^1]todas las posibles muestras) de <span class="math inline">\(\sigma_{B}(\hat{\theta})\)</span> y <span class="math inline">\(\hat{\sigma}_{B}(\hat{\theta})\)</span> respectivamente. En este caso la relación entre ambos coeficientes de variación viene dada por la expresión:
<span class="math display">\[
C V\left(\hat{\sigma}_{B}(\hat{\theta})\right) \doteq\left\{\left[C V\left(\sigma_{B}\right)\right]^{2}+\left[\frac{E[\hat{\Delta}]+2}{4 B}\right]^{1 / 2}\right\}
\]</span></p>
<p>La tabla siguiente muestra <span class="math inline">\(C V\left(\hat{\sigma}_{B}\right)\)</span> para diversos valores de <span class="math inline">\(B\)</span> y <span class="math inline">\(C V\left(\sigma_{B}\right)\)</span> suponiendo que sea <span class="math inline">\(E[\hat{\Delta}]=0\)</span>. Valores de <span class="math inline">\(C V\left(\sigma_{B}\right) \geq 0,10\)</span>, lo que, según Efron [11], es habitual en la práctica, se observa poca mejora a partir de <span class="math inline">\(B=100\)</span>, lo que sugiere que, para estimar el error estándar este puede ser un número de remuestras adecuado.</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
<th align="center">B</th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(C V(\hat{\sigma})\)</span></td>
<td align="center">25</td>
<td align="center">50</td>
<td align="center">100</td>
<td align="center">200</td>
<td align="center"><span class="math inline">\(\infty\)</span></td>
</tr>
<tr class="even">
<td align="center">.25</td>
<td align="center">.29</td>
<td align="center">.27</td>
<td align="center">.26</td>
<td align="center">.25</td>
<td align="center">.25</td>
</tr>
<tr class="odd">
<td align="center">.20</td>
<td align="center">.24</td>
<td align="center">.22</td>
<td align="center">.21</td>
<td align="center">.21</td>
<td align="center">.20</td>
</tr>
<tr class="even">
<td align="center">.15</td>
<td align="center">.21</td>
<td align="center">.18</td>
<td align="center">.17</td>
<td align="center">.16</td>
<td align="center">.15</td>
</tr>
<tr class="odd">
<td align="center">.10</td>
<td align="center">.17</td>
<td align="center">.14</td>
<td align="center">.12</td>
<td align="center">.11</td>
<td align="center">.10</td>
</tr>
<tr class="even">
<td align="center">.05</td>
<td align="center">.15</td>
<td align="center">.11</td>
<td align="center">.09</td>
<td align="center">.07</td>
<td align="center">.05</td>
</tr>
<tr class="odd">
<td align="center">0</td>
<td align="center">.14</td>
<td align="center">.10</td>
<td align="center">.07</td>
<td align="center">.05</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>Razonamientos similares sugieren que para los intervalos de confianza el número de remuestras debería ser mucho mayor, del orden de 1000 o 2000.</p>
<p>En un artículo de Booth y Sarkar ([3]) se critica el razonamiento anterior argumentando que es preciso controlar la variabilidad derivada del remuestreo de Monte Carlo, para evitar que las conclusiones del uso del bootstrap difieran entre dos repeticiones del mismo cálculo como resultado de factores como las semillas de los generadores de números aleatorios.</p>
</div>
</div>
<div id="ejercicios" class="section level3 hasAnchor" number="14.1.8">
<h3><span class="header-section-number">14.1.8</span> Ejercicios<a href="métodos-de-computación-intensiva-el-bootstrap.html#ejercicios" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Sea <span class="math inline">\(x_{(1)}&lt;x_{(2)}&lt;\ldots&lt;x_{(7)}\)</span> una muestra ordenada de tamaño <span class="math inline">\(n=7\)</span>. Sea <span class="math inline">\(\mathbf{x}^{*}\)</span> una muestra bootstrap y <span class="math inline">\(s\left(\mathbf{x}^{*}\right)\)</span> la correspondiente replica bootstrap de la mediana. Muestre que:</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(s\left(\mathbf{x}^{*}\right)\)</span> coincide con uno de los valores originales de la muestra <span class="math inline">\(x_{(i)}\)</span>, <span class="math inline">\(i=1,2, \ldots 7\)</span>.</li>
<li><span class="math inline">\(P\left[s(\mathbf{x})=x_{(i)}\right]=p(i)\)</span> donde</li>
</ol>
<p><span class="math display">\[
p(i)=\sum_{j=0}^{3}\left\{\operatorname{Bi}\left(j ; n, \frac{i-1}{n}\right)-\operatorname{Bi}\left(j ; n, \frac{i}{n}\right)\right\},
\]</span></p>
<p>donde <span class="math inline">\(\operatorname{Bi}(j ; n, p)\)</span> es la probabilidad binomial <span class="math inline">\(\binom{n}{j} p^{j}(1-p)^{n-j}\)</span>. (Los valores numéricos de <span class="math inline">\(p(i)\)</span> son <span class="math inline">\(.0102, .0981, .2386, .3062, .2386\)</span>, .0981, .0102.) Estos valores se utilizaron para calcular un error estándar <span class="math inline">\(\hat{\sigma}_{B=\infty}\)</span> (mediana) <span class="math inline">\(=37,83\)</span> con el grupo tratamiento con los datos de supervivencia de <span class="math inline">\(9+9\)</span> ratones (“mouse data set”).
2. Aplique la ley débil de los grandes números para demostrar que, si <span class="math inline">\(s\left(\mathbf{x}^{*}\right)\)</span> es la media muestral <span class="math inline">\(\bar{x}\)</span> el estimador bootstrap del error estándar</p>
<p><span class="math display">\[
\hat{\sigma}_{B}=\left\{\frac{1}{(B-1)} \sum_{b=1}^{B}\left[s\left(\mathbf{x}_{b}^{*}\right)-s(\cdot)\right]^{2}\right\}^{\frac{1}{2}}
\]</span></p>
<p>siendo <span class="math inline">\(s(\cdot)=\sum_{b=1}^{B} s\left(\mathbf{x}^{*}{ }_{b}\right) / B\)</span>, tiende hacia</p>
<p><span class="math display">\[
\left\{\sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2} / n^{2}\right\}^{\frac{1}{2}},
\]</span></p>
<p>cuando <span class="math inline">\(n\)</span> tiende a infinito.
3. Tomamos una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> con reemplazamiento de una población de tamaño <span class="math inline">\(N\)</span>. Muestre que la probabilidad de que no aparezcan repeticiones en la muestra se obtiene del producto:</p>
<p><span class="math display">\[
\prod_{j=0}^{n-1}\left(1-\frac{j}{N}\right) .
\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>Sean <span class="math inline">\(\bar{X}\)</span> y <span class="math inline">\(S\)</span> la media y la desviación típica de un conjunto de <span class="math inline">\(N\)</span> valores <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{N}\)</span> :</li>
</ol>
<p><span class="math display">\[
\bar{X}=\sum_{i=1}^{N} X_{i}, \quad S=\left\{\sum_{i=1}^{N}\left(X_{i}-\bar{X}\right)^{2} / N\right\}^{\frac{1}{2}} .
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Extraemos una muestra <span class="math inline">\(\left(x_{1}, x_{2}, \ldots, x_{n}\right)\)</span> de <span class="math inline">\(X_{1}, \ldots, X_{N}\)</span> con reemplazamiento. La desviación típica de la media muestral, <span class="math inline">\(\bar{x}=\sum_{i=1}^{n} x_{i}\)</span>, se indica como <span class="math inline">\(\sigma_{\bar{x}}, \mathrm{y}\)</span> suele denominarse el error estándar de la media. Demuestre que:</li>
</ol>
<p><span class="math display">\[
\sigma_{\bar{x}}=\frac{S}{\sqrt{n}}
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Supongamos que el muestreo se realiza sin reemplazamiento (es decir es preciso que <span class="math inline">\(n \leq N\)</span>. Demuestre que:</li>
</ol>
<p><span class="math display">\[
\sigma_{\bar{x}}=\frac{S}{\sqrt{n}}\left[\frac{N-n}{N-1}\right]^{\frac{1}{2}}
\]</span></p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Como puede verse el muestreo sin reemplazamiento da lugar a un menor error para <span class="math inline">\(\bar{x}\)</span>. Proporcionalmente qué tan menor será en el caso de los datos de las escuelas norteamericanas de abogacía <span class="math inline">\((N=84, n=15)\)</span> ?.</li>
</ol>
<ol start="5" style="list-style-type: decimal">
<li>Dado un conjunto de <span class="math inline">\(n\)</span> valores distintos pruebe que el número de muestras bootstrap distintas es:</li>
</ol>
<p><span class="math display">\[
\binom{2 n-1}{n .}
\]</span></p>
<p>Cuantas son para <span class="math inline">\(n=15 ?\)</span>.</p>
</div>
<div id="practicas" class="section level3 hasAnchor" number="14.1.9">
<h3><span class="header-section-number">14.1.9</span> Practicas<a href="métodos-de-computación-intensiva-el-bootstrap.html#practicas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ol style="list-style-type: decimal">
<li>Es posible, aunque poco práctico implementar el bootstrap por uno mismo en cualquier lenguaje de ordenador.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li>Las instrucciones contenidas en BOOTSD1. R y BOOTSD1B. <span class="math inline">\(\mathrm{R}^{3}\)</span> en realizan remuestreo no paramétrico sobre la media de tiempo de supervivencia de 9 ratones asignados a un tratamiento destinado a prolongar la supervivencia después de una intervención quirúrgica. El resultado se compara con el error estándar de la media.</li>
<li>Las instrucciones contenidas en BOOTSD2.R realizan remuestreo no paramétrico sobre la mediana del tiempo de supervivencia de 9 ratones asignados a un tratamiento destinado a prolongar la supervivencia después de una intervención quirúrgica. El resultado se compara con el error estándar teórico de la mediana,</li>
</ol>
<p><span class="math display">\[
\sqrt{\operatorname{var}(\widehat{M})}=\sqrt{\frac{1}{4 n \cdot[f(\widehat{M})]^{2}}},
\]</span></p>
<p>donde <span class="math inline">\(f()\)</span> es la función de densidad evaluada en la mediana de la muestra, <span class="math inline">\(\widehat{M} . f()\)</span> se estima mediante un estimador kernel.
c) Las instrucciones contenidas en BOOTSD3. R y BOOTSD3B. R realizan remuestreo no paramétrico sobre el coeficiente de correlación de las notas de COU y selectividad de 15 estudiantes. En este caso no disponemos, en general, de una fórmula teórica con la que comparar y, en todo caso la varianza auténtica debe estimarse por simulación.
2. En ocasiones se dispone de alguna hipótesis razonable sobre la distribución de los datos, lo cual sugiere la utilización de un remuestreo paramétrico. Modificar el mecanismo de remuestreo del ejercicio anterior para que las remuestras del tiempo de supervivencia se realicen mediante la generación de muestras de tamaño <span class="math inline">\(\mathrm{n}=9\)</span> de una distribución exponencial de parámetro <span class="math inline">\(\alpha=\bar{x}\)</span>. Comparar los resultados obtenidos con los del remuestreo no paramétrico.
3. El jackknife ofrece un procedimiento alternativo al bootstrap para estimar la varianza de un estimador. Modifique las rutinas del ejercicio 1</p>
<p>[^2]para calcular también el estimador jackknife de la varianza de los estimadores. Compárelo con el estimador bootstrap. (Solución JACKSD1.R )
4. El bootstrap, junto con el jackknife pueden utilizarse para estimar el sesgo y para obtener estimadores corregidos para el sesgo.A partir de la siguiente muestra obtenida mediante un generador de números aleatorios <span class="math inline">\(\mathrm{N}(0,1)\)</span>
<span class="math display">\[
\begin{aligned}
\mathbf{X}= &amp; 0,3996,1,5074,0,5640,-1,3542,-0,5846,0,4271,-0,7518 \\
&amp; 0,4622,-0,4563,-0,0783
\end{aligned}
\]</span>
a) Calcular el sesgo bootstrap y jackknife del estimador de la varianza muestral y compararlo con el estimador exacto <span class="math inline">\(\frac{-1}{n} \sigma^{2}\)</span>, que en este ejemplo es conocido al proceder los datos de una distribución simulada.
b) Repetir varias veces los cálculos y observe como varían las estimaciones. ¿Como explica la variación observada?.
c) ¿Como se modifica la variabilidad de las estimaciones del sesgo al aumentar el número de remuestras?. Podemos estimar esta variabilidad mediante simulación o mediante jackknife after bootstrap
5. Si no se dispone de un “patron-oro” con el que comparar las estimacionesbootstrap, jackknife u otras- del error estándar pueden validarse estos métodos por simulación. Por ejemplo, para realizar esta validación en el caso del error estándar bootstrap del coeficiente de correlación ejecutaremos el siguiente algoritmo:
a) Repetir un elevado número de veces <span class="math inline">\(s=1, \ldots, S\)</span> (p.ej. <span class="math inline">\(S=10000\)</span> ) el siguiente proceso:</p>
<ol style="list-style-type: decimal">
<li>Generar una muestra de una distribución bivariante, p.ej. una normal, <span class="math inline">\(N(\mu, \boldsymbol{\Sigma})\)</span>.</li>
<li>Calcular sobre ella el coeficiente de correlación <span class="math inline">\(\hat{\rho}_{s}\)</span>, y el error estándar bootstrap <span class="math inline">\(\hat{\sigma}_{B}\)</span></li>
</ol>
<ol start="2" style="list-style-type: lower-alpha">
<li>La desviación típica muestral, <span class="math inline">\(s_{\hat{\rho}}\)</span> de los coeficientes de correlación <span class="math inline">\(\hat{\rho}_{1}, \ldots, \hat{\rho}_{s}\)</span> es una buena estimación del error estándar de <span class="math inline">\(\hat{\rho}\)</span> y la media muestral de los errores estándar bootstrap, <span class="math inline">\(\overline{\hat{\sigma}}_{B}\)</span> es una buena estimación del error estándar bootstrap del coeficiente de correlación.
<span class="math inline">\(c)\)</span> Cuanto más similares sean <span class="math inline">\(s_{\hat{\rho}}\)</span> y <span class="math inline">\(\overline{\hat{\sigma}}_{B}\)</span> mejor será la calidad de <span class="math inline">\(\hat{\sigma}_{B}\)</span> cómo estimador de <span class="math inline">\(\sigma_{\hat{\rho}}\)</span>.</li>
</ol>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estadística-no-paramétrica.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="capítulo-2.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["FundamentosInferenciaEstadistica.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
