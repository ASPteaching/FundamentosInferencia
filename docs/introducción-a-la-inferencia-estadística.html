<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 6 Introducción a la inferencia estadística | Fundamentos de Inferencia Estadistica</title>
  <meta name="description" content="Capítulo 6 Introducción a la inferencia estadística | Fundamentos de Inferencia Estadistica" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 6 Introducción a la inferencia estadística | Fundamentos de Inferencia Estadistica" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 6 Introducción a la inferencia estadística | Fundamentos de Inferencia Estadistica" />
  
  
  

<meta name="author" content="Alex Sanchez Pla y Santiago Pérez Hoyos" />


<meta name="date" content="2025-10-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="grandes-muestras.html"/>
<link rel="next" href="estimación-puntual.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="blocks.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/docs/_main.pdf" title="Version en PDF" target="_blank"><img alt="Versión en pdf" src="./images(pdf.png)" width="12" height="15" />    </a>
</li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path=""><a href="#presentaci%C3%B3n"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path=""><a href="#prerequisitos-y-organizaci%C3%B3n-del-material"><i class="fa fa-check"></i>Prerequisitos y organización del material</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html"><i class="fa fa-check"></i>Agradecimiento y fuentes utilizadas</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#el-proyecto-statmedia"><i class="fa fa-check"></i>El proyecto Statmedia</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#otros-materiales-utilizados"><i class="fa fa-check"></i>Otros materiales utilizados</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#materiales-complementarios"><i class="fa fa-check"></i>Materiales complementarios</a>
<ul>
<li class="chapter" data-level="" data-path=""><a href="#complementos-matem%C3%A1ticos"><i class="fa fa-check"></i>Complementos matemáticos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html"><i class="fa fa-check"></i><b>1</b> Probabilidad y Experimentos aleatorios</a>
<ul>
<li class="chapter" data-level="1.1" data-path="06-introInferencia.html"><a href="#introducci%C3%B3n"><i class="fa fa-check"></i><b>1.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="06-introInferencia.html"><a href="#fen%C3%B3menos-deterministas-y-fen%C3%B3menos-aleatorios"><i class="fa fa-check"></i><b>1.1.1</b> Fenómenos deterministas y fenómenos aleatorios</a></li>
<li class="chapter" data-level="1.1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos"><i class="fa fa-check"></i><b>1.1.2</b> Sucesos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="06-introInferencia.html"><a href="#funci%C3%B3n-de-probabilidad"><i class="fa fa-check"></i><b>1.2</b> Función de probabilidad</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#diferentes-funciones-de-probabilidad-para-una-misma-experiencia-aleatoria"><i class="fa fa-check"></i><b>1.2.1</b> ¿Diferentes funciones de probabilidad para una misma experiencia aleatoria?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="06-introInferencia.html"><a href="#c%C3%B3mo-se-calculan-las-probabilidades"><i class="fa fa-check"></i><b>1.3</b> ¿Cómo se calculan las probabilidades?</a></li>
<li class="chapter" data-level="1.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-elementales-y-sucesos-observables"><i class="fa fa-check"></i><b>1.4</b> Sucesos elementales y sucesos observables</a></li>
<li class="chapter" data-level="1.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#propiedades-inmediatas-de-la-probabilidad"><i class="fa fa-check"></i><b>1.5</b> Propiedades inmediatas de la probabilidad</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#succeso-imposible"><i class="fa fa-check"></i><b>1.5.1</b> Succeso imposible</a></li>
<li class="chapter" data-level="1.5.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#suceso-implicado"><i class="fa fa-check"></i><b>1.5.2</b> Suceso implicado</a></li>
<li class="chapter" data-level="1.5.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#complementario-de-un-suceso"><i class="fa fa-check"></i><b>1.5.3</b> Complementario de un suceso</a></li>
<li class="chapter" data-level="1.5.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ocurrencia-de-algun-suceso"><i class="fa fa-check"></i><b>1.5.4</b> Ocurrencia de algun suceso</a></li>
<li class="chapter" data-level="1.5.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurra-algun-suceso"><i class="fa fa-check"></i><b>1.5.5</b> Probabilidad de que ocurra algun suceso</a></li>
<li class="chapter" data-level="1.5.6" data-path="06-introInferencia.html"><a href="#probabilidad-de-que-ocurran-dos-o-m%C3%A1s-sucesos-a-la-vez"><i class="fa fa-check"></i><b>1.5.6</b> Probabilidad de que ocurran dos (o más) sucesos a la vez</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#espacios-de-probabilidad"><i class="fa fa-check"></i><b>1.6</b> Espacios de probabilidad</a></li>
<li class="chapter" data-level="1.7" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>1.7</b> Probabilidad condicionada</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#la-probabilidad-condicionada-es-una-medida-de-probabilidad"><i class="fa fa-check"></i><b>1.7.1</b> La probabilidad condicionada es una medida de probabilidad</a></li>
<li class="chapter" data-level="1.7.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-dependientes-y-sucesos-independientes"><i class="fa fa-check"></i><b>1.7.2</b> Sucesos dependientes y sucesos independientes</a></li>
<li class="chapter" data-level="1.7.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#incompatibilidad-e-independencia"><i class="fa fa-check"></i><b>1.7.3</b> Incompatibilidad e independencia</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#dos-teoremas-importantes"><i class="fa fa-check"></i><b>1.8</b> Dos Teoremas importantes</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-las-probabilidades-totales"><i class="fa fa-check"></i><b>1.8.1</b> Teorema de las probabilidades totales</a></li>
<li class="chapter" data-level="1.8.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-bayes"><i class="fa fa-check"></i><b>1.8.2</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="06-introInferencia.html"><a href="#introducci%C3%B3n-a-los-experimentos-m%C3%BAltiples"><i class="fa fa-check"></i><b>1.9</b> Introducción a los experimentos múltiples</a></li>
<li class="chapter" data-level="1.10" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinatoria"><i class="fa fa-check"></i><b>1.10</b> Combinatoria</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones"><i class="fa fa-check"></i><b>1.10.1</b> Permutaciones</a></li>
<li class="chapter" data-level="1.10.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones"><i class="fa fa-check"></i><b>1.10.2</b> Variaciones</a></li>
<li class="chapter" data-level="1.10.3" data-path="06-introInferencia.html"><a href="#variaciones-con-repetici%C3%B3n"><i class="fa fa-check"></i><b>1.10.3</b> Variaciones con repetición</a></li>
<li class="chapter" data-level="1.10.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinaciones"><i class="fa fa-check"></i><b>1.10.4</b> Combinaciones</a></li>
<li class="chapter" data-level="1.10.5" data-path="06-introInferencia.html"><a href="#permutaciones-con-repetici%C3%B3n"><i class="fa fa-check"></i><b>1.10.5</b> Permutaciones con repetición</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#frecuencia-relativa-y-probabilidad"><i class="fa fa-check"></i><b>1.11</b> Frecuencia relativa y probabilidad</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="06-introInferencia.html"><a href="#ilustraci%C3%B3n-por-simulaci%C3%B3n"><i class="fa fa-check"></i><b>1.11.1</b> Ilustración por simulación</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="06-introInferencia.html"><a href="#caso-de-estudio-eficacia-de-una-prueba-diagn%C3%B3stica"><i class="fa fa-check"></i><b>1.12</b> Caso de Estudio: Eficacia de una prueba diagnóstica</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="06-introInferencia.html"><a href="#aplicaci%C3%B3n-del-teorema-de-bayes"><i class="fa fa-check"></i><b>1.12.1</b> Aplicación del Teorema de Bayes</a></li>
<li class="chapter" data-level="1.12.2" data-path="06-introInferencia.html"><a href="#ejemplo-num%C3%A9rico"><i class="fa fa-check"></i><b>1.12.2</b> Ejemplo numérico</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>2</b> Variables aleatorias y Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#el-espacio-muestral-y-sus-elementos"><i class="fa fa-check"></i><b>2.1</b> El espacio muestral y sus elementos</a></li>
<li class="chapter" data-level="2.2" data-path="06-introInferencia.html"><a href="#representaci%C3%B3n-num%C3%A9rica-de-los-sucesos-elementales.-variables-aleatorias"><i class="fa fa-check"></i><b>2.2</b> Representación numérica de los sucesos elementales. Variables aleatorias</a></li>
<li class="chapter" data-level="2.3" data-path="06-introInferencia.html"><a href="#caracterizaci%C3%B3n-de-una-variable-aleatoria-a-trav%C3%A9s-de-la-probabilidad.-funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.3</b> Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución</a></li>
<li class="chapter" data-level="2.4" data-path="06-introInferencia.html"><a href="#propiedades-de-la-funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.4</b> Propiedades de la función de distribución</a></li>
<li class="chapter" data-level="2.5" data-path="06-introInferencia.html"><a href="#clasificaci%C3%B3n-de-las-variables-aleatorias"><i class="fa fa-check"></i><b>2.5</b> Clasificación de las variables aleatorias</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-discretas"><i class="fa fa-check"></i><b>2.5.1</b> Variables aleatorias discretas</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.5.2</b> Variables aleatorias continuas</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variable-aleatoria-discretas"><i class="fa fa-check"></i><b>2.6</b> Variable aleatoria discretas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="06-introInferencia.html"><a href="#caracterizaci%C3%B3n-de-las-v.a.-discretas"><i class="fa fa-check"></i><b>2.6.1</b> Caracterización de las v.a. discretas</a></li>
<li class="chapter" data-level="2.6.2" data-path="06-introInferencia.html"><a href="#propiedades-de-la-funci%C3%B3n-de-densidad-discreta"><i class="fa fa-check"></i><b>2.6.2</b> Propiedades de la función de densidad discreta</a></li>
<li class="chapter" data-level="2.6.3" data-path="06-introInferencia.html"><a href="#relaciones-entre-la-funci%C3%B3n-de-distribuci%C3%B3n-y-la-funci%C3%B3n-de-densidad-discreta.-probabilidad-de-intervalos."><i class="fa fa-check"></i><b>2.6.3</b> Relaciones entre la función de distribución y la función de densidad discreta. <br> Probabilidad de intervalos.</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>2.7</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="06-introInferencia.html"><a href="#funci%C3%B3n-de-densidad-continua"><i class="fa fa-check"></i><b>2.7.1</b> Función de densidad continua</a></li>
<li class="chapter" data-level="2.7.2" data-path="06-introInferencia.html"><a href="#relaciones-entre-la-funci%C3%B3n-de-distribuci%C3%B3n-y-la-funci%C3%B3n-de-densidad."><i class="fa fa-check"></i><b>2.7.2</b> Relaciones entre la función de distribución y la función de densidad.</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="06-introInferencia.html"><a href="#caracterizaci%C3%B3n-de-una-variable-aleatoria-a-trav%C3%A9s-de-par%C3%A1metros"><i class="fa fa-check"></i><b>2.8</b> Caracterización de una variable aleatoria a través de parámetros</a></li>
<li class="chapter" data-level="2.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-discreta"><i class="fa fa-check"></i><b>2.9</b> Esperanza de una variable aleatoria discreta</a></li>
<li class="chapter" data-level="2.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-continua"><i class="fa fa-check"></i><b>2.10</b> Esperanza de una variable aleatoria continua</a></li>
<li class="chapter" data-level="2.11" data-path="06-introInferencia.html"><a href="#propiedades-de-la-esperanza-matem%C3%A1tica"><i class="fa fa-check"></i><b>2.11</b> Propiedades de la esperanza matemática</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="06-introInferencia.html"><a href="#linealidad-de-la-esperanza-matem%C3%A1tica"><i class="fa fa-check"></i><b>2.11.1</b> Linealidad de la esperanza matemática</a></li>
<li class="chapter" data-level="2.11.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-del-producto"><i class="fa fa-check"></i><b>2.11.2</b> Esperanza del producto</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.12</b> Varianza de una variable aleatoria</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-varianza"><i class="fa fa-check"></i><b>2.12.1</b> Propiedades de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#momentos-de-orden-k-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.13</b> Momentos (de orden <span class="math inline">\(k\)</span>) de una variable aleatoria</a></li>
<li class="chapter" data-level="2.14" data-path="06-introInferencia.html"><a href="#definici%C3%B3n-formal-de-variable-aleatoria"><i class="fa fa-check"></i><b>2.14</b> Definición formal de variable aleatoria</a></li>
<li class="chapter" data-level="2.15" data-path="06-introInferencia.html"><a href="#caso-pr%C3%A1ctico-lanzamiento-de-dos-dados"><i class="fa fa-check"></i><b>2.15</b> Caso práctico: Lanzamiento de dos dados</a>
<ul>
<li class="chapter" data-level="2.15.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#espacio-muestral"><i class="fa fa-check"></i><b>2.15.1</b> Espacio muestral</a></li>
<li class="chapter" data-level="2.15.2" data-path="06-introInferencia.html"><a href="#representaci%C3%B3n-num%C3%A9rica"><i class="fa fa-check"></i><b>2.15.2</b> Representación numérica</a></li>
<li class="chapter" data-level="2.15.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#algunas-probabilidades"><i class="fa fa-check"></i><b>2.15.3</b> Algunas probabilidades</a></li>
<li class="chapter" data-level="2.15.4" data-path="06-introInferencia.html"><a href="#funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.15.4</b> Función de distribución</a></li>
<li class="chapter" data-level="2.15.5" data-path="06-introInferencia.html"><a href="#clasificaci%C3%B3n-de-las-variables"><i class="fa fa-check"></i><b>2.15.5</b> Clasificación de las variables</a></li>
<li class="chapter" data-level="2.15.6" data-path="06-introInferencia.html"><a href="#funci%C3%B3n-de-densidad-discreta"><i class="fa fa-check"></i><b>2.15.6</b> Función de densidad discreta</a></li>
<li class="chapter" data-level="2.15.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-intervalos-1"><i class="fa fa-check"></i><b>2.15.7</b> Probabilidad de intervalos</a></li>
<li class="chapter" data-level="2.15.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza"><i class="fa fa-check"></i><b>2.15.8</b> Esperanza</a></li>
<li class="chapter" data-level="2.15.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-un-juego"><i class="fa fa-check"></i><b>2.15.9</b> Esperanza de un juego</a></li>
<li class="chapter" data-level="2.15.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-con-recorrido-infinito"><i class="fa fa-check"></i><b>2.15.10</b> Esperanza con recorrido infinito</a></li>
<li class="chapter" data-level="2.15.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-infinita"><i class="fa fa-check"></i><b>2.15.11</b> Esperanza infinita</a></li>
<li class="chapter" data-level="2.15.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza"><i class="fa fa-check"></i><b>2.15.12</b> Varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html"><i class="fa fa-check"></i><b>3</b> Distribuciones Notables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-discretas"><i class="fa fa-check"></i><b>3.1</b> Distribuciones discretas</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-de-bernouilli"><i class="fa fa-check"></i><b>3.1.1</b> La distribución de Bernouilli</a></li>
<li class="chapter" data-level="3.1.2" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>3.1.2</b> La distribución Binomial</a></li>
<li class="chapter" data-level="3.1.3" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>3.1.3</b> La distribución de Poisson</a></li>
<li class="chapter" data-level="3.1.4" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-uniforme-discreta"><i class="fa fa-check"></i><b>3.1.4</b> La distribución Uniforme discreta</a></li>
<li class="chapter" data-level="3.1.5" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-hipergeom%C3%A9trica"><i class="fa fa-check"></i><b>3.1.5</b> La distribución Hipergeométrica</a></li>
<li class="chapter" data-level="3.1.6" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-geom%C3%A9trica-o-de-pascal"><i class="fa fa-check"></i><b>3.1.6</b> La distribución Geométrica o de Pascal</a></li>
<li class="chapter" data-level="3.1.7" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-binomial-negativa"><i class="fa fa-check"></i><b>3.1.7</b> La distribución Binomial negativa</a></li>
<li class="chapter" data-level="3.1.8" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-distribuciones-discretas-principales"><i class="fa fa-check"></i><b>3.1.8</b> Tabla resumen de las distribuciones discretas principales</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-continuas"><i class="fa fa-check"></i><b>3.2</b> Distribuciones Continuas</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-uniforme"><i class="fa fa-check"></i><b>3.2.1</b> La distribución Uniforme</a></li>
<li class="chapter" data-level="3.2.2" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-exponencial"><i class="fa fa-check"></i><b>3.2.2</b> La distribución Exponencial</a></li>
<li class="chapter" data-level="3.2.3" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>3.2.3</b> La distribución Normal</a></li>
<li class="chapter" data-level="3.2.4" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-gamma"><i class="fa fa-check"></i><b>3.2.4</b> La distribución Gamma</a></li>
<li class="chapter" data-level="3.2.5" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-de-cauchy"><i class="fa fa-check"></i><b>3.2.5</b> La distribución de Cauchy</a></li>
<li class="chapter" data-level="3.2.6" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-de-weibull"><i class="fa fa-check"></i><b>3.2.6</b> La distribución de Weibull</a></li>
<li class="chapter" data-level="3.2.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-principales-distribuciones-continuas"><i class="fa fa-check"></i><b>3.2.7</b> Tabla resumen de las principales distribuciones continuas</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-con-r-y-python"><i class="fa fa-check"></i><b>3.3</b> Distribuciones con R (y Python)</a></li>
<li class="chapter" data-level="3.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-familia-exponencial-de-distribuciones"><i class="fa fa-check"></i><b>3.4</b> La familia exponencial de distribuciones</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#ejemplos-de-distribuciones-de-esta-familia"><i class="fa fa-check"></i><b>3.4.1</b> Ejemplos de distribuciones de esta familia</a></li>
<li class="chapter" data-level="3.4.2" data-path="06-introInferencia.html"><a href="#distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>3.4.2</b> Distribución Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#importancia-y-utilidad-de-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.3</b> Importancia y utilidad de la familia exponencial</a></li>
<li class="chapter" data-level="3.4.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#los-modelos-lineales-generalizados-glms"><i class="fa fa-check"></i><b>3.4.4</b> Los modelos lineales generalizados (GLMs)</a></li>
<li class="chapter" data-level="3.4.5" data-path="06-introInferencia.html"><a href="#estimaci%C3%B3n-en-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.5</b> Estimación en la familia exponencial</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html"><i class="fa fa-check"></i><b>4</b> Distribuciones de probabilidad multidimensionales</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-conjuntas-de-probabilidades"><i class="fa fa-check"></i><b>4.1</b> Distribuciones conjuntas de probabilidades</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatoria-bivariante"><i class="fa fa-check"></i><b>4.1.1</b> Variable aleatoria bivariante</a></li>
<li class="chapter" data-level="4.1.2" data-path="06-introInferencia.html"><a href="#funci%C3%B3n-de-distribuci%C3%B3n-bivariante"><i class="fa fa-check"></i><b>4.1.2</b> Función de distribución bivariante</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatorias-bivariantes-discretas"><i class="fa fa-check"></i><b>4.2</b> Variable aleatorias bivariantes discretas</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="06-introInferencia.html"><a href="#funci%C3%B3n-de-masa-de-probabilidad-discreta-fmp"><i class="fa fa-check"></i><b>4.2.1</b> Función de masa de probabilidad discreta (fmp)</a></li>
<li class="chapter" data-level="4.2.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-fmp-bivariante"><i class="fa fa-check"></i><b>4.2.2</b> Propiedades de la fmp bivariante</a></li>
<li class="chapter" data-level="4.2.3" data-path="06-introInferencia.html"><a href="#ejemplo-de-distribuci%C3%B3n-bivariante-discreta"><i class="fa fa-check"></i><b>4.2.3</b> Ejemplo de distribución bivariante discreta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-multinomial"><i class="fa fa-check"></i><b>4.3</b> La distribución multinomial</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="06-introInferencia.html"><a href="#generaci%C3%B3n-de-las-observaciones"><i class="fa fa-check"></i><b>4.3.1</b> Generación de las observaciones</a></li>
<li class="chapter" data-level="4.3.2" data-path="06-introInferencia.html"><a href="#funcion-de-masa-de-probabilidad-de-la-distribuci%C3%B3n-multinomial"><i class="fa fa-check"></i><b>4.3.2</b> Funcion de masa de probabilidad de la distribución multinomial</a></li>
<li class="chapter" data-level="4.3.3" data-path="06-introInferencia.html"><a href="#relaci%C3%B3n-con-la-distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>4.3.3</b> Relación con la distribución binomial</a></li>
<li class="chapter" data-level="4.3.4" data-path="06-introInferencia.html"><a href="#un-caso-particular-la-distribuci%C3%B3n-trinomial"><i class="fa fa-check"></i><b>4.3.4</b> Un caso particular: La distribución trinomial</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-marginales"><i class="fa fa-check"></i><b>4.4</b> Distribuciones marginales</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="06-introInferencia.html"><a href="#las-marginales-est%C3%A1n-en-los-m%C3%A1rgenes"><i class="fa fa-check"></i><b>4.4.1</b> Las marginales están en los márgenes</a></li>
<li class="chapter" data-level="4.4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-discretas"><i class="fa fa-check"></i><b>4.4.2</b> Densidades marginales discretas</a></li>
<li class="chapter" data-level="4.4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribuciones-marginales"><i class="fa fa-check"></i><b>4.4.3</b> Trinomial M(5; 0.6, 0.2): Distribuciones marginales</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales"><i class="fa fa-check"></i><b>4.5</b> Distribuciones condicionales</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional"><i class="fa fa-check"></i><b>4.5.1</b> Densidad condicional</a></li>
<li class="chapter" data-level="4.5.2" data-path="06-introInferencia.html"><a href="#trinomial-m5-0.6-0.2-distribuci%C3%B3n-condicional"><i class="fa fa-check"></i><b>4.5.2</b> Trinomial M(5; 0.6, 0.2): Distribución condicional</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#vectores-aleatorios-absolutamente-continuos"><i class="fa fa-check"></i><b>4.6</b> Vectores aleatorios absolutamente continuos</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="06-introInferencia.html"><a href="#propiedades-de-la-funci%C3%B3n-de-densidad-conjunta"><i class="fa fa-check"></i><b>4.6.1</b> Propiedades de la función de densidad conjunta</a></li>
<li class="chapter" data-level="4.6.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.2</b> Densidades marginales en el caso continuo</a></li>
<li class="chapter" data-level="4.6.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.3</b> Densidad condicional en el caso continuo</a></li>
<li class="chapter" data-level="4.6.4" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-normal-bivariante"><i class="fa fa-check"></i><b>4.6.4</b> La Distribución Normal Bivariante</a></li>
<li class="chapter" data-level="4.6.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales-1"><i class="fa fa-check"></i><b>4.6.5</b> Distribuciones Condicionales</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#independencia-de-variables-aleatorias"><i class="fa fa-check"></i><b>4.7</b> Independencia de variables aleatorias</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="06-introInferencia.html"><a href="#primera-caracterizaci%C3%B3n-de-la-independencia"><i class="fa fa-check"></i><b>4.7.1</b> Primera caracterización de la independencia</a></li>
<li class="chapter" data-level="4.7.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-las-variables-independientes"><i class="fa fa-check"></i><b>4.7.2</b> Propiedades de las variables independientes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#momentos-de-vectores-aleatorios"><i class="fa fa-check"></i><b>4.8</b> Momentos de vectores aleatorios</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#esperanza-de-un-vector-aleatorio-o-vector-de-medias"><i class="fa fa-check"></i><b>4.8.1</b> Esperanza de un vector aleatorio o vector de medias</a></li>
<li class="chapter" data-level="4.8.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-entre-dos-variables-aleatorias"><i class="fa fa-check"></i><b>4.8.2</b> Covarianza entre dos variables aleatorias</a></li>
<li class="chapter" data-level="4.8.3" data-path="06-introInferencia.html"><a href="#covarianza-y-correlaci%C3%B3n"><i class="fa fa-check"></i><b>4.8.3</b> Covarianza y correlación</a></li>
<li class="chapter" data-level="4.8.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.4</b> Matriz de varianzas-covarianzas</a></li>
<li class="chapter" data-level="4.8.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>4.8.5</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="4.8.6" data-path="06-introInferencia.html"><a href="#segunda-caracterizaci%C3%B3n-de-la-independencia"><i class="fa fa-check"></i><b>4.8.6</b> Segunda caracterización de la independencia</a></li>
<li class="chapter" data-level="4.8.7" data-path="06-introInferencia.html"><a href="#relaci%C3%B3n-entre-incorrelaci%C3%B3n-e-independencia"><i class="fa fa-check"></i><b>4.8.7</b> Relación entre incorrelación e independencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="grandes-muestras.html"><a href="grandes-muestras.html"><i class="fa fa-check"></i><b>5</b> Grandes muestras</a>
<ul>
<li class="chapter" data-level="5.1" data-path="06-introInferencia.html"><a href="#introducci%C3%B3n-aproximaciones-asint%C3%B3ticas"><i class="fa fa-check"></i><b>5.1</b> Introducción: Aproximaciones asintóticas</a></li>
<li class="chapter" data-level="5.2" data-path="06-introInferencia.html"><a href="#ley-de-los-grandes-n%C3%BAmeros-ley-d%C3%A9bil"><i class="fa fa-check"></i><b>5.2</b> Ley de los Grandes Números (Ley débil)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ejemplo-3"><i class="fa fa-check"></i><b>5.2.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="06-introInferencia.html"><a href="#el-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3</b> El teorema central del límite</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#sumas-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.3.1</b> Sumas de variables aleatorias</a></li>
<li class="chapter" data-level="5.3.2" data-path="06-introInferencia.html"><a href="#definici%C3%B3n-de-convergencia-en-ley"><i class="fa fa-check"></i><b>5.3.2</b> Definición de convergencia en ley</a></li>
<li class="chapter" data-level="5.3.3" data-path="06-introInferencia.html"><a href="#enunciado-del-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3.3</b> Enunciado del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.4" data-path="06-introInferencia.html"><a href="#algunos-ejemplos-de-aplicaci%C3%B3n-del-tcl"><i class="fa fa-check"></i><b>5.3.4</b> Algunos ejemplos de aplicación del TCL</a></li>
<li class="chapter" data-level="5.3.5" data-path="06-introInferencia.html"><a href="#casos-particulares-m%C3%A1s-notables"><i class="fa fa-check"></i><b>5.3.5</b> Casos particulares más notables</a></li>
<li class="chapter" data-level="5.3.6" data-path="06-introInferencia.html"><a href="#interpretaci%C3%B3n-del-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3.6</b> Interpretación del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.7" data-path="grandes-muestras.html"><a href="grandes-muestras.html#acerca-de-las-variables-aproximadamente-normales"><i class="fa fa-check"></i><b>5.3.7</b> Acerca de las variables aproximadamente normales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="06-introInferencia.html"><a href="#introducci%C3%B3n-a-la-inferencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>6</b> Introducción a la inferencia estadística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="06-introInferencia.html"><a href="#inferencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>6.1</b> Inferencia estadística</a></li>
<li class="chapter" data-level="6.2" data-path="06-introInferencia.html"><a href="#problemas-de-inferencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>6.2</b> Problemas de inferencia estadística</a></li>
<li class="chapter" data-level="6.3" data-path="06-introInferencia.html"><a href="#distribuci%C3%B3n-de-la-poblaci%C3%B3n"><i class="fa fa-check"></i><b>6.3</b> Distribución de la población</a></li>
<li class="chapter" data-level="6.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html"><i class="fa fa-check"></i><b>6.4</b> Muestra aleatoria simple</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="06-introInferencia.html"><a href="#definici%C3%B3n"><i class="fa fa-check"></i><b>6.4.1</b> Definición</a></li>
<li class="chapter" data-level="6.4.2" data-path="06-introInferencia.html"><a href="#distribuci%C3%B3n-de-la-muestra"><i class="fa fa-check"></i><b>6.4.2</b> Distribución de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="06-introInferencia.html"><a href="#estad%C3%ADsticos"><i class="fa fa-check"></i><b>6.5</b> Estadísticos</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="06-introInferencia.html"><a href="#definici%C3%B3n-1"><i class="fa fa-check"></i><b>6.5.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="06-introInferencia.html"><a href="#distribuci%C3%B3n-en-el-muestreo-de-un-estad%C3%ADstico"><i class="fa fa-check"></i><b>6.6</b> Distribución en el muestreo de un estadístico</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="06-introInferencia.html"><a href="#demostraci%C3%B3n"><i class="fa fa-check"></i><b>6.6.1</b> Demostración:</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-emp%C3%ADrica"><i class="fa fa-check"></i><b>6.7</b> La distribución empírica</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="06-introInferencia.html"><a href="#definici%C3%B3n-2"><i class="fa fa-check"></i><b>6.7.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#los-momentos-muestrales"><i class="fa fa-check"></i><b>6.8</b> Los momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="06-introInferencia.html"><a href="#definici%C3%B3n-3"><i class="fa fa-check"></i><b>6.8.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="06-introInferencia.html"><a href="#distribuci%C3%B3n-en-el-muestreo-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.9</b> Distribución en el muestreo de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10" data-path="06-introInferencia.html"><a href="#propiedades-asint%C3%B3ticas-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.10</b> Propiedades asintóticas de los momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#convergencia-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.10.1</b> Convergencia de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10.2" data-path="06-introInferencia.html"><a href="#distribuci%C3%B3n-asint%C3%B3tica"><i class="fa fa-check"></i><b>6.10.2</b> Distribución asintótica</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestreo-en-poblaciones-normales"><i class="fa fa-check"></i><b>6.11</b> Muestreo en poblaciones normales</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-chi-cuadrado"><i class="fa fa-check"></i><b>6.11.1</b> La distribución chi-cuadrado</a></li>
<li class="chapter" data-level="6.11.2" data-path="06-introInferencia.html"><a href="#distribuci%C3%B3n-t-de-student"><i class="fa fa-check"></i><b>6.11.2</b> Distribución <span class="math inline">\(t\)</span> de Student</a></li>
<li class="chapter" data-level="6.11.3" data-path="06-introInferencia.html"><a href="#la-distribuci%C3%B3n-f-de-fisher"><i class="fa fa-check"></i><b>6.11.3</b> La distribución <span class="math inline">\(F\)</span> de Fisher</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="06-introInferencia.html"><a href="#estimaci%C3%B3n-puntual"><i class="fa fa-check"></i><b>7</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1" data-path="06-introInferencia.html"><a href="#el-problema-de-la-estimaci%C3%B3n-puntual"><i class="fa fa-check"></i><b>7.1</b> El problema de la estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html"><i class="fa fa-check"></i><b>7.1.1</b> Criterios de optimalidad de estimadores. El Riesgo</a></li>
<li class="chapter" data-level="7.1.2" data-path="06-introInferencia.html"><a href="#el-error-cuadr%C3%A1tico-medio"><i class="fa fa-check"></i><b>7.1.2</b> El error cuadrático medio</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estudio-de-las-propiedades-deseables-de-los-estimadores"><i class="fa fa-check"></i><b>7.2</b> Estudio de las propiedades deseables de los estimadores</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-sesgo"><i class="fa fa-check"></i><b>7.2.1</b> El sesgo</a></li>
<li class="chapter" data-level="7.2.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#consistencia"><i class="fa fa-check"></i><b>7.2.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estimadores-consistentes"><i class="fa fa-check"></i><b>7.3</b> Propiedades de los estimadores consistentes</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#eficiencia"><i class="fa fa-check"></i><b>7.3.1</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="06-introInferencia.html"><a href="#informaci%C3%B3n-de-fisher-y-cota-de-cramerrao"><i class="fa fa-check"></i><b>7.4</b> Información de Fisher y cota de CramerRao</a></li>
<li class="chapter" data-level="7.5" data-path="06-introInferencia.html"><a href="#informaci%C3%B3n-y-verosimilitud-de-un-modelo-estad%C3%ADstico"><i class="fa fa-check"></i><b>7.5</b> Información y verosimilitud de un modelo estadístico</a></li>
<li class="chapter" data-level="7.6" data-path="06-introInferencia.html"><a href="#informaci%C3%B3n-de-fisher"><i class="fa fa-check"></i><b>7.6</b> Información de Fisher</a></li>
<li class="chapter" data-level="7.7" data-path="estimación-puntual.html"><a href="estimación-puntual.html#la-desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>7.7</b> La desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="7.8" data-path="06-introInferencia.html"><a href="#caracterizaci%C3%B3n-del-estimador-eficiente"><i class="fa fa-check"></i><b>7.8</b> Caracterización del estimador eficiente</a></li>
<li class="chapter" data-level="7.9" data-path="06-introInferencia.html"><a href="#estad%C3%ADsticos-suficientes"><i class="fa fa-check"></i><b>7.9</b> Estadísticos suficientes</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="06-introInferencia.html"><a href="#definici%C3%B3-de-estad%C3%ADsticop-suficiente"><i class="fa fa-check"></i><b>7.9.1</b> Definició de estadísticop suficiente</a></li>
<li class="chapter" data-level="7.9.2" data-path="06-introInferencia.html"><a href="#teorema-de-factorizaci%C3%B3n"><i class="fa fa-check"></i><b>7.9.2</b> Teorema de factorización</a></li>
<li class="chapter" data-level="7.9.3" data-path="06-introInferencia.html"><a href="#propiedades-de-los-estad%C3%ADsticos-suficientes"><i class="fa fa-check"></i><b>7.9.3</b> Propiedades de los estadísticos suficientes</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="06-introInferencia.html"><a href="#obtenci%C3%B3n-de-estimadores"><i class="fa fa-check"></i><b>7.10</b> Obtención de estimadores</a></li>
<li class="chapter" data-level="7.11" data-path="06-introInferencia.html"><a href="#el-m%C3%A9todo-de-los-momentos"><i class="fa fa-check"></i><b>7.11</b> El método de los momentos</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#observaciones"><i class="fa fa-check"></i><b>7.11.1</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="06-introInferencia.html"><a href="#el-m%C3%A9todo-del-m%C3%A1ximo-de-verosimilitud"><i class="fa fa-check"></i><b>7.12</b> El método del máximo de verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="06-introInferencia.html"><a href="#estimaci%C3%B3n-por-int%C3%A9rvalos"><i class="fa fa-check"></i><b>8</b> Estimación por intérvalos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="06-introInferencia.html"><a href="#motivaci%C3%B3n-de-los-intervalos-de-confianza-la-estimaci%C3%B3n-puntual-casi-siempre-es-falsa"><i class="fa fa-check"></i><b>8.1</b> Motivación de los intervalos de confianza: la estimación puntual casi siempre es falsa</a></li>
<li class="chapter" data-level="8.2" data-path="06-introInferencia.html"><a href="#definici%C3%B3n-formal-de-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.2</b> Definición formal de intervalo de confianza</a></li>
<li class="chapter" data-level="8.3" data-path="06-introInferencia.html"><a href="#un-ejemplo-de-construcci%C3%B3n-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.3</b> Un ejemplo de construcción de un intervalo de confianza</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html"><i class="fa fa-check"></i><b>8.3.1</b> Planteamiento</a></li>
<li class="chapter" data-level="8.3.2" data-path="06-introInferencia.html"><a href="#desarrollo-de-la-construcci%C3%B3n"><i class="fa fa-check"></i><b>8.3.2</b> Desarrollo de la construcción</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="06-introInferencia.html"><a href="#por-qu%C3%A9-hablamos-de-confianza-y-no-de-probabilidad"><i class="fa fa-check"></i><b>8.4</b> ¿Por qué hablamos de confianza y no de probabilidad?</a></li>
<li class="chapter" data-level="8.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#elementos-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.5</b> Elementos de un intervalo de confianza</a></li>
<li class="chapter" data-level="8.6" data-path="06-introInferencia.html"><a href="#m%C3%A9todo-del-pivote"><i class="fa fa-check"></i><b>8.6</b> Método del pivote</a></li>
<li class="chapter" data-level="8.7" data-path="06-introInferencia.html"><a href="#algunos-estad%C3%ADsticos-pivote"><i class="fa fa-check"></i><b>8.7</b> Algunos estadísticos pivote</a></li>
<li class="chapter" data-level="8.8" data-path="06-introInferencia.html"><a href="#intervalo-de-confianza-para-la-media-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.8</b> Intervalo de confianza para la media de una distribución Normal</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-conocida"><i class="fa fa-check"></i><b>8.8.1</b> Caso de varianza conocida</a></li>
<li class="chapter" data-level="8.8.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-desconocida"><i class="fa fa-check"></i><b>8.8.2</b> Caso de varianza desconocida</a></li>
<li class="chapter" data-level="8.8.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#calculo-con-r"><i class="fa fa-check"></i><b>8.8.3</b> Calculo con R</a></li>
<li class="chapter" data-level="8.8.4" data-path="06-introInferencia.html"><a href="#tama%C3%B1o-de-muestra-para-la-media-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.8.4</b> Tamaño de muestra para la media de una distribución Normal</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="06-introInferencia.html"><a href="#intervalo-de-confianza-para-la-varianza-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.9</b> Intervalo de confianza para la varianza de una distribución Normal</a></li>
<li class="chapter" data-level="8.10" data-path="06-introInferencia.html"><a href="#intervalo-de-confianza-para-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>8.10</b> Intervalo de confianza para una proporción</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="06-introInferencia.html"><a href="#aproximaci%C3%B3n-asint%C3%B3tica"><i class="fa fa-check"></i><b>8.10.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.10.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto"><i class="fa fa-check"></i><b>8.10.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.10.3" data-path="06-introInferencia.html"><a href="#tama%C3%B1o-muestral-para-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>8.10.3</b> Tamaño muestral para una proporción</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="06-introInferencia.html"><a href="#intervalo-de-confianza-para-el-par%C3%A1metro-de-una-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.11</b> Intervalo de confianza para el parámetro de una distribución de Poisson</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="06-introInferencia.html"><a href="#aproximaci%C3%B3n-asint%C3%B3tica-1"><i class="fa fa-check"></i><b>8.11.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.11.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto-1"><i class="fa fa-check"></i><b>8.11.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.11.3" data-path="06-introInferencia.html"><a href="#tama%C3%B1o-de-muestra-para-el-par%C3%A1metro-de-una-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.11.3</b> Tamaño de muestra para el parámetro de una distribución de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes."><i class="fa fa-check"></i><b>8.12</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.12.1" data-path="06-introInferencia.html"><a href="#varianza-com%C3%BAn"><i class="fa fa-check"></i><b>8.12.1</b> Varianza común</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.-1"><i class="fa fa-check"></i><b>8.13</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.13.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#varianza-diferente"><i class="fa fa-check"></i><b>8.13.1</b> Varianza diferente</a></li>
<li class="chapter" data-level="8.13.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianzas-desconocidas-y-diferentes"><i class="fa fa-check"></i><b>8.13.2</b> Caso de varianzas desconocidas y diferentes</a></li>
<li class="chapter" data-level="8.13.3" data-path="06-introInferencia.html"><a href="#int%C3%A9rvalos-de-confianza-y-decisiones-estad%C3%ADsticas"><i class="fa fa-check"></i><b>8.13.3</b> Intérvalos de confianza y decisiones estadísticas</a></li>
</ul></li>
<li class="chapter" data-level="8.14" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-cociente-de-varianzas-de-distribuciones-normales-independientes"><i class="fa fa-check"></i><b>8.14</b> Intervalo de confianza para el cociente de varianzas de distribuciones normales independientes</a></li>
<li class="chapter" data-level="8.15" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#complementos"><i class="fa fa-check"></i><b>8.15</b> Complementos</a>
<ul>
<li class="chapter" data-level="8.15.1" data-path="06-introInferencia.html"><a href="#interpretaci%C3%B3n-geom%C3%A9trica-de-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>8.15.1</b> Interpretación geométrica de los intervalos de confianza</a></li>
<li class="chapter" data-level="8.15.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-para-muestras-grandes"><i class="fa fa-check"></i><b>8.15.2</b> Intervalos para muestras grandes</a></li>
<li class="chapter" data-level="8.15.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-exactos-para-distribuciones-discretas"><i class="fa fa-check"></i><b>8.15.3</b> Intervalos exactos para distribuciones discretas</a></li>
<li class="chapter" data-level="8.15.4" data-path="06-introInferencia.html"><a href="#una-aproximaci%C3%B3n-diferente-para-la-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.15.4</b> Una aproximación diferente para la distribución de Poisson</a></li>
<li class="chapter" data-level="8.15.5" data-path="06-introInferencia.html"><a href="#aproximaci%C3%B3n-mediante-ch%C3%A9bishev"><i class="fa fa-check"></i><b>8.15.5</b> Aproximación mediante Chébishev</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="06-introInferencia.html"><a href="#pruebas-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="06-introInferencia.html"><a href="#introducci%C3%B3n-2"><i class="fa fa-check"></i><b>9.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="06-introInferencia.html"><a href="#de-las-hip%C3%B3tesis-cient%C3%ADficas-a-las-hip%C3%B3tesis-estad%C3%ADsticas"><i class="fa fa-check"></i><b>9.1.1</b> De las hipótesis científicas a las hipótesis estadísticas</a></li>
<li class="chapter" data-level="9.1.2" data-path="06-introInferencia.html"><a href="#del-lenguaje-natural-a-la-hip%C3%B3tesis-estad%C3%ADstica"><i class="fa fa-check"></i><b>9.1.2</b> Del lenguaje natural a la hipótesis estadística</a></li>
<li class="chapter" data-level="9.1.3" data-path="06-introInferencia.html"><a href="#caso-1-presentaci%C3%B3n"><i class="fa fa-check"></i><b>9.1.3</b> Caso 1: Presentación</a></li>
<li class="chapter" data-level="9.1.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>9.1.4</b> Caso 1: Modelo de probabilidad</a></li>
<li class="chapter" data-level="9.1.5" data-path="06-introInferencia.html"><a href="#caso-2-presentaci%C3%B3n"><i class="fa fa-check"></i><b>9.1.5</b> Caso 2: Presentación</a></li>
<li class="chapter" data-level="9.1.6" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-modelo-de-probabilidad"><i class="fa fa-check"></i><b>9.1.6</b> Caso 2: Modelo de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="06-introInferencia.html"><a href="#las-hip%C3%B3tesis-del-contraste-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.2</b> Las hipótesis del contraste de hipótesis</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="06-introInferencia.html"><a href="#caso-1-hip%C3%B3tesis-para-dirimir-la-controversia-sobre-el-n%C3%BAmero-de-hembras"><i class="fa fa-check"></i><b>9.2.1</b> Caso 1: Hipótesis para dirimir la controversia sobre el número de hembras</a></li>
<li class="chapter" data-level="9.2.2" data-path="06-introInferencia.html"><a href="#caso-2-hip%C3%B3tesis-a-contrastar-en-el-problema-de-la-tasa-de-statdrolona"><i class="fa fa-check"></i><b>9.2.2</b> Caso 2: Hipótesis a contrastar en el problema de la tasa de statdrolona</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="06-introInferencia.html"><a href="#compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.3</b> Compatibilidad de resultados e hipótesis</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="06-introInferencia.html"><a href="#caso-1-compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.3.1</b> Caso 1: Compatibilidad de resultados e hipótesis</a></li>
<li class="chapter" data-level="9.3.2" data-path="06-introInferencia.html"><a href="#caso-2-compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.3.2</b> Caso 2: Compatibilidad de resultados e hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#no-todo-es-igualmente-probable"><i class="fa fa-check"></i><b>9.4</b> No todo es igualmente probable…</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="06-introInferencia.html"><a href="#caso-1-una-regi%C3%B3n-con-n.%C2%BA-de-hembras-con-baja-probabilidad-bajo-mathrmh_0"><i class="fa fa-check"></i><b>9.4.1</b> Caso 1: Una región con n.º de hembras con baja probabilidad bajo <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
<li class="chapter" data-level="9.4.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-medias-de-las-tasas-de-statdrolona-improbables-si-se-cumple-mathrmh_0"><i class="fa fa-check"></i><b>9.4.2</b> Caso 2: Medias de las tasas de statdrolona improbables si se cumple <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="06-introInferencia.html"><a href="#el-papel-privilegiado-de-la-hip%C3%B3tesis-nula-criterio-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>9.5</b> El papel privilegiado de la hipótesis nula: criterio de decisión</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="06-introInferencia.html"><a href="#caso-1-n.%C2%BA-de-nidos-propuestos-ad-hoc-como-inicio-de-regi%C3%B3n-cr%C3%ADtica.-regla-de-decisi%C3%B3n-resultante"><i class="fa fa-check"></i><b>9.5.1</b> Caso 1: N.º de nidos propuestos ad hoc como inicio de región crítica. Regla de decisión resultante</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="06-introInferencia.html"><a href="#hip%C3%B3tesis-nula-y-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>9.6</b> Hipótesis nula y nivel de significación</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="06-introInferencia.html"><a href="#caso-1-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>9.6.1</b> Caso 1: Nivel de significación</a></li>
<li class="chapter" data-level="9.6.2" data-path="06-introInferencia.html"><a href="#caso-1-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>9.6.2</b> Caso 1: Elección de la región crítica</a></li>
<li class="chapter" data-level="9.6.3" data-path="06-introInferencia.html"><a href="#caso-2-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>9.6.3</b> Caso 2: Elección de la región crítica</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="06-introInferencia.html"><a href="#regi%C3%B3n-cr%C3%ADtica-y-formalizaci%C3%B3n-del-contraste"><i class="fa fa-check"></i><b>9.7</b> Región crítica y formalización del contraste</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="06-introInferencia.html"><a href="#caso-1-resumen-de-conceptos-asociados-al-contraste.-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>9.7.1</b> Caso 1: Resumen de conceptos asociados al contraste. Región crítica</a></li>
<li class="chapter" data-level="9.7.2" data-path="06-introInferencia.html"><a href="#caso-2-tabla-resumen-de-la-regi%C3%B3n-cr%C3%ADtica-el-estad%C3%ADstico-de-test-y-del-criterio-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>9.7.2</b> Caso 2: Tabla resumen de la región crítica, el estadístico de test y del criterio de decisión</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="06-introInferencia.html"><a href="#tabla-de-decisi%C3%B3n-del-contraste"><i class="fa fa-check"></i><b>9.8</b> Tabla de decisión del contraste</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="06-introInferencia.html"><a href="#caso-1-evaluaci%C3%B3n-de-los-dos-errores-asociados-al-contraste"><i class="fa fa-check"></i><b>9.8.1</b> Caso 1: Evaluación de los dos errores asociados al contraste</a></li>
<li class="chapter" data-level="9.8.2" data-path="06-introInferencia.html"><a href="#caso-2-c%C3%A1lculo-expl%C3%ADcito-de-los-errores-de-primera-alpha-y-segunda-especie-1--beta"><i class="fa fa-check"></i><b>9.8.2</b> Caso 2: Cálculo explícito de los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="06-introInferencia.html"><a href="#relaci%C3%B3n-entre-el-error-de-tipo-i-y-el-de-tipo-ii"><i class="fa fa-check"></i><b>9.9</b> Relación entre el error de tipo I y el de tipo II</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="06-introInferencia.html"><a href="#caso-1-evaluaci%C3%B3n-de-alpha-y-1--beta-para-diferentes-regiones-cr%C3%ADticas"><i class="fa fa-check"></i><b>9.9.1</b> Caso 1: Evaluación de <span class="math inline">\(\alpha\)</span> y 1- <span class="math inline">\(\beta\)</span> para diferentes regiones críticas</a></li>
<li class="chapter" data-level="9.9.2" data-path="06-introInferencia.html"><a href="#caso-2-relaci%C3%B3n-entre-los-errores-de-primera-alpha-y-segunda-especie-1--beta"><i class="fa fa-check"></i><b>9.9.2</b> Caso 2: Relación entre los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="06-introInferencia.html"><a href="#potencia-y-test-m%C3%A1s-potente"><i class="fa fa-check"></i><b>9.10</b> Potencia y test más potente</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="06-introInferencia.html"><a href="#caso-1-potencia-en-hip%C3%B3tesis-simple-vs-simple"><i class="fa fa-check"></i><b>9.10.1</b> Caso 1: Potencia en hipótesis simple vs simple</a></li>
<li class="chapter" data-level="9.10.2" data-path="06-introInferencia.html"><a href="#caso-2-potencia-en-hip%C3%B3tesis-simple-vs-simple"><i class="fa fa-check"></i><b>9.10.2</b> Caso 2: Potencia en hipótesis simple vs simple</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="06-introInferencia.html"><a href="#efecto-del-tama%C3%B1o-muestral"><i class="fa fa-check"></i><b>9.11</b> Efecto del tamaño muestral</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1"><i class="fa fa-check"></i><b>9.11.1</b> Caso 1</a></li>
<li class="chapter" data-level="9.11.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2"><i class="fa fa-check"></i><b>9.11.2</b> Caso 2</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="06-introInferencia.html"><a href="#hip%C3%B3tesis-simples-vs.-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>9.12</b> Hipótesis simples vs. hipótesis compuestas</a>
<ul>
<li class="chapter" data-level="9.12.1" data-path="06-introInferencia.html"><a href="#caso-1-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>9.12.1</b> Caso 1: Hipótesis compuestas</a></li>
<li class="chapter" data-level="9.12.2" data-path="06-introInferencia.html"><a href="#caso-2-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>9.12.2</b> Caso 2: Hipótesis compuestas</a></li>
</ul></li>
<li class="chapter" data-level="9.13" data-path="06-introInferencia.html"><a href="#funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>9.13</b> Función de potencia</a>
<ul>
<li class="chapter" data-level="9.13.1" data-path="06-introInferencia.html"><a href="#caso-1-funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>9.13.1</b> Caso 1: Función de potencia</a></li>
<li class="chapter" data-level="9.13.2" data-path="06-introInferencia.html"><a href="#caso-2-funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>9.13.2</b> Caso 2: Función de potencia</a></li>
</ul></li>
<li class="chapter" data-level="9.14" data-path="06-introInferencia.html"><a href="#tests-%C3%B3ptimos"><i class="fa fa-check"></i><b>9.14</b> Tests óptimos</a></li>
<li class="chapter" data-level="9.15" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-bilaterales-y-pruebas-unilaterales"><i class="fa fa-check"></i><b>9.15</b> Pruebas bilaterales y pruebas unilaterales</a>
<ul>
<li class="chapter" data-level="9.15.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-prueba-unilateral"><i class="fa fa-check"></i><b>9.15.1</b> Caso 1: Prueba unilateral</a></li>
<li class="chapter" data-level="9.15.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-prueba-unilateral"><i class="fa fa-check"></i><b>9.15.2</b> Caso 2: Prueba unilateral</a></li>
</ul></li>
<li class="chapter" data-level="9.16" data-path="06-introInferencia.html"><a href="#elecci%C3%B3n-del-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>9.16</b> Elección del nivel de significación</a></li>
<li class="chapter" data-level="9.17" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#el-p-valor"><i class="fa fa-check"></i><b>9.17</b> El p-valor</a>
<ul>
<li class="chapter" data-level="9.17.1" data-path="06-introInferencia.html"><a href="#caso-1-c%C3%A1lculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>9.17.1</b> Caso 1: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="9.17.2" data-path="06-introInferencia.html"><a href="#caso-2-c%C3%A1lculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>9.17.2</b> Caso 2: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="9.17.3" data-path="06-introInferencia.html"><a href="#caso-2-c%C3%A1lculo-del-p-valor-prueba-bilateral"><i class="fa fa-check"></i><b>9.17.3</b> Caso 2: Cálculo del p-valor (prueba bilateral)</a></li>
</ul></li>
<li class="chapter" data-level="9.18" data-path="06-introInferencia.html"><a href="#pruebas-exactas-y-pruebas-asint%C3%B3ticas"><i class="fa fa-check"></i><b>9.18</b> Pruebas exactas y pruebas asintóticas</a>
<ul>
<li class="chapter" data-level="9.18.1" data-path="06-introInferencia.html"><a href="#caso-1-test-asint%C3%B3tico"><i class="fa fa-check"></i><b>9.18.1</b> Caso 1: Test asintótico</a></li>
<li class="chapter" data-level="9.18.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-test-exacto"><i class="fa fa-check"></i><b>9.18.2</b> Caso 2: Test exacto</a></li>
</ul></li>
<li class="chapter" data-level="9.19" data-path="06-introInferencia.html"><a href="#relaci%C3%B3n-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>9.19</b> Relación con los intervalos de confianza</a>
<ul>
<li class="chapter" data-level="9.19.1" data-path="06-introInferencia.html"><a href="#caso-2-relaci%C3%B3n-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>9.19.1</b> Caso 2: Relación con los intervalos de confianza</a></li>
</ul></li>
<li class="chapter" data-level="9.20" data-path="06-introInferencia.html"><a href="#tama%C3%B1os-de-muestra.-diferencia-m%C3%ADnima-significativa"><i class="fa fa-check"></i><b>9.20</b> Tamaños de muestra. Diferencia mínima significativa</a>
<ul>
<li class="chapter" data-level="9.20.1" data-path="06-introInferencia.html"><a href="#caso-2-c%C3%A1lculo-del-tama%C3%B1o-de-la-muestra"><i class="fa fa-check"></i><b>9.20.1</b> Caso 2: Cálculo del tamaño de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="9.21" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#esquema-de-un-contraste-correctamente-planteado"><i class="fa fa-check"></i><b>9.21</b> Esquema de un contraste correctamente planteado</a></li>
<li class="chapter" data-level="9.22" data-path="06-introInferencia.html"><a href="#significaci%C3%B3n-estad%C3%ADstica-y-significaci%C3%B3n-aplicada"><i class="fa fa-check"></i><b>9.22</b> Significación estadística y significación aplicada</a>
<ul>
<li class="chapter" data-level="9.22.1" data-path="06-introInferencia.html"><a href="#caso-2-significaci%C3%B3n-estad%C3%ADstica-y-aplicada"><i class="fa fa-check"></i><b>9.22.1</b> Caso 2: Significación estadística y aplicada</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html"><i class="fa fa-check"></i><b>10</b> Inferencia Aplicada</a>
<ul>
<li class="chapter" data-level="10.1" data-path="06-introInferencia.html"><a href="#pruebas-de-normalidad.pruebas-gr%C3%A1ficas.-el-test-de-shapiro-wilks"><i class="fa fa-check"></i><b>10.1</b> Pruebas de normalidad.Pruebas gráficas. El test de Shapiro-Wilks</a></li>
<li class="chapter" data-level="10.2" data-path="06-introInferencia.html"><a href="#pruebas-de-hip%C3%B3tesis-para-constrastar-variables-cuantitativas-pruebas-param%C3%A8tricas-t-test-y-anova"><i class="fa fa-check"></i><b>10.2</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas paramètricas t-test y Anova</a></li>
<li class="chapter" data-level="10.3" data-path="06-introInferencia.html"><a href="#pruebas-de-hip%C3%B3tesis-para-constrastar-variables-cuantitativas-pruebas-de-hip%C3%B3tesis-no-param%C3%A9tricas-de-wilcoxon-y-kruskal-wallis"><i class="fa fa-check"></i><b>10.3</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas de hipótesis no paramétricas de Wilcoxon y Kruskal-Wallis</a></li>
<li class="chapter" data-level="10.4" data-path="06-introInferencia.html"><a href="#contrastes-para-datos-categ%C3%B3ricos.-pruebas-binomiales-ji-cuadrado-y-test-de-fisher."><i class="fa fa-check"></i><b>10.4</b> Contrastes para datos categóricos. Pruebas binomiales, ji cuadrado y test de Fisher.</a></li>
<li class="chapter" data-level="10.5" data-path="06-introInferencia.html"><a href="#riesgo-relativo-y-raz%C3%B3n-de-odds"><i class="fa fa-check"></i><b>10.5</b> Riesgo relativo y razón de «odds»</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="06-introInferencia.html"><a href="#computaci%C3%B3n-intensiva-y-multiple-testing"><i class="fa fa-check"></i><b>11</b> Computación Intensiva y <em>Multiple Testing</em></a>
<ul>
<li class="chapter" data-level="11.1" data-path="06-introInferencia.html"><a href="#tests-de-permutaciones-qu%C3%A9-cu%C3%A1ndo-c%C3%B3mo"><i class="fa fa-check"></i><b>11.1</b> Tests de permutaciones; ¿Qué?, ¿Cuándo?, ¿Cómo?</a></li>
<li class="chapter" data-level="11.2" data-path="06-introInferencia.html"><a href="#el-bootstrap-en-contraste-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>11.2</b> El bootstrap en contraste de hipótesis</a></li>
<li class="chapter" data-level="11.3" data-path="06-introInferencia.html"><a href="#el-problema-de-las-comparaciones-m%C3%BAltiples"><i class="fa fa-check"></i><b>11.3</b> El problema de las comparaciones múltiples</a></li>
<li class="chapter" data-level="11.4" data-path="06-introInferencia.html"><a href="#m%C3%A9todos-de-control-de-error-fwer-y-fdr"><i class="fa fa-check"></i><b>11.4</b> Métodos de control de error: FWER y FDR</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de Inferencia Estadistica</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introducción-a-la-inferencia-estadística" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Capítulo 6</span> Introducción a la inferencia estadística<a href="#introducci%C3%B3n-a-la-inferencia-estad%C3%ADstica" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="inferencia-estadística" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Inferencia estadística<a href="#inferencia-estad%C3%ADstica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para comenzar, vamos a definir cuál es el ámbito de estudio de la inferencia estadística desde su relación con el cálculo de probabilidades. El cálculo de probabilidades proporciona una teoría matemática que permite analizar (o modelizar) las propiedades de los fenómenos donde interviene el azar.
El cálculo de probabilidades utiliza como modelo básico para cualquier situación aleatoria el concepto de espacio de probabilidades <span class="math inline">\((\Omega, \mathcal{A}, P)\)</span> y una variable aleatoria <span class="math inline">\(X: \Omega \rightarrow \mathbb{R}\)</span> definida sobre él.
El conocimiento de la distribución de la variable aleatoria permite:</p>
<ol style="list-style-type: decimal">
<li>Análisis deductivo de situaciones. Por ejemplo: si asumimos que el peso de los recién nacidos se distribuye según una distribución <span class="math inline">\(N(\mu=\)</span> <span class="math inline">\(3 \mathrm{~kg}, \sigma=0.25 \mathrm{~kg}\)</span> ), nos puede interesar calcular la probabilidad de que un recién nacido pese entre 2.9 y 3.1 kg , o encontrar unos valores centrados en la media entre los cuales esperemos que se encuentren el <span class="math inline">\(10 \%(25 \%, 50 \%, 95 \%, \ldots)\)</span> de los recién nacidos.</li>
<li>Modelización de situaciones aleatorias. Por ejemplo: si asumimos que el tiempo, en años, hasta que se estropea un componente de un ordenador se distribuye según una distribución exponencial <span class="math inline">\(T \sim \xi(\lambda=\)</span> <span class="math inline">\(0.3)\)</span>, nos puede interesar calcular la probabilidad de que un componente dado dure más de 4 años.</li>
</ol>
<p>En los casos anteriores nos encontramos en una situación muy común, donde ya disponemos de un modelo sobre el cual efectuamos los cálculos, pero del cual desconocemos la procedencia. Parece razonable, y de hecho es precisamente así, que si queremos adaptar un modelo a una situación debamos basarnos únicamente en las observaciones del fenómeno.
Si queremos saber cómo se distribuyen los pesos de los recién nacidos tomaremos unos cuantos, los pesaremos y después observaremos la distribución de estos. Puede que no sea necesario pesar a todos los recién nacidos (jde hecho, no es posible!), pero tampoco es posible deducir la ley por consideraciones puramente teóricas.
Ahora, en lugar de partir de un espacio de probabilidades, partiremos de unas observaciones <span class="math inline">\(\left(x_{1}, \ldots, x_{n}\right)\)</span> y el objetivo que perseguiremos será obtener información sobre la distribución de probabilidades de un fenómeno a partir de una observación no exhaustiva del mismo.</p>
</div>
<div id="problemas-de-inferencia-estadística" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> Problemas de inferencia estadística<a href="#problemas-de-inferencia-estad%C3%ADstica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hemos presentado como objetivo de la inferencia estadística inducir propiedades del modelo probabilístico que representa la población a partir de un conjunto de observaciones.
Según el tipo de conclusión que queramos extraer, diferenciaremos diferentes tipos de problemas:</p>
<ol style="list-style-type: decimal">
<li>Si queremos utilizar la información proporcionada por la muestra para obtener un pronóstico numérico único (es decir, una única aproximación numérica) de una o más características de la población, tenemos un problema de estimación puntual.</li>
<li>Si queremos obtener información sobre un rango de valores dentro del cual podamos afirmar, con un cierto grado de confianza, que podemos capturar un parámetro desconocido de la distribución, hablamos de estimación por intervalo.</li>
<li>Si lo que queremos hacer es decidir si podemos aceptar o debemos rechazar una afirmación sobre la distribución de probabilidad del fenómeno estudiado, hablamos de contraste de hipótesis. Este contraste puede ser:</li>
</ol>
<ul>
<li>Paramétrico: si la afirmación (la hipótesis) se refiere a los parámetros de la distribución.</li>
<li>No paramétrico: si la afirmación es sobre la forma de la distribución.</li>
</ul>
</div>
<div id="distribución-de-la-población" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> Distribución de la población<a href="#distribuci%C3%B3n-de-la-poblaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Todo problema de inferencia está motivado por un cierto grado de desconocimiento de la ley de probabilidades que rige un determinado fenómeno aleatorio.
El caso más sencillo que encontramos es cuando nos interesa una cierta variable <span class="math inline">\(X\)</span> con una función de distribución <span class="math inline">\(F\)</span> desconocida en mayor o menor grado.
La distribución que teóricamente sigue la variable de interés <span class="math inline">\(X\)</span> en la población recibe el nombre de distribución teórica o distribución de la población. La distribución de la población es importante ya que, a menudo, se utiliza para determinar la distribución de alguna característica de los individuos de una población.
En los modelos de la inferencia estadística indicamos el relativo grado de desconocimiento sobre la distribución <span class="math inline">\(F\)</span> en función de su pertenencia a una familia <span class="math inline">\(\mathcal{F}\)</span> de distribuciones. Por ello, en lugar de explicar que <span class="math inline">\(X \sim F=F_{0}\)</span> indicaremos que <span class="math inline">\(X \sim F \in \mathcal{F}\)</span>, donde <span class="math inline">\(\mathcal{F}\)</span> puede ser un conjunto más o menos amplio de distribuciones de probabilidad, como todas las distribuciones normales o las distribuciones simétricas o las distribuciones discretas sobre <span class="math inline">\(\mathbb{N}\)</span>.
Muchas veces, la distribución poblacional <span class="math inline">\(F\)</span> está completamente especificada excepto por el valor de algún parámetro o parámetros. En este caso, podemos concretar más la forma de la familia de distribuciones:</p>
<p><span class="math display">\[
X \sim F \in \mathcal{F}=\left\{F_{\theta}: \theta \in \Theta \subset \mathbb{R}^{k}\right\}
\]</span></p>
<p>donde <span class="math inline">\(\Theta\)</span> es el espacio de los <span class="math inline">\(k\)</span> parámetros.
La familia de posibles distribuciones de probabilidad para <span class="math inline">\(X\)</span> se denomina, genéricamente, modelo estadístico y se indica como: <span class="math inline">\(\left\{X \sim F_{\theta}: \theta \in \Theta\right\}\)</span>. Veamos algunos ejemplos.</p>
<p>Ejemplo 1.3.1 Supongamos que <span class="math inline">\(X\)</span> representa la duración de un componente electrónico que no envejece, solo se estropea. Es decir, si en un instante <span class="math inline">\(t\)</span> está funcionando, su estado es el mismo que en cualquier momento del pasado y la distribución del tiempo hasta que se estropee es la misma que al principio. Esta propiedad se denomina falta de memoria.
Un modelo razonable para esta situación lo da la distribución de Weibull que, en este caso, podemos definir a través de la siguiente función de densidad:</p>
<p><span class="math display">\[
f_{\theta}(x)= \begin{cases}\alpha \beta x^{\beta-1} e^{-\alpha x^{\beta}} &amp; \text { si } x \geq 0 \\ 0 &amp; \text { si } x&lt;0\end{cases}
\]</span></p>
<p>La familia de distribuciones asociada es</p>
<p><span class="math display">\[
\mathcal{F}=\left\{F_{\theta}: \theta=(\alpha, \beta) \in(0, \infty) \times(0, \infty)\right\}
\]</span></p>
<p>Ejemplo 1.3.2 Supongamos que queremos determinar la masa de un cierto tipo de partículas elementales a partir de las observaciones en una cámara de burbujas. En cada observación obtenemos un dato de la masa de la partícula <span class="math inline">\(x_{i}\)</span> y asociado con ella un cierto error de medida <span class="math inline">\(\varepsilon\)</span>. Si la masa común de cada una de ellas es <span class="math inline">\(\mu\)</span>, entonces podemos escribir:</p>
<p><span class="math display">\[
x_{i}=\mu+\varepsilon_{i} \quad i=1, \ldots, n
\]</span></p>
<p>donde la distribución <span class="math inline">\(\varepsilon_{i} \sim F\)</span> es desconocida. Nuestro objetivo es obtener información sobre <span class="math inline">\(F\)</span>.
Si admitimos que <span class="math inline">\(P\left(\varepsilon_{i}&lt;0\right)=P\left(\varepsilon_{i}&gt;0\right)\)</span>, según el grado de exigencia que queramos tener, podemos suponer:</p>
<ul>
<li>Con un enfoque de inferencia paramétrica:</li>
</ul>
<p><span class="math display">\[
X \sim F \in \mathcal{F}=\left\{N(0, \sigma): \sigma \in \mathbb{R}^{+}\right\}
\]</span></p>
<ul>
<li>Con un enfoque de inferencia no paramétrica:</li>
</ul>
<p><span class="math display">\[
X \sim F \in \mathcal{F}=\{\text { Distribuciones simétricas }\}
\]</span></p>
</div>
<div id="muestra-aleatoria-simple" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Muestra aleatoria simple<a href="introducción-a-la-inferencia-estadística.html#muestra-aleatoria-simple" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="definición" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Definición<a href="#definici%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para estudiar un problema de inferencia estadística analizamos una muestra de tamaño <span class="math inline">\(n\)</span>. Se trata de escoger <span class="math inline">\(n\)</span> individuos o elementos de la población <span class="math inline">\(\Omega\)</span></p>
<p><span class="math display">\[
\omega_{1}, \omega_{2}, \ldots, \omega_{n}
\]</span></p>
<p>que sean representativos. El valor de <span class="math inline">\(n\)</span> y la forma de elección de los individuos de la muestra es una materia de Estadística llamada Muestreo estadístico. Por ahora y para simplificar, solo hace falta decir que la elección se hace de forma que todos los individuos tienen la misma probabilidad de estar presentes en la muestra, si es necesario con reemplazo, y que el valor de <span class="math inline">\(n\)</span> está dado.
En realidad, lo que nos interesa verdaderamente no son los individuos de la muestra sino las mediciones de una característica <span class="math inline">\(X\)</span> sobre ellos. Es decir, los valores de una variable aleatoria <span class="math inline">\(X\)</span> sobre estos individuos</p>
<p><span class="math display">\[
X\left(\omega_{1}\right)=x_{1}, X\left(\omega_{2}\right)=x_{2}, \ldots, X\left(\omega_{n}\right)=x_{n}
\]</span></p>
<p>También podemos pensar que los valores muestrales <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{n}\)</span> son generados directamente desde la variable aleatoria. En todo caso, los valores muestrales no son únicos y podemos generar varias muestras</p>
<p><span class="math display">\[
\begin{array}{ccccc}
x_{1}^{1} &amp; x_{2}^{1} &amp; x_{3}^{1} &amp; \ldots &amp; x_{n}^{1} \\
x_{1}^{2} &amp; x_{2}^{2} &amp; x_{3}^{2} &amp; \ldots &amp; x_{n}^{2} \\
\vdots &amp; \vdots &amp; \vdots &amp; &amp; \vdots \\
x_{1}^{s} &amp; x_{2}^{s} &amp; x_{3}^{s} &amp; \ldots &amp; x_{n}^{s}
\end{array}
\]</span></p>
<p>Si todos los valores son independientes, de la misma forma que <span class="math inline">\(x_{1}, x_{2}, x_{3}, \ldots, x_{n}\)</span> es una muestra generada por <span class="math inline">\(X\)</span>, podemos considerar todos los <span class="math inline">\(x_{1}^{i} \quad i=1, \ldots, s\)</span> provenientes de una variable aleatoria <span class="math inline">\(X_{1}\)</span> con la misma distribución que <span class="math inline">\(X\)</span> <span class="math inline">\(X_{1} \stackrel{d}{=} X\)</span> y que genera los primeros valores, los <span class="math inline">\(x_{i}^{2}\)</span> provenientes de una variable aleatoria <span class="math inline">\(X_{2} \stackrel{d}{=} X\)</span> que genera los segundos y así sucesivamente.
Todo esto nos lleva a definir el concepto de muestra aleatoria de una forma muy conveniente para trabajar con ella:</p>
<p>Definició 1.1 Una muestra aleatoria simple de tamaño <span class="math inline">\(n\)</span> de una variable aleatoria <span class="math inline">\(X\)</span> con distribución <span class="math inline">\(F\)</span> es una colección de <span class="math inline">\(n\)</span> variables aleatorias independientes <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> con la misma distribución <span class="math inline">\(F\)</span> que <span class="math inline">\(X\)</span>. Esto se suele indicar como:</p>
<p><span class="math display">\[
\mathbf{X}=X_{1}, X_{2}, \ldots, X_{n} \stackrel{i . i . d}{\sim} X
\]</span></p>
<p>Definició 1.2 El conjunto <span class="math inline">\(\left(x_{1}, x_{2}, \ldots, x_{n}\right) \in \mathbb{R}^{n}\)</span> de observaciones concretas de <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> se denomina realización de la muestra.</p>
</div>
<div id="distribución-de-la-muestra" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Distribución de la muestra<a href="#distribuci%C3%B3n-de-la-muestra" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una muestra aleatoria simple, como vector aleatorio <span class="math inline">\(n\)</span>-dimensional que es, tiene una distribución conjunta o distribución de la muestra que depende de <span class="math inline">\(F\)</span>, pero que obviamente es diferente, ya que en particular <span class="math inline">\(X\)</span> y <span class="math inline">\(\mathbf{X}\)</span> tienen dimensiones diferentes. Sin embargo, gracias a la independencia de las variables <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span>, la función de distribución conjunta de <span class="math inline">\(\mathbf{X}\)</span>, que podría ser muy complicada, toma una forma muy sencilla. En resumen:</p>
<p>Definició 1.3 Se llama distribución de la muestra de una variable aleatoria <span class="math inline">\(X \sim F\)</span> a la distribución del vector aleatorio <span class="math inline">\(n\)</span>-dimensional <span class="math inline">\(\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span></p>
<p><span class="math display">\[
G\left(x_{1}, x_{2}, \ldots, x_{n}\right)=F\left(x_{1}\right) F\left(x_{2}\right) \cdots F\left(x_{n}\right)
\]</span></p>
<p>En los casos particulares en que <span class="math inline">\(X\)</span> sea discreta o absolutamente continua, la distribución conjunta de la muestra suele expresarse mediante la función de masa de probabilidad o la función de densidad:</p>
<ul>
<li>Para variables discretas:</li>
</ul>
<p><span class="math display">\[
\begin{aligned}
p_{G}\left(x_{1}, x_{2}, \ldots, x_{n}\right) &amp; =P\left(X_{1}=x_{1}, X_{2}=x_{2}, \ldots, X_{n}=x_{n}\right) \\
&amp; =\prod_{i=1}^{n} P\left(X=x_{i}\right)=\prod_{i=1}^{n} p_{F}\left(x_{i}\right),
\end{aligned}
\]</span></p>
<ul>
<li>Para variables absolutamente continuas:</li>
</ul>
<p><span class="math display">\[
g\left(x_{1}, x_{2}, \ldots, x_{n}\right)=\prod_{i=1}^{n} f\left(x_{i}\right)
\]</span></p>
<p>Ejemplo 1.4.1 Una moneda tiene una probabilidad <span class="math inline">\(\theta\)</span> de salir cara. Queremos estudiar la variable aleatoria:</p>
<p><span class="math display">\[
X= \begin{cases}1 &amp; \text { si sale cara } \\ 0 &amp; \text { si sale cruz }\end{cases}
\]</span></p>
<p>con densidad <span class="math inline">\(P\{X=1\}=\theta, P\{X=0\}=1-\theta\)</span>. Es decir</p>
<p><span class="math display">\[
X \sim F_{\theta} \in \mathcal{F}=\left\{F_{\theta}=B(1, \theta): \theta \in(0,1)\right\}
\]</span></p>
<p>Supongamos que hacemos tres lanzamientos. Las posibles muestras son:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(X_{1}\)</span></th>
<th align="center"><span class="math inline">\(X_{2}\)</span></th>
<th align="center"><span class="math inline">\(X_{3}\)</span></th>
<th align="center">Probabilidad</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(\theta^{3}\)</span></td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center"><span class="math inline">\(\theta(1-\theta)^{2}\)</span></td>
</tr>
<tr class="odd">
<td align="center">0</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center"><span class="math inline">\(\theta(1-\theta)^{2}\)</span></td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(\theta(1-\theta)^{2}\)</span></td>
</tr>
<tr class="odd">
<td align="center">1</td>
<td align="center">0</td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(\theta^{2}(1-\theta)\)</span></td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">1</td>
<td align="center">0</td>
<td align="center"><span class="math inline">\(\theta^{2}(1-\theta)\)</span></td>
</tr>
<tr class="odd">
<td align="center">0</td>
<td align="center">1</td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(\theta^{2}(1-\theta)\)</span></td>
</tr>
<tr class="even">
<td align="center">0</td>
<td align="center">0</td>
<td align="center">0</td>
<td align="center"><span class="math inline">\((1-\theta)^{3}\)</span></td>
</tr>
</tbody>
</table>
<p>El muestreo ha especificado la distribución conjunta de la muestra a través de la distribución desconocida <span class="math inline">\(F_{\theta}\)</span>. Si escribimos la función de probabilidades de la variable aleatoria como <span class="math inline">\(f_{\theta}(x)=\theta^{x}(1-\theta)^{1-x}\)</span>, entonces la función de probabilidades de la muestra la podemos expresar como:</p>
<p><span class="math display">\[
g_{\theta}\left(x_{1}, x_{2}, x_{3}\right)=\theta^{x_{1}+x_{2}+x_{3}}(1-\theta)^{3-\left(x_{1}+x_{2}+x_{3}\right)}
\]</span></p>
</div>
</div>
<div id="estadísticos" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Estadísticos<a href="#estad%C3%ADsticos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="definición-1" class="section level3 hasAnchor" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Definición<a href="#definici%C3%B3n-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para lograr el objetivo de realizar inferencias sobre la población a partir de la muestra, solemos basarnos en la realización de cálculos sobre la muestra para tratar de obtener la información que deseamos. En este proceso aparecen los conceptos de estadístico y el caso particular, que más nos interesa a nosotros, de estimador. Un estadístico es una función de la muestra que no depende del valor del parámetro.</p>
<p>Definició 1.4 Dada una muestra aleatoria simple <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> y una función medible <span class="math inline">\(T: \mathbb{R}^{n} \longrightarrow \mathbb{R}^{k}\)</span>, entonces <span class="math inline">\(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span> es un vector aleatorio (variable aleatoria cuando <span class="math inline">\(k=1\)</span> ). Si <span class="math inline">\(T\)</span> no depende de <span class="math inline">\(\theta\)</span> (donde <span class="math inline">\(\theta\)</span> es un parámetro a especificar en <span class="math inline">\(F_{\theta}\)</span> ), entonces <span class="math inline">\(T\)</span> recibe el nombre de estadístico.</p>
<p>Solo por su nombre, parece evidente que un estimador de un parámetro <span class="math inline">\(\theta\)</span> será alguna función de la muestra que sirva para aproximar, en algún sentido, el valor desconocido de <span class="math inline">\(\theta\)</span>. Si añadimos la condición razonable de que un estimador no pueda tomar valores que no puede tomar el parámetro, podemos dar la siguiente definición.</p>
<p>Definició 1.5 Un estimador de un parámetro <span class="math inline">\(\theta\)</span> es un estadístico <span class="math inline">\(T\)</span> cuyo recorrido es el espacio de los parámetros, es decir:</p>
<p><span class="math display">\[
\begin{array}{ccc}
T: &amp; \mathbb{R}^{n} &amp; \longrightarrow \\
\left(x_{1}, x_{2}, \ldots, x_{n}\right) &amp; \longrightarrow \\
\left(t_{1}, \ldots, t_{k}\right) \quad \in \Theta \subset \mathbb{R}^{k}
\end{array}
\]</span></p>
<p>Aquí tienes el texto traducido al castellano manteniendo toda la notación en LaTeX:</p>
</div>
</div>
<div id="distribución-en-el-muestreo-de-un-estadístico" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Distribución en el muestreo de un estadístico<a href="#distribuci%C3%B3n-en-el-muestreo-de-un-estad%C3%ADstico" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dado un estadístico <span class="math inline">\(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span> nos interesa conocer su distribución de probabilidad, ya que para hacer inferencia necesitaremos hacer cálculos del tipo</p>
<p><span class="math display">\[
P\left[T\left(X_{1}, X_{2}, \ldots, X_{n}\right)&gt;t_{0}\right]
\]</span></p>
<p>La distribución de probabilidad del estadístico se denomina distribución muestral o distribución en el muestreo del estadístico. Encontrarla es un problema que puede ser desde bastante sencillo hasta extremadamente complicado. Algunas de las técnicas utilizadas para intentar resolverlo son las siguientes:</p>
<ul>
<li>Uso de la técnica de cambio de variable.</li>
<li>Uso de la función generadora de momentos.</li>
<li>Aplicación del Teorema Central del Límite.</li>
</ul>
<p>Ejemplo 1.5.1 Sea <span class="math inline">\(X \sim F_{\theta}\)</span> una variable aleatoria absolutamente continua con densidad</p>
<p><span class="math display">\[
f_{\theta}(x)=e^{-(x-\theta)} e^{-e^{-(x-\theta)}} \quad \theta \in \mathbb{R}
\]</span></p>
<p>y consideremos el estadístico</p>
<p><span class="math display">\[
T\left(X_{1}, X_{2}, \ldots, X_{n}\right)=\sum_{i=1}^{n} e^{-X_{i}}
\]</span></p>
<p>Si aplicamos el teorema de cambio de variable unidimensional, se obtiene fácilmente que la variable aleatoria <span class="math inline">\(Y=e^{-X}\)</span> sigue una distribución exponencial de parámetro <span class="math inline">\(e^{-\theta}\)</span>, de donde la suma seguirá una distribución gamma <span class="math inline">\(T \sim \Gamma\left(e^{-\theta}, n\right)\)</span>.</p>
<p>Ejemplo 1.5.2 Supongamos que <span class="math inline">\(X\)</span> representa el número de averías en una máquina al cabo de un mes. Este valor varía mes a mes. Sea <span class="math inline">\(\bar{X}\)</span> la media de averías en <span class="math inline">\(n\)</span> meses. Si <span class="math inline">\(X\)</span> sigue una distribución de Poisson <span class="math inline">\(P(\lambda)\)</span>, ¿cuál es la distribución de <span class="math inline">\(\bar{X}\)</span> ?
Como la suma de Poisson i.i.d. es <span class="math inline">\(\sum_{i=1}^{n} X_{i} \sim P(n \lambda)\)</span></p>
<p><span class="math display">\[
P[\bar{X}=r]=P\left[\sum_{i=1}^{n} X_{i}=n r\right]=\frac{e^{-n \lambda}(n \lambda)^{n r}}{(n r)!}
\]</span></p>
<p>Como ocurre en este ejemplo, uno de los estadísticos para el cual a menudo deseamos calcular la distribución en el muestreo es la media aritmética. Una manera útil de hacerlo es con la función generadora de momentos y la aplicación del siguiente lema.</p>
<p>Lema 1 Si <span class="math inline">\(X\)</span> es una v.a. con <span class="math inline">\(M_{X}(t)\)</span> como función generadora de momentos, entonces la f.g.m. de <span class="math inline">\(\bar{X}_{n}=\frac{1}{n} \sum_{i=1}^{n} X_{i}\)</span> es</p>
<p><span class="math display">\[
M_{\bar{X}_{n}}(t)=\left[M_{X}(t / n)\right]^{n}
\]</span></p>
<div id="demostración" class="section level3 hasAnchor" number="6.6.1">
<h3><span class="header-section-number">6.6.1</span> Demostración:<a href="#demostraci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La demostración es inmediata a partir de la definición o por las propiedades de la función generadora de momentos.</p>
<p>Si aplicamos directamente la definición de la f.g.m tenemos:</p>
<p><span class="math display">\[
\begin{aligned}
E\left(e^{t \bar{X}_{n}}\right) &amp; =E\left(e^{t \frac{1}{n} \sum_{i=1}^{n} X_{i}}\right)=E\left(\prod_{i=1}^{n} e^{\frac{t}{n} X_{i}}\right)=\prod_{i=1}^{n} E\left(e^{\frac{t}{n} X_{i}}\right) \\
&amp; =\prod_{i=1}^{n} M_{X_{i}}(t / n)=\left[M_{X}(t / n)\right]^{n}
\end{aligned}
\]</span></p>
<p>Si usamos las propiedades de la f.g.m tenemos:</p>
<ol style="list-style-type: decimal">
<li>Dado que <span class="math inline">\(M_{a X}(t)=M_{X}(a t)\)</span> y si <span class="math inline">\(a=\frac{1}{n}\)</span>, entonces <span class="math inline">\(M_{\bar{X}}(t)=M_{\sum_{i=1}^{n} X_{i}}(t / n)\)</span>.</li>
<li><span class="math inline">\(M_{\sum_{i=1}^{n} X_{i}}(t / n) \stackrel{\text { ind }}{=} \prod_{i=1}^{n} M_{X_{i}}(t / n) \stackrel{\text { id }}{=}\left[M_{X}(t / n)\right]^{n}\)</span>.</li>
</ol>
<p>Ejemplo 1.5.3 Para una variable aleatoria <span class="math inline">\(X \sim N(\mu, \sigma)\)</span> y por tanto <span class="math inline">\(M_{X}(t)=\)</span> <span class="math inline">\(\exp \left(t \mu+\frac{t^{2} \sigma^{2}}{2}\right)\)</span>, entonces</p>
<p><span class="math display">\[
\begin{aligned}
M_{\bar{X}_{n}}(t) &amp; =\left[\exp \left(\frac{t \mu}{n}+\frac{t^{2} \sigma^{2}}{n^{2} 2}\right)\right]^{n} \\
&amp; =\exp \left[n\left(\frac{t \mu}{n}+\frac{t^{2} \sigma^{2}}{n^{2} 2}\right)\right] \\
&amp; =\exp \left[t \mu+\frac{1}{2} t^{2}\left(\frac{\sigma}{\sqrt{n}}\right)^{2}\right]
\end{aligned}
\]</span></p>
<p>que es la función generadora de momentos de una variable <span class="math inline">\(N(\mu, \sigma / \sqrt{n})\)</span>.</p>
</div>
</div>
<div id="la-distribución-empírica" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> La distribución empírica<a href="#la-distribuci%C3%B3n-emp%C3%ADrica" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="definición-2" class="section level3 hasAnchor" number="6.7.1">
<h3><span class="header-section-number">6.7.1</span> Definición<a href="#definici%C3%B3n-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el apartado anterior hemos visto que a partir de una muestra <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> es interesante considerar la distribución muestral como la distribución conjunta del vector aleatorio <span class="math inline">\(\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span>, sin que intervenga una realización concreta de la muestra <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{n}\)</span>. Un enfoque diferente consiste en asociar una distribución particular directamente a las observaciones <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{n}\)</span> con la intención de que, en tanto que la muestra “representa” la v.a. <span class="math inline">\(X\)</span>, esta distribución asociada a la muestra <span class="math inline">\(F_{n}(x)\)</span> emule la distribución de la población. Esta distribución se denomina distribución empírica o distribución muestral y se define así:</p>
<p><span class="math display">\[
F_{n}(x)=\frac{k(x)}{n}
\]</span></p>
<p>donde <span class="math inline">\(k(x)\)</span> es el número de datos muestrales menores o iguales que <span class="math inline">\(x\)</span>. En la práctica se construye por ordenación de la muestra</p>
<p><span class="math display">\[
x_{1}, x_{2}, \ldots, x_{n} \longrightarrow x_{(1)} \leq x_{(2)} \leq \cdots \leq x_{(n)}
\]</span></p>
<p>y con la siguiente definición:</p>
<p><span class="math display">\[
F_{n}(x)= \begin{cases}0 &amp; \text { si } x&lt;x_{(1)} \\ \frac{k}{n} &amp; \text { si } x_{(k)} \leq x&lt;x_{(k+1)} \\ 1 &amp; \text { si } x_{(n)} \leq x\end{cases}
\]</span></p>
<p>Ejemplo 1.6.1 Extraemos una muestra y obtenemos:</p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x_{1}\)</span></th>
<th align="center"><span class="math inline">\(x_{2}\)</span></th>
<th align="center"><span class="math inline">\(x_{3}\)</span></th>
<th align="center"><span class="math inline">\(x_{4}\)</span></th>
<th align="center"><span class="math inline">\(x_{5}\)</span></th>
<th align="center"><span class="math inline">\(x_{6}\)</span></th>
<th align="center"><span class="math inline">\(x_{7}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">5.1</td>
<td align="center">3.4</td>
<td align="center">1.2</td>
<td align="center">17.6</td>
<td align="center">2.1</td>
<td align="center">16.4</td>
<td align="center">4.3</td>
</tr>
</tbody>
</table>
<p>Una vez ordenada queda:</p>
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(x_{(1)}\)</span></th>
<th align="center"><span class="math inline">\(x_{(2)}\)</span></th>
<th align="center"><span class="math inline">\(x_{(3)}\)</span></th>
<th align="center"><span class="math inline">\(x_{(4)}\)</span></th>
<th align="center"><span class="math inline">\(x_{(5)}\)</span></th>
<th align="center"><span class="math inline">\(x_{(6)}\)</span></th>
<th align="center"><span class="math inline">\(x_{(7)}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(x_{3}\)</span></td>
<td align="center"><span class="math inline">\(x_{5}\)</span></td>
<td align="center"><span class="math inline">\(x_{2}\)</span></td>
<td align="center"><span class="math inline">\(x_{7}\)</span></td>
<td align="center"><span class="math inline">\(x_{1}\)</span></td>
<td align="center"><span class="math inline">\(x_{6}\)</span></td>
<td align="center"><span class="math inline">\(x_{4}\)</span></td>
</tr>
<tr class="even">
<td align="center">1.2</td>
<td align="center">2.1</td>
<td align="center">3.4</td>
<td align="center">4.3</td>
<td align="center">5.1</td>
<td align="center">16.4</td>
<td align="center">17.6</td>
</tr>
</tbody>
</table>
<p>y si hacemos la representación gráfica:</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="introducción-a-la-inferencia-estadística.html#cb22-1" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">5.1</span> , <span class="fl">3.4</span> , <span class="fl">1.2</span> , <span class="fl">17.6</span> , <span class="fl">2.1</span> , <span class="fl">16.4</span> , <span class="fl">4.3</span>, <span class="fl">1.2</span> , <span class="fl">2.1</span> , <span class="fl">3.4</span> , <span class="fl">4.3</span> , <span class="fl">5.1</span> , <span class="fl">16.4</span> , <span class="fl">17.6</span> )</span>
<span id="cb22-2"><a href="introducción-a-la-inferencia-estadística.html#cb22-2" tabindex="-1"></a></span>
<span id="cb22-3"><a href="introducción-a-la-inferencia-estadística.html#cb22-3" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">ecdf</span>(x))</span></code></pre></div>
<p><img src="FundamentosInferenciaEstadistica_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Figura 1.1: Función de distribución empírica con los datos del ejemplo</p>
<p>La distribución empírica refleja exclusivamente los valores observados en la muestra y, por lo tanto, no se relaciona directamente ni con la distribución conjunta de la muestra <span class="math inline">\(G\left(x_{1}, x_{2}, \ldots, x_{n}\right)\)</span> ni con la distribución de la población <span class="math inline">\(F\)</span>.</p>
</div>
</div>
<div id="los-momentos-muestrales" class="section level2 hasAnchor" number="6.8">
<h2><span class="header-section-number">6.8</span> Los momentos muestrales<a href="introducción-a-la-inferencia-estadística.html#los-momentos-muestrales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="definición-3" class="section level3 hasAnchor" number="6.8.1">
<h3><span class="header-section-number">6.8.1</span> Definición<a href="#definici%C3%B3n-3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sea <span class="math inline">\(F_{n}\)</span> la v.a. que tiene <span class="math inline">\(F_{n}(x)\)</span> por distribución. La función de densidad de probabilidad de <span class="math inline">\(F_{n}\)</span> es una densidad discreta que asigna probabilidades <span class="math inline">\(1 / n\)</span> a cada una de las observaciones muestrales <span class="math inline">\(x_{1}, x_{2}, \ldots, x_{n}\)</span>. Así pues, tiene sentido calcular sus momentos, que se conocen como momentos muestrales <span class="math inline">\(a_{k}\)</span>, y también sus momentos muestrales centrados respecto a la media <span class="math inline">\(b_{k}\)</span>.</p>
<p><span class="math display">\[
\begin{aligned}
a_{k} &amp; =E\left(F_{n}^{k}\right)=\sum_{i=1}^{n} x_{i}^{k} \cdot P\left(F_{n}=x_{i}\right)=\sum_{i=1}^{n} x_{i}^{k} \cdot \frac{1}{n}=\frac{1}{n} \sum_{i=1}^{n} x_{i}^{k} \\
b_{k} &amp; =\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{k}
\end{aligned}
\]</span></p>
<p>Observamos que dos medidas conocidas de la estadística descriptiva adquieren un significado diferente:</p>
<ul>
<li>Media muestral <span class="math inline">\(=\)</span> Media de la distribución muestral</li>
</ul>
<p><span class="math display">\[
a_{1}=\frac{1}{n} \sum_{i=1}^{n} x_{i}
\]</span></p>
<ul>
<li>Varianza muestral <span class="math inline">\(=\)</span> Varianza de la distribución muestral</li>
</ul>
<p><span class="math display">\[
b_{2}=\frac{1}{n} \sum_{i=1}^{n}\left(x_{i}-\bar{x}\right)^{2}
\]</span></p>
</div>
</div>
<div id="distribución-en-el-muestreo-de-los-momentos-muestrales" class="section level2 hasAnchor" number="6.9">
<h2><span class="header-section-number">6.9</span> Distribución en el muestreo de los momentos muestrales<a href="#distribuci%C3%B3n-en-el-muestreo-de-los-momentos-muestrales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Dada una m.a.s. <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span>, los momentos muestrales son estadísticos y, como tales, tienen su distribución en el muestreo. Por ejemplo, <span class="math inline">\(a_{k}=\)</span> <span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}\)</span>.</p>
<p>La distribución en cada caso puede ser compleja y depender de la distribución poblacional subyacente.
Lo que sí es posible calcular son los momentos de los momentos muestrales o, mejor dicho, los momentos de las distribuciones en el muestreo de los momentos muestrales.</p>
<ol style="list-style-type: decimal">
<li>Si consideramos <span class="math inline">\(a_{k}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}\)</span> y escribimos <span class="math inline">\(\alpha_{k}=E\left(X^{k}\right)\)</span> como el momento poblacional de orden <span class="math inline">\(k\)</span>, tenemos:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
E\left(a_{k}\right) &amp; =E\left(\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}\right)=\frac{1}{n} \cdot n \cdot \alpha_{k}=\alpha_{k} \\
\operatorname{var}\left(a_{k}\right) &amp; =\operatorname{var}\left(\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}\right)=\frac{1}{n^{2}} \sum_{i=1}^{n} \operatorname{var}\left(X_{i}^{k}\right)=\frac{1}{n} \operatorname{var}\left(X^{k}\right) \\
&amp; =\frac{1}{n}\left[E\left(X^{2 k}\right)-\left(E\left(X^{k}\right)\right)^{2}\right]=\frac{\alpha_{2 k}-\alpha_{k}^{2}}{n}
\end{aligned}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Si consideramos <span class="math inline">\(s^{2}=b_{2}=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{2}-\bar{X}^{2}\)</span>, podemos calcular:</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
E\left(s^{2}\right) &amp; =\frac{1}{n} \sum_{i=1}^{n} E\left(X_{i}^{2}\right)-E(\bar{X})^{2}=\alpha_{2}-\left(\frac{\sigma^{2}}{n}+\mu^{2}\right) \\
&amp; =\left(\sigma^{2}+\mu^{2}\right)-\left(\frac{\sigma^{2}}{n}+\mu^{2}\right)=\frac{n-1}{n} \sigma^{2}
\end{aligned}
\]</span></p>
<p>El cálculo de la varianza de <span class="math inline">\(s^{2}\)</span> es laborioso <span class="math inline">\({ }^{1}\)</span> y no lo haremos aquí. Su valor es</p>
<p><span class="math display">\[
\operatorname{var}\left(s^{2}\right)=\frac{\mu_{4}-\mu_{2}^{2}}{n}-\frac{2\left(\mu_{4}-2 \mu_{2}^{2}\right)}{n^{2}}+\frac{\mu_{4}-3 \mu_{2}^{2}}{n^{3}}
\]</span></p>
<p>donde <span class="math inline">\(\mu_{k}\)</span> es el momento poblacional centrado de orden <span class="math inline">\(k\)</span>.</p>
</div>
<div id="propiedades-asintóticas-de-los-momentos-muestrales" class="section level2 hasAnchor" number="6.10">
<h2><span class="header-section-number">6.10</span> Propiedades asintóticas de los momentos muestrales<a href="#propiedades-asint%C3%B3ticas-de-los-momentos-muestrales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="convergencia-de-los-momentos-muestrales" class="section level3 hasAnchor" number="6.10.1">
<h3><span class="header-section-number">6.10.1</span> Convergencia de los momentos muestrales<a href="introducción-a-la-inferencia-estadística.html#convergencia-de-los-momentos-muestrales" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los momentos muestrales, tanto respecto al origen como respecto a la media, convergen hacia los momentos poblacionales. Es posible establecer la convergencia basándose en la ley fuerte de los grandes números (convergencia casi [^0]segura) o en la ley débil (convergencia en probabilidad). Si nos limitamos a esta última podemos afirmar que
<span class="math display">\[
a_{k} \xrightarrow{P} \alpha_{k} \quad \text { es decir } \quad \lim _{n \rightarrow \infty} P\left[\left|a_{k}-\alpha_{k}\right| \geq \epsilon\right]=0
\]</span></p>
<p>La prueba se basa en la desigualdad de Tchebychev. Si suponemos que <span class="math inline">\(\alpha_{2 k}&lt;\infty\)</span>, tenemos</p>
<p><span class="math display">\[
P\left[\left|a_{k}-\alpha_{k}\right| \geq \epsilon\right] \leq \frac{E\left|a_{k}-\alpha_{k}\right|^{2}}{\epsilon^{2}}=\frac{\operatorname{var}\left(a_{k}\right)}{\epsilon^{2}}=\frac{\alpha_{2 k}-\alpha_{k}^{2}}{n \epsilon^{2}} \longrightarrow 0
\]</span></p>
<p>Esta propiedad es importante porque hará posible el concepto de estimador consistente y en ella se basa un método de estimación llamado método de los momentos.</p>
</div>
<div id="distribución-asintótica" class="section level3 hasAnchor" number="6.10.2">
<h3><span class="header-section-number">6.10.2</span> Distribución asintótica<a href="#distribuci%C3%B3n-asint%C3%B3tica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si consideramos el momento muestral <span class="math inline">\(a_{k}=\frac{1}{n} \sum_{i=1}^{n} X_{i}^{k}\)</span>, entonces <span class="math inline">\(n \cdot a_{k}\)</span> es una suma de variables aleatorias i.i.d. a la que podemos aplicar el Teorema Central del Límite. Como hemos visto:</p>
<p><span class="math display">\[
E\left(n a_{k}\right)=n \alpha_{k} \quad \operatorname{var}\left(n a_{k}\right)=n^{2} \operatorname{var}\left(a_{k}\right)=n^{2} \frac{\alpha_{2 k}-\alpha_{k}^{2}}{n}
\]</span></p>
<p>y por el Teorema Central del Límite de Lindeberg-Levy la variable</p>
<p><span class="math display">\[
\frac{n a_{k}-E\left(n a_{k}\right)}{\sqrt{\operatorname{var}\left(n a_{k}\right)}}=\frac{n a_{k}-n \alpha_{k}}{n \sqrt{\operatorname{var}\left(a_{k}\right)}}=\frac{a_{k}-\alpha_{k}}{\sqrt{\operatorname{var}\left(a_{k}\right)}}
\]</span></p>
<p>verifica</p>
<p><span class="math display">\[
\frac{a_{k}-\alpha_{k}}{\sqrt{\operatorname{var}\left(a_{k}\right)}} \xrightarrow{\mathcal{L}} N(0,1)
\]</span></p>
<p>es decir</p>
<p><span class="math display">\[
a_{k} \sim A N\left(\alpha_{k}, \sqrt{\frac{\alpha_{2 k}-\alpha_{k}^{2}}{n}}\right)
\]</span></p>
</div>
</div>
<div id="muestreo-en-poblaciones-normales" class="section level2 hasAnchor" number="6.11">
<h2><span class="header-section-number">6.11</span> Muestreo en poblaciones normales<a href="introducción-a-la-inferencia-estadística.html#muestreo-en-poblaciones-normales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como hemos visto, a partir de una m.a.s. <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{n}\)</span> y si consideramos un estadístico <span class="math inline">\(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span>, puede resultar complicado obtener su distribución en el muestreo. Esta distribución depende de:</p>
<ul>
<li>La forma funcional de <span class="math inline">\(T\left(X_{1}, X_{2}, \ldots, X_{n}\right)\)</span>.</li>
<li>La distribución subyacente de <span class="math inline">\(X\)</span>, es decir, la distribución de la población.</li>
</ul>
<p>Hay un caso especial en el que el problema se ha estudiado en profundidad para algunos estadísticos de gran importancia práctica. Si <span class="math inline">\(X \sim N(\mu, \sigma)\)</span> es posible encontrar la distribución de los estadísticos más utilizados como <span class="math inline">\(\bar{X}\)</span> y <span class="math inline">\(S^{2}=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\)</span>. De hecho, obtendremos la distribución de funciones de estos estadísticos como</p>
<p><span class="math display">\[
\frac{\bar{X}-\mu}{s / \sqrt{n-1}} ; \quad \frac{n s^{2}}{\sigma^{2}} ; \quad \bar{X}_{1}-\bar{X}_{2} ; \quad \frac{S_{1}^{2} /\left(n_{1}-1\right)}{S_{2}^{2} /\left(n_{2}-1\right)}
\]</span></p>
<p>donde <span class="math inline">\(s^{2}=(1 / n) S^{2}\)</span>.
En el estudio de las distribuciones de estos estadísticos aparecen algunas distribuciones de probabilidad que han resultado ser de gran utilidad. Son las llamadas “distribuciones derivadas de la normal” y se conocen por el nombre del investigador que las formuló:</p>
<ul>
<li>la <span class="math inline">\(\chi^{2}\)</span> chi-cuadrado de Pearson</li>
<li>la <span class="math inline">\(t\)</span> de Student (Gosset)</li>
<li>la <span class="math inline">\(F\)</span> de Fisher-Snedecor</li>
</ul>
<div id="la-distribución-chi-cuadrado" class="section level3 hasAnchor" number="6.11.1">
<h3><span class="header-section-number">6.11.1</span> La distribución chi-cuadrado<a href="#la-distribuci%C3%B3n-chi-cuadrado" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean <span class="math inline">\(X_{1}, X_{2}, \ldots, X_{k}\)</span> un conjunto de v.a. independientes sobre un mismo espacio de probabilidad <span class="math inline">\((\Omega, \mathcal{A}, P)\)</span> y con distribución común <span class="math inline">\(N(0,1)\)</span>. Consideremos la variable</p>
<p><span class="math display">\[
Y=X_{1}^{2}+X_{2}^{2}+\cdots+X_{k}^{2}
\]</span></p>
<p>La distribución de la variable <span class="math inline">\(Y\)</span> se llama chi-cuadrado con <span class="math inline">\(k\)</span> grados de libertad.
La función de densidad de la variable aleatoria <span class="math inline">\(Y\)</span> es</p>
<p><span class="math display">\[
f(x)=\frac{1}{\Gamma(k / 2) 2^{k / 2}} e^{-x / 2} x^{k / 2-1} \quad \text { si } x&gt;0
\]</span></p>
<p>De modo que resulta que <span class="math inline">\(Y=\sum_{i=1}^{k} X_{i}^{2}\)</span> tiene una distribución gamma <span class="math inline">\(G\left(\frac{1}{2}, \frac{k}{2}\right)\)</span> y su f.g.m. es</p>
<p><span class="math display">\[
M(t)=(1-2 t)^{-k / 2} \quad \text { si } t&lt;1 / 2
\]</span></p>
<div id="propiedades" class="section level4 hasAnchor" number="6.11.1.1">
<h4><span class="header-section-number">6.11.1.1</span> Propiedades<a href="introducción-a-la-inferencia-estadística.html#propiedades" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>Si recordamos que para <span class="math inline">\(X \sim G(p, \alpha)\)</span> entonces <span class="math inline">\(E(X)=\frac{p}{\alpha} \mathrm{y} \operatorname{var}(X)=\)</span> <span class="math inline">\(\frac{p}{\alpha^{2}}\)</span>, resulta</li>
</ol>
<p><span class="math display">\[
E(Y)=\frac{k / 2}{1 / 2}=k \quad \operatorname{var}(Y)=\frac{k / 2}{1 / 4}=2 k
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>De la aditividad (reproductividad) de las leyes gamma se deduce también la reproductividad de la chi-cuadrado <span class="math inline">\(\chi^{2}\)</span>, es decir</li>
</ol>
<p><span class="math display">\[
Y_{1}^{2} \sim \chi_{n_{1}}^{2}, Y_{2}^{2} \sim \chi_{n_{2}}^{2} \quad \text { indep. } \longrightarrow Y_{1}^{2}+Y_{2}^{2} \sim \chi_{n_{1}+n_{2}}^{2}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Como <span class="math inline">\(Y\)</span> es la suma de v.a. independientes <span class="math inline">\(X_{i}^{2} \sim \chi_{1}^{2}\)</span> se verifica</li>
</ol>
<p><span class="math display">\[
\frac{Y-k}{\sqrt{2 k}} \xrightarrow{\mathcal{L}} N(0,1)
\]</span></p>
<p>Pero es mejor la aproximación de Fisher</p>
<p><span class="math display">\[
\sqrt{2 \chi_{k}^{2}}-\sqrt{2 k-1} \xrightarrow{\mathcal{L}} N(0,1)
\]</span></p>
<p>de donde se obtiene para valores de <span class="math inline">\(k \geq 30\)</span></p>
<p><span class="math display">\[
\chi_{k}^{2} \stackrel{\text { aprox }}{=} \frac{1}{2}(Z+\sqrt{2 k-1})^{2}
\]</span></p>
<p>donde <span class="math inline">\(Z \sim N(0,1)\)</span>.</p>
</div>
</div>
<div id="distribución-t-de-student" class="section level3 hasAnchor" number="6.11.2">
<h3><span class="header-section-number">6.11.2</span> Distribución <span class="math inline">\(t\)</span> de Student<a href="#distribuci%C3%B3n-t-de-student" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sean <span class="math inline">\(Y, Z\)</span> dos variables aleatorias independientes con distribuciones <span class="math inline">\(Z \sim\)</span> <span class="math inline">\(N(0,1)\)</span> y <span class="math inline">\(Y \sim \chi_{m}^{2}\)</span>, entonces se dice que la variable aleatoria</p>
<p><span class="math display">\[
t=\frac{Z}{\sqrt{Y / m}}
\]</span></p>
<p>tiene una distribución <span class="math inline">\(t\)</span> de Student con <span class="math inline">\(m\)</span> grados de libertad.
Su función de densidad es</p>
<p><span class="math display">\[
f(t)=\frac{\Gamma\left(\frac{m+1}{2}\right)}{\Gamma\left(\frac{m}{2}\right) \sqrt{m \pi}}\left(1+\frac{t^{2}}{m}\right)^{-(m+1) / 2} \quad t \in \mathbb{R}
\]</span></p>
<p>Esta expresión se obtiene de la resolución del correspondiente problema de cambio de variable para encontrar la distribución de un cociente.</p>
<p>Se trata de una distribución unimodal y simétrica respecto al cero. La distribución depende de <span class="math inline">\(m\)</span>, que llamamos los grados de libertad (g.l.). A medida que <span class="math inline">\(m\)</span> crece, la forma acampanada se va “cerrando”, acercándose a la ley normal:</p>
<p><span class="math display">\[
\left(1+\frac{t^{2}}{m}\right)^{-(m+1) / 2} \xrightarrow{m \rightarrow \infty} e^{-t^{2} / 2}
\]</span></p>
<p>Este hecho es muy relevante en inferencia estadística.</p>
<div id="propiedades-1" class="section level4 hasAnchor" number="6.11.2.1">
<h4><span class="header-section-number">6.11.2.1</span> Propiedades<a href="introducción-a-la-inferencia-estadística.html#propiedades-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>Si <span class="math inline">\(m=1\)</span>, entonces la <span class="math inline">\(t\)</span> es una Cauchy y, en particular, no tiene esperanza.</li>
<li>Para <span class="math inline">\(m&gt;1, E(t)=0\)</span> y para <span class="math inline">\(m&gt;2, \operatorname{var}(t)=m /(m-2)\)</span>.</li>
<li>Cuando <span class="math inline">\(m \rightarrow \infty\)</span>, entonces <span class="math inline">\(t \xrightarrow{P} N(0,1)\)</span>.</li>
</ol>
</div>
</div>
<div id="la-distribución-f-de-fisher" class="section level3 hasAnchor" number="6.11.3">
<h3><span class="header-section-number">6.11.3</span> La distribución <span class="math inline">\(F\)</span> de Fisher<a href="#la-distribuci%C3%B3n-f-de-fisher" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Esta distribución aparece cuando se considera un cociente entre dos distribuciones chi-cuadrado <span class="math inline">\(U \sim \chi_{m}^{2}, V \sim \chi_{n}^{2}\)</span> con <span class="math inline">\(m\)</span> y <span class="math inline">\(n\)</span> g.l. respectivamente. En concreto decimos que la variable aleatoria</p>
<p><span class="math display">\[
F=\frac{U / m}{V / n}
\]</span></p>
<p>sigue una distribución <span class="math inline">\(F\)</span> de Fisher con <span class="math inline">\(m\)</span> y <span class="math inline">\(n\)</span> grados de libertad. La función de densidad tiene la forma:</p>
<p><span class="math display">\[
f(x)=\frac{m^{m / 2} n^{n / 2} \Gamma[(m+n) / 2]}{\Gamma(m / 2) \Gamma(n / 2)} \cdot \frac{x^{m / 2-1}}{(m x+n)^{(m+n) / 2}} \quad \text { para } x&gt;0
\]</span></p>
<div id="propiedades-2" class="section level4 hasAnchor" number="6.11.3.1">
<h4><span class="header-section-number">6.11.3.1</span> Propiedades<a href="introducción-a-la-inferencia-estadística.html#propiedades-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ol style="list-style-type: decimal">
<li>La esperanza y la varianza son</li>
</ol>
<p><span class="math display">\[
E(F)=\frac{n}{n-2} \quad \operatorname{var}(F)=\frac{2 n^{2}(m+n-2)}{m(n-2)^{2}(n-4)}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Esta distribución tiene una moda en <span class="math inline">\(x=\frac{m-2}{m} \cdot \frac{n}{n+2}\)</span>, siempre que <span class="math inline">\(m&gt;2\)</span>.</li>
<li>Si <span class="math inline">\(F \sim F_{m, n}\)</span>, entonces resulta que <span class="math inline">\(1 / F \sim F_{n, m}\)</span> y por lo tanto:</li>
</ol>
<p><span class="math display">\[
P(F \leq x)=P\left(\frac{1}{F} \geq \frac{1}{x}\right)=1-P\left(\frac{1}{F} \leq \frac{1}{x}\right)
\]</span></p>
<p>Esta propiedad es de gran utilidad en el uso de las tablas.
4. Cuando <span class="math inline">\(n \rightarrow \infty, F_{m, \infty} \xrightarrow{\mathcal{L}} \chi_{m}^{2}\)</span>.
5. Cuando <span class="math inline">\(m \rightarrow \infty\)</span> y <span class="math inline">\(n \rightarrow \infty\)</span>, entonces <span class="math inline">\(F_{m, n} \xrightarrow{\mathcal{L}} 1\)</span>.</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="grandes-muestras.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="estimación-puntual.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": "https://github.com/ASPteaching/FundamentosInferencia/edit/BRANCH/06-introInferencia.Rmd",
    "text": "Edit"
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": "https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/06-introInferencia.Rmd",
    "text": null
  },
  "download": "https://github.com/ASPteaching/FundamentosInferencia-Bookdown/blob/main/docs/_main.pdf",
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
