<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 9 Pruebas de hipótesis | Contrastes en poblaciones normales</title>
  <meta name="description" content="Capítulo 9 Pruebas de hipótesis | Contrastes en poblaciones normales" />
  <meta name="generator" content="bookdown 0.45 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 9 Pruebas de hipótesis | Contrastes en poblaciones normales" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 9 Pruebas de hipótesis | Contrastes en poblaciones normales" />
  
  
  

<meta name="author" content="Alex Sanchez Pla y Santiago Pérez Hoyos" />


<meta name="date" content="2025-12-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimación-por-intérvalos.html"/>
<link rel="next" href="construcción-de-contrastes-de-hipótesis.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="blocks.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<div style="margin:0 0 10px 15px;">
  <a href="FundamentosInferenciaEstadistica.pdf" target="_blank"
     title="Descargar PDF"
     style="display:flex;align-items:center;gap:6px;text-decoration:none;">
    <img src="images/aPDF.png" alt="PDF" width="16" height="20">
    <span style="font-weight:bold;">Descargar versión PDF</span>
  </a>
</div>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentación</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#objetivo"><i class="fa fa-check"></i>Objetivo</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisitos-y-organizaci%C3%B3n-del-material"><i class="fa fa-check"></i>Prerequisitos y organización del material</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html"><i class="fa fa-check"></i>Agradecimiento y fuentes utilizadas</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#el-proyecto-statmedia"><i class="fa fa-check"></i>El proyecto Statmedia</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#otros-materiales-utilizados"><i class="fa fa-check"></i>Otros materiales utilizados</a></li>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#materiales-complementarios"><i class="fa fa-check"></i>Materiales complementarios</a>
<ul>
<li class="chapter" data-level="" data-path="agradecimiento-y-fuentes-utilizadas.html"><a href="agradecimiento-y-fuentes-utilizadas.html#complementos-matem%C3%A1ticos"><i class="fa fa-check"></i>Complementos matemáticos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html"><i class="fa fa-check"></i><b>1</b> Probabilidad y Experimentos aleatorios</a>
<ul>
<li class="chapter" data-level="1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducci%C3%B3n"><i class="fa fa-check"></i><b>1.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#fen%C3%B3menos-deterministas-y-fen%C3%B3menos-aleatorios"><i class="fa fa-check"></i><b>1.1.1</b> Fenómenos deterministas y fenómenos aleatorios</a></li>
<li class="chapter" data-level="1.1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos"><i class="fa fa-check"></i><b>1.1.2</b> Sucesos</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#funci%C3%B3n-de-probabilidad"><i class="fa fa-check"></i><b>1.2</b> Función de probabilidad</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#diferentes-funciones-de-probabilidad-para-una-misma-experiencia-aleatoria"><i class="fa fa-check"></i><b>1.2.1</b> ¿Diferentes funciones de probabilidad para una misma experiencia aleatoria?</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#c%C3%B3mo-se-calculan-las-probabilidades"><i class="fa fa-check"></i><b>1.3</b> ¿Cómo se calculan las probabilidades?</a></li>
<li class="chapter" data-level="1.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-elementales-y-sucesos-observables"><i class="fa fa-check"></i><b>1.4</b> Sucesos elementales y sucesos observables</a></li>
<li class="chapter" data-level="1.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#propiedades-inmediatas-de-la-probabilidad"><i class="fa fa-check"></i><b>1.5</b> Propiedades inmediatas de la probabilidad</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#succeso-imposible"><i class="fa fa-check"></i><b>1.5.1</b> Succeso imposible</a></li>
<li class="chapter" data-level="1.5.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#suceso-implicado"><i class="fa fa-check"></i><b>1.5.2</b> Suceso implicado</a></li>
<li class="chapter" data-level="1.5.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#complementario-de-un-suceso"><i class="fa fa-check"></i><b>1.5.3</b> Complementario de un suceso</a></li>
<li class="chapter" data-level="1.5.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ocurrencia-de-algun-suceso"><i class="fa fa-check"></i><b>1.5.4</b> Ocurrencia de algun suceso</a></li>
<li class="chapter" data-level="1.5.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurra-algun-suceso"><i class="fa fa-check"></i><b>1.5.5</b> Probabilidad de que ocurra algun suceso</a></li>
<li class="chapter" data-level="1.5.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-de-que-ocurran-dos-o-m%C3%A1s-sucesos-a-la-vez"><i class="fa fa-check"></i><b>1.5.6</b> Probabilidad de que ocurran dos (o más) sucesos a la vez</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#espacios-de-probabilidad"><i class="fa fa-check"></i><b>1.6</b> Espacios de probabilidad</a></li>
<li class="chapter" data-level="1.7" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#probabilidad-condicionada"><i class="fa fa-check"></i><b>1.7</b> Probabilidad condicionada</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#la-probabilidad-condicionada-es-una-medida-de-probabilidad"><i class="fa fa-check"></i><b>1.7.1</b> La probabilidad condicionada es una medida de probabilidad</a></li>
<li class="chapter" data-level="1.7.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#sucesos-dependientes-y-sucesos-independientes"><i class="fa fa-check"></i><b>1.7.2</b> Sucesos dependientes y sucesos independientes</a></li>
<li class="chapter" data-level="1.7.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#incompatibilidad-e-independencia"><i class="fa fa-check"></i><b>1.7.3</b> Incompatibilidad e independencia</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#dos-teoremas-importantes"><i class="fa fa-check"></i><b>1.8</b> Dos Teoremas importantes</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-las-probabilidades-totales"><i class="fa fa-check"></i><b>1.8.1</b> Teorema de las probabilidades totales</a></li>
<li class="chapter" data-level="1.8.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#teorema-de-bayes"><i class="fa fa-check"></i><b>1.8.2</b> Teorema de Bayes</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#introducci%C3%B3n-a-los-experimentos-m%C3%BAltiples"><i class="fa fa-check"></i><b>1.9</b> Introducción a los experimentos múltiples</a></li>
<li class="chapter" data-level="1.10" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinatoria"><i class="fa fa-check"></i><b>1.10</b> Combinatoria</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones"><i class="fa fa-check"></i><b>1.10.1</b> Permutaciones</a></li>
<li class="chapter" data-level="1.10.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones"><i class="fa fa-check"></i><b>1.10.2</b> Variaciones</a></li>
<li class="chapter" data-level="1.10.3" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#variaciones-con-repetici%C3%B3n"><i class="fa fa-check"></i><b>1.10.3</b> Variaciones con repetición</a></li>
<li class="chapter" data-level="1.10.4" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#combinaciones"><i class="fa fa-check"></i><b>1.10.4</b> Combinaciones</a></li>
<li class="chapter" data-level="1.10.5" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#permutaciones-con-repetici%C3%B3n"><i class="fa fa-check"></i><b>1.10.5</b> Permutaciones con repetición</a></li>
</ul></li>
<li class="chapter" data-level="1.11" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#frecuencia-relativa-y-probabilidad"><i class="fa fa-check"></i><b>1.11</b> Frecuencia relativa y probabilidad</a>
<ul>
<li class="chapter" data-level="1.11.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ilustraci%C3%B3n-por-simulaci%C3%B3n"><i class="fa fa-check"></i><b>1.11.1</b> Ilustración por simulación</a></li>
</ul></li>
<li class="chapter" data-level="1.12" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#caso-de-estudio-eficacia-de-una-prueba-diagn%C3%B3stica"><i class="fa fa-check"></i><b>1.12</b> Caso de Estudio: Eficacia de una prueba diagnóstica</a>
<ul>
<li class="chapter" data-level="1.12.1" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#aplicaci%C3%B3n-del-teorema-de-bayes"><i class="fa fa-check"></i><b>1.12.1</b> Aplicación del Teorema de Bayes</a></li>
<li class="chapter" data-level="1.12.2" data-path="probabilidad-y-experimentos-aleatorios.html"><a href="probabilidad-y-experimentos-aleatorios.html#ejemplo-num%C3%A9rico"><i class="fa fa-check"></i><b>1.12.2</b> Ejemplo numérico</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html"><i class="fa fa-check"></i><b>2</b> Variables aleatorias y Distribuciones de probabilidad</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#el-espacio-muestral-y-sus-elementos"><i class="fa fa-check"></i><b>2.1</b> El espacio muestral y sus elementos</a></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representaci%C3%B3n-num%C3%A9rica-de-los-sucesos-elementales.-variables-aleatorias"><i class="fa fa-check"></i><b>2.2</b> Representación numérica de los sucesos elementales. Variables aleatorias</a></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterizaci%C3%B3n-de-una-variable-aleatoria-a-trav%C3%A9s-de-la-probabilidad.-funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.3</b> Caracterización de una variable aleatoria a través de la probabilidad. Función de distribución</a></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.4</b> Propiedades de la función de distribución</a></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificaci%C3%B3n-de-las-variables-aleatorias"><i class="fa fa-check"></i><b>2.5</b> Clasificación de las variables aleatorias</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-discretas"><i class="fa fa-check"></i><b>2.5.1</b> Variables aleatorias discretas</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas"><i class="fa fa-check"></i><b>2.5.2</b> Variables aleatorias continuas</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variable-aleatoria-discretas"><i class="fa fa-check"></i><b>2.6</b> Variable aleatoria discretas</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterizaci%C3%B3n-de-las-v.a.-discretas"><i class="fa fa-check"></i><b>2.6.1</b> Caracterización de las v.a. discretas</a></li>
<li class="chapter" data-level="2.6.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-funci%C3%B3n-de-densidad-discreta"><i class="fa fa-check"></i><b>2.6.2</b> Propiedades de la función de densidad discreta</a></li>
<li class="chapter" data-level="2.6.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-funci%C3%B3n-de-distribuci%C3%B3n-y-la-funci%C3%B3n-de-densidad-discreta.-probabilidad-de-intervalos."><i class="fa fa-check"></i><b>2.6.3</b> Relaciones entre la función de distribución y la función de densidad discreta. <br> Probabilidad de intervalos.</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>2.7</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="2.7.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#funci%C3%B3n-de-densidad-continua"><i class="fa fa-check"></i><b>2.7.1</b> Función de densidad continua</a></li>
<li class="chapter" data-level="2.7.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#relaciones-entre-la-funci%C3%B3n-de-distribuci%C3%B3n-y-la-funci%C3%B3n-de-densidad."><i class="fa fa-check"></i><b>2.7.2</b> Relaciones entre la función de distribución y la función de densidad.</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caracterizaci%C3%B3n-de-una-variable-aleatoria-a-trav%C3%A9s-de-par%C3%A1metros"><i class="fa fa-check"></i><b>2.8</b> Caracterización de una variable aleatoria a través de parámetros</a></li>
<li class="chapter" data-level="2.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-discreta"><i class="fa fa-check"></i><b>2.9</b> Esperanza de una variable aleatoria discreta</a></li>
<li class="chapter" data-level="2.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-una-variable-aleatoria-continua"><i class="fa fa-check"></i><b>2.10</b> Esperanza de una variable aleatoria continua</a></li>
<li class="chapter" data-level="2.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-esperanza-matem%C3%A1tica"><i class="fa fa-check"></i><b>2.11</b> Propiedades de la esperanza matemática</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#linealidad-de-la-esperanza-matem%C3%A1tica"><i class="fa fa-check"></i><b>2.11.1</b> Linealidad de la esperanza matemática</a></li>
<li class="chapter" data-level="2.11.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-del-producto"><i class="fa fa-check"></i><b>2.11.2</b> Esperanza del producto</a></li>
</ul></li>
<li class="chapter" data-level="2.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.12</b> Varianza de una variable aleatoria</a>
<ul>
<li class="chapter" data-level="2.12.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#propiedades-de-la-varianza"><i class="fa fa-check"></i><b>2.12.1</b> Propiedades de la varianza</a></li>
</ul></li>
<li class="chapter" data-level="2.13" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#momentos-de-orden-k-de-una-variable-aleatoria"><i class="fa fa-check"></i><b>2.13</b> Momentos (de orden <span class="math inline">\(k\)</span>) de una variable aleatoria</a></li>
<li class="chapter" data-level="2.14" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#definici%C3%B3n-formal-de-variable-aleatoria"><i class="fa fa-check"></i><b>2.14</b> Definición formal de variable aleatoria</a></li>
<li class="chapter" data-level="2.15" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#caso-pr%C3%A1ctico-lanzamiento-de-dos-dados"><i class="fa fa-check"></i><b>2.15</b> Caso práctico: Lanzamiento de dos dados</a>
<ul>
<li class="chapter" data-level="2.15.1" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#espacio-muestral"><i class="fa fa-check"></i><b>2.15.1</b> Espacio muestral</a></li>
<li class="chapter" data-level="2.15.2" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#representaci%C3%B3n-num%C3%A9rica"><i class="fa fa-check"></i><b>2.15.2</b> Representación numérica</a></li>
<li class="chapter" data-level="2.15.3" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#algunas-probabilidades"><i class="fa fa-check"></i><b>2.15.3</b> Algunas probabilidades</a></li>
<li class="chapter" data-level="2.15.4" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#funci%C3%B3n-de-distribuci%C3%B3n"><i class="fa fa-check"></i><b>2.15.4</b> Función de distribución</a></li>
<li class="chapter" data-level="2.15.5" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#clasificaci%C3%B3n-de-las-variables"><i class="fa fa-check"></i><b>2.15.5</b> Clasificación de las variables</a></li>
<li class="chapter" data-level="2.15.6" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#funci%C3%B3n-de-densidad-discreta"><i class="fa fa-check"></i><b>2.15.6</b> Función de densidad discreta</a></li>
<li class="chapter" data-level="2.15.7" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#probabilidad-de-intervalos-1"><i class="fa fa-check"></i><b>2.15.7</b> Probabilidad de intervalos</a></li>
<li class="chapter" data-level="2.15.8" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza"><i class="fa fa-check"></i><b>2.15.8</b> Esperanza</a></li>
<li class="chapter" data-level="2.15.9" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-de-un-juego"><i class="fa fa-check"></i><b>2.15.9</b> Esperanza de un juego</a></li>
<li class="chapter" data-level="2.15.10" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-con-recorrido-infinito"><i class="fa fa-check"></i><b>2.15.10</b> Esperanza con recorrido infinito</a></li>
<li class="chapter" data-level="2.15.11" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#esperanza-infinita"><i class="fa fa-check"></i><b>2.15.11</b> Esperanza infinita</a></li>
<li class="chapter" data-level="2.15.12" data-path="variables-aleatorias-y-distribuciones-de-probabilidad.html"><a href="variables-aleatorias-y-distribuciones-de-probabilidad.html#varianza"><i class="fa fa-check"></i><b>2.15.12</b> Varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html"><i class="fa fa-check"></i><b>3</b> Distribuciones Notables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-discretas"><i class="fa fa-check"></i><b>3.1</b> Distribuciones discretas</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-bernouilli"><i class="fa fa-check"></i><b>3.1.1</b> La distribución de Bernouilli</a></li>
<li class="chapter" data-level="3.1.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>3.1.2</b> La distribución Binomial</a></li>
<li class="chapter" data-level="3.1.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>3.1.3</b> La distribución de Poisson</a></li>
<li class="chapter" data-level="3.1.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-uniforme-discreta"><i class="fa fa-check"></i><b>3.1.4</b> La distribución Uniforme discreta</a></li>
<li class="chapter" data-level="3.1.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-hipergeom%C3%A9trica"><i class="fa fa-check"></i><b>3.1.5</b> La distribución Hipergeométrica</a></li>
<li class="chapter" data-level="3.1.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-geom%C3%A9trica-o-de-pascal"><i class="fa fa-check"></i><b>3.1.6</b> La distribución Geométrica o de Pascal</a></li>
<li class="chapter" data-level="3.1.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-binomial-negativa"><i class="fa fa-check"></i><b>3.1.7</b> La distribución Binomial negativa</a></li>
<li class="chapter" data-level="3.1.8" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-distribuciones-discretas-principales"><i class="fa fa-check"></i><b>3.1.8</b> Tabla resumen de las distribuciones discretas principales</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-continuas"><i class="fa fa-check"></i><b>3.2</b> Distribuciones Continuas</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-uniforme"><i class="fa fa-check"></i><b>3.2.1</b> La distribución Uniforme</a></li>
<li class="chapter" data-level="3.2.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-exponencial"><i class="fa fa-check"></i><b>3.2.2</b> La distribución Exponencial</a></li>
<li class="chapter" data-level="3.2.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>3.2.3</b> La distribución Normal</a></li>
<li class="chapter" data-level="3.2.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-gamma"><i class="fa fa-check"></i><b>3.2.4</b> La distribución Gamma</a></li>
<li class="chapter" data-level="3.2.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-cauchy"><i class="fa fa-check"></i><b>3.2.5</b> La distribución de Cauchy</a></li>
<li class="chapter" data-level="3.2.6" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-distribuci%C3%B3n-de-weibull"><i class="fa fa-check"></i><b>3.2.6</b> La distribución de Weibull</a></li>
<li class="chapter" data-level="3.2.7" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#tabla-resumen-de-las-principales-distribuciones-continuas"><i class="fa fa-check"></i><b>3.2.7</b> Tabla resumen de las principales distribuciones continuas</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuciones-con-r-y-python"><i class="fa fa-check"></i><b>3.3</b> Distribuciones con R (y Python)</a></li>
<li class="chapter" data-level="3.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#la-familia-exponencial-de-distribuciones"><i class="fa fa-check"></i><b>3.4</b> La familia exponencial de distribuciones</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#ejemplos-de-distribuciones-de-esta-familia"><i class="fa fa-check"></i><b>3.4.1</b> Ejemplos de distribuciones de esta familia</a></li>
<li class="chapter" data-level="3.4.2" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>3.4.2</b> Distribución Binomial</a></li>
<li class="chapter" data-level="3.4.3" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#importancia-y-utilidad-de-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.3</b> Importancia y utilidad de la familia exponencial</a></li>
<li class="chapter" data-level="3.4.4" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#los-modelos-lineales-generalizados-glms"><i class="fa fa-check"></i><b>3.4.4</b> Los modelos lineales generalizados (GLMs)</a></li>
<li class="chapter" data-level="3.4.5" data-path="distribuciones-notables.html"><a href="distribuciones-notables.html#estimaci%C3%B3n-en-la-familia-exponencial"><i class="fa fa-check"></i><b>3.4.5</b> Estimación en la familia exponencial</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html"><i class="fa fa-check"></i><b>4</b> Distribuciones de probabilidad multidimensionales</a>
<ul>
<li class="chapter" data-level="4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-conjuntas-de-probabilidades"><i class="fa fa-check"></i><b>4.1</b> Distribuciones conjuntas de probabilidades</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatoria-bivariante"><i class="fa fa-check"></i><b>4.1.1</b> Variable aleatoria bivariante</a></li>
<li class="chapter" data-level="4.1.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funci%C3%B3n-de-distribuci%C3%B3n-bivariante"><i class="fa fa-check"></i><b>4.1.2</b> Función de distribución bivariante</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#variable-aleatorias-bivariantes-discretas"><i class="fa fa-check"></i><b>4.2</b> Variable aleatorias bivariantes discretas</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funci%C3%B3n-de-masa-de-probabilidad-discreta-fmp"><i class="fa fa-check"></i><b>4.2.1</b> Función de masa de probabilidad discreta (fmp)</a></li>
<li class="chapter" data-level="4.2.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-fmp-bivariante"><i class="fa fa-check"></i><b>4.2.2</b> Propiedades de la fmp bivariante</a></li>
<li class="chapter" data-level="4.2.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#ejemplo-de-distribuci%C3%B3n-bivariante-discreta"><i class="fa fa-check"></i><b>4.2.3</b> Ejemplo de distribución bivariante discreta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribuci%C3%B3n-multinomial"><i class="fa fa-check"></i><b>4.3</b> La distribución multinomial</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#generaci%C3%B3n-de-las-observaciones"><i class="fa fa-check"></i><b>4.3.1</b> Generación de las observaciones</a></li>
<li class="chapter" data-level="4.3.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#funcion-de-masa-de-probabilidad-de-la-distribuci%C3%B3n-multinomial"><i class="fa fa-check"></i><b>4.3.2</b> Funcion de masa de probabilidad de la distribución multinomial</a></li>
<li class="chapter" data-level="4.3.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relaci%C3%B3n-con-la-distribuci%C3%B3n-binomial"><i class="fa fa-check"></i><b>4.3.3</b> Relación con la distribución binomial</a></li>
<li class="chapter" data-level="4.3.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#un-caso-particular-la-distribuci%C3%B3n-trinomial"><i class="fa fa-check"></i><b>4.3.4</b> Un caso particular: La distribución trinomial</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-marginales"><i class="fa fa-check"></i><b>4.4</b> Distribuciones marginales</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#las-marginales-est%C3%A1n-en-los-m%C3%A1rgenes"><i class="fa fa-check"></i><b>4.4.1</b> Las marginales están en los márgenes</a></li>
<li class="chapter" data-level="4.4.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-discretas"><i class="fa fa-check"></i><b>4.4.2</b> Densidades marginales discretas</a></li>
<li class="chapter" data-level="4.4.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribuciones-marginales"><i class="fa fa-check"></i><b>4.4.3</b> Trinomial M(5; 0.6, 0.2): Distribuciones marginales</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales"><i class="fa fa-check"></i><b>4.5</b> Distribuciones condicionales</a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional"><i class="fa fa-check"></i><b>4.5.1</b> Densidad condicional</a></li>
<li class="chapter" data-level="4.5.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#trinomial-m5-0.6-0.2-distribuci%C3%B3n-condicional"><i class="fa fa-check"></i><b>4.5.2</b> Trinomial M(5; 0.6, 0.2): Distribución condicional</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#vectores-aleatorios-absolutamente-continuos"><i class="fa fa-check"></i><b>4.6</b> Vectores aleatorios absolutamente continuos</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-la-funci%C3%B3n-de-densidad-conjunta"><i class="fa fa-check"></i><b>4.6.1</b> Propiedades de la función de densidad conjunta</a></li>
<li class="chapter" data-level="4.6.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidades-marginales-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.2</b> Densidades marginales en el caso continuo</a></li>
<li class="chapter" data-level="4.6.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#densidad-condicional-en-el-caso-continuo"><i class="fa fa-check"></i><b>4.6.3</b> Densidad condicional en el caso continuo</a></li>
<li class="chapter" data-level="4.6.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#la-distribuci%C3%B3n-normal-bivariante"><i class="fa fa-check"></i><b>4.6.4</b> La Distribución Normal Bivariante</a></li>
<li class="chapter" data-level="4.6.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#distribuciones-condicionales-1"><i class="fa fa-check"></i><b>4.6.5</b> Distribuciones Condicionales</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#independencia-de-variables-aleatorias"><i class="fa fa-check"></i><b>4.7</b> Independencia de variables aleatorias</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#primera-caracterizaci%C3%B3n-de-la-independencia"><i class="fa fa-check"></i><b>4.7.1</b> Primera caracterización de la independencia</a></li>
<li class="chapter" data-level="4.7.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#propiedades-de-las-variables-independientes"><i class="fa fa-check"></i><b>4.7.2</b> Propiedades de las variables independientes</a></li>
</ul></li>
<li class="chapter" data-level="4.8" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#momentos-de-vectores-aleatorios"><i class="fa fa-check"></i><b>4.8</b> Momentos de vectores aleatorios</a>
<ul>
<li class="chapter" data-level="4.8.1" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#esperanza-de-un-vector-aleatorio-o-vector-de-medias"><i class="fa fa-check"></i><b>4.8.1</b> Esperanza de un vector aleatorio o vector de medias</a></li>
<li class="chapter" data-level="4.8.2" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-entre-dos-variables-aleatorias"><i class="fa fa-check"></i><b>4.8.2</b> Covarianza entre dos variables aleatorias</a></li>
<li class="chapter" data-level="4.8.3" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#covarianza-y-correlaci%C3%B3n"><i class="fa fa-check"></i><b>4.8.3</b> Covarianza y correlación</a></li>
<li class="chapter" data-level="4.8.4" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-varianzas-covarianzas"><i class="fa fa-check"></i><b>4.8.4</b> Matriz de varianzas-covarianzas</a></li>
<li class="chapter" data-level="4.8.5" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#matriz-de-correlaciones"><i class="fa fa-check"></i><b>4.8.5</b> Matriz de correlaciones</a></li>
<li class="chapter" data-level="4.8.6" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#segunda-caracterizaci%C3%B3n-de-la-independencia"><i class="fa fa-check"></i><b>4.8.6</b> Segunda caracterización de la independencia</a></li>
<li class="chapter" data-level="4.8.7" data-path="distribuciones-de-probabilidad-multidimensionales.html"><a href="distribuciones-de-probabilidad-multidimensionales.html#relaci%C3%B3n-entre-incorrelaci%C3%B3n-e-independencia"><i class="fa fa-check"></i><b>4.8.7</b> Relación entre incorrelación e independencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="grandes-muestras.html"><a href="grandes-muestras.html"><i class="fa fa-check"></i><b>5</b> Grandes muestras</a>
<ul>
<li class="chapter" data-level="5.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#introducci%C3%B3n-aproximaciones-asint%C3%B3ticas"><i class="fa fa-check"></i><b>5.1</b> Introducción: Aproximaciones asintóticas</a></li>
<li class="chapter" data-level="5.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ley-de-los-grandes-n%C3%BAmeros-ley-d%C3%A9bil"><i class="fa fa-check"></i><b>5.2</b> Ley de los Grandes Números (Ley débil)</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#ejemplo-3"><i class="fa fa-check"></i><b>5.2.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#el-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3</b> El teorema central del límite</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="grandes-muestras.html"><a href="grandes-muestras.html#sumas-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.3.1</b> Sumas de variables aleatorias</a></li>
<li class="chapter" data-level="5.3.2" data-path="grandes-muestras.html"><a href="grandes-muestras.html#definici%C3%B3n-de-convergencia-en-ley"><i class="fa fa-check"></i><b>5.3.2</b> Definición de convergencia en ley</a></li>
<li class="chapter" data-level="5.3.3" data-path="grandes-muestras.html"><a href="grandes-muestras.html#enunciado-del-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3.3</b> Enunciado del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.4" data-path="grandes-muestras.html"><a href="grandes-muestras.html#algunos-ejemplos-de-aplicaci%C3%B3n-del-tcl"><i class="fa fa-check"></i><b>5.3.4</b> Algunos ejemplos de aplicación del TCL</a></li>
<li class="chapter" data-level="5.3.5" data-path="grandes-muestras.html"><a href="grandes-muestras.html#casos-particulares-m%C3%A1s-notables"><i class="fa fa-check"></i><b>5.3.5</b> Casos particulares más notables</a></li>
<li class="chapter" data-level="5.3.6" data-path="grandes-muestras.html"><a href="grandes-muestras.html#interpretaci%C3%B3n-del-teorema-central-del-l%C3%ADmite"><i class="fa fa-check"></i><b>5.3.6</b> Interpretación del teorema central del límite</a></li>
<li class="chapter" data-level="5.3.7" data-path="grandes-muestras.html"><a href="grandes-muestras.html#acerca-de-las-variables-aproximadamente-normales"><i class="fa fa-check"></i><b>5.3.7</b> Acerca de las variables aproximadamente normales</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html"><i class="fa fa-check"></i><b>6</b> Introducción a la inferencia estadística</a>
<ul>
<li class="chapter" data-level="6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#inferencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>6.1</b> Inferencia estadística</a></li>
<li class="chapter" data-level="6.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#problemas-de-inferencia-estad%C3%ADstica"><i class="fa fa-check"></i><b>6.2</b> Problemas de inferencia estadística</a></li>
<li class="chapter" data-level="6.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-de-la-poblaci%C3%B3n"><i class="fa fa-check"></i><b>6.3</b> Distribución de la población</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-4"><i class="fa fa-check"></i><b>6.3.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestra-aleatoria-simple"><i class="fa fa-check"></i><b>6.4</b> Muestra aleatoria simple</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definici%C3%B3n-muestra-aleatoria-simple"><i class="fa fa-check"></i><b>6.4.1</b> Definición (Muestra aleatoria simple)</a></li>
<li class="chapter" data-level="6.4.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-de-la-muestra"><i class="fa fa-check"></i><b>6.4.2</b> Distribución de la muestra</a></li>
<li class="chapter" data-level="6.4.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#casos-particulares"><i class="fa fa-check"></i><b>6.4.3</b> Casos particulares</a></li>
<li class="chapter" data-level="6.4.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-5"><i class="fa fa-check"></i><b>6.4.4</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#estad%C3%ADsticos"><i class="fa fa-check"></i><b>6.5</b> Estadísticos</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#definici%C3%B3n"><i class="fa fa-check"></i><b>6.5.1</b> Definición</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-en-el-muestreo-de-un-estad%C3%ADstico"><i class="fa fa-check"></i><b>6.6</b> Distribución en el muestreo de un estadístico</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-6"><i class="fa fa-check"></i><b>6.6.1</b> Ejemplo</a></li>
<li class="chapter" data-level="6.6.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-7"><i class="fa fa-check"></i><b>6.6.2</b> Ejemplo</a></li>
<li class="chapter" data-level="6.6.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-8"><i class="fa fa-check"></i><b>6.6.3</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-emp%C3%ADrica"><i class="fa fa-check"></i><b>6.7</b> La distribución empírica</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ejemplo-9"><i class="fa fa-check"></i><b>6.7.1</b> Ejemplo</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#momentos-muestrales"><i class="fa fa-check"></i><b>6.8</b> Momentos muestrales</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#observaciones"><i class="fa fa-check"></i><b>6.8.1</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="6.9" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#distribuci%C3%B3n-en-el-muestreo-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.9</b> Distribución en el muestreo de los momentos muestrales</a></li>
<li class="chapter" data-level="6.10" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#muestreo-en-poblaciones-normales"><i class="fa fa-check"></i><b>6.10</b> Muestreo en poblaciones normales</a>
<ul>
<li class="chapter" data-level="6.10.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-chi-cuadrado-y-la-varianza-muestral"><i class="fa fa-check"></i><b>6.10.1</b> La distribución chi-cuadrado y la varianza muestral</a></li>
<li class="chapter" data-level="6.10.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-t-de-student-y-el-estad%C3%ADstico-t"><i class="fa fa-check"></i><b>6.10.2</b> La distribución t de Student y el estadístico <span class="math inline">\(T\)</span></a></li>
<li class="chapter" data-level="6.10.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#la-distribuci%C3%B3n-f-de-fisher-y-la-raz%C3%B3n-de-varianzas."><i class="fa fa-check"></i><b>6.10.3</b> La distribución F de Fisher y la razón de varianzas.</a></li>
</ul></li>
<li class="chapter" data-level="6.11" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#ap%C3%A9ndice-t%C3%A9cnico-opcional"><i class="fa fa-check"></i><b>6.11</b> Apéndice técnico (opcional)</a>
<ul>
<li class="chapter" data-level="6.11.1" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#funci%C3%B3n-generadora-de-momentos-de-la-media-muestral"><i class="fa fa-check"></i><b>6.11.1</b> Función generadora de momentos de la media muestral</a></li>
<li class="chapter" data-level="6.11.2" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#momentos-centrales-y-relaci%C3%B3n-con-la-varianza-muestral"><i class="fa fa-check"></i><b>6.11.2</b> Momentos centrales y relación con la varianza muestral</a></li>
<li class="chapter" data-level="6.11.3" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#propiedades-asint%C3%B3ticas-de-los-momentos-muestrales"><i class="fa fa-check"></i><b>6.11.3</b> Propiedades asintóticas de los momentos muestrales</a></li>
<li class="chapter" data-level="6.11.4" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#recordatorio-propiedades-%C3%BAtiles-de-la-distribuci%C3%B3n-gamma"><i class="fa fa-check"></i><b>6.11.4</b> Recordatorio: propiedades útiles de la distribución Gamma</a></li>
<li class="chapter" data-level="6.11.5" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#derivaci%C3%B3n-estructurada-de-chi2-t-y-f"><i class="fa fa-check"></i><b>6.11.5</b> Derivación estructurada de <span class="math inline">\(\chi^2\)</span>, <span class="math inline">\(t\)</span> y <span class="math inline">\(F\)</span></a></li>
<li class="chapter" data-level="6.11.6" data-path="introducción-a-la-inferencia-estadística.html"><a href="introducción-a-la-inferencia-estadística.html#asint%C3%B3tica-%C3%BAtil-para-inferencia"><i class="fa fa-check"></i><b>6.11.6</b> Asintótica útil para inferencia</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="estimación-puntual.html"><a href="estimación-puntual.html"><i class="fa fa-check"></i><b>7</b> Estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-problema-de-la-estimaci%C3%B3n-puntual"><i class="fa fa-check"></i><b>7.1</b> El problema de la estimación puntual</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#criterios-de-optimalidad-de-estimadores.-el-riesgo"><i class="fa fa-check"></i><b>7.1.1</b> Criterios de optimalidad de estimadores. El Riesgo</a></li>
<li class="chapter" data-level="7.1.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-error-cuadr%C3%A1tico-medio"><i class="fa fa-check"></i><b>7.1.2</b> El error cuadrático medio</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estudio-de-las-propiedades-deseables-de-los-estimadores"><i class="fa fa-check"></i><b>7.2</b> Estudio de las propiedades deseables de los estimadores</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-sesgo"><i class="fa fa-check"></i><b>7.2.1</b> El sesgo</a></li>
<li class="chapter" data-level="7.2.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#consistencia"><i class="fa fa-check"></i><b>7.2.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estimadores-consistentes"><i class="fa fa-check"></i><b>7.3</b> Propiedades de los estimadores consistentes</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#eficiencia"><i class="fa fa-check"></i><b>7.3.1</b> Eficiencia</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="estimación-puntual.html"><a href="estimación-puntual.html#informaci%C3%B3n-de-fisher-y-cota-de-cramerrao"><i class="fa fa-check"></i><b>7.4</b> Información de Fisher y cota de CramerRao</a></li>
<li class="chapter" data-level="7.5" data-path="estimación-puntual.html"><a href="estimación-puntual.html#informaci%C3%B3n-y-verosimilitud-de-un-modelo-estad%C3%ADstico"><i class="fa fa-check"></i><b>7.5</b> Información y verosimilitud de un modelo estadístico</a></li>
<li class="chapter" data-level="7.6" data-path="estimación-puntual.html"><a href="estimación-puntual.html#informaci%C3%B3n-de-fisher"><i class="fa fa-check"></i><b>7.6</b> Información de Fisher</a></li>
<li class="chapter" data-level="7.7" data-path="estimación-puntual.html"><a href="estimación-puntual.html#la-desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>7.7</b> La desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="7.8" data-path="estimación-puntual.html"><a href="estimación-puntual.html#caracterizaci%C3%B3n-del-estimador-eficiente"><i class="fa fa-check"></i><b>7.8</b> Caracterización del estimador eficiente</a></li>
<li class="chapter" data-level="7.9" data-path="estimación-puntual.html"><a href="estimación-puntual.html#estad%C3%ADsticos-suficientes"><i class="fa fa-check"></i><b>7.9</b> Estadísticos suficientes</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#definici%C3%B3-de-estad%C3%ADsticop-suficiente"><i class="fa fa-check"></i><b>7.9.1</b> Definició de estadísticop suficiente</a></li>
<li class="chapter" data-level="7.9.2" data-path="estimación-puntual.html"><a href="estimación-puntual.html#teorema-de-factorizaci%C3%B3n"><i class="fa fa-check"></i><b>7.9.2</b> Teorema de factorización</a></li>
<li class="chapter" data-level="7.9.3" data-path="estimación-puntual.html"><a href="estimación-puntual.html#propiedades-de-los-estad%C3%ADsticos-suficientes"><i class="fa fa-check"></i><b>7.9.3</b> Propiedades de los estadísticos suficientes</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="estimación-puntual.html"><a href="estimación-puntual.html#obtenci%C3%B3n-de-estimadores"><i class="fa fa-check"></i><b>7.10</b> Obtención de estimadores</a></li>
<li class="chapter" data-level="7.11" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-m%C3%A9todo-de-los-momentos"><i class="fa fa-check"></i><b>7.11</b> El método de los momentos</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="estimación-puntual.html"><a href="estimación-puntual.html#observaciones-1"><i class="fa fa-check"></i><b>7.11.1</b> Observaciones</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="estimación-puntual.html"><a href="estimación-puntual.html#el-m%C3%A9todo-del-m%C3%A1ximo-de-verosimilitud"><i class="fa fa-check"></i><b>7.12</b> El método del máximo de verosimilitud</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html"><i class="fa fa-check"></i><b>8</b> Estimación por intérvalos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#motivaci%C3%B3n-de-los-intervalos-de-confianza-la-estimaci%C3%B3n-puntual-casi-siempre-es-falsa"><i class="fa fa-check"></i><b>8.1</b> Motivación de los intervalos de confianza: la estimación puntual casi siempre es falsa</a></li>
<li class="chapter" data-level="8.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#definici%C3%B3n-formal-de-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.2</b> Definición formal de intervalo de confianza</a></li>
<li class="chapter" data-level="8.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#un-ejemplo-de-construcci%C3%B3n-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.3</b> Un ejemplo de construcción de un intervalo de confianza</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#planteamiento"><i class="fa fa-check"></i><b>8.3.1</b> Planteamiento</a></li>
<li class="chapter" data-level="8.3.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#desarrollo-de-la-construcci%C3%B3n"><i class="fa fa-check"></i><b>8.3.2</b> Desarrollo de la construcción</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#por-qu%C3%A9-hablamos-de-confianza-y-no-de-probabilidad"><i class="fa fa-check"></i><b>8.4</b> ¿Por qué hablamos de confianza y no de probabilidad?</a></li>
<li class="chapter" data-level="8.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#elementos-de-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>8.5</b> Elementos de un intervalo de confianza</a></li>
<li class="chapter" data-level="8.6" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#m%C3%A9todo-del-pivote"><i class="fa fa-check"></i><b>8.6</b> Método del pivote</a></li>
<li class="chapter" data-level="8.7" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#algunos-estad%C3%ADsticos-pivote"><i class="fa fa-check"></i><b>8.7</b> Algunos estadísticos pivote</a></li>
<li class="chapter" data-level="8.8" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-media-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.8</b> Intervalo de confianza para la media de una distribución Normal</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-conocida"><i class="fa fa-check"></i><b>8.8.1</b> Caso de varianza conocida</a></li>
<li class="chapter" data-level="8.8.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianza-desconocida"><i class="fa fa-check"></i><b>8.8.2</b> Caso de varianza desconocida</a></li>
<li class="chapter" data-level="8.8.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#calculo-con-r"><i class="fa fa-check"></i><b>8.8.3</b> Calculo con R</a></li>
<li class="chapter" data-level="8.8.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tama%C3%B1o-de-muestra-para-la-media-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.8.4</b> Tamaño de muestra para la media de una distribución Normal</a></li>
</ul></li>
<li class="chapter" data-level="8.9" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-varianza-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>8.9</b> Intervalo de confianza para la varianza de una distribución Normal</a></li>
<li class="chapter" data-level="8.10" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>8.10</b> Intervalo de confianza para una proporción</a>
<ul>
<li class="chapter" data-level="8.10.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximaci%C3%B3n-asint%C3%B3tica"><i class="fa fa-check"></i><b>8.10.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.10.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto"><i class="fa fa-check"></i><b>8.10.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.10.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tama%C3%B1o-muestral-para-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>8.10.3</b> Tamaño muestral para una proporción</a></li>
</ul></li>
<li class="chapter" data-level="8.11" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-par%C3%A1metro-de-una-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.11</b> Intervalo de confianza para el parámetro de una distribución de Poisson</a>
<ul>
<li class="chapter" data-level="8.11.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximaci%C3%B3n-asint%C3%B3tica-1"><i class="fa fa-check"></i><b>8.11.1</b> Aproximación asintótica</a></li>
<li class="chapter" data-level="8.11.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-exacto-1"><i class="fa fa-check"></i><b>8.11.2</b> Intervalo exacto</a></li>
<li class="chapter" data-level="8.11.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#tama%C3%B1o-de-muestra-para-el-par%C3%A1metro-de-una-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.11.3</b> Tamaño de muestra para el parámetro de una distribución de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="8.12" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes."><i class="fa fa-check"></i><b>8.12</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.12.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#varianza-com%C3%BAn"><i class="fa fa-check"></i><b>8.12.1</b> Varianza común</a></li>
</ul></li>
<li class="chapter" data-level="8.13" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-la-diferencia-de-medias-de-distribuciones-normales-independientes.-1"><i class="fa fa-check"></i><b>8.13</b> Intervalo de confianza para la diferencia de medias de distribuciones normales independientes.</a>
<ul>
<li class="chapter" data-level="8.13.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#varianza-diferente"><i class="fa fa-check"></i><b>8.13.1</b> Varianza diferente</a></li>
<li class="chapter" data-level="8.13.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#caso-de-varianzas-desconocidas-y-diferentes"><i class="fa fa-check"></i><b>8.13.2</b> Caso de varianzas desconocidas y diferentes</a></li>
<li class="chapter" data-level="8.13.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#int%C3%A9rvalos-de-confianza-y-decisiones-estad%C3%ADsticas"><i class="fa fa-check"></i><b>8.13.3</b> Intérvalos de confianza y decisiones estadísticas</a></li>
</ul></li>
<li class="chapter" data-level="8.14" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalo-de-confianza-para-el-cociente-de-varianzas-de-distribuciones-normales-independientes"><i class="fa fa-check"></i><b>8.14</b> Intervalo de confianza para el cociente de varianzas de distribuciones normales independientes</a></li>
<li class="chapter" data-level="8.15" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#complementos"><i class="fa fa-check"></i><b>8.15</b> Complementos</a>
<ul>
<li class="chapter" data-level="8.15.1" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#interpretaci%C3%B3n-geom%C3%A9trica-de-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>8.15.1</b> Interpretación geométrica de los intervalos de confianza</a></li>
<li class="chapter" data-level="8.15.2" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-para-muestras-grandes"><i class="fa fa-check"></i><b>8.15.2</b> Intervalos para muestras grandes</a></li>
<li class="chapter" data-level="8.15.3" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#intervalos-exactos-para-distribuciones-discretas"><i class="fa fa-check"></i><b>8.15.3</b> Intervalos exactos para distribuciones discretas</a></li>
<li class="chapter" data-level="8.15.4" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#una-aproximaci%C3%B3n-diferente-para-la-distribuci%C3%B3n-de-poisson"><i class="fa fa-check"></i><b>8.15.4</b> Una aproximación diferente para la distribución de Poisson</a></li>
<li class="chapter" data-level="8.15.5" data-path="estimación-por-intérvalos.html"><a href="estimación-por-intérvalos.html#aproximaci%C3%B3n-mediante-ch%C3%A9bishev"><i class="fa fa-check"></i><b>8.15.5</b> Aproximación mediante Chébishev</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>9</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="9.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#introducci%C3%B3n-2"><i class="fa fa-check"></i><b>9.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#de-las-hip%C3%B3tesis-cient%C3%ADficas-a-las-hip%C3%B3tesis-estad%C3%ADsticas"><i class="fa fa-check"></i><b>9.1.1</b> De las hipótesis científicas a las hipótesis estadísticas</a></li>
<li class="chapter" data-level="9.1.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#del-lenguaje-natural-a-la-hip%C3%B3tesis-estad%C3%ADstica"><i class="fa fa-check"></i><b>9.1.2</b> Del lenguaje natural a la hipótesis estadística</a></li>
<li class="chapter" data-level="9.1.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-presentaci%C3%B3n"><i class="fa fa-check"></i><b>9.1.3</b> Caso 1: Presentación</a></li>
<li class="chapter" data-level="9.1.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-modelo-de-probabilidad"><i class="fa fa-check"></i><b>9.1.4</b> Caso 1: Modelo de probabilidad</a></li>
<li class="chapter" data-level="9.1.5" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-presentaci%C3%B3n"><i class="fa fa-check"></i><b>9.1.5</b> Caso 2: Presentación</a></li>
<li class="chapter" data-level="9.1.6" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-modelo-de-probabilidad"><i class="fa fa-check"></i><b>9.1.6</b> Caso 2: Modelo de probabilidad</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#las-hip%C3%B3tesis-del-contraste-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.2</b> Las hipótesis del contraste de hipótesis</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-hip%C3%B3tesis-para-dirimir-la-controversia-sobre-el-n%C3%BAmero-de-hembras"><i class="fa fa-check"></i><b>9.2.1</b> Caso 1: Hipótesis para dirimir la controversia sobre el número de hembras</a></li>
<li class="chapter" data-level="9.2.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-hip%C3%B3tesis-a-contrastar-en-el-problema-de-la-tasa-de-statdrolona"><i class="fa fa-check"></i><b>9.2.2</b> Caso 2: Hipótesis a contrastar en el problema de la tasa de statdrolona</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.3</b> Compatibilidad de resultados e hipótesis</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.3.1</b> Caso 1: Compatibilidad de resultados e hipótesis</a></li>
<li class="chapter" data-level="9.3.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-compatibilidad-de-resultados-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>9.3.2</b> Caso 2: Compatibilidad de resultados e hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#no-todo-es-igualmente-probable"><i class="fa fa-check"></i><b>9.4</b> No todo es igualmente probable…</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-una-regi%C3%B3n-con-n%C3%BAmero-de-hembras-con-baja-probabilidad-bajo-mathrmh_0"><i class="fa fa-check"></i><b>9.4.1</b> Caso 1: Una región con número de hembras con baja probabilidad bajo <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
<li class="chapter" data-level="9.4.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-medias-de-las-tasas-de-statdrolona-improbables-si-se-cumple-mathrmh_0"><i class="fa fa-check"></i><b>9.4.2</b> Caso 2: Medias de las tasas de statdrolona improbables si se cumple <span class="math inline">\(\mathrm{H}_{0}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#el-papel-privilegiado-de-la-hip%C3%B3tesis-nula-criterio-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>9.5</b> El papel privilegiado de la hipótesis nula: criterio de decisión</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-n.%C2%BA-de-nidos-propuestos-ad-hoc-como-inicio-de-regi%C3%B3n-cr%C3%ADtica.-regla-de-decisi%C3%B3n-resultante"><i class="fa fa-check"></i><b>9.5.1</b> Caso 1: N.º de nidos propuestos ad hoc como inicio de región crítica. Regla de decisión resultante</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#hip%C3%B3tesis-nula-y-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>9.6</b> Hipótesis nula y nivel de significación</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>9.6.1</b> Caso 1: Nivel de significación</a></li>
<li class="chapter" data-level="9.6.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>9.6.2</b> Caso 1: Elección de la región crítica</a></li>
<li class="chapter" data-level="9.6.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>9.6.3</b> Caso 2: Elección de la región crítica</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#regi%C3%B3n-cr%C3%ADtica-y-formalizaci%C3%B3n-del-contraste"><i class="fa fa-check"></i><b>9.7</b> Región crítica y formalización del contraste</a>
<ul>
<li class="chapter" data-level="9.7.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-resumen-de-conceptos-asociados-al-contraste.-regi%C3%B3n-cr%C3%ADtica"><i class="fa fa-check"></i><b>9.7.1</b> Caso 1: Resumen de conceptos asociados al contraste. Región crítica</a></li>
<li class="chapter" data-level="9.7.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-tabla-resumen-de-la-regi%C3%B3n-cr%C3%ADtica-el-estad%C3%ADstico-de-test-y-del-criterio-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>9.7.2</b> Caso 2: Tabla resumen de la región crítica, el estadístico de test y del criterio de decisión</a></li>
<li class="chapter" data-level="9.7.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#regi%C3%B3n-cr%C3%ADtica-frente-a-estad%C3%ADstico-de-test"><i class="fa fa-check"></i><b>9.7.3</b> Región crítica frente a Estadístico de Test</a></li>
</ul></li>
<li class="chapter" data-level="9.8" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tabla-de-decisi%C3%B3n-del-contraste"><i class="fa fa-check"></i><b>9.8</b> Tabla de decisión del contraste</a>
<ul>
<li class="chapter" data-level="9.8.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-evaluaci%C3%B3n-de-los-dos-errores-asociados-al-contraste"><i class="fa fa-check"></i><b>9.8.1</b> Caso 1: Evaluación de los dos errores asociados al contraste</a></li>
<li class="chapter" data-level="9.8.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-expl%C3%ADcito-de-los-errores-de-primera-alpha-y-segunda-especie-1--beta"><i class="fa fa-check"></i><b>9.8.2</b> Caso 2: Cálculo explícito de los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )</a></li>
</ul></li>
<li class="chapter" data-level="9.9" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#relaci%C3%B3n-entre-el-error-de-tipo-i-y-el-de-tipo-ii"><i class="fa fa-check"></i><b>9.9</b> Relación entre el error de tipo I y el de tipo II</a>
<ul>
<li class="chapter" data-level="9.9.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-evaluaci%C3%B3n-de-alpha-y-1--beta-para-diferentes-regiones-cr%C3%ADticas"><i class="fa fa-check"></i><b>9.9.1</b> Caso 1: Evaluación de <span class="math inline">\(\alpha\)</span> y 1- <span class="math inline">\(\beta\)</span> para diferentes regiones críticas</a></li>
<li class="chapter" data-level="9.9.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-relaci%C3%B3n-entre-los-errores-de-primera-alpha-y-segunda-especie-1--beta"><i class="fa fa-check"></i><b>9.9.2</b> Caso 2: Relación entre los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )</a></li>
</ul></li>
<li class="chapter" data-level="9.10" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#potencia-y-test-m%C3%A1s-potente"><i class="fa fa-check"></i><b>9.10</b> Potencia y test más potente</a>
<ul>
<li class="chapter" data-level="9.10.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-potencia-en-hip%C3%B3tesis-simple-vs-simple"><i class="fa fa-check"></i><b>9.10.1</b> Caso 1: Potencia en hipótesis simple vs simple</a></li>
<li class="chapter" data-level="9.10.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-potencia-en-hip%C3%B3tesis-simple-vs-simple"><i class="fa fa-check"></i><b>9.10.2</b> Caso 2: Potencia en hipótesis simple vs simple</a></li>
</ul></li>
<li class="chapter" data-level="9.11" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#efecto-del-tama%C3%B1o-muestral"><i class="fa fa-check"></i><b>9.11</b> Efecto del tamaño muestral</a>
<ul>
<li class="chapter" data-level="9.11.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1"><i class="fa fa-check"></i><b>9.11.1</b> Caso 1</a></li>
<li class="chapter" data-level="9.11.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2"><i class="fa fa-check"></i><b>9.11.2</b> Caso 2</a></li>
</ul></li>
<li class="chapter" data-level="9.12" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#hip%C3%B3tesis-simples-vs.-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>9.12</b> Hipótesis simples vs. hipótesis compuestas</a>
<ul>
<li class="chapter" data-level="9.12.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>9.12.1</b> Caso 1: Hipótesis compuestas</a></li>
<li class="chapter" data-level="9.12.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-hip%C3%B3tesis-compuestas"><i class="fa fa-check"></i><b>9.12.2</b> Caso 2: Hipótesis compuestas</a></li>
</ul></li>
<li class="chapter" data-level="9.13" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>9.13</b> Función de potencia</a>
<ul>
<li class="chapter" data-level="9.13.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>9.13.1</b> Caso 1: Función de potencia</a></li>
<li class="chapter" data-level="9.13.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-funci%C3%B3n-de-potencia"><i class="fa fa-check"></i><b>9.13.2</b> Caso 2: Función de potencia</a></li>
</ul></li>
<li class="chapter" data-level="9.14" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tests-%C3%B3ptimos"><i class="fa fa-check"></i><b>9.14</b> Tests óptimos</a></li>
<li class="chapter" data-level="9.15" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-bilaterales-y-pruebas-unilaterales"><i class="fa fa-check"></i><b>9.15</b> Pruebas bilaterales y pruebas unilaterales</a>
<ul>
<li class="chapter" data-level="9.15.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-prueba-unilateral"><i class="fa fa-check"></i><b>9.15.1</b> Caso 1: Prueba unilateral</a></li>
<li class="chapter" data-level="9.15.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-prueba-unilateral"><i class="fa fa-check"></i><b>9.15.2</b> Caso 2: Prueba unilateral</a></li>
</ul></li>
<li class="chapter" data-level="9.16" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#elecci%C3%B3n-del-nivel-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>9.16</b> Elección del nivel de significación</a></li>
<li class="chapter" data-level="9.17" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#el-p-valor"><i class="fa fa-check"></i><b>9.17</b> El p-valor</a>
<ul>
<li class="chapter" data-level="9.17.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-c%C3%A1lculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>9.17.1</b> Caso 1: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="9.17.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-del-p-valor-prueba-unilateral"><i class="fa fa-check"></i><b>9.17.2</b> Caso 2: Cálculo del p-valor (prueba unilateral)</a></li>
<li class="chapter" data-level="9.17.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-del-p-valor-prueba-bilateral"><i class="fa fa-check"></i><b>9.17.3</b> Caso 2: Cálculo del p-valor (prueba bilateral)</a></li>
</ul></li>
<li class="chapter" data-level="9.18" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-exactas-y-pruebas-asint%C3%B3ticas"><i class="fa fa-check"></i><b>9.18</b> Pruebas exactas y pruebas asintóticas</a>
<ul>
<li class="chapter" data-level="9.18.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-1-test-asint%C3%B3tico"><i class="fa fa-check"></i><b>9.18.1</b> Caso 1: Test asintótico</a></li>
<li class="chapter" data-level="9.18.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-test-exacto"><i class="fa fa-check"></i><b>9.18.2</b> Caso 2: Test exacto</a></li>
</ul></li>
<li class="chapter" data-level="9.19" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#relaci%C3%B3n-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>9.19</b> Relación con los intervalos de confianza</a>
<ul>
<li class="chapter" data-level="9.19.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-relaci%C3%B3n-con-los-intervalos-de-confianza"><i class="fa fa-check"></i><b>9.19.1</b> Caso 2: Relación con los intervalos de confianza</a></li>
</ul></li>
<li class="chapter" data-level="9.20" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#tama%C3%B1os-de-muestra.-diferencia-m%C3%ADnima-significativa"><i class="fa fa-check"></i><b>9.20</b> Tamaños de muestra. Diferencia mínima significativa</a>
<ul>
<li class="chapter" data-level="9.20.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-del-tama%C3%B1o-de-la-muestra"><i class="fa fa-check"></i><b>9.20.1</b> Caso 2: Cálculo del tamaño de la muestra</a></li>
</ul></li>
<li class="chapter" data-level="9.21" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#esquema-de-un-contraste-correctamente-planteado"><i class="fa fa-check"></i><b>9.21</b> Esquema de un contraste correctamente planteado</a></li>
<li class="chapter" data-level="9.22" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#significaci%C3%B3n-estad%C3%ADstica-y-significaci%C3%B3n-aplicada"><i class="fa fa-check"></i><b>9.22</b> Significación estadística y significación aplicada</a>
<ul>
<li class="chapter" data-level="9.22.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#caso-2-significaci%C3%B3n-estad%C3%ADstica-y-aplicada"><i class="fa fa-check"></i><b>9.22.1</b> Caso 2: Significación estadística y aplicada</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html"><i class="fa fa-check"></i><b>10</b> Construcción de contrastes de hipótesis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#qu%C3%A9-significa-construir-un-contraste-de-hip%C3%B3tesis"><i class="fa fa-check"></i><b>10.1</b> ¿Qué significa “construir” un contraste de hipótesis?</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#el-contraste-como-regla-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>10.1.1</b> El contraste como regla de decisión</a></li>
<li class="chapter" data-level="10.1.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#nivel-de-significaci%C3%B3n-como-restricci%C3%B3n-b%C3%A1sica"><i class="fa fa-check"></i><b>10.1.2</b> Nivel de significación como restricción básica</a></li>
<li class="chapter" data-level="10.1.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#primer-ejemplo-distintos-contrastes-con-el-mismo-nivel"><i class="fa fa-check"></i><b>10.1.3</b> Primer ejemplo: distintos contrastes con el mismo nivel</a></li>
<li class="chapter" data-level="10.1.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#potencia-como-criterio-de-comparaci%C3%B3n"><i class="fa fa-check"></i><b>10.1.4</b> Potencia como criterio de comparación</a></li>
<li class="chapter" data-level="10.1.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#segundo-ejemplo-misma-alpha-distinta-potencia"><i class="fa fa-check"></i><b>10.1.5</b> Segundo ejemplo: misma alpha, distinta potencia</a></li>
<li class="chapter" data-level="10.1.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#de-contrastes-razonables-a-contrastes-%C3%B3ptimos"><i class="fa fa-check"></i><b>10.1.6</b> De contrastes razonables a contrastes óptimos</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#evidencia-y-decisi%C3%B3n-dos-enfoques-cl%C3%A1sicos"><i class="fa fa-check"></i><b>10.2</b> Evidencia y decisión: dos enfoques clásicos</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#el-enfoque-de-fisher-tests-de-significaci%C3%B3n"><i class="fa fa-check"></i><b>10.2.1</b> El enfoque de Fisher: tests de significación</a></li>
<li class="chapter" data-level="10.2.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#el-enfoque-de-neymanpearson-contraste-como-regla-de-decisi%C3%B3n"><i class="fa fa-check"></i><b>10.2.2</b> El enfoque de Neyman–Pearson: contraste como regla de decisión</a></li>
<li class="chapter" data-level="10.2.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#diferencias-conceptuales-clave"><i class="fa fa-check"></i><b>10.2.3</b> Diferencias conceptuales clave</a></li>
<li class="chapter" data-level="10.2.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#convivencia-de-ambos-enfoques-en-la-pr%C3%A1ctica"><i class="fa fa-check"></i><b>10.2.4</b> Convivencia de ambos enfoques en la práctica</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#tests-%C3%B3ptimos-el-lema-de-neymanpearson"><i class="fa fa-check"></i><b>10.3</b> Tests óptimos: el lema de Neyman–Pearson</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#hip%C3%B3tesis-simples-y-raz%C3%B3n-de-verosimilitudes"><i class="fa fa-check"></i><b>10.3.1</b> Hipótesis simples y razón de verosimilitudes</a></li>
<li class="chapter" data-level="10.3.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#enunciado-del-lema-de-neymanpearson"><i class="fa fa-check"></i><b>10.3.2</b> Enunciado del lema de Neyman–Pearson</a></li>
<li class="chapter" data-level="10.3.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-modelo-normal-con-varianza-conocida"><i class="fa fa-check"></i><b>10.3.3</b> Ejemplo: modelo normal con varianza conocida</a></li>
<li class="chapter" data-level="10.3.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-modelo-de-poisson"><i class="fa fa-check"></i><b>10.3.4</b> Ejemplo: modelo de Poisson</a></li>
<li class="chapter" data-level="10.3.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#extensiones-del-lema-de-neymanpearson"><i class="fa fa-check"></i><b>10.3.5</b> Extensiones del lema de Neyman–Pearson</a></li>
<li class="chapter" data-level="10.3.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#l%C3%ADmites-del-enfoque"><i class="fa fa-check"></i><b>10.3.6</b> Límites del enfoque</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#contrastes-de-raz%C3%B3n-de-verosimilitudes-generalizados"><i class="fa fa-check"></i><b>10.4</b> Contrastes de razón de verosimilitudes generalizados</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#definici%C3%B3n-del-estad%C3%ADstico-de-raz%C3%B3n-de-verosimilitudes"><i class="fa fa-check"></i><b>10.4.1</b> Definición del estadístico de razón de verosimilitudes</a></li>
<li class="chapter" data-level="10.4.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#regla-de-decisi%C3%B3n-y-aproximaci%C3%B3n-asint%C3%B3tica"><i class="fa fa-check"></i><b>10.4.2</b> Regla de decisión y aproximación asintótica</a></li>
<li class="chapter" data-level="10.4.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-comparaci%C3%B3n-de-par%C3%A1metros-en-un-modelo-de-poisson"><i class="fa fa-check"></i><b>10.4.3</b> Ejemplo: comparación de parámetros en un modelo de Poisson</a></li>
<li class="chapter" data-level="10.4.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-contraste-en-un-modelo-exponencial"><i class="fa fa-check"></i><b>10.4.4</b> Ejemplo: contraste en un modelo exponencial</a></li>
<li class="chapter" data-level="10.4.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-contraste-en-un-modelo-trinomial"><i class="fa fa-check"></i><b>10.4.5</b> Ejemplo: contraste en un modelo trinomial</a></li>
<li class="chapter" data-level="10.4.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#del-contraste-de-raz%C3%B3n-de-verosimilitudes-al-test-ji-cuadrado"><i class="fa fa-check"></i><b>10.4.6</b> Del contraste de razón de verosimilitudes al test ji-cuadrado</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#tests-de-permutaciones"><i class="fa fa-check"></i><b>10.5</b> Tests de permutaciones</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#idea-b%C3%A1sica"><i class="fa fa-check"></i><b>10.5.1</b> Idea básica</a></li>
<li class="chapter" data-level="10.5.2" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-1-test-de-permutaciones-con-enumeraci%C3%B3n-completa"><i class="fa fa-check"></i><b>10.5.2</b> Ejemplo 1: test de permutaciones con enumeración completa</a></li>
<li class="chapter" data-level="10.5.3" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#valor-observado-del-estad%C3%ADstico"><i class="fa fa-check"></i><b>10.5.3</b> Valor observado del estadístico</a></li>
<li class="chapter" data-level="10.5.4" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#distribuci%C3%B3n-exacta-por-permutaciones"><i class="fa fa-check"></i><b>10.5.4</b> Distribución exacta por permutaciones</a></li>
<li class="chapter" data-level="10.5.5" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#ejemplo-2-test-de-permutaciones-mediante-simulaci%C3%B3n"><i class="fa fa-check"></i><b>10.5.5</b> Ejemplo 2: test de permutaciones mediante simulación</a></li>
<li class="chapter" data-level="10.5.6" data-path="construcción-de-contrastes-de-hipótesis.html"><a href="construcción-de-contrastes-de-hipótesis.html#comentario-final"><i class="fa fa-check"></i><b>10.5.6</b> Comentario final</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html"><i class="fa fa-check"></i><b>11</b> Pruebas de una muestra</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-a-los-contrastes-de-una-muestra."><i class="fa fa-check"></i><b>11.1</b> Introducción a los contrastes de una muestra.</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#esquema-de-los-contrastes-presentados"><i class="fa fa-check"></i><b>11.1.1</b> Esquema de los contrastes presentados</a></li>
<li class="chapter" data-level="11.1.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contrastes-sobre-los-par%C3%A1metros-de-una-distribuci%C3%B3n-normal"><i class="fa fa-check"></i><b>11.1.2</b> Contrastes sobre los parámetros de una distribución Normal</a></li>
<li class="chapter" data-level="11.1.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contrastes-sobre-una-proporci%C3%B3n"><i class="fa fa-check"></i><b>11.1.3</b> Contrastes sobre una proporción</a></li>
<li class="chapter" data-level="11.1.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#esquema-general-de-los-contrastes-presentados"><i class="fa fa-check"></i><b>11.1.4</b> Esquema general de los contrastes presentados</a></li>
<li class="chapter" data-level="11.1.5" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contrastes-param%C3%A9tricos-frente-a-no-param%C3%A9tricos"><i class="fa fa-check"></i><b>11.1.5</b> Contrastes paramétricos frente a no paramétricos</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida-z-test."><i class="fa fa-check"></i><b>11.2</b> Contraste de hipótesis para la media de una distribución Normal con varianza conocida: <span class="math inline">\(Z\)</span>-test.</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-3"><i class="fa fa-check"></i><b>11.2.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida."><i class="fa fa-check"></i><b>11.2.2</b> Resolución del contraste para la media de una distribución Normal con varianza conocida.</a></li>
<li class="chapter" data-level="11.2.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida."><i class="fa fa-check"></i><b>11.2.3</b> Intervalo de confianza para la media de una distribución Normal con varianza conocida.</a></li>
<li class="chapter" data-level="11.2.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#c%C3%A1lculo-del-tama%C3%B1o-muestral-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-conocida."><i class="fa fa-check"></i><b>11.2.4</b> Cálculo del tamaño muestral para la media de una distribución Normal con varianza conocida.</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida-t-test."><i class="fa fa-check"></i><b>11.3</b> Contraste de hipótesis para la media de una distribución Normal con varianza desconocida: <span class="math inline">\(T\)</span>-test.</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-4"><i class="fa fa-check"></i><b>11.3.1</b> Introducción</a></li>
<li class="chapter" data-level="11.3.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida."><i class="fa fa-check"></i><b>11.3.2</b> Resolución del contraste para la media de una distribución Normal con varianza desconocida.</a></li>
<li class="chapter" data-level="11.3.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida."><i class="fa fa-check"></i><b>11.3.3</b> Intervalo de confianza para la media de una distribución Normal con varianza desconocida.</a></li>
<li class="chapter" data-level="11.3.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#c%C3%A1lculo-del-tama%C3%B1o-muestral-para-la-media-de-una-distribuci%C3%B3n-normal-con-varianza-desconocida."><i class="fa fa-check"></i><b>11.3.4</b> Cálculo del tamaño muestral para la media de una distribución Normal con varianza desconocida.</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-varianza-de-una-distribuci%C3%B3n-normal."><i class="fa fa-check"></i><b>11.4</b> Contraste de hipótesis para la varianza de una distribución Normal.</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-5"><i class="fa fa-check"></i><b>11.4.1</b> Introducción</a></li>
<li class="chapter" data-level="11.4.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#informaci%C3%B3n-previa-premisas"><i class="fa fa-check"></i><b>11.4.2</b> Información previa (premisas)</a></li>
<li class="chapter" data-level="11.4.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-varianza-de-una-distribuci%C3%B3n-normal."><i class="fa fa-check"></i><b>11.4.3</b> Resolución del contraste para la varianza de una distribución Normal.</a></li>
<li class="chapter" data-level="11.4.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-varianza-de-una-distribuci%C3%B3n-normal."><i class="fa fa-check"></i><b>11.4.4</b> Intervalo de confianza para la varianza de una distribución Normal.</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#contraste-de-hip%C3%B3tesis-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>11.5</b> Contraste de hipótesis para la proporción.</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#introducci%C3%B3n-6"><i class="fa fa-check"></i><b>11.5.1</b> Introducción:</a></li>
<li class="chapter" data-level="11.5.2" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#informaci%C3%B3n-previa-premisas-1"><i class="fa fa-check"></i><b>11.5.2</b> Información previa (premisas)</a></li>
<li class="chapter" data-level="11.5.3" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#resoluci%C3%B3n-del-contraste-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>11.5.3</b> Resolución del contraste para la proporción.</a></li>
<li class="chapter" data-level="11.5.4" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>11.5.4</b> Intervalo de confianza para la proporción.</a></li>
<li class="chapter" data-level="11.5.5" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#c%C3%A1lculo-del-tama%C3%B1o-muestral-para-la-proporci%C3%B3n."><i class="fa fa-check"></i><b>11.5.5</b> Cálculo del tamaño muestral para la proporción.</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#tabla-resumen-para-una-muestra."><i class="fa fa-check"></i><b>11.6</b> Tabla resumen para una muestra.</a></li>
<li class="chapter" data-level="11.7" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#la-importancia-de-elegir-correctamente-la-hip%C3%B3tesis-nula."><i class="fa fa-check"></i><b>11.7</b> La importancia de elegir correctamente la hipótesis nula.</a></li>
<li class="chapter" data-level="11.8" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#relaci%C3%B3n-con-los-intervalos-de-confianza-1"><i class="fa fa-check"></i><b>11.8</b> Relación con los intervalos de confianza</a></li>
<li class="chapter" data-level="11.9" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#relaci%C3%B3n-entre-el-intervalo-y-el-contraste"><i class="fa fa-check"></i><b>11.9</b> Relación entre el intervalo y el contraste</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="pruebas-de-una-muestra.html"><a href="pruebas-de-una-muestra.html#intervalo-de-confianza-para-la-varianza-de-una-distribuci%C3%B3n-normal-1"><i class="fa fa-check"></i><b>11.9.1</b> Intervalo de confianza para la varianza de una distribución Normal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html"><i class="fa fa-check"></i><b>12</b> Contrastes con dos muestras</a>
<ul>
<li class="chapter" data-level="12.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#introducci%C3%B3n-7"><i class="fa fa-check"></i><b>12.1</b> Introducción</a></li>
<li class="chapter" data-level="12.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-independencia-vs-datos-apareados"><i class="fa fa-check"></i><b>12.2</b> Premisas: independencia vs datos apareados</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#ejemplo-datos-independientes-vs-apareados"><i class="fa fa-check"></i><b>12.2.1</b> Ejemplo: Datos independientes vs apareados</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis-en-comparaciones-de-medias-de-datos-normales-independientes."><i class="fa fa-check"></i><b>12.3</b> Premisas e hipótesis en comparaciones de medias de datos normales independientes.</a></li>
<li class="chapter" data-level="12.4" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaci%C3%B3n-de-medias-de-datos-normales-independientes."><i class="fa fa-check"></i><b>12.4</b> Comparación de medias de datos normales independientes.</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#estad%C3%ADstico-de-test-y-valores-cr%C3%ADticos"><i class="fa fa-check"></i><b>12.4.1</b> Estadístico de test y valores críticos</a></li>
<li class="chapter" data-level="12.4.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#intervalo-de-confianza-para-la-diferencia-de-medias."><i class="fa fa-check"></i><b>12.4.2</b> Intervalo de confianza para la diferencia de medias.</a></li>
<li class="chapter" data-level="12.4.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#c%C3%A1lculo-del-tama%C3%B1o-de-muestra"><i class="fa fa-check"></i><b>12.4.3</b> Cálculo del tamaño de muestra</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaci%C3%B3n-de-varianzas-de-datos-normales-independientes."><i class="fa fa-check"></i><b>12.5</b> Comparación de varianzas de datos normales independientes.</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis-en"><i class="fa fa-check"></i><b>12.5.1</b> Premisas e hipótesis en</a></li>
<li class="chapter" data-level="12.5.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#estad%C3%ADstico-de-test-y-valores-cr%C3%ADticos-1"><i class="fa fa-check"></i><b>12.5.2</b> Estadístico de test y valores críticos</a></li>
<li class="chapter" data-level="12.5.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#intervalo-de-confianza-para-la-raz%C3%B3n-de-varianzas"><i class="fa fa-check"></i><b>12.5.3</b> Intervalo de confianza para la razón de varianzas</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaciones-de-medias-de-datos-normales-apareados"><i class="fa fa-check"></i><b>12.6</b> Comparaciones de medias de datos normales apareados</a>
<ul>
<li class="chapter" data-level="12.6.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis"><i class="fa fa-check"></i><b>12.6.1</b> Premisas e hipótesis</a></li>
<li class="chapter" data-level="12.6.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#relaci%C3%B3n-entre-el-contraste-de-datos-apareados-y-el-de-una-media-datos-normales."><i class="fa fa-check"></i><b>12.6.2</b> Relación entre el contraste de datos apareados y el de una media (datos normales).</a></li>
<li class="chapter" data-level="12.6.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#int%C3%A9rvalos-de-confianza-para-la-diferencia"><i class="fa fa-check"></i><b>12.6.3</b> Intérvalos de confianza para la diferencia</a></li>
<li class="chapter" data-level="12.6.4" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#tama%C3%B1o-muestral"><i class="fa fa-check"></i><b>12.6.4</b> Tamaño muestral</a></li>
<li class="chapter" data-level="12.6.5" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#ejemplo-efecto-de-una-intervenci%C3%B3n-sobre-el-colesterol-hdl"><i class="fa fa-check"></i><b>12.6.5</b> Ejemplo: efecto de una intervención sobre el colesterol HDL</a></li>
<li class="chapter" data-level="12.6.6" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#resumen-datos-independientes-frente-a-datos-apareados"><i class="fa fa-check"></i><b>12.6.6</b> Resumen: Datos independientes frente a datos apareados</a></li>
</ul></li>
<li class="chapter" data-level="12.7" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaciones-de-2-proporciones-datos-independientes"><i class="fa fa-check"></i><b>12.7</b> Comparaciones de 2 proporciones (datos independientes)</a>
<ul>
<li class="chapter" data-level="12.7.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#premisas-e-hip%C3%B3tesis-1"><i class="fa fa-check"></i><b>12.7.1</b> Premisas e hipótesis</a></li>
<li class="chapter" data-level="12.7.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#estad%C3%ADstico-de-test-y-valores-cr%C3%ADticos-2"><i class="fa fa-check"></i><b>12.7.2</b> Estadístico de test y valores críticos</a></li>
<li class="chapter" data-level="12.7.3" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#condiciones-de-aplicaci%C3%B3n-del-test"><i class="fa fa-check"></i><b>12.7.3</b> Condiciones de aplicación del test</a></li>
<li class="chapter" data-level="12.7.4" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#intervalo-de-confianza-para-la-diferencia-de-proporciones-datos-independientes."><i class="fa fa-check"></i><b>12.7.4</b> Intervalo de confianza para la diferencia de proporciones (datos independientes).</a></li>
<li class="chapter" data-level="12.7.5" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#c%C3%A1lculo-del-tama%C3%B1o-de-muestra-en-el-contraste-de-proporciones-de-datos-independientes."><i class="fa fa-check"></i><b>12.7.5</b> Cálculo del tamaño de muestra en el contraste de proporciones de datos independientes.</a></li>
</ul></li>
<li class="chapter" data-level="12.8" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#comparaciones-de-dos-muestras-tabla-resumen"><i class="fa fa-check"></i><b>12.8</b> Comparaciones de dos muestras: Tabla resumen</a></li>
<li class="chapter" data-level="12.9" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#complementos-efecto-de-las-transformaciones-de-los-datos-en-el-test-t"><i class="fa fa-check"></i><b>12.9</b> Complementos: efecto de las transformaciones de los datos en el test t</a>
<ul>
<li class="chapter" data-level="12.9.1" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#efecto-del-cambi-de-posici%C3%B3n"><i class="fa fa-check"></i><b>12.9.1</b> Efecto del cambi de posición</a></li>
<li class="chapter" data-level="12.9.2" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#efecto-de-un-cambio-de-escala"><i class="fa fa-check"></i><b>12.9.2</b> Efecto de un cambio de escala</a></li>
</ul></li>
<li class="chapter" data-level="12.10" data-path="contrastes-con-dos-muestras.html"><a href="contrastes-con-dos-muestras.html#presentaci%C3%B3n-del-caso-1"><i class="fa fa-check"></i><b>12.10</b> Presentación del caso 1</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html"><i class="fa fa-check"></i><b>13</b> Inferencia Aplicada</a>
<ul>
<li class="chapter" data-level="13.1" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-normalidad.-pruebas-gr%C3%A1ficas.-el-test-de-shapiro-wilks"><i class="fa fa-check"></i><b>13.1</b> Pruebas de normalidad. Pruebas gráficas. El test de Shapiro-Wilks</a></li>
<li class="chapter" data-level="13.2" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-hip%C3%B3tesis-para-constrastar-variables-cuantitativas-pruebas-param%C3%A8tricas-t-test-y-anova"><i class="fa fa-check"></i><b>13.2</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas paramètricas, t-test y Anova</a></li>
<li class="chapter" data-level="13.3" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#pruebas-de-hip%C3%B3tesis-para-constrastar-variables-cuantitativas-pruebas-de-hip%C3%B3tesis-no-param%C3%A9tricas-de-wilcoxon-y-kruskal-wallis"><i class="fa fa-check"></i><b>13.3</b> Pruebas de hipótesis para constrastar variables cuantitativas: pruebas de hipótesis no paramétricas de Wilcoxon y Kruskal-Wallis</a></li>
<li class="chapter" data-level="13.4" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#contrastes-para-datos-categ%C3%B3ricos.-pruebas-binomiales-ji-cuadrado-y-test-de-fisher."><i class="fa fa-check"></i><b>13.4</b> Contrastes para datos categóricos. Pruebas binomiales, ji cuadrado y test de Fisher.</a></li>
<li class="chapter" data-level="13.5" data-path="inferencia-aplicada.html"><a href="inferencia-aplicada.html#riesgo-relativo-y-raz%C3%B3n-de-odds"><i class="fa fa-check"></i><b>13.5</b> Riesgo relativo y razón de “odds”</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Contrastes en poblaciones normales</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pruebas-de-hipótesis" class="section level1 hasAnchor" number="9">
<h1><span class="header-section-number">Capítulo 9</span> Pruebas de hipótesis<a href="pruebas-de-hipótesis.html#pruebas-de-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="introducción-2" class="section level2 hasAnchor" number="9.1">
<h2><span class="header-section-number">9.1</span> Introducción<a href="pruebas-de-hipótesis.html#introducci%C3%B3n-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="de-las-hipótesis-científicas-a-las-hipótesis-estadísticas" class="section level3 hasAnchor" number="9.1.1">
<h3><span class="header-section-number">9.1.1</span> De las hipótesis científicas a las hipótesis estadísticas<a href="pruebas-de-hipótesis.html#de-las-hip%C3%B3tesis-cient%C3%ADficas-a-las-hip%C3%B3tesis-estad%C3%ADsticas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Antes de introducir los conceptos asociados al contraste estadístico de hipótesis, es conveniente situar este tema en el contexto más general de la <em>confirmación de hipótesis</em>, materia que la filosofía de la ciencia estudia en profundidad. Así pues, en este punto solo se plantean consideraciones generales, dejando para los siguientes apartados cómo aborda la Estadística este tema.</p>
<p>Una cuestión esencial en cualquier rama de la ciencia -básica o aplicada- es cómo verificar hipótesis sobre un determinado fenómeno real. Muchas veces, cuando se expone este tema al estudiante durante las primeras etapas de su formación científica, el llamado método de razonamiento científico se simplifica en exceso, presentando la verificación de hipótesis en términos absolutos. En este esquema simplificado del método científico se expone cómo teorizar sobre un determinado aspecto de la realidad más o menos de la siguiente forma:</p>
<ol style="list-style-type: lower-alpha">
<li>se formula una teoría (o una hipótesis, o una ley, …) sobre el fenómeno de estudio<br />
</li>
<li>se diseña un experimento para tratar de corroborar dicha teoría<br />
</li>
<li>si los resultados del experimento concuerdan con la teoría, ésta se da provisionalmente por válida<br />
</li>
<li>si el experimento contradice la teoría, se vuelve al apartado a), se modifica la ley o se elabora una nueva, de modo que se ajuste a la realidad experimental.<br />
</li>
<li>cualquier teoría relacionada con aspectos de la realidad es siempre provisional, pendiente de ser revisada al entrar en conflicto con resultados de experimentos posteriores.</li>
</ol>
<p>Esta forma de proceder -como veremos, excesivamente simplista- se basa en el hecho de asumir que en cualquier experimento se obtendrán resultados que serán <em>o bien totalmente contradictorios</em> con la teoría (y por tanto habrá que abandonarla inmediatamente) <em>o bien concordantes</em> con la teoría (y por tanto resulta razonable mantenerla).</p>
<p>Antes se ha calificado este método de validación como absoluto: si obviamos el posible error experimental, la decisión que se tome no conllevará ningún error, ya que basta con verificar los resultados del experimento para aceptar o rechazar la teoría.</p>
<p>Debe quedar claro al lector que el esquema anterior <em>no es el de un contraste estadístico</em>, y de hecho el desarrollo de este tema se encargará de revisarlo. En los próximos apartados se expondrá, para empezar, una primera idea fundamental en Estadística: cuando se introduce un modelo de probabilidad para explicar un fenómeno, emerge inevitablemente un error ya en la misma toma de decisión. En otras palabras, el esquema anterior debe revisarse en los puntos c) y d).</p>
<p>Una vez se han expuesto estas cuestiones fundamentales en los primeros puntos del capítulo, entraremos en el núcleo de este tema que consiste en el desarrollo ya puramente técnico del contraste estadístico de hipótesis.</p>
</div>
<div id="del-lenguaje-natural-a-la-hipótesis-estadística" class="section level3 hasAnchor" number="9.1.2">
<h3><span class="header-section-number">9.1.2</span> Del lenguaje natural a la hipótesis estadística<a href="pruebas-de-hipótesis.html#del-lenguaje-natural-a-la-hip%C3%B3tesis-estad%C3%ADstica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Es necesario considerar, antes de afrontar la validación estadística de una hipótesis, cómo se plantea ésta en términos estadísticos, ya que su formulación exige una traducción del lenguaje natural.</p>
<p>Conviene pues recordar que una hipótesis sobre un determinado fenómeno se formula en lenguaje natural como una <em>proposición sobre la realidad</em>. Por ejemplo, si se está estudiando determinada especie de aves, una posible hipótesis es que la proporción de machos es idéntica a la de hembras. Un segundo ejemplo nos lo proporciona el estudio del metabolismo humano en donde se propone como hipótesis que la concentración de cierta hormona se mantiene constante cuando se suministra un fármaco anabolizante.</p>
<p>Las hipótesis planteadas en los ejemplos, similares a otras que se trataran en este capítulo se denominan genéricamente <em>hipótesis paramétricas</em> porque hacen referencia a características de la población que pueden relacionarse directamente con los parámetros de un modelo probabilístico que la describe. Por ejemplo, si utilizamos una distribución binomial para representar el número de aves hembra en un nido, la proporción de hembras se corresponde con el parámetro <span class="math inline">\(p\)</span> de dicha distribución.</p>
<p>Así pues, el primer esfuerzo que debe realizar el experimentador es trasladar sus hipótesis, que generalmente expresa en lenguaje natural, a afirmaciones (proposiciones) sobre los parámetros de la distribución que considere más apropiada para describir el fenómeno que estudia.</p>
<p>En ocasiones, sin embargo, la selección misma del modelo probabilístico puede ser el problema. En estos casos la hipótesis se formulará en erminos de la distribución en vez de los parámetros de la misma. Por ejemplo al hablar de la concentración de la hormona durante la metabolizacioón de un fármaco el investigador puede desear decidir si es mas adecuada una distribución normal o una distribución gamma para representar dicha concentración. En este caso hablaríamos de <em>hipótesis no paramétricas</em>, que se discutiran más adelante en el curso.</p>
<p>En los casos prácticos siguientes, cuya solución completa se verá a lo largo del capítulo, se presentan dos situaciones diferentes.</p>
</div>
<div id="caso-1-presentación" class="section level3 hasAnchor" number="9.1.3">
<h3><span class="header-section-number">9.1.3</span> Caso 1: Presentación<a href="pruebas-de-hipótesis.html#caso-1-presentaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dos conocidos ornitólogos, especialistas en aves autóctonas del Amazonas Central, discrepan sobre la interpretación de los datos de una nueva especie de cacatúa que ha reseñado uno de ellos. La discusión la centraremos aquí en una de las variables del estudio: la proporción de hembras y machos en los nidos. Es importante precisar que estas cacatúas se caracterizan por incubar un solo huevo por nido.</p>
<p>El Dr. da Souza Faria ha censado diez nidos, cuyos datos se detallarán después. Según su experiencia, esta especie tiene una gran semejanza con otra especie mejor estudiada, con una proporción idéntica de machos y hembras. Apoyado en los datos obtenidos, concluye que la nueva especie también tiene la misma proporción de individuos de cada sexo.</p>
<p>El Dr. Calves discrepa de esta apreciación y sostiene que la proporción debe ser de seis hembras por cada 4 machos.</p>
</div>
<div id="caso-1-modelo-de-probabilidad" class="section level3 hasAnchor" number="9.1.4">
<h3><span class="header-section-number">9.1.4</span> Caso 1: Modelo de probabilidad<a href="pruebas-de-hipótesis.html#caso-1-modelo-de-probabilidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El Dr. da Souza Faria ha contado en 10 nidos el número de hembras (complementariamente, el de machos). La variable es, por tanto, discreta y su soporte es el conjunto <span class="math inline">\(\{0,1,2,3,4,5,6,7,8,9,10\}\)</span>.</p>
<p>Si asumimos que el posible nacimiento de hembras es independiente entre nidos, y definimos:</p>
<p><span class="math display">\[
X=\text { número de hembras en un total de } 10 \text { nidos. }
\]</span></p>
<p>la distribución de <span class="math inline">\(X\)</span> es una distribución binomial, de parámetros <span class="math inline">\(n=10\)</span> y <span class="math inline">\(p\)</span> desconocida.</p>
<p><span class="math display">\[
f(k)=p(X=k)=\binom{10}{k} p^{k}(1-p)^{10-k}
\]</span></p>
<p>el único parámetro desconocido es la proporción <span class="math inline">\(\boldsymbol{p}\)</span> de hembras. Las hipótesis estadísticas se referirán solo a <span class="math inline">\(p\)</span>.</p>
</div>
<div id="caso-2-presentación" class="section level3 hasAnchor" number="9.1.5">
<h3><span class="header-section-number">9.1.5</span> Caso 2: Presentación<a href="pruebas-de-hipótesis.html#caso-2-presentaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el mundo del deporte profesional se controlan con mucha precisión algunos metabolitos que aparecen en bajas concentraciones en condiciones normales. Este es el caso de la statdrolona<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>, que en individuos normales presenta una concentración media de 7.0 nanogramos por ml de orina. Este valor se ha establecido mediante una muestra muy grande de deportistas después de años de análisis antes, durante y después de competiciones. Asimismo, se ha descrito que la desviación estándar es de <span class="math inline">\(\mathbf{2 . 4 ~ n g} / \mathbf{m l}\)</span>. Estos dos valores poblacionales sirven como justificación médica a las autoridades deportivas para declarar cuándo la tasa de statdrolona se asocia a un presunto dopaje.</p>
<p>No obstante, un estudio reciente encargado por la asociación de deportistas ADG a un prestigioso departamento universitario de fisiología sostiene que, cuando se mide la concentración de statdrolona en individuos no dopados con cierto tipo de alimentos sobreabundantes en su dieta (queso parmesano, por ejemplo), el valor de la media poblacional es del orden de <span class="math inline">\(\mathbf{1 . 5}\)</span> unidades mayor. En cambio, la desviación estándar poblacional se mantiene en el valor <span class="math inline">\(2,4 \mathrm{ng} / \mathrm{ml}\)</span>, es decir, equivalente a la normal. Si esta hipótesis fuera cierta, permitiría explicar algunos de los falsos positivos detectados en los últimos tiempos. Como prueba experimental aportan una serie de datos sobre 16 deportistas que se detallarán más adelante.</p>
</div>
<div id="caso-2-modelo-de-probabilidad" class="section level3 hasAnchor" number="9.1.6">
<h3><span class="header-section-number">9.1.6</span> Caso 2: Modelo de probabilidad<a href="pruebas-de-hipótesis.html#caso-2-modelo-de-probabilidad" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El análisis de la concentración de statdrolona se mide en términos de nanogramos por <span class="math inline">\(\mathrm{mil} \cdot\)</span> litro, por lo tanto, parece razonable considerarla como una variable continua. El conjunto de resultados posibles será un subconjunto de los reales.</p>
<p>Como muchas otras variables antropométricas, la concentración se puede asociar a la distribución Normal. Se puede justificar la adopción de este modelo de acuerdo con el teorema central del límite.</p>
<p>Según las autoridades deportivas, los valores en un deportista no dopado deben corresponder a una media de <span class="math inline">\(7.0 \mathrm{ng} / \mathrm{ml}\)</span>, mientras que para ADG la media puede ser mayor en algunas circunstancias. En cualquier caso, la variable:</p>
<p><span class="math display">\[
X=\text { concentración de statdrolona en un deportista. }
\]</span></p>
<p>se aceptará que tiene distribución Normal. Así, la discusión se centrará solo en el parámetro <span class="math inline">\(\mu\)</span> desconocido, mientras que la desviación estándar se tomará, para simplificar la explicación, como <span class="math inline">\(\sigma=2.4\)</span> (conocida), aunque se sabe que es más realista seleccionarla como desconocida (véase más adelante en el curso, o los temas anteriores de intérvalos de confianza y distribuciones en el muestreo).</p>
<p>La fórmula de la densidad Normal:</p>
<p><span class="math display">\[
f_{X}(x)=\frac{1}{2.4 \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^{2}}{2 \times 2.4^{2}}\right)
\]</span></p>
<p>indica para este caso que el único parámetro desconocido es la media de la población <span class="math inline">\(\boldsymbol{\mu}\)</span>, a la que se referirán las hipótesis estadísticas.</p>
<p>Ahora bien, también resulta importante describir la densidad de la media de los dieciséis deportistas, ya que jugará un papel importante en la construcción del test. Si aceptamos la distribución <span class="math inline">\(\mathrm{N}(\mu, 2.4)\)</span> para un deportista, y <em>consideramos que el muestreo es aleatorio simple</em>, entonces:</p>
<p><span class="math display">\[
\bar{X}_{16}=\text { media concentración statdrolona en } 16 \text { deportistas }
\]</span></p>
<p>que tendrá una densidad de la forma:</p>
<p><span class="math display">\[
\bar{X}_{16} \approx N(\mu, 2.4 / \sqrt{16})
\]</span></p>
<p>Simplificando 2.4 por la raíz cuadrada de 16 resulta 0.6 , así pues:</p>
<p><span class="math display">\[
f_{\bar{X}_{16}}(x)=\frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^{2}}{2 \times 0.6^{2}}\right)
\]</span></p>
<p>Una expresión más general para todo <span class="math inline">\(n\)</span> sería:</p>
<p><span class="math display">\[
\bar{X}_{n} \approx N(\mu, 2.4 / \sqrt{n})
\]</span></p>
<p>La densidad para todo <span class="math inline">\(n\)</span> es:</p>
<p><span class="math display">\[
f_{\bar{X}_{n}}(x)=\frac{\sqrt{n}}{2.4 \sqrt{2 \pi}} \exp \left(-\frac{n \times(x-\mu)^{2}}{2 \times 2.4^{2}}\right)
\]</span></p>
<p>Y una expresión para todo <span class="math inline">\(n\)</span> y cualquier varianza es:</p>
<p><span class="math display">\[
f_{\bar{X}_{n}}(x)=\frac{\sqrt{n}}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{n \times(x-\mu)^{2}}{2 \times \sigma^{2}}\right)
\]</span></p>
</div>
</div>
<div id="las-hipótesis-del-contraste-de-hipótesis" class="section level2 hasAnchor" number="9.2">
<h2><span class="header-section-number">9.2</span> Las hipótesis del contraste de hipótesis<a href="pruebas-de-hipótesis.html#las-hip%C3%B3tesis-del-contraste-de-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La teoría del contraste de hipótesis es una de las partes más discutidas de la estadística, por motivos que esperamos iran quedando claros a medida que se avanza en este tema y los siguientes.</p>
<p>De hecho esta teoría ya nació entre la polémica porque, prácticamente desee sus comienzos hubieron dos escuelas de pensamiento enfrentadas. La escuela de Ronald A. Fisher, genético y estadístic británico y la de los matemáticos Polacos y Americanos Neymann y Pearson.</p>
<p>Con el fin de evitar que la polémica confunda el aprendizaje, al menos en esta fae inicial, lo que se presenta a continuación se basa principalmente en las ideas de Neymann y Pearson que, con la finalidad de encontrar el mejor contraste posible para un problema dado, plantearon los contrastes de hipótesis estadísticos como una <em>decisión entre dos hipótesis</em>: la <strong>hipótesis nula</strong> y la <strong>hipótesis alternativa</strong>.</p>
<ul>
<li><p>La <em>hipótesis nula</em> consiste, en general, en una afirmación sobre (alguna característica de) la población de origen de la muestra. Usualmente representa algún tipo de simplificación (por ejemplo: el tratamiento administrado NO tiene efecto por lo que no hay diferencia entre antes y después de recibirlo. La hipótesis nula se designa con el símbolo <span class="math inline">\(\mathbf{H}_{\mathbf{0}}\)</span>.</p></li>
<li><p>La <em>hipótesis alternativa</em> es igualmente una afirmación sobre la población de origen, y, amenudo, aunque no siempre, consiste simplemente en negar la afirmación de <span class="math inline">\(\mathrm{H}_{0}\)</span>. La hipótesis alternativa se designa con el símbolo <span class="math inline">\(\mathbf{H}_{1}\)</span>.</p></li>
</ul>
<p>En el estudio del contraste de hipótesis se suele partir del caso, que de tan sencillo resulta poco realista, en el cual las dos hipótesis hacen referencia a un único valor del parámetro. En esta situación general, las hipótesis se refieren a un parámetro <span class="math inline">\(\theta\)</span> (theta). La formulación es:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathrm{H}_{0}: \theta=\theta_{0} \\
&amp; \mathrm{H}_{1}: \theta=\theta_{1}
\end{aligned}
\]</span> De hecho, sería mucho más realista plantear que la alternativa a un valor <span class="math inline">\(\theta_0\)</span> sea que el parámetro toma valores superiores (<span class="math inline">\(\mathrm{H}_{1}: \theta \geq \theta_{0}\)</span>), inferiores (<span class="math inline">\(\mathrm{H}_{1}: \theta \leq \theta_{0}\)</span>) o distintos (<span class="math inline">\(\mathrm{H}_{1}: \theta \neq \theta_{0}\)</span>)a <span class="math inline">\(\theta_0\)</span>. En la práctica este será el planteamiento de los tests que se presentará más adelante.</p>
<p>En la teoría del contraste de hipótesis este tipo de planteamiento se conoce como contraste de hipótesis <em>simple contra simple</em>. Así pues, una hipótesis simple postula que el parámetro <span class="math inline">\(\theta\)</span> solo puede tomar un valor, o, más técnicamente, que el conjunto de parámetros de una hipótesis simple consiste en un solo punto.</p>
<div id="caso-1-hipótesis-para-dirimir-la-controversia-sobre-el-número-de-hembras" class="section level3 hasAnchor" number="9.2.1">
<h3><span class="header-section-number">9.2.1</span> Caso 1: Hipótesis para dirimir la controversia sobre el número de hembras<a href="pruebas-de-hipótesis.html#caso-1-hip%C3%B3tesis-para-dirimir-la-controversia-sobre-el-n%C3%BAmero-de-hembras" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El Dr. da Souza Faria postula la misma proporción para machos y hembras. En términos de la proporción de la variable <span class="math inline">\(X\)</span> (n.º de hembras en 10 nidos) esto equivale a la hipótesis de que la proporción (en la población) es <span class="math inline">\(\mathbf{0 . 5}\)</span>.</p>
<p>En cambio, según el Dr. Calves la proporción es 6:4 a favor de las hembras, y por lo tanto equivale a la hipótesis de que el parámetro <span class="math inline">\(p\)</span> en la variable Binomial es 0.6.</p>
<p>Así pues, si <span class="math inline">\(X\)</span> es el número de hembras en 10 nidos, y <span class="math inline">\(p\)</span> es la proporción de hembras, la forma final del contraste es:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathrm{H}_{0}: \mathrm{p}=0.5 \\
&amp; \mathrm{H}_{1}: \mathrm{p}=0.6
\end{aligned}
\]</span></p>
<p>Respecto a los datos obtenidos por da Souza son:</p>
<table>
<thead>
<tr class="header">
<th align="left">Nido</th>
<th align="left">Polluelo</th>
<th align="left">Nido</th>
<th align="left">Polluelo</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="left">hembra</td>
<td align="left">6</td>
<td align="left">macho</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">macho</td>
<td align="left">7</td>
<td align="left">hembra</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">hembra</td>
<td align="left">8</td>
<td align="left">hembra</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">hembra</td>
<td align="left">9</td>
<td align="left">macho</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">macho</td>
<td align="left">10</td>
<td align="left">hembra</td>
</tr>
</tbody>
</table>
<p>En resumen, ha observado que en <span class="math inline">\(\mathbf{6}\)</span> de los nidos hay una hembra.</p>
</div>
<div id="caso-2-hipótesis-a-contrastar-en-el-problema-de-la-tasa-de-statdrolona" class="section level3 hasAnchor" number="9.2.2">
<h3><span class="header-section-number">9.2.2</span> Caso 2: Hipótesis a contrastar en el problema de la tasa de statdrolona<a href="pruebas-de-hipótesis.html#caso-2-hip%C3%B3tesis-a-contrastar-en-el-problema-de-la-tasa-de-statdrolona" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las autoridades deportivas postulan una media de <span class="math inline">\(7.0 \mathrm{ng} / \mathrm{ml}\)</span>, mientras que ADG indica una media de <span class="math inline">\(8.5 \mathrm{ng} / \mathrm{ml}\)</span> para los individuos sometidos a este tipo de dieta. Por tanto, en síntesis el contraste consistirá en:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathrm{H}_{0}: \mu=7,0 \\
&amp; \mathrm{H}_{1}: \mu=8,5
\end{aligned}
\]</span></p>
<p>tanto para <span class="math inline">\(\mathrm{H}_{0}\)</span> como para <span class="math inline">\(\mathrm{H}_{1}\)</span> el modelo contempla <span class="math inline">\(\sigma=2,4\)</span>.<br />
Los datos del estudio que ha obtenido la asociación ADG, y que según ellos respaldaban su tesis, han sido los siguientes:</p>
<table>
<thead>
<tr class="header">
<th align="center">Individuo</th>
<th align="center">Concentración</th>
<th align="center">Individuo</th>
<th align="center">Concentración</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1</td>
<td align="center">10.47</td>
<td align="center">9</td>
<td align="center">7.01</td>
</tr>
<tr class="even">
<td align="center">2</td>
<td align="center">5.39</td>
<td align="center">10</td>
<td align="center">11.36</td>
</tr>
<tr class="odd">
<td align="center">3</td>
<td align="center">6.70</td>
<td align="center">11</td>
<td align="center">10.11</td>
</tr>
<tr class="even">
<td align="center">4</td>
<td align="center">9.91</td>
<td align="center">12</td>
<td align="center">5.89</td>
</tr>
<tr class="odd">
<td align="center">5</td>
<td align="center">5.99</td>
<td align="center">13</td>
<td align="center">10.39</td>
</tr>
<tr class="even">
<td align="center">6</td>
<td align="center">11.67</td>
<td align="center">14</td>
<td align="center">10.67</td>
</tr>
<tr class="odd">
<td align="center">7</td>
<td align="center">6.23</td>
<td align="center">15</td>
<td align="center">6.89</td>
</tr>
<tr class="even">
<td align="center">8</td>
<td align="center">6.69</td>
<td align="center">16</td>
<td align="center">11.27</td>
</tr>
</tbody>
</table>
<p>La media aritmética de los 16 atletas es <span class="math inline">\(\mathbf{8 . 5 4} \mathrm{ng} / \mathrm{ml}\)</span>.</p>
</div>
</div>
<div id="compatibilidad-de-resultados-e-hipótesis" class="section level2 hasAnchor" number="9.3">
<h2><span class="header-section-number">9.3</span> Compatibilidad de resultados e hipótesis<a href="pruebas-de-hipótesis.html#compatibilidad-de-resultados-e-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Volviendo a la cuestión fundamental de la verificación de hipótesis, un resultado incompatible con una hipótesis es aquel que no puede haberse producido de ninguna manera si dicha hipótesis es cierta.</p>
<p>En este sentido, incompatible es sinónimo de imposible. En términos de probabilidad, un resultado incompatible es aquel que tiene probabilidad cero de producirse si la hipótesis es cierta. La lógica elemental indica que si se obtiene un resultado incompatible con una hipótesis, esta última es forzosamente falsa.</p>
<p>Ahora bien, cuando se toma un modelo aleatorio para explicar el fenómeno observado, el carácter probabilístico del modelo habitualmente evita que se descarte cualquier hipótesis por haber obtenido datos incompatibles con ella.</p>
<p>Al contrario, todos los resultados serán estrictamente compatibles con las dos hipótesis, o dicho de otro modo, cualquier conjunto de datos que se obtenga en el estudio se puede llegar a observar tanto bajo <span class="math inline">\(\mathrm{H}_{0}\)</span> como bajo <span class="math inline">\(\mathrm{H}_{1}\)</span>. Esto rompe el esquema excesivamente simple expuesto antes en la verificación ideal de hipótesis.</p>
<p>En definitiva, si se modela la realidad como un fenómeno aleatorio, se debe abandonar la idea de la toma de decisiones basada solo en una inspección de resultados que descarte sin error en la toma de decisión una de las dos hipótesis.</p>
<div id="caso-1-compatibilidad-de-resultados-e-hipótesis" class="section level3 hasAnchor" number="9.3.1">
<h3><span class="header-section-number">9.3.1</span> Caso 1: Compatibilidad de resultados e hipótesis<a href="pruebas-de-hipótesis.html#caso-1-compatibilidad-de-resultados-e-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El Dr. da Souza Faria ha obtenido una muestra de 6 hembras y 4 machos en los 10 nidos. Sin embargo, este es solo uno de los resultados posibles que se podían dar bajo la hipótesis nula. Si hubiera elegido como muestra otros nidos, podría haber encontrado otro número de hembras.</p>
<p>Como ya hemos visto, <span class="math inline">\(X\)</span> (n.º de hembras en 10 nidos) es una <span class="math inline">\(\operatorname{Binomial}(10,0.5)\)</span>. En la tabla siguiente se detallan los resultados que podían haber sucedido bajo <span class="math inline">\(\mathrm{H}_{0}\)</span>, junto con la probabilidad de obtenerlos según la fórmula de la densidad binomial:</p>
<table>
<thead>
<tr class="header">
<th align="right">X</th>
<th align="right">Prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0.0010</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0.0098</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">0.0439</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">0.1172</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">0.2051</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="right">0.2461</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="right">0.2051</td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="right">0.1172</td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="right">0.0439</td>
</tr>
<tr class="even">
<td align="right">9</td>
<td align="right">0.0098</td>
</tr>
<tr class="odd">
<td align="right">10</td>
<td align="right">0.0010</td>
</tr>
</tbody>
</table>
<!-- ![](https://cdn.mathpix.com/cropped/2024_12_15_dc401fd40c75e9888fdeg-08.jpg?height=521&width=849&top_left_y=1941&top_left_x=609) -->
<p>Al igual que para <span class="math inline">\(\mathrm{H}_{0}\)</span>, la muestra obtenida por el Dr. da Souza Faria con 6 hembras y 4 machos es solo uno de los resultados posibles que se podían dar bajo la hipótesis alternativa. En este caso <span class="math inline">\(X\)</span> (n.º de hembras en 10 nidos) es una <span class="math inline">\(\operatorname{Binomial}(10,0.6)\)</span>.</p>
<p>En la tabla siguiente se detallan los resultados que podrían haberse observado bajo <span class="math inline">\(\mathrm{H}_{1}\)</span>, junto con la probabilidad de obtenerlos según la fórmula de la densidad binomial:</p>
<table>
<thead>
<tr class="header">
<th align="right">X</th>
<th align="right">Prob</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0.0001049</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0.0015729</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">0.0106168</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">0.0424673</td>
</tr>
<tr class="odd">
<td align="right">4</td>
<td align="right">0.1114767</td>
</tr>
<tr class="even">
<td align="right">5</td>
<td align="right">0.2006581</td>
</tr>
<tr class="odd">
<td align="right">6</td>
<td align="right">0.2508227</td>
</tr>
<tr class="even">
<td align="right">7</td>
<td align="right">0.2149908</td>
</tr>
<tr class="odd">
<td align="right">8</td>
<td align="right">0.1209324</td>
</tr>
<tr class="even">
<td align="right">9</td>
<td align="right">0.0403108</td>
</tr>
<tr class="odd">
<td align="right">10</td>
<td align="right">0.0060466</td>
</tr>
</tbody>
</table>
<!-- ![](https://cdn.mathpix.com/cropped/2024_12_15_dc401fd40c75e9888fdeg-09.jpg?height=507&width=838&top_left_y=386&top_left_x=615) -->
<p>Un sencillo código R puede calcular las probabilidades tienen los once resultados bajo otras hipótesis que se podrían formular sobre el verdadero valor de la probabilidad <span class="math inline">\(p\)</span> de la población.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="pruebas-de-hipótesis.html#cb58-1" tabindex="-1"></a>prob_p <span class="ot">&lt;-</span> p <span class="co"># p algun valor entre 0 y 1</span></span>
<span id="cb58-2"><a href="pruebas-de-hipótesis.html#cb58-2" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x=</span><span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">size=</span><span class="dv">10</span>, <span class="at">prob=</span>prob_p)</span></code></pre></div>
<p>Podemos entender estas diferentes ” <span class="math inline">\(p\)</span> ” como hipótesis distintas que se podrían haber establecido como alternativa a <span class="math inline">\(\mathrm{H}_{0}\)</span>. Excepto en los casos triviales <span class="math inline">\(p=0\)</span> o <span class="math inline">\(p=1\)</span>, no hay ningún resultado que no pueda presentarse, aunque sea con probabilidades muy pequeñas.</p>
</div>
<div id="caso-2-compatibilidad-de-resultados-e-hipótesis" class="section level3 hasAnchor" number="9.3.2">
<h3><span class="header-section-number">9.3.2</span> Caso 2: Compatibilidad de resultados e hipótesis<a href="pruebas-de-hipótesis.html#caso-2-compatibilidad-de-resultados-e-hip%C3%B3tesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La asociación ADG ha obtenido una muestra con media <span class="math inline">\(8.54 \mathrm{ng} / \mathrm{ml}\)</span> de statdrolona para 16 deportistas. Ya hemos visto en el modelo de probabilidad qué densidad asociamos con la variable de cada deportista y con la media de todos ellos. Hay que recordar que una variable continua tiene probabilidad cero de obtener un resultado puntual y que las probabilidades en variables continuas se calculan sobre intervalos. Así pues, el valor 8.54 debe interpretarse como un intervalo <span class="math inline">\((8.54-\epsilon, 8.54+\epsilon)\)</span>, ya que las medidas de los deportistas individualmente corresponden en realidad a cierto intervalo de precisión experimental (por ejemplo, 0.3 <span class="math inline">\(\mathrm{ng} / \mathrm{ml}\)</span>). El valor 8.54 elegido como marca de un cierto intervalo no es en absoluto incompatible con la hipótesis nula. De hecho, es posible obtener cualquier media.</p>
<p>En la parte izquierda de la tabla que se presenta a continuación se detallan las probabilidades de diferentes resultados que podían haber sucedido bajo <span class="math inline">\(H_0\)</span> expresadas en términos de la función de distribución. La media de los 11 resultados corresponde a una Normal (8.5, 0.6).</p>
<p>En la parte derecha de la tabla se detallan las probabilidades para intervalos de anchura <span class="math inline">\(0.3 ml\)</span> más cercanos a la media bajo <span class="math inline">\(H_0\)</span>.</p>
<!-- ```{r echo=FALSE, out.width="90%", fig.align='center'} -->
<!-- knitr::include_graphics("images/cap9-comparaProbs.png") -->
<!-- ``` -->
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(X\)</span></th>
<th align="center"><span class="math inline">\(P(X\leq x)\)</span></th>
<th align="center"><span class="math inline">\(X-\epsilon\)</span></th>
<th align="center"><span class="math inline">\(X+\epsilon\)</span></th>
<th align="center"><span class="math inline">\(P(X)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">6.7</td>
<td align="center">0.3085</td>
<td align="center">-Inf</td>
<td align="center">6.7</td>
<td align="center">0.3085</td>
</tr>
<tr class="even">
<td align="center">7.0</td>
<td align="center">0.5000</td>
<td align="center">6.7</td>
<td align="center">7.0</td>
<td align="center">0.1915</td>
</tr>
<tr class="odd">
<td align="center">7.3</td>
<td align="center">0.6915</td>
<td align="center">7.0</td>
<td align="center">7.3</td>
<td align="center">0.1915</td>
</tr>
<tr class="even">
<td align="center">7.6</td>
<td align="center">0.8413</td>
<td align="center">7.3</td>
<td align="center">7.6</td>
<td align="center">0.1499</td>
</tr>
<tr class="odd">
<td align="center">7.9</td>
<td align="center">0.9332</td>
<td align="center">7.6</td>
<td align="center">7.9</td>
<td align="center">0.0918</td>
</tr>
<tr class="even">
<td align="center">8.2</td>
<td align="center">0.9772</td>
<td align="center">7.9</td>
<td align="center">8.2</td>
<td align="center">0.0441</td>
</tr>
<tr class="odd">
<td align="center">8.5</td>
<td align="center">0.9938</td>
<td align="center">8.2</td>
<td align="center">8.5</td>
<td align="center">0.0165</td>
</tr>
<tr class="even">
<td align="center">8.8</td>
<td align="center">0.9987</td>
<td align="center">8.5</td>
<td align="center">8.8</td>
<td align="center">0.0049</td>
</tr>
<tr class="odd">
<td align="center">9.1</td>
<td align="center">0.9998</td>
<td align="center">8.8</td>
<td align="center">9.1</td>
<td align="center">0.0011</td>
</tr>
<tr class="even">
<td align="center">9.4</td>
<td align="center">1.0000</td>
<td align="center">9.1</td>
<td align="center">9.4</td>
<td align="center">0.0002</td>
</tr>
<tr class="odd">
<td align="center">9.7</td>
<td align="center">1.0000</td>
<td align="center">9.4</td>
<td align="center">9.7</td>
<td align="center">0.0000</td>
</tr>
</tbody>
</table>
<p>En el caso de <span class="math inline">\(\mathrm{H}_{1}\)</span> tampoco es incompatible ninguna media, y por tanto en particular no lo es el valor 8.54. Ahora la densidad de la media de los 16 valores es una variable aleatoria Normal <span class="math inline">\(\mathrm{N}(8.5,0.6)\)</span>.</p>
<p>En la parte izquierda de la tabla se detallan las probabilidades de diferentes resultados que podrían haber sucedido bajo <span class="math inline">\(\mathrm{H}_{1}\)</span> expresadas en términos de la función de distribución. En la parte de la derecha se muestran las probabilidades para intervalos de anchura <span class="math inline">\(0.3 ml\)</span></p>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(X\)</span></th>
<th align="center"><span class="math inline">\(P(X\leq x)\)</span></th>
<th align="center"><span class="math inline">\(X-\epsilon\)</span></th>
<th align="center"><span class="math inline">\(X+\epsilon\)</span></th>
<th align="center"><span class="math inline">\(P(X)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">6.7</td>
<td align="center">0.0013</td>
<td align="center">-Inf</td>
<td align="center">6.7</td>
<td align="center">0.0013</td>
</tr>
<tr class="even">
<td align="center">7.0</td>
<td align="center">0.0062</td>
<td align="center">6.7</td>
<td align="center">7.0</td>
<td align="center">0.0049</td>
</tr>
<tr class="odd">
<td align="center">7.3</td>
<td align="center">0.0228</td>
<td align="center">7.0</td>
<td align="center">7.3</td>
<td align="center">0.0165</td>
</tr>
<tr class="even">
<td align="center">7.6</td>
<td align="center">0.0668</td>
<td align="center">7.3</td>
<td align="center">7.6</td>
<td align="center">0.0441</td>
</tr>
<tr class="odd">
<td align="center">7.9</td>
<td align="center">0.1587</td>
<td align="center">7.6</td>
<td align="center">7.9</td>
<td align="center">0.0918</td>
</tr>
<tr class="even">
<td align="center">8.2</td>
<td align="center">0.3085</td>
<td align="center">7.9</td>
<td align="center">8.2</td>
<td align="center">0.1499</td>
</tr>
<tr class="odd">
<td align="center">8.5</td>
<td align="center">0.5000</td>
<td align="center">8.2</td>
<td align="center">8.5</td>
<td align="center">0.1915</td>
</tr>
<tr class="even">
<td align="center">8.8</td>
<td align="center">0.6915</td>
<td align="center">8.5</td>
<td align="center">8.8</td>
<td align="center">0.1915</td>
</tr>
<tr class="odd">
<td align="center">9.1</td>
<td align="center">0.8413</td>
<td align="center">8.8</td>
<td align="center">9.1</td>
<td align="center">0.1499</td>
</tr>
<tr class="even">
<td align="center">9.4</td>
<td align="center">0.9332</td>
<td align="center">9.1</td>
<td align="center">9.4</td>
<td align="center">0.0918</td>
</tr>
<tr class="odd">
<td align="center">9.7</td>
<td align="center">0.9772</td>
<td align="center">9.4</td>
<td align="center">9.7</td>
<td align="center">0.0441</td>
</tr>
</tbody>
</table>
<!-- ```{r echo=FALSE, out.width="90%", fig.align='center'} -->
<!-- knitr::include_graphics("images/cap9-comparaProbs.png") -->
<!-- ``` -->
</div>
</div>
<div id="no-todo-es-igualmente-probable" class="section level2 hasAnchor" number="9.4">
<h2><span class="header-section-number">9.4</span> No todo es igualmente probable…<a href="pruebas-de-hipótesis.html#no-todo-es-igualmente-probable" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La segunda consideración fundamental en un contraste de hipótesis estadístico es que no todos los resultados son igualmente probables bajo <span class="math inline">\(\mathrm{H}_{0} \circ \mathrm{H}_{1}\)</span>. Este es el principal argumento para establecer un criterio de decisión -una regla- que permita decidir en la práctica si es aceptable <span class="math inline">\(\mathrm{H}_{0}\)</span> o bien <span class="math inline">\(\mathrm{H}_{1}\)</span>.</p>
<p>La idea provisional que debe guiar al lector en este momento, cuando inspecciona los casos prácticos, es que <em>los resultados (muy) improbables bajo cierta hipótesis sugieren que ésta seguramente no es válida</em>. Así pues, en el contraste estadístico de hipótesis no hay resultados imposibles, solo improbables, y por lo tanto en las decisiones se introduce forzosamente una probabilidad de error.</p>
<div id="caso-1-una-región-con-número-de-hembras-con-baja-probabilidad-bajo-mathrmh_0" class="section level3 hasAnchor" number="9.4.1">
<h3><span class="header-section-number">9.4.1</span> Caso 1: Una región con número de hembras con baja probabilidad bajo <span class="math inline">\(\mathrm{H}_{0}\)</span><a href="pruebas-de-hipótesis.html#caso-1-una-regi%C3%B3n-con-n%C3%BAmero-de-hembras-con-baja-probabilidad-bajo-mathrmh_0" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hemos visto antes las probabilidades de obtener cada uno de los resultados posibles para <span class="math inline">\(X\)</span>: <span class="math inline">\(0,1, \ldots\)</span>, hasta 10 hembras. El sentido común indica que si se obtienen valores de X cercanos a 0 o a 10, la hipótesis <span class="math inline">\(p=0.5\)</span> resulta poco verosímil.</p>
<p>Es importante entender que el verdadero valor de <span class="math inline">\(p\)</span> (el valor en la población) no es, ni será nunca, conocido en la práctica, solo formulamos hipótesis sobre este valor.</p>
<p>Veamos cuál es la probabilidad de obtener valores mayores que 8 hembras. Para abreviar, designamos la región de valores mayores o iguales a 8 con el símbolo <span class="math inline">\(\mathrm{W}_{\alpha}=\{8,9,10\}\)</span>.</p>
<!-- ```{r echo=FALSE, out.width="90%", fig.align='center'} -->
<!-- knitr::include_graphics("images/cap9-ProbsH0.png") -->
<!-- ``` -->
<table>
<thead>
<tr class="header">
<th align="center">Valor de <span class="math inline">\(X\)</span></th>
<th align="center">Prob. <span class="math inline">\(X&gt;=X\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">1.0000</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">0.9990</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">0.9893</td>
</tr>
<tr class="even">
<td align="center">3</td>
<td align="center">0.9453</td>
</tr>
<tr class="odd">
<td align="center">4</td>
<td align="center">0.8281</td>
</tr>
<tr class="even">
<td align="center">5</td>
<td align="center">0.6230</td>
</tr>
<tr class="odd">
<td align="center">6</td>
<td align="center">0.3770</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">0.1719</td>
</tr>
<tr class="odd">
<td align="center">8</td>
<td align="center">0.0547</td>
</tr>
<tr class="even">
<td align="center">9</td>
<td align="center">0.0107</td>
</tr>
<tr class="odd">
<td align="center">10</td>
<td align="center">0.0010</td>
</tr>
</tbody>
</table>
</div>
<div id="caso-2-medias-de-las-tasas-de-statdrolona-improbables-si-se-cumple-mathrmh_0" class="section level3 hasAnchor" number="9.4.2">
<h3><span class="header-section-number">9.4.2</span> Caso 2: Medias de las tasas de statdrolona improbables si se cumple <span class="math inline">\(\mathrm{H}_{0}\)</span><a href="pruebas-de-hipótesis.html#caso-2-medias-de-las-tasas-de-statdrolona-improbables-si-se-cumple-mathrmh_0" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>De la misma manera que se ha razonado para el caso 1, en esta ocasión con las dos hipótesis ( <span class="math inline">\(\mu=7\)</span> contra <span class="math inline">\(\mu=8.5\)</span> ) que tenemos en el caso de la detección de la statdrolona, el sentido común indica que si obtenemos una media de statdrolona en los 16 atletas alejada del valor de referencia 7, hará inverosímil la hipótesis nula.</p>
<p>En la tabla siguiente se muestran las probabilidades de obtener valores mayores que 7 <span class="math inline">\(\mathrm{ng} / \mathrm{ml}\)</span>. Observemos particularmente la región de valores mayores que 7.9869, que se representará con el símbolo <span class="math inline">\(\mathrm{W}_{\alpha}\)</span>. Expresada como intervalo, <span class="math inline">\(\mathrm{W}_{\alpha}=[7.9869, \infty)\)</span>.</p>
<!-- ```{r echo=FALSE, out.width="90%", fig.align='center'} -->
<!-- knitr::include_graphics("images/cap9-ProbsH1.png") -->
<!-- ``` -->
<table>
<thead>
<tr class="header">
<th align="center">Miljana <span class="math inline">\((x)\)</span></th>
<th align="center">Prob. <span class="math inline">\(X=x\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">6,506</td>
<td align="center">0.7946</td>
</tr>
<tr class="even">
<td align="center">6,671</td>
<td align="center">0.7083</td>
</tr>
<tr class="odd">
<td align="center">6,835</td>
<td align="center">0.6080</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">0.5000</td>
</tr>
<tr class="odd">
<td align="center">7,165</td>
<td align="center">0.3920</td>
</tr>
<tr class="even">
<td align="center">7,329</td>
<td align="center">0.2917</td>
</tr>
<tr class="odd">
<td align="center">7,494</td>
<td align="center">0.2054</td>
</tr>
<tr class="even">
<td align="center">7,658</td>
<td align="center">0.1364</td>
</tr>
<tr class="odd">
<td align="center">7,823</td>
<td align="center">0.0852</td>
</tr>
<tr class="even">
<td align="center">7,987</td>
<td align="center">0.0500</td>
</tr>
<tr class="odd">
<td align="center">8,152</td>
<td align="center">0.0275</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="el-papel-privilegiado-de-la-hipótesis-nula-criterio-de-decisión" class="section level2 hasAnchor" number="9.5">
<h2><span class="header-section-number">9.5</span> El papel privilegiado de la hipótesis nula: criterio de decisión<a href="pruebas-de-hipótesis.html#el-papel-privilegiado-de-la-hip%C3%B3tesis-nula-criterio-de-decisi%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un contraste estadístico de hipótesis consta forzosamente de un criterio de decisión. En resumen, consiste en una regla operativa que divide en dos partes disjuntas el espacio muestral. Estas partes se llaman región crítica y región de aceptación respectivamente. En cualquier test estadístico, si la muestra obtenida pertenece a la región crítica, se debe aceptar <span class="math inline">\(\mathrm{H}_{1}\)</span>. En caso contrario, si pertenece a la región de aceptación, se aceptará <span class="math inline">\(\mathrm{H}_{0}\)</span>.</p>
<p>Un primer principio básico consiste en priorizar en el criterio de decisión a <span class="math inline">\(\mathrm{H}_{0}\)</span>, en el siguiente sentido: se construye el criterio fijando a priori la probabilidad de error asociada con el hecho de rechazar -erróneamente- <span class="math inline">\(\mathrm{H}_{0}\)</span>. A fin de que el criterio de decisión sea razonable debe resultar improbable obtener una muestra que pertenezca a la región crítica cuando sea cierta <span class="math inline">\(\mathrm{H}_{0}\)</span>. En el ejemplo siguiente se propondrá una regla de decisión provisional.</p>
<div id="caso-1-n.º-de-nidos-propuestos-ad-hoc-como-inicio-de-región-crítica.-regla-de-decisión-resultante" class="section level3 hasAnchor" number="9.5.1">
<h3><span class="header-section-number">9.5.1</span> Caso 1: N.º de nidos propuestos ad hoc como inicio de región crítica. Regla de decisión resultante<a href="pruebas-de-hipótesis.html#caso-1-n.%C2%BA-de-nidos-propuestos-ad-hoc-como-inicio-de-regi%C3%B3n-cr%C3%ADtica.-regla-de-decisi%C3%B3n-resultante" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Definiremos la región crítica de la siguiente forma:</p>
<p><span class="math display">\[
\mathrm{W}_{\alpha}=\{8,9,10\}
\]</span></p>
<p>Por lo tanto, la región de aceptación será:</p>
<p><span class="math display">\[
\mathrm{W}_{\alpha}^{\mathrm{C}}=\{0,1,2,3,4,5,6,7\}
\]</span></p>
<p>El criterio de decisión será por tanto:</p>
<ul>
<li>si el número de hembras es mayor o igual que 8, se acepta <span class="math inline">\(\mathrm{H}_{1}\)</span> (la probabilidad de hembras es 0.6)<br />
</li>
<li>si el número de hembras es menor o igual que 7, se acepta <span class="math inline">\(\mathrm{H}_{0}\)</span> (la probabilidad de hembras es 0.5)</li>
</ul>
<p>Es importante entender en este momento que se propone ad hoc la región crítica. Más adelante se justificará por qué esta propuesta es razonable.</p>
<p>Nota: en la muestra obtenida se han observado 6 hembras, por tanto da Souza debe aceptar <span class="math inline">\(\mathrm{H}_{0}\)</span>.</p>
</div>
</div>
<div id="hipótesis-nula-y-nivel-de-significación" class="section level2 hasAnchor" number="9.6">
<h2><span class="header-section-number">9.6</span> Hipótesis nula y nivel de significación<a href="pruebas-de-hipótesis.html#hip%C3%B3tesis-nula-y-nivel-de-significaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Se ha indicado anteriormente que, en los contrastes estadísticos, la hipótesis nula juega un papel privilegiado, ya que la regla de decisión se ajusta de acuerdo con la probabilidad de equivocarse al rechazar <span class="math inline">\(H_{0}\)</span> cuando ésta es cierta.</p>
<p>Esta probabilidad se designa de forma equivalente como:</p>
<ul>
<li>error de tipo I (o de primera especie)<br />
</li>
<li>nivel de significación del contraste</li>
</ul>
<p>y usualmente se simboliza con la letra griega alfa.<br />
El nivel de significación se puede definir equivalentemente de las dos maneras siguientes:<br />
- <span class="math inline">\(\alpha=\)</span> probabilidad de rechazo de <span class="math inline">\(\mathbf{H}_{\mathbf{0}}\)</span>, cuando <span class="math inline">\(\mathrm{H}_{0}\)</span> es cierta<br />
- <span class="math inline">\(\alpha=\)</span> probabilidad de que la muestra pertenezca a la región crítica, cuando <span class="math inline">\(\mathbf{H}_{0}\)</span> es cierta.</p>
<div id="caso-1-nivel-de-significación" class="section level3 hasAnchor" number="9.6.1">
<h3><span class="header-section-number">9.6.1</span> Caso 1: Nivel de significación<a href="pruebas-de-hipótesis.html#caso-1-nivel-de-significaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el apartado 9.5.1 se ha indicado la tabla resultante de los cálculos de la cola derecha de la Binomial, cuando se verifica la hipótesis nula <span class="math inline">\((p=0.5)\)</span>. Como la definición de nivel de significación es:</p>
<p><span class="math display">\[
\alpha=\text { prob. muestra pertenezca a la región crítica, cuando } \mathbf{H}_{0} \text { es cierta }
\]</span></p>
<p>en la fila correspondiente a prob <span class="math inline">\((\mathrm{X} \geq 8)\)</span> de la tabla anterior se puede observar la probabilidad de rechazar <span class="math inline">\(\mathrm{H}_{0}\)</span> cuando ésta es cierta (véase el criterio de decisión adoptado en el apartado 9.6.1).</p>
<p>Simbólicamente hemos calculado:</p>
<p><span class="math display">\[
\alpha=p\left(X \geq 8 / H_{0}\right)=\sum_{i=8}^{10} p\left(X=i / H_{0}\right)=\sum_{i=8}^{10}\binom{10}{i} 0.5^{10}
\]</span></p>
<p>Resulta pues: <span class="math inline">\(\quad \alpha=0.0547\)</span>.</p>
</div>
<div id="caso-1-elección-de-la-región-crítica" class="section level3 hasAnchor" number="9.6.2">
<h3><span class="header-section-number">9.6.2</span> Caso 1: Elección de la región crítica<a href="pruebas-de-hipótesis.html#caso-1-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se ha propuesto antes, de forma directa, la región crítica:</p>
<p><span class="math display">\[
\mathrm{W}_{\alpha}=\{8,9,10\}
\]</span></p>
<p>Podemos considerar ahora otra región que nos proporcionaría un nivel de significación idéntico (ver tabla de probabilidades bajo <span class="math inline">\(\mathrm{H}_{0}\)</span>):</p>
<p><span class="math display">\[
\begin{gathered}
\mathrm{W}_{\alpha}^{\prime}=\{0,1,2\} \\
\alpha=0.0010+0.0098+0.0439=0.0547
\end{gathered}
\]</span></p>
<p>Ahora bien, un criterio de decisión basado en <span class="math inline">\(\mathrm{W}^{\prime}{ }_{\alpha}=\{0,1,2\}\)</span> es absurdo, teniendo en cuenta que <span class="math inline">\(\mathrm{H}_{1}\)</span> es <span class="math inline">\(p=0.6\)</span>. Veamos por qué.</p>
<p>El valor <span class="math inline">\(\alpha=0.0547\)</span> indica que es improbable obtener menos de 3 hembras bajo <span class="math inline">\(\mathrm{H}_{0}\)</span>. Si se elige <span class="math inline">\(\mathrm{W}^{\prime}{ }_{\alpha}\)</span> como región crítica, implica aceptar <span class="math inline">\(\mathrm{H}_{1}\)</span> cuando el número de hembras es menor que 3. Sin embargo, cuando se consulta la tabla de probabilidades bajo <span class="math inline">\(\mathrm{H}_{1}\)</span>, resulta:<br />
prob. (número hembras <span class="math inline">\(&lt;3 / \mathrm{H}_{1}\)</span> cierta) <span class="math inline">\(=0.0001+0.0016+0.0106=0.0123\)</span><br />
Es, por tanto, todavía más improbable obtener 3 hembras bajo <span class="math inline">\(\mathrm{H}_{1}\)</span>. En otras palabras, <span class="math inline">\(\mathrm{W}^{\prime}{ }_{\alpha}\)</span> induce un criterio absurdo, ya que llevaría a aceptar la hipótesis menos verosímil de las dos.</p>
</div>
<div id="caso-2-elección-de-la-región-crítica" class="section level3 hasAnchor" number="9.6.3">
<h3><span class="header-section-number">9.6.3</span> Caso 2: Elección de la región crítica<a href="pruebas-de-hipótesis.html#caso-2-elecci%C3%B3n-de-la-regi%C3%B3n-cr%C3%ADtica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A continuación se definen las regiones crítica y de aceptación, respectivamente, como:</p>
<p><span class="math display">\[
\mathrm{W}_{\alpha}=[7.9869,+\infty) \quad \mathrm{W}_{\alpha}^{\mathrm{C}}=(-\infty, 7.9869)
\]</span></p>
<p>El criterio de decisión será, por tanto:<br />
si el nivel de statdrolona es mayor o igual que 7.9869, se acepta <span class="math inline">\(\mathbf{H}_{\mathbf{1}}\)</span> (el nivel es 8.5)<br />
Al igual que en el caso 1, también se ha propuesto la región crítica de forma ad hoc. Si se consultan en la tabla del apartado 9.5.2 los valores de la cola derecha de la Normal, como la definición de nivel de significación es:</p>
<p><span class="math display">\[
\alpha=\text { prob. muestra pertenezca a la región crítica, cuando } \mathbf{H}_{0} \text { es cierta }
\]</span></p>
<p>en la fila correspondiente a prob <span class="math inline">\((\mathrm{X}&gt;=7.987)\)</span> de la tabla se puede observar la probabilidad de rechazar <span class="math inline">\(\mathrm{H}_{0}(\mu=7.0)\)</span> cuando ésta es cierta. Simbólicamente hemos calculado:</p>
<p><span class="math display">\[
\alpha=p\left(\bar{X}_{16} \geq 7.9869 / H_{0}\right)=\int_{7.9869}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left\{-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right\} d x=\\ = 1-F_{Z}\left(\frac{7.9869-7}{2.4 / \sqrt{16}}\right)
\]</span></p>
<p>donde <span class="math inline">\(F_{z}\)</span> es la función de distribución de la Normal tipificada <span class="math inline">\(N(0,1)\)</span>.<br />
La región crítica <span class="math inline">\(\mathrm{W}_{\alpha}=[7.9869,+\infty)\)</span> lleva asociado un nivel de significación <span class="math inline">\(\alpha=0.05\)</span>. Ahora bien, como el estadístico media muestral es una variable continua, concretamente Normal, se pueden encontrar infinitas regiones que satisfagan la condición:</p>
<p><span class="math display">\[
\operatorname{prob}\left(\operatorname{muestra} \text { en } \mathrm{W}_{\alpha} / \mathrm{H}_{0}\right)=0.05
\]</span></p>
</div>
</div>
<div id="región-crítica-y-formalización-del-contraste" class="section level2 hasAnchor" number="9.7">
<h2><span class="header-section-number">9.7</span> Región crítica y formalización del contraste<a href="pruebas-de-hipótesis.html#regi%C3%B3n-cr%C3%ADtica-y-formalizaci%C3%B3n-del-contraste" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La regla de decisión queda definida siempre (aunque sea implícitamente) a partir de una región crítica. A esta región crítica le corresponde un determinado nivel de significación.<br />
La información contenida en la muestra se resume mediante un estadístico de test, así que una práctica habitual es definir la región crítica en función del estadístico de test empleado. Un estadístico de test es una variable aleatoria y, como tal, tiene asociada una ley de distribución que juega un papel capital en el contraste.</p>
<p>Reuniendo los conceptos, en un contraste de hipótesis <span class="math inline">\(\mathrm{H}_{0}\)</span> contra <span class="math inline">\(\mathrm{H}_{1}\)</span>, tenemos:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha &amp; =\text { nivel de significación, } \\
\mathrm{W}_{\alpha} &amp; =\text { región crítica, subconjunto del espacio muestral definido a partir de } \mathrm{T}
\end{aligned}
\]</span></p>
<p>Regla de decisión:</p>
<ul>
<li>si la muestra pertenece a <span class="math inline">\(\mathrm{W}_{\alpha}\)</span> entonces rechazar <span class="math inline">\(\mathrm{H}_{0}\)</span><br />
</li>
<li>si la muestra no pertenece a <span class="math inline">\(\mathrm{W}_{\alpha}\)</span> entonces rechazar <span class="math inline">\(\mathrm{H}_{1}\)</span></li>
</ul>
<p>Finalmente:</p>
<p><span class="math display">\[
\alpha=\text { prob.(rechazar } H_{0} / H_{0} \text { cierta) = prob.(muestra pertenezca a } W_{\alpha} / H_{0} \text { cierta) }
\]</span></p>
<div id="caso-1-resumen-de-conceptos-asociados-al-contraste.-región-crítica" class="section level3 hasAnchor" number="9.7.1">
<h3><span class="header-section-number">9.7.1</span> Caso 1: Resumen de conceptos asociados al contraste. Región crítica<a href="pruebas-de-hipótesis.html#caso-1-resumen-de-conceptos-asociados-al-contraste.-regi%C3%B3n-cr%C3%ADtica" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Región crítica</th>
<th align="center"><span class="math inline">\(\mathrm{W}_{\alpha}=\{8,9,10\}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Región de aceptación</td>
<td align="center"><span class="math inline">\(\mathrm{W}_{\alpha}^{\mathrm{C}}=\{0,1,2,3,4,5,6,7\}\)</span></td>
</tr>
<tr class="even">
<td align="left">Estadístico de test</td>
<td align="center"><span class="math inline">\(\mathrm{T}=\)</span> número de hembras totales en los 10 nidos</td>
</tr>
<tr class="odd">
<td align="left">Criterio de decisión:</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">aceptar <span class="math inline">\(\mathrm{H}_{1}\)</span> si</td>
<td align="center"><span class="math inline">\(\mathrm{T} \geq 8\)</span></td>
</tr>
<tr class="odd">
<td align="left">aceptar <span class="math inline">\(\mathrm{H}_{0}\)</span> si</td>
<td align="center"><span class="math inline">\(\mathrm{T} \leq 7\)</span></td>
</tr>
<tr class="even">
<td align="left">Nivel de significación</td>
<td align="center"><span class="math inline">\(\alpha=0.0547\)</span></td>
</tr>
</tbody>
</table>
<p>La distribución del estadístico de test T es una Binomial B (10, p). Se puede adoptar un estadístico alternativo: la frecuencia relativa <span class="math inline">\(=\mathbf{f r}\)</span> del número de hembras en los 10 nidos.</p>
</div>
<div id="caso-2-tabla-resumen-de-la-región-crítica-el-estadístico-de-test-y-del-criterio-de-decisión" class="section level3 hasAnchor" number="9.7.2">
<h3><span class="header-section-number">9.7.2</span> Caso 2: Tabla resumen de la región crítica, el estadístico de test y del criterio de decisión<a href="pruebas-de-hipótesis.html#caso-2-tabla-resumen-de-la-regi%C3%B3n-cr%C3%ADtica-el-estad%C3%ADstico-de-test-y-del-criterio-de-decisi%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Región crítica</th>
<th align="center"><span class="math inline">\(\mathrm{W}_{\alpha}=[7.9869,+\infty)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Región de aceptación</td>
<td align="center"><span class="math inline">\(\mathrm{W}_{\alpha}^{\mathrm{C}}=(-\infty, 7.9869)\)</span></td>
</tr>
<tr class="even">
<td align="left">Estadístico de test</td>
<td align="center"><span class="math inline">\(\mathrm{T}=\)</span> media de statdrolona en 16 atletas</td>
</tr>
<tr class="odd">
<td align="left">Criterio de decisión:</td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">aceptar <span class="math inline">\(\mathrm{H}_{1}\)</span> si</td>
<td align="center"><span class="math inline">\(\mathrm{T} \geq 7.9869\)</span></td>
</tr>
<tr class="odd">
<td align="left">aceptar <span class="math inline">\(\mathrm{H}_{0}\)</span> si</td>
<td align="center"><span class="math inline">\(\mathrm{T}&lt;7.9869\)</span></td>
</tr>
<tr class="even">
<td align="left">Nivel de significación</td>
<td align="center"><span class="math inline">\(\alpha=0.05\)</span></td>
</tr>
</tbody>
</table>
<p>La distribución del estadístico de test T bajo <span class="math inline">\(\mathrm{H}_{0}\)</span> es una normal <span class="math inline">\(\mathrm{N}(7,0.6)\)</span>.</p>
</div>
<div id="región-crítica-frente-a-estadístico-de-test" class="section level3 hasAnchor" number="9.7.3">
<h3><span class="header-section-number">9.7.3</span> Región crítica frente a Estadístico de Test<a href="pruebas-de-hipótesis.html#regi%C3%B3n-cr%C3%ADtica-frente-a-estad%C3%ADstico-de-test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En los párrafos anteriores se han introducido y utilizado los conceptos de estadístico de test y región crítica dandose a entender que la región crítica esta definida por <em>aquellos valores del estadístico de test que llevan a rechazar la hipótesis nula</em>.</p>
<p>Aunque esta aproximación es habitual, también lo es el presentarlos ambos como dos formas equivalentes de definir una región de rechazo. Es decir, la decisión de rechazar <span class="math inline">\(H_0\)</span> puede llevarse a cabo:</p>
<ol style="list-style-type: decimal">
<li><p>Mediante una <strong>región crítica</strong> <span class="math inline">\(\mathcal{R}\)</span>, entendida como un subconjunto del espacio muestral, de modo que se rechaza <span class="math inline">\(H_0\)</span> cuando la muestra observada pertenece a <span class="math inline">\(\mathcal{R}\)</span>.</p></li>
<li><p>Mediante un <strong>estadístico de contraste</strong> <span class="math inline">\(T=T(X)\)</span> y una condición sobre los valores que puede tomar dicho estadístico. En este caso, se rechaza <span class="math inline">\(H_0\)</span> cuando <span class="math inline">\(T(X)\in C\)</span>, donde <span class="math inline">\(C\)</span> es un subconjunto del espacio de valores de <span class="math inline">\(T\)</span>.</p></li>
</ol>
<p>En esta segunda formulación, la región crítica en el espacio muestral viene dada implícitamente por</p>
<p><span class="math display">\[
\mathcal{R}=\{x:T(x)\in C\}.
\]</span></p>
<p>Aunque la primera formulación es conceptualmente más general, en la práctica se trabaja casi siempre con el estadístico de contraste por ser más operativo. En este capítulo utilizaremos ambas formulaciones, dando preferencia a la segunda.</p>
</div>
</div>
<div id="tabla-de-decisión-del-contraste" class="section level2 hasAnchor" number="9.8">
<h2><span class="header-section-number">9.8</span> Tabla de decisión del contraste<a href="pruebas-de-hipótesis.html#tabla-de-decisi%C3%B3n-del-contraste" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cuando se resuelve un contraste la decisión final puede ser correcta o bien conducir a un error. En esta tabla se presentan las cuatro posibles situaciones que se pueden producir:</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center">Hipótesis verdadera</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Hipótesis aceptada</td>
<td align="center"><span class="math inline">\(\mathrm{H}_{0}\)</span></td>
<td align="center"><span class="math inline">\(\mathrm{H}_{1}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\mathrm{H}_{0}\)</span></td>
<td align="center">-</td>
<td align="center">error tipo II</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\mathrm{H}_{1}\)</span></td>
<td align="center">error tipo I</td>
<td align="center">-</td>
</tr>
</tbody>
</table>
<p>Existe, por tanto, un segundo tipo de error, designado como error de tipo II o de segunda especie. Se puede definir de manera equivalente para cualquiera de las dos expresiones siguientes:</p>
<ul>
<li><span class="math inline">\(1-\beta=\)</span> probabilidad de rechazar <span class="math inline">\(\mathrm{H}_{1}\)</span>, cuando <span class="math inline">\(\mathrm{H}_{1}\)</span> es cierta<br />
</li>
<li><span class="math inline">\(1-\beta=\)</span> probabilidad de que la muestra no pertenezca a la región crítica, cuando <span class="math inline">\(\mathbf{H}_{1}\)</span> es cierta</li>
</ul>
<p>En realidad, solo una de las hipótesis es verdadera. Una vez se obtenga la muestra, se aceptará o se rechazará <span class="math inline">\(\mathrm{H}_{1}\)</span> según el criterio de decisión. Si se decide de manera equivocada, se producirá solo uno de los dos errores, según cuál sea la hipótesis verdadera. Es decir, a posteriori se produce, como mucho, solo uno de los errores.</p>
<p>Ahora bien, el contraste se lleva a cabo precisamente porque se ignora cuál de las dos hipótesis es la verdadera. Como consecuencia, sin que ello contradiga el párrafo anterior, los dos errores tienen importancia a priori.</p>
<p>Un contraste será más adecuado si son menores los dos errores asociados.</p>
<div id="caso-1-evaluación-de-los-dos-errores-asociados-al-contraste" class="section level3 hasAnchor" number="9.8.1">
<h3><span class="header-section-number">9.8.1</span> Caso 1: Evaluación de los dos errores asociados al contraste<a href="pruebas-de-hipótesis.html#caso-1-evaluaci%C3%B3n-de-los-dos-errores-asociados-al-contraste" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El criterio de decisión que se ha adoptado para este caso consiste en:</p>
<table>
<thead>
<tr class="header">
<th align="center">aceptar <span class="math inline">\(\mathrm{H}_{1}\)</span> si</th>
<th align="center"><span class="math inline">\(\mathrm{T} \geq 8\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">aceptar <span class="math inline">\(\mathrm{H}_{0}\)</span> si</td>
<td align="center"><span class="math inline">\(\mathrm{T} \leq 7\)</span></td>
</tr>
<tr class="even">
<td align="center">Nivel de significación</td>
<td align="center"><span class="math inline">\(\alpha=0.0547\)</span></td>
</tr>
</tbody>
</table>
<p>Supongamos que <span class="math inline">\(\mathrm{H}_{1}\)</span> es cierta, es decir, que <span class="math inline">\(p=0,6\)</span>. En la tabla siguiente podemos encontrar el valor del error de tipo II:</p>
<!-- ```{r echo=FALSE, out.width="90%", fig.align='center'} -->
<!-- knitr::include_graphics("images/cap9-ProbsErrTipo2.png") -->
<!-- ``` -->
<table>
<thead>
<tr class="header">
<th align="center">Valor de <span class="math inline">\(X\)</span></th>
<th align="center">Prob. <span class="math inline">\(X&lt;=\mathrm{X}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">0</td>
<td align="center">0.0001</td>
</tr>
<tr class="even">
<td align="center">1</td>
<td align="center">0.0017</td>
</tr>
<tr class="odd">
<td align="center">2</td>
<td align="center">0.0123</td>
</tr>
<tr class="even">
<td align="center">3</td>
<td align="center">0.0548</td>
</tr>
<tr class="odd">
<td align="center">4</td>
<td align="center">0.1662</td>
</tr>
<tr class="even">
<td align="center">5</td>
<td align="center">0.3669</td>
</tr>
<tr class="odd">
<td align="center">6</td>
<td align="center">0.6177</td>
</tr>
<tr class="even">
<td align="center">7</td>
<td align="center">0.8327</td>
</tr>
<tr class="odd">
<td align="center">8</td>
<td align="center">0.9536</td>
</tr>
<tr class="even">
<td align="center">9</td>
<td align="center">0.9940</td>
</tr>
<tr class="odd">
<td align="center">10</td>
<td align="center">1.0000</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(1-\beta=\)</span> prob. (rechazar <span class="math inline">\(H_{1}/H_{1}\)</span> cierta)= prob. <span class="math inline">\((T \leq 7/H_{1}\)</span> cierta) <span class="math inline">\(=\mathbf{0 . 8 3 2 7}\)</span><br />
Simbólicamente corresponde a calcular:</p>
<p><span class="math display">\[
1-\beta=p\left(X&lt;8 / H_{1}\right)=\sum_{i=0}^{7} p\left(X=i / H_{1}\right)=\sum_{i=0}^{7}\binom{10}{i} 0.6^{i} 0.4^{10-i}
\]</span></p>
</div>
<div id="caso-2-cálculo-explícito-de-los-errores-de-primera-alpha-y-segunda-especie-1--beta" class="section level3 hasAnchor" number="9.8.2">
<h3><span class="header-section-number">9.8.2</span> Caso 2: Cálculo explícito de los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )<a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-expl%C3%ADcito-de-los-errores-de-primera-alpha-y-segunda-especie-1--beta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El criterio de decisión que se ha elegido para este caso consiste en:</p>
<table>
<thead>
<tr class="header">
<th align="center">aceptar <span class="math inline">\(\mathrm{H}_{1}\)</span> si</th>
<th align="center"><span class="math inline">\(\mathrm{T} \geq 7.9869\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Nivel de significación</td>
<td align="center"><span class="math inline">\(\alpha=0.05\)</span></td>
</tr>
</tbody>
</table>
<p>Supongamos que es cierta <span class="math inline">\(\mathrm{H}_{1}\)</span>, es decir, que <span class="math inline">\(\mu=8.5\)</span>. En la tabla siguiente podemos encontrar el valor del error de tipo II:</p>
<!--  ```{r echo=FALSE, out.width="90%", fig.align='center'} -->
<!--   -->
<!--  knitr::include_graphics("images/cap9-ProbsErrTipo2c.png") -->
<!--   -->
<!--  ``` -->
<table>
<thead>
<tr class="header">
<th align="center">Mitiana <span class="math inline">\((x)\)</span></th>
<th align="center">Prob. <span class="math inline">\(X==x\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">5,933</td>
<td align="center">1.0000</td>
</tr>
<tr class="even">
<td align="center">6,189</td>
<td align="center">0.9999</td>
</tr>
<tr class="odd">
<td align="center">6,446</td>
<td align="center">0.9997</td>
</tr>
<tr class="even">
<td align="center">6,703</td>
<td align="center">0.9986</td>
</tr>
<tr class="odd">
<td align="center">6,96</td>
<td align="center">0.9949</td>
</tr>
<tr class="even">
<td align="center">7,216</td>
<td align="center">0.9838</td>
</tr>
<tr class="odd">
<td align="center">7,473</td>
<td align="center">0.9565</td>
</tr>
<tr class="even">
<td align="center">7,73</td>
<td align="center">0.9004</td>
</tr>
<tr class="odd">
<td align="center">7,987</td>
<td align="center">0.8040</td>
</tr>
<tr class="even">
<td align="center">8,243</td>
<td align="center">0.6656</td>
</tr>
<tr class="odd">
<td align="center">8,5</td>
<td align="center">0.5000</td>
</tr>
</tbody>
</table>
<p><span class="math inline">\(1-\beta=\)</span> prob. (rechazar <span class="math inline">\(\mathrm{H}_{1}/\mathrm{H}_{1}\)</span> cierta)= prob. <span class="math inline">\((\mathrm{T}&lt;7.9869/\mathrm{H}_{1})=1-0.8040=0.1960\)</span><br />
Simbólicamente, corresponde a calcular:</p>
<p><span class="math display">\[
\begin{aligned}
1-\beta &amp; =p\left(\bar{X}_{16}&lt;7.9869 / H_{1}\right)=\int_{-\infty}^{7.9869} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-8.5)^{2}}{2 \times 0.6^{2}}\right) d x =\\
&amp; =F_{Z}\left(\frac{7.9869-8.5}{2.4 / \sqrt{16}}\right)
\end{aligned}
\]</span></p>
</div>
</div>
<div id="relación-entre-el-error-de-tipo-i-y-el-de-tipo-ii" class="section level2 hasAnchor" number="9.9">
<h2><span class="header-section-number">9.9</span> Relación entre el error de tipo I y el de tipo II<a href="pruebas-de-hipótesis.html#relaci%C3%B3n-entre-el-error-de-tipo-i-y-el-de-tipo-ii" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Es importante entender que no es posible reducir simultáneamente los dos errores en un contraste de hipótesis.</p>
<p>Supongamos que se intenta reducir a cero el nivel de significación. Esto equivale a plantear que la probabilidad de que una muestra pertenezca a la región crítica, en el caso de que sea cierta <span class="math inline">\(\mathrm{H}_{0}\)</span>, es cero. En la mayoría de situaciones aplicadas este hecho da lugar a una región crítica igual al conjunto vacío, o lo que es lo mismo, provoca que se acepte siempre <span class="math inline">\(\mathrm{H}_{0}\)</span>, independientemente del resultado obtenido en la muestra. Se llega por tanto a la situación absurda de poder prescindir de la muestra, aceptando siempre <span class="math inline">\(H_{0}\)</span>! Así, reducir <span class="math inline">\(\alpha\)</span> a cero tiene la grave contrapartida de rechazar siempre <span class="math inline">\(\mathrm{H}_{1}\)</span>, lo que implica a su vez que el error de tipo II sea uno. De manera análoga se puede razonar para un error de tipo II nulo. En conclusión, los dos errores están relacionados: disminuir <span class="math inline">\(\alpha\)</span> conlleva reducir el tamaño de la región crítica y, por lo tanto, aumentar 1- <span class="math inline">\(\beta\)</span>.</p>
<div id="caso-1-evaluación-de-alpha-y-1--beta-para-diferentes-regiones-críticas" class="section level3 hasAnchor" number="9.9.1">
<h3><span class="header-section-number">9.9.1</span> Caso 1: Evaluación de <span class="math inline">\(\alpha\)</span> y 1- <span class="math inline">\(\beta\)</span> para diferentes regiones críticas<a href="pruebas-de-hipótesis.html#caso-1-evaluaci%C3%B3n-de-alpha-y-1--beta-para-diferentes-regiones-cr%C3%ADticas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez se especifica la región crítica, los errores de tipo I y II quedan determinados. En los dos cuadros siguientes hay dos regiones críticas y sus errores asociados. En la versión interactiva ( <em>no disponible</em>) de Statmedia se podía cambiar dinámicamente la región crítica y se calculaban automáticamente los errores:</p>
<p><img src="images/cap9-ProbsErrTipo2b.png" width="90%" style="display: block; margin: auto;" /></p>
<p>En el gráfico siguiente se representan los dos errores simultáneamente para diferentes regiones críticas. Para simplificar la comprensión del gráfico, se consideran solo regiones de la forma <span class="math inline">\(\{a, a+1, \ldots 10\}\)</span>, donde <span class="math inline">\(a\)</span> es un entero entre 0 y 10. Así, por ejemplo, el punto de abscisas 8 representa la región crítica <span class="math inline">\(\{8,9,10\}\)</span>. La hipótesis alternativa considerada es <span class="math inline">\(p_{1}=0.6\)</span>, tal y como se indica en la leyenda del gráfico.</p>
<p><img src="images/cap9-PlotProbsErrTipo2b.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="caso-2-relación-entre-los-errores-de-primera-alpha-y-segunda-especie-1--beta" class="section level3 hasAnchor" number="9.9.2">
<h3><span class="header-section-number">9.9.2</span> Caso 2: Relación entre los errores de primera ( <span class="math inline">\(\alpha\)</span> ) y segunda especie (1- <span class="math inline">\(\beta\)</span> )<a href="pruebas-de-hipótesis.html#caso-2-relaci%C3%B3n-entre-los-errores-de-primera-alpha-y-segunda-especie-1--beta" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La relación entre los errores de tipo I y II es más fácil de interpretar en este caso, dado que la media es un estadístico de distribución continua. En los cuadros siguientes se presentan dos regiones críticas y los errores asociados, visualizando el área que representan.</p>
<p><img src="images/cap9-PlotProbsErrTipo_1_y_2.png" width="90%" style="display: block; margin: auto;" /></p>
<div class="calloutBox Note">
<p>Aunque esta aplicación ya no está disponible en los siguientes enlaces encontraréis una versión actualizada de la misma, que permite investigar de forma interactiva la relación entre los errores de tipo I, tipo II y la potencia.</p>
<ul>
<li><p><a href="https://www.grbio.eu/statmedia/Statmedia_3/">Error de tipo I, de tipo II y potencia en un Z-test (1 muestra normal, varianza conocida)</a></p></li>
<li><p><a href="https://www.grbio.eu/statmedia/Statmedia_4/">Errores de tipo I, II, potencia y p-valor en el test normal de una muestra, varianza conocida</a></p></li>
</ul>
</div>
<p>En el gráfico siguiente se representan los dos errores simultáneamente. Tomando siempre la misma alternativa:</p>
<p><span class="math display">\[
\mathrm{H}_{1}: \mu_{1}=8.5
\]</span></p>
<p>y para cada región crítica de la forma <span class="math inline">\([a,+\infty)\)</span> se calculan <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(1-\beta\)</span>. En el eje de abscisas se representa el extremo inferior (a) de las regiones críticas más relevantes, las próximas a <span class="math inline">\(\mu_{0}\)</span>.</p>
<p><img src="images/cap9-PlotProbsErrTipo_1_y_2b.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="potencia-y-test-más-potente" class="section level2 hasAnchor" number="9.10">
<h2><span class="header-section-number">9.10</span> Potencia y test más potente<a href="pruebas-de-hipótesis.html#potencia-y-test-m%C3%A1s-potente" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La potencia de un contraste se define como:<br />
<span class="math inline">\(\beta=\)</span> prob.(aceptar <span class="math inline">\(H_{1}/H_{1}\)</span> cierta) = prob.(muestra pertenezca a <span class="math inline">\(W_{a}/H_{1}\)</span> cierta)<br />
es, por tanto, la probabilidad complementaria al error del tipo II.<br />
Retomando ideas anteriores, un contraste debe pretender un compromiso razonable entre el nivel de significación (lo más bajo posible) y la potencia (lo más alta posible).</p>
<p>En principio, si hay varios tests alternativos (basados en diferentes reglas de decisión y/o estadísticos) para resolver un mismo contraste paramétrico, el mejor test será aquel que, una vez fijados <span class="math inline">\(\mathrm{H}_{0}, \mathrm{H}_{1}\)</span> y el nivel de significación <span class="math inline">\(\alpha\)</span>, proporcione la potencia más alta entre todos ellos.</p>
<p>Un test que tenga esta propiedad se denomina test más potente. Simbólicamente, si <span class="math inline">\(mp\)</span> designa el test más potente, deberá cumplir:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \beta_{m p}=\text { prob.(aceptar } \mathrm{H}_{1} \text { con el test } m p / \mathrm{H}_{1} \text { cierta) } \\
&amp; \geq \beta_{t}=\text { prob.(aceptar } \mathrm{H}_{1} \text { con el test } t / \mathrm{H}_{1} \text { cierta) }
\end{aligned}
\]</span></p>
<p>donde <span class="math inline">\(t\)</span> es cualquier otro test con el mismo nivel de significación que <span class="math inline">\(mp\)</span>.</p>
<div id="caso-1-potencia-en-hipótesis-simple-vs-simple" class="section level3 hasAnchor" number="9.10.1">
<h3><span class="header-section-number">9.10.1</span> Caso 1: Potencia en hipótesis simple vs simple<a href="pruebas-de-hipótesis.html#caso-1-potencia-en-hip%C3%B3tesis-simple-vs-simple" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En la tabla siguiente se indica la probabilidad para cada uno de los valores del soporte. Se destaca en color diferente la región crítica.</p>
<p><img src="images/cap9-ProbsTestOptim.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Se puede leer entonces que la potencia es:</p>
<p><span class="math display">\[
\beta=\operatorname{prob} .\left(\operatorname{aceptar} \mathrm{H}_{1} / \mathrm{H}_{1}\right)=\operatorname{prob} .\left(X \text { en } \mathrm{W}_{\alpha} / \mathrm{H}_{1}\right)=0.1673
\]</span></p>
<p>Simbólicamente hemos calculado:</p>
<p><span class="math display">\[
\beta=p\left(X \geq 8 / \mathrm{H}_{1}\right)=\sum_{i=8}^{10} p\left(X=i / \mathrm{H}_{1}\right)=\sum_{i=8}^{10}\binom{10}{i} 0.6^{i} 0.4^{10-i}
\]</span></p>
<p>Observamos que coincide con el cálculo anterior del error de tipo II para este ejemplo.</p>
</div>
<div id="caso-2-potencia-en-hipótesis-simple-vs-simple" class="section level3 hasAnchor" number="9.10.2">
<h3><span class="header-section-number">9.10.2</span> Caso 2: Potencia en hipótesis simple vs simple<a href="pruebas-de-hipótesis.html#caso-2-potencia-en-hip%C3%B3tesis-simple-vs-simple" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hemos definido antes la región crítica para este caso. En el cuadro siguiente se pueden visualizar los dos errores (I= verde y II= naranja) y, opcionalmente, la potencia del test (región amarilla).</p>
<p><img src="images/cap9-PlotProbsTestOptim.png" width="90%" style="display: block; margin: auto;" /></p>
<p>La definición de potencia aplicada a este caso resulta:</p>
<p><span class="math display">\[
\beta=\operatorname{prob} .\left(\operatorname{aceptar} \mathrm{H}_{1} / \mathrm{H}_{1}\right)=\operatorname{prob} .\left(X \text { en } \mathrm{W}_{\alpha} / \mathrm{H}_{1}\right)=0.80377
\]</span></p>
<p>Simbólicamente hemos calculado:</p>
<p><span class="math display">\[
\beta=p\left(\bar{X}_{16} \geq 7.9869 / H_{1}\right)=\int_{7.9869}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-8.5)^{2}}{2 \times 0.6^{2}}\right) d x
\]</span></p>
<p>En el documento interactivo se especifica la expresión para todo <span class="math inline">\(n\)</span>.</p>
</div>
</div>
<div id="efecto-del-tamaño-muestral" class="section level2 hasAnchor" number="9.11">
<h2><span class="header-section-number">9.11</span> Efecto del tamaño muestral<a href="pruebas-de-hipótesis.html#efecto-del-tama%C3%B1o-muestral" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los contrastes óptimos para las situaciones aplicadas más habituales ya están completamente resueltos, de modo que usualmente el experimentador solo debe elegir el nivel de significación que desee, (ver por ejemplo el capítulo de contrastes de una población).</p>
<p>Una vez elegido <span class="math inline">\(\alpha\)</span>, quedan fijadas tanto la región crítica como la potencia del contraste. La única manera de conseguir que un contraste mejore su potencia sin que repercuta en un aumento excesivo de <span class="math inline">\(\alpha\)</span> es incrementar el tamaño muestral <span class="math inline">\(N\)</span>.</p>
<p>Aumentar <span class="math inline">\(N\)</span> varía la ley de distribución del estadístico de test y generalmente disminuye su varianza. La consecuencia de mantener <span class="math inline">\(\boldsymbol{\alpha}\)</span> constante y aumentar <span class="math inline">\(N\)</span> se traduce en una mejora de las propiedades del test. Una pregunta crucial -abierta, de momento- es: ¿cuánta muestra hace falta?</p>
<div id="caso-1" class="section level3 hasAnchor" number="9.11.1">
<h3><span class="header-section-number">9.11.1</span> Caso 1<a href="pruebas-de-hipótesis.html#caso-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el documento interactivo se presenta un applet donde se calcula el error de tipo II cuando aumenta N. Aquí solo se presenta el gráfico donde se representan los dos errores simultáneamente para diferentes regiones críticas de la forma <span class="math inline">\(\{a, a+1, \ldots N\}\)</span>. La hipótesis alternativa está indicada en la leyenda.</p>
<p><img src="images/cap9-SampleSizeEffect-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="caso-2" class="section level3 hasAnchor" number="9.11.2">
<h3><span class="header-section-number">9.11.2</span> Caso 2<a href="pruebas-de-hipótesis.html#caso-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Veremos aquí solo cómo afecta el tamaño de la muestra (para <span class="math inline">\(N=16\)</span> y <span class="math inline">\(N=30\)</span>) a los dos errores, manteniendo la región crítica constante. En el documento interactivo se pueden consultar otras combinaciones. Al aumentar <span class="math inline">\(N\)</span>, las distribuciones en el muestreo de la media bajo <span class="math inline">\(\mathrm{H}_{0}\)</span> y <span class="math inline">\(\mathrm{H}_{1}\)</span> presentan cada vez un menor solapamiento.</p>
<p><img src="images/cap9-SampleSizeEffect-2.png" width="90%" style="display: block; margin: auto;" /></p>
<p>En el gráfico siguiente se observa el efecto de <span class="math inline">\(N\)</span> para todo el rango de regiones críticas:</p>
<p><img src="images/cap9-SampleSizeEffect-3.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="hipótesis-simples-vs.-hipótesis-compuestas" class="section level2 hasAnchor" number="9.12">
<h2><span class="header-section-number">9.12</span> Hipótesis simples vs. hipótesis compuestas<a href="pruebas-de-hipótesis.html#hip%C3%B3tesis-simples-vs.-hip%C3%B3tesis-compuestas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Hasta ahora hemos tratado el caso más sencillo de contraste: dos hipótesis simples. En la práctica, las situaciones realmente interesantes conllevan -al menos- una hipótesis compuesta. Uno de los contrastes de hipótesis más habituales consiste en:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathrm{H}_{0}: \theta=\theta_{0} \\
&amp; \mathrm{H}_{1}: \theta \neq \theta_{0}
\end{aligned}
\]</span></p>
<p>es decir, la hipótesis alternativa es la simple negación de la nula. Este contraste se conoce como el de la alternativa bilateral.</p>
<p>Los conceptos de estadístico de test, de región crítica, de región de aceptación y de nivel de significación seguirán siendo los mismos. Ahora bien, como se verá a continuación, se debe ampliar la definición de potencia respecto al caso simple contra simple.</p>
<div id="caso-1-hipótesis-compuestas" class="section level3 hasAnchor" number="9.12.1">
<h3><span class="header-section-number">9.12.1</span> Caso 1: Hipótesis compuestas<a href="pruebas-de-hipótesis.html#caso-1-hip%C3%B3tesis-compuestas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cambiando el planteamiento inicial, supongamos que la polémica sobre la proporción de hembras en los nidos se refiere a si es equitativa o no respecto al número de machos. Las hipótesis a verificar entonces serán:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathrm{H}_{0}: \mathrm{p}=0.5 \\
&amp; \mathrm{H}_{1}: \mathrm{p} \neq 0.5
\end{aligned}
\]</span></p>
<p>Observemos primero que ya no es consistente mantener una región crítica basada solo en la cola derecha de la distribución, como en el caso simple contra simple, que en resumen consistía en:</p>
<table>
<colgroup>
<col width="44%" />
<col width="55%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Regió crítica</th>
<th align="center"><span class="math inline">\(\mathrm{W}_{\alpha}=\{8,9,10\}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Estadístic de test</td>
<td align="center"><span class="math inline">\(\mathrm{T}=\)</span> nombre de femelles totals en els 10 nius</td>
</tr>
<tr class="even">
<td align="left">Nivell de significació</td>
<td align="center"><span class="math inline">\(\alpha=0.0547\)</span></td>
</tr>
</tbody>
</table>
<p>Ahora esta región ya no es adecuada. Basta con considerar el ejemplo de obtener una muestra con <span class="math inline">\(\mathrm{T}=0\)</span>. A pesar de ser sumamente improbable bajo <span class="math inline">\(\mathrm{H}_{0}\)</span>, el criterio impone aceptar la hipótesis nula, en contra de otras hipótesis más plausibles (cualquier con p &lt; 0.5).</p>
<p>El sentido común indica que la región crítica debe abarcar ahora ambos extremos del soporte. Si tomamos por ejemplo:</p>
<p><span class="math display">\[
\mathrm{W}_{\alpha}=\{0,1,2,8,9,10\}
\]</span></p>
<p><img src="images/cap9-RCSimpleVsComposta.png" width="90%" style="display: block; margin: auto;" /></p>
<p>la suma siguiente (que corresponde a los valores destacados en la tabla):</p>
<p><span class="math display">\[
\begin{aligned}
\alpha &amp; =p\left(X \leq 2 / H_{0}\right)+p\left(X \geq 8 / H_{0}\right)=\sum_{i=0}^{2} p\left(X=i / H_{0}\right)+\sum_{i=8}^{10} p\left(X=i / H_{0}\right) \\
&amp; =\left[\binom{10}{0}+\binom{10}{1}+\binom{10}{2}+\binom{10}{8}+\binom{10}{9}+\binom{10}{10}\right] 0.5^{10}
\end{aligned}
\]</span></p>
<p>nos proporciona el nivel de significación de este test bilateral.</p>
</div>
<div id="caso-2-hipótesis-compuestas" class="section level3 hasAnchor" number="9.12.2">
<h3><span class="header-section-number">9.12.2</span> Caso 2: Hipótesis compuestas<a href="pruebas-de-hipótesis.html#caso-2-hip%C3%B3tesis-compuestas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A pesar de que seguramente todavía no es el contraste de hipótesis que realmente interesa a la asociación ADG, por razones didácticas supondremos que se pretende dirimir simplemente si es aceptable la media propuesta en la bibliografía. Las hipótesis que hay que verificar entonces serán:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H_{0}: \mu=7 \\
&amp; H_{1}: \mu \neq 7
\end{aligned}
\]</span></p>
<p>Ya no es consistente mantener una región crítica basada solo en la cola derecha de la distribución, como en el planteamiento original de este caso (que contrastaba una hipótesis simple contra otra simple).</p>
<p>Para entenderlo se puede considerar por ejemplo una muestra con una media muestral de 5. A pesar de ser sumamente improbable bajo <span class="math inline">\(\mathrm{H}_{0}\)</span>, dado que pertenece a la región de aceptación, el criterio impone aceptar la hipótesis nula, en contra de otras hipótesis más plausibles (cualquiera con <span class="math inline">\(\mu&lt;7\)</span>).</p>
<p>Nuevamente, el sentido común indica que la región crítica debe abarcar ahora ambos extremos del soporte. Si tomamos por ejemplo:</p>
<p><span class="math display">\[
\mathrm{W}_{\alpha}=(-\infty, 6.0131] \mathrm{U}[7.9869,+\infty)
\]</span></p>
<p>Se obtiene <span class="math inline">\(\alpha=0.1\)</span>. En el cuadro siguiente se visualiza la región crítica y se evalúa el nivel de significación resultante:</p>
<p><img src="images/cap9-RCHipotesisComposta.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Simbólicamente, el nivel de significación de este test se calcula de la siguiente forma:</p>
<p><span class="math display">\[
\begin{aligned}
\alpha &amp; =p\left(\bar{X}_{16} \leq 6.0131 / H_{0}\right)+p\left(\bar{X}_{16} \geq 7.9869 / H_{0}\right) \\
&amp; =\int_{-\infty}^{6.0131} f_{\bar{X}_{16}}(x) d x+\int_{7.9869}^{\infty} f_{\bar{X}_{16}}(x) d x \\
&amp; =F_{Z}\left(\frac{6.0131-7}{2.4 / \sqrt{16}}\right)+1-F_{z}\left(\frac{7.9869-7}{2.4 / \sqrt{16}}\right)
\end{aligned}
\]</span></p>
<p>Donde:</p>
<p><span class="math display">\[
f_{\bar{X}_{16}}(x)=\frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right)
\]</span></p>
</div>
</div>
<div id="función-de-potencia" class="section level2 hasAnchor" number="9.13">
<h2><span class="header-section-number">9.13</span> Función de potencia<a href="pruebas-de-hipótesis.html#funci%C3%B3n-de-potencia" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una de las diferencias conceptuales más importantes entre el caso de una hipótesis simple contra otra simple y el caso con una alternativa compuesta se encuentra en la definición de potencia. En este segundo caso ya no se presenta un único posible valor del parámetro bajo la hipótesis alternativa, sino que se contempla todo un conjunto. En la mayoría de tests habituales, será un intervalo real o una unión de intervalos reales. Por ejemplo:</p>
<p><span class="math display">\[
\mathrm{H}_{1}: \theta \neq \theta_{0}
\]</span></p>
<p>Desde el punto de vista de la estadística paramétrica clásica, una vez hecho el experimento aleatorio, <span class="math inline">\(\theta\)</span> presenta solo uno de los posibles valores dentro del subconjunto de la alternativa, aunque éste sea desconocido. Por tanto, la definición de potencia enunciada antes:</p>
<p><span class="math display">\[
\beta=\operatorname{prob} .\left(\operatorname{aceptar} \mathrm{H}_{1} / \mathrm{H}_{1}\right. \text { cierta) }
\]</span></p>
<p>no se puede calcular globalmente para toda <span class="math inline">\(\mathrm{H}_{1}\)</span>, sino que se debe distinguir cada uno de los valores posibles dentro de <span class="math inline">\(\mathrm{H}_{1}\)</span>. De ahí el interés de definir la función de potencia:</p>
<p><span class="math display">\[
\beta(\theta)=\operatorname{prob}\left(\operatorname{aceptar} \mathrm{H}_{1} / \theta \text { cierto }\right)
\]</span></p>
<p>donde <span class="math inline">\(\theta\)</span> es un valor cualquiera del parámetro, incluso valores correspondientes a <span class="math inline">\(\mathrm{H}_{0}\)</span>. Si <span class="math inline">\(\mathrm{H}_{0}\)</span> es simple (un solo parámetro <span class="math inline">\(\theta_{0}\)</span>), resultará:</p>
<p><span class="math display">\[
\beta\left(\theta_{0}\right)=\operatorname{prob}\left(\operatorname{aceptar} \mathrm{H}_{1} / \theta_{0} \text { cierto }\right)=\alpha
\]</span></p>
<div id="caso-1-función-de-potencia" class="section level3 hasAnchor" number="9.13.1">
<h3><span class="header-section-number">9.13.1</span> Caso 1: Función de potencia<a href="pruebas-de-hipótesis.html#caso-1-funci%C3%B3n-de-potencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora la potencia depende de la proporción concreta de hembras que se elija como alternativa. La expresión general es:</p>
<p><span class="math display">\[
1-\beta=p\left(3 \leq X \leq 7 / H_{1}\right)=\sum_{i=3}^{7} p\left(X=i / H_{1}\right)=\sum_{i=3}^{7}\binom{10}{i} p^{i}(1-p)^{10-i}
\]</span></p>
<p>dado que la región crítica es <span class="math inline">\(\mathrm{W}_{\alpha}=\{0,1,2,8,9,10\}\)</span>. En los cuadros siguientes se obtiene el valor de la potencia <span class="math inline">\((\beta)\)</span> inicialmente para <span class="math inline">\(p=0.6\)</span> y para <span class="math inline">\(p=0.8\)</span> (en el documento interactivo se puede variar arbitrariamente la proporción bajo <span class="math inline">\(\mathrm{H}_{1}\)</span>):</p>
<p><img src="images/cap9-comparaProbs.png" width="90%" style="display: block; margin: auto;" /></p>
<p>En el gráfico siguiente se representa la función de potencia para todo el rango de parámetros:</p>
<p><img src="images/cap9-FuncPotencia1.png" width="60%" style="display: block; margin: auto;" /></p>
</div>
<div id="caso-2-función-de-potencia" class="section level3 hasAnchor" number="9.13.2">
<h3><span class="header-section-number">9.13.2</span> Caso 2: Función de potencia<a href="pruebas-de-hipótesis.html#caso-2-funci%C3%B3n-de-potencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ahora la potencia depende de la media concreta <span class="math inline">\(\mu_{1}\)</span> que se elija como alternativa. La expresión general del error de tipo II es:</p>
<p><span class="math display">\[
\begin{aligned}
1-\beta &amp; =p\left(6.0131 \leq \bar{X}_{16} \leq 7.9869 / H_{1}\right) \\
&amp; =\int_{6.0131}^{7.9869} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{\left(x-\mu_{1}\right)^{2}}{2 \times 0.6^{2}}\right) d x \\
&amp; =F_{z}\left(\frac{6.0131-\mu_{1}}{2.4 / \sqrt{16}}\right)+1-F_{z}\left(\frac{7.9869-\mu_{1}}{2.4 / \sqrt{16}}\right)
\end{aligned}
\]</span></p>
<p>dado que la región crítica es <span class="math inline">\(\mathrm{W}_{\alpha}=(-\infty, 6,0131] \mathrm{U}[7,9869,+\infty)\)</span>.<br />
En el cuadro siguiente se obtiene el valor de la potencia ( <span class="math inline">\(\beta\)</span> ) inicialmente para <span class="math inline">\(\mu=8.5\)</span>.</p>
<p>En el documento interactivo representado en la imagen puede cambiar el valor de la alternativa y observar los cambios en los dos errores y en la potencia:</p>
<p><img src="images/cap9-FuncPotencia2.png" width="60%" style="display: block; margin: auto;" /></p>
<p>En el gráfico siguiente se representan dos funciones de potencia, para <span class="math inline">\(\alpha=0.05, \sigma=\)</span> 2.4 y que respectivamente corresponden a <span class="math inline">\(n=16\)</span> (la situación de este caso 2) y a <span class="math inline">\(n=1\)</span>.
En el documento interactivo representado en la imagen se pueden variar todos aquellos parámetros que afectan a <span class="math inline">\(\beta: \alpha, \sigma y n\)</span> y compararlos con la situación original.</p>
<p><img src="images/cap9-FuncPotencia3.png" width="60%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="tests-óptimos" class="section level2 hasAnchor" number="9.14">
<h2><span class="header-section-number">9.14</span> Tests óptimos<a href="pruebas-de-hipótesis.html#tests-%C3%B3ptimos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En muchas situaciones aplicadas se pueden plantear diferentes reglas de decisión para resolver un mismo contraste, de modo que proporcionen un mismo error de tipo I. Es necesario entonces adoptar un criterio adicional para escoger cuál es el mejor test posible para resolver este contraste. Tal como hemos visto en el caso de hipótesis simple vs. simple, esto ocurre forzosamente por analizar el error de tipo II asociado a cada test. En el caso de una alternativa compuesta, esto lleva a estudiar el comportamiento de la función de potencia en todo el rango de parámetros asociados a la alternativa.</p>
<p>El estudio de los tests que presentan propiedades óptimas desde el punto de vista de la potencia sobrepasa los objetivos marcados por este curso El lector interesado puede consultar alguna definición más en los complementos, aunque esta información no es estrictamente necesaria para seguir ni el resto de este tema ni los ulteriores. En los próximos capítulos solo se señalará, a título informativo, cuándo un test es óptimo desde el punto de vista de la potencia. En nuestro desarrollo es suficiente conocer que existen resultados generales en estadística matemática que permiten asegurar cuándo existe este tipo de test y cómo obtenerlo.</p>
</div>
<div id="pruebas-bilaterales-y-pruebas-unilaterales" class="section level2 hasAnchor" number="9.15">
<h2><span class="header-section-number">9.15</span> Pruebas bilaterales y pruebas unilaterales<a href="pruebas-de-hipótesis.html#pruebas-bilaterales-y-pruebas-unilaterales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un contraste bilateral adopta en general la forma:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta \neq \theta_{0}
\]</span></p>
<p>En determinadas ocasiones el experimentador prefiere plantear directamente un contraste de la forma:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta&gt;\theta_{0}
\]</span></p>
<p>conocido como contraste unilateral derecho. Obviamente, otra posibilidad es el unilateral izquierdo:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta&lt;\theta_{0}
\]</span></p>
<p>En estos tres casos, el contraste de hipótesis es simple contra compuesta. En la mayoría de situaciones aplicadas, en realidad se pretenden resolver contrastes unilaterales que conllevan hipótesis compuestas. El unilateral derecho es entonces:</p>
<table>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left"><span class="math inline">\(\mathrm{H}_{0}: \theta \leq \theta_{0}\)</span></th>
<th align="left">contra</th>
<th align="left"><span class="math inline">\(\mathrm{H}_{1}: \theta&gt;\theta_{0}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">el izquierdo es:</td>
<td align="left"><span class="math inline">\(\mathrm{H}_{0}: \theta \geq \theta_{0}\)</span></td>
<td align="left">contra</td>
<td align="left"><span class="math inline">\(\mathrm{H}_{1}: \theta&lt;\theta_{0}\)</span></td>
</tr>
</tbody>
</table>
<p>Aunque esta última formulación está relacionada con los contrastes unilaterales simple contra compuesta anteriores, las dos hipótesis no son técnicamente equivalentes. A fin de simplificar la interpretación de los contrastes unilaterales, atendiendo a los casos que se tratan en este curso, se formulan los contrastes de esta última manera (compuesta contra compuesta) y se toma el nivel de significación como si fuera el del contraste simple contra compuesta.</p>
<p>En cualquier caso, es importante entender que solo se ha resuelto uno de los tres contrastes (bilateral o unilateral) con un conjunto de datos concreto. Por ejemplo, es incorrecto desde el punto de vista metodológico comenzar contrastando bilateralmente y hacer después un test unilateral. El contraste que se debe emplear debe decidirse con base en conocimientos previos del problema, o bien siguiendo la cuestión de interés aplicado que se quiere responder.</p>
<div id="caso-1-prueba-unilateral" class="section level3 hasAnchor" number="9.15.1">
<h3><span class="header-section-number">9.15.1</span> Caso 1: Prueba unilateral<a href="pruebas-de-hipótesis.html#caso-1-prueba-unilateral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supongamos que la controversia entre los dos ornitólogos se hubiera planteado originalmente en los siguientes términos. Según da Souza, el número de hembras por nido es como máximo del 50%. En cambio, para Calves, hay más hembras que machos. El contraste que hay que resolver para dirimir cuál de los dos especialistas tiene razón sería, pues:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathrm{H}_{0}: \mathrm{p} \leq 0.5 \\
&amp; \mathrm{H}_{1}: \mathrm{p}&gt;0.5
\end{aligned}
\]</span></p>
<p>Respecto al caso general se sustituye el parámetro genérico <span class="math inline">\(\theta\)</span> por p, y el valor <span class="math inline">\(\theta_{0}=0.5\)</span>. Tomando la región crítica como <span class="math inline">\(\mathrm{W}_{\alpha}=\{8,9,10\}\)</span>, en el cuadro siguiente se presenta el nivel de significación:</p>
<p><img src="images/cap9-comparaProbs.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="caso-2-prueba-unilateral" class="section level3 hasAnchor" number="9.15.2">
<h3><span class="header-section-number">9.15.2</span> Caso 2: Prueba unilateral<a href="pruebas-de-hipótesis.html#caso-2-prueba-unilateral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El planteamiento siguiente se aproxima más a lo que realmente debería intentar aclarar la asociación de deportistas ADG. Si hacen caso a la fuerte sospecha de que la tasa de statdrolona ha aumentado, es más coherente plantear las siguientes hipótesis:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \mathrm{H}_{0}: \mu \leq 7 \\
&amp; \mathrm{H}_{1}: \mu&gt;7
\end{aligned}
\]</span></p>
<p>Tal como ya se ha planteado en el caso 1, ahora se debe considerar una región crítica basada en la cola derecha de la distribución. Se deja al lector razonar por qué debe ser así. Cuando se toma, por ejemplo:</p>
<p><span class="math display">\[
\mathrm{W}_{\alpha}=[7,9869,+\infty)
\]</span></p>
<p>se obtiene <span class="math inline">\(\alpha=0.05\)</span>. En el cuadro siguiente se presenta la región crítica (en el documento interactivo se puede variar la región crítica y modificar por tanto el nivel de significación):</p>
<p><img src="images/cap9-RCHipotesisComposta2.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Simbólicamente, se calcula:</p>
<p><span class="math display">\[
\alpha=p\left(\bar{X}_{16} \geq 7.9869 / H_{0}\right)=\int_{7.9869}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right) d x=\\ = 1-F_{z}\left(\frac{7.9869-7}{2.4 / \sqrt{16}}\right)
\]</span></p>
<p>que nos proporciona el nivel de significación de este test unilateral. Así pues, no hay ninguna diferencia ni en el cálculo ni en el gráfico respecto a lo ya visto en el apartado de hipótesis simple contra simple. En relación con la potencia, se trata de una función que depende de la <span class="math inline">\(\mu\)</span> concreta de la hipótesis alternativa (simple), y por esta razón resulta:</p>
<p><img src="images/cap9-PotenciaHipotesisComposta.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Una observación final referente a este caso 2. En el planteamiento actual solo queda ya la arbitrariedad consistente en asumir una <span class="math inline">\(\sigma=2.4\)</span> poblacional fija. En el tema <span class="math inline">\(10\)</span>, se estudiará cómo abordar este estudio sin asumir más condición que el modelo de probabilidad Normal.</p>
</div>
</div>
<div id="elección-del-nivel-de-significación" class="section level2 hasAnchor" number="9.16">
<h2><span class="header-section-number">9.16</span> Elección del nivel de significación<a href="pruebas-de-hipótesis.html#elecci%C3%B3n-del-nivel-de-significaci%C3%B3n" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>¿Qué nivel de significación se debe utilizar? En contra de cierta práctica estadística, desgraciadamente bastante extendida, en realidad no se puede responder a esta pregunta dando simplemente un valor al nivel de significación. Si se consultan publicaciones científicas aplicadas para conocer qué <span class="math inline">\(\alpha\)</span> usar, en la mayoría de estudios se obtendrá que el más utilizado es <span class="math inline">\(\alpha=0.05\)</span> (5% de error), siendo el segundo lugar ex aequo <span class="math inline">\(\alpha=0.01\)</span> (1%) y <span class="math inline">\(\alpha=0.1\)</span> (10%). Estos son los niveles aconsejados en muchos textos elementales de estadística. Veamos por qué se han aconsejado estos valores.</p>
<p>Antes de la universalización del uso del ordenador, los cálculos estadísticos se completaban mediante diferentes tablas para encontrar las fronteras de la región crítica y decidir qué hipótesis aceptar. Los valores 5%, 1% y 10% fueron inicialmente elegidos como los más representativos en las colecciones de tablas, ya que no resultaba práctico publicar tablas para cualquier <span class="math inline">\(\alpha\)</span>. Así, estos valores se fueron convirtiendo, con el paso del tiempo, en un convencionalismo más. Se ha llegado a producir el efecto perverso, en algunos campos del conocimiento, de que algunos editores mal informados solo aceptan trabajos con un 5% de significación.</p>
<p>No obstante, no hay ninguna razón científica que indique que estos valores son forzosamente los más adecuados. Ya hemos visto que la potencia tiene también una importancia capital cuando hay que calificar la bondad del test, sin olvidar la influencia que tiene el tamaño de la muestra sobre <span class="math inline">\(1-\beta\)</span>. La metodología más razonable es obtener el p-valor y, si es posible, definir antes de la obtención de la muestra una diferencia mínima significativa que garantice la potencia deseada (definiremos a continuación estos dos conceptos). Solo con estas tres cantidades el contraste queda satisfactoriamente planteado.</p>
<p>Desde nuestro punto de vista, hoy en día, exponer las conclusiones de cualquier estudio solo a partir de un nivel de significación fijo para todos los contrastes es un procedimiento estadístico muy rudimentario.</p>
</div>
<div id="el-p-valor" class="section level2 hasAnchor" number="9.17">
<h2><span class="header-section-number">9.17</span> El p-valor<a href="pruebas-de-hipótesis.html#el-p-valor" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La elección del nivel de significación, tal como se ha comentado anteriormente, es en cierta manera arbitraria. Sin embargo, una vez obtenida la muestra, se puede calcular una cantidad que sí permite resumir el resultado del experimento de manera objetiva. Esta cantidad es el p-valor, que corresponde al nivel de significación más pequeño posible que se puede elegir, para el cual todavía se aceptaría la hipótesis alternativa con las observaciones actuales. Cualquier nivel de significación elegido inferior al p-valor (simbólicamente <span class="math inline">\(\mathrm{p}_{\mathrm{v}}\)</span>) conlleva aceptar <span class="math inline">\(\mathrm{H}_{0}\)</span>. Obviamente, como es una probabilidad, se cumple que:</p>
<p><span class="math display">\[
0 \leq p_{v} \leq 1
\]</span></p>
<p>El p-valor es una medida directa de lo inverosímil que resulta obtener una muestra como la actual si es cierta <span class="math inline">\(\mathrm{H}_{0}\)</span>. Los valores pequeños indican que es muy infrecuente obtener una muestra como la actual, en cambio, los valores altos muestran que es frecuente. El p-valor se utiliza para indicar cuánto (o cuán poco) contradice la muestra actual la hipótesis alternativa.</p>
<p>Informar sobre cuál es el p-valor tiene la ventaja de permitir que cualquiera decida qué hipótesis acepta basándose en su propio nivel de riesgo <span class="math inline">\(\boldsymbol{\alpha}\)</span>. Esto no es posible cuando se informa, como ha sido tradicional, indicando solo el resultado de la decisión, es decir, aceptando o rechazando <span class="math inline">\(\mathrm{H}_{0}\)</span> con un <span class="math inline">\(\alpha\)</span> fijo.</p>
<p>Cuando se proporciona el p-valor obtenido con la muestra actual, la decisión se hace según la siguiente regla:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text { si } \mathrm{p}_{\mathrm{v}} \leq \alpha, \text { aceptar } \mathrm{H}_{1} \\
&amp; \text { si } \mathrm{p}_{\mathrm{v}}&gt;\alpha, \text { aceptar } \mathrm{H}_{0}
\end{aligned}
\]</span></p>
<p>Desde el punto de vista práctico, algunos paquetes estadísticos proporcionan en sus listados el “significance level”, cuya traducción literal es “nivel de significación”, cuando en muchas ocasiones se refieren en realidad al p-valor (“p-value”).</p>
<div id="caso-1-cálculo-del-p-valor-prueba-unilateral" class="section level3 hasAnchor" number="9.17.1">
<h3><span class="header-section-number">9.17.1</span> Caso 1: Cálculo del p-valor (prueba unilateral)<a href="pruebas-de-hipótesis.html#caso-1-c%C3%A1lculo-del-p-valor-prueba-unilateral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Sigamos con la hipótesis unilateral:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H_{0}: p \leq 0.5 \\
&amp; H_{1}: p&gt;0.5
\end{aligned}
\]</span></p>
<p>Supongamos que, una vez obtenida la muestra de <span class="math inline">\(n=10\)</span> nidos, resulta que en seis de ellos el polluelo corresponde a una hembra. Hay que recordar primeramente que en este caso el estadístico de test T es una variable discreta, y por lo tanto no es posible obtener cualquier <span class="math inline">\(\alpha\)</span>.</p>
<p>El p-valor es el menor <span class="math inline">\(\alpha\)</span> que permite aceptar <span class="math inline">\(\mathrm{H}_{1}\)</span>. Con la tabla siguiente:</p>
<p><img src="images/cap9-comparaProbs.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Se obtiene el p-valor asociado a <span class="math inline">\(\mathrm{T}=6\)</span> hembras. Consideremos principalmente los siguientes casos:</p>
<ol style="list-style-type: decimal">
<li>Si se escogiera <span class="math inline">\(\alpha=0.1719\)</span>, la región crítica correspondiente sería <span class="math inline">\(\mathrm{W}_{\alpha}=\{7,8,9,10\}\)</span>. Como no se incluyen 6 hembras, habría que aceptar <span class="math inline">\(H_{0}\)</span>. Por tanto, <span class="math inline">\(\alpha\)</span> no cumple la definición de p-valor, ya que se debe rechazar <span class="math inline">\(\mathrm{H}_{0}\)</span>: <span class="math inline">\(\mathrm{p}_{\mathrm{v}}\)</span> debe ser forzosamente mayor.</li>
<li>Si se eligiera <span class="math inline">\(\alpha^{\prime}=0.3770\)</span>, la región crítica correspondiente sería <span class="math inline">\(W_{\alpha^{\prime}}=\{6,7,8,9,10\}\)</span>. Con <span class="math inline">\(\alpha^{\prime}\)</span> se rechazaría <span class="math inline">\(H_{0}\)</span>.</li>
<li>Si se seleccionara <span class="math inline">\(\alpha^{\prime\prime}=0.6230\)</span>, la región crítica correspondiente sería <span class="math inline">\(\mathrm{W}_{\alpha^{\prime\prime}}=\{5,6,7,8,9,10\}\)</span>. Con <span class="math inline">\(\alpha^{\prime\prime}\)</span> también se rechazaría <span class="math inline">\(\mathrm{H}_{0}\)</span>.</li>
</ol>
<p>Observamos que <span class="math inline">\(\alpha^{\prime}&lt;\alpha^{\prime\prime}\)</span>, y entre los dos valores no es posible obtener ningún otro nivel de significación con el test que hemos planteado. Por tanto, <span class="math inline">\(\alpha^{\prime}\)</span> es el nivel de significación mínimo con el que rechazaríamos <span class="math inline">\(H_{0}\)</span> con la muestra actual o, dicho de otro modo, <span class="math inline">\(\alpha^{\prime}\)</span> es el p-valor.</p>
<p>Este es el detalle de cómo se calcula el p-valor. Usualmente, de esto se encarga software especializado (un paquete estadístico, una hoja de cálculo,…), que devuelve simplemente la información <span class="math inline">\(\mathrm{p}_{\mathrm{v}}=0.3770\)</span>. Ahora bien, lo que no resuelve el programa es qué debe decidir finalmente el experimentador, es decir, en nuestro caso, da Souza o Calves.</p>
<p>Pues bien, en este momento, se deberá comparar <span class="math inline">\(\mathrm{p}_{\mathrm{v}}\)</span> con el nivel de significación elegido a priori (por ejemplo, <span class="math inline">\(\alpha=0.05\)</span>):</p>
<p><span class="math display">\[
\mathrm{p}_{\mathrm{v}}=0.3770&gt;\alpha=0.05 \text { por tanto, aceptar } \mathbf{H}_{\mathbf{0}}.
\]</span></p>
<p>El valor de <span class="math inline">\(p_{v}\)</span> indica que hay una frecuencia del 37.7% de obtener muestras con T <span class="math inline">\(\geq 6\)</span> hembras bajo <span class="math inline">\(\mathrm{H}_{0}\)</span> y, por tanto, que no hay indicios suficientes de discrepancia entre la muestra obtenida y la hipótesis de da Souza consistente en que <span class="math inline">\(\mathrm{p} \leq 0.5\)</span>.</p>
<p>Una vez más, hay que insistir en que <span class="math inline">\(\mathrm{p}_{\mathrm{v}}\)</span> es un valor objetivo -cualquier experimentador dará el mismo valor una vez obtenida la muestra-, mientras que <span class="math inline">\(\alpha\)</span> es subjetivo, elegido por el experimentador según su experiencia.</p>
</div>
<div id="caso-2-cálculo-del-p-valor-prueba-unilateral" class="section level3 hasAnchor" number="9.17.2">
<h3><span class="header-section-number">9.17.2</span> Caso 2: Cálculo del p-valor (prueba unilateral)<a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-del-p-valor-prueba-unilateral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consideremos primero el cálculo del p-valor cuando las hipótesis son:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \mu \leq 7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu&gt;7
\]</span></p>
<p>En el cuadro siguiente se presentan los datos obtenidos en el experimento, su media y la desviación estándar corregida, así como el p-valor y la decisión final según el nivel de significación 0.05. Como <span class="math inline">\(\mathrm{T}=8.54\)</span>, el p-valor corresponde a la cola de la curva Normal situada a la derecha de T. En el gráfico se superpone el color rojo del p-valor al verde de la zona correspondiente a <span class="math inline">\(\alpha\)</span> en la parte más extrema de la cola.</p>
<p><img src="images/cap9-CalculPvalorUnilateral.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Así pues, se rechaza <span class="math inline">\(\mathbf{H}_{0}\)</span>, ya que <span class="math inline">\(\alpha=0.05&gt;\mathrm{p}_{\mathrm{v}}=0.00513\)</span>. En el documento interactivo es posible elegir otros niveles de significación. Según el nivel elegido se aceptará o rechazará la hipótesis nula.</p>
<p>El cuadro anterior ilustra la relación entre los conceptos del p-valor y del nivel de significación, ahora bien, el lector NO debe extraer la conclusión de que debe ajustar <span class="math inline">\(\alpha\)</span> en ningún sentido: <span class="math inline">\(\alpha\)</span> se elige siempre a priori (antes del análisis), nunca en función de los datos (o del p-valor). Respecto al cálculo simbólico del p-valor, en el ejemplo se ajusta a la expresión siguiente:</p>
<p><span class="math display">\[
\begin{aligned}
p v &amp; =p\left(\bar{X}_{16} \geq 8.54 / H_{0}\right) \\
&amp; =\int_{8.54}^{\infty} \frac{1}{0.6 \sqrt{2 \pi}} \exp \left(-\frac{(x-7)^{2}}{2 \times 0.6^{2}}\right) d x \\
&amp; =1-F_{z}\left(\frac{8.54-7}{0.6}\right)=0.0513
\end{aligned}
\]</span></p>
<p>En el documento interactivo se pueden cambiar los datos de los dieciséis atletas, lo que permite resolver algunas de las cuestiones planteadas más adelante. Alternativamente al p-valor, también se puede visualizar la potencia o el error de tipo II.</p>
</div>
<div id="caso-2-cálculo-del-p-valor-prueba-bilateral" class="section level3 hasAnchor" number="9.17.3">
<h3><span class="header-section-number">9.17.3</span> Caso 2: Cálculo del p-valor (prueba bilateral)<a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-del-p-valor-prueba-bilateral" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consideremos ahora el cálculo del p-valor cuando las hipótesis son:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \mu=7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq 7
\]</span></p>
<p>El p-valor corresponde ahora a dos colas de la curva Normal: una es la misma que en el caso unilateral, es decir, la situada a la derecha de <span class="math inline">\(\mathrm{T}=8.54\)</span>, la segunda es la cola simétrica a la anterior respecto a <span class="math inline">\(\mu=7\)</span>, es decir, la cola izquierda situada en <span class="math inline">\(2 \mu-\mathrm{T}=5.46\)</span>. Como antes, en el cuadro se superpone el color rojo del p-valor al verde de la zona correspondiente a <span class="math inline">\(\alpha\)</span> en la parte más extrema de las dos colas. En el documento interactivo se pueden cambiar datos, el nivel de significación y el punto donde se calcula la potencia.</p>
<p><img src="images/cap9-CalculPvalorBilateral.png" width="90%" style="display: block; margin: auto;" /></p>
<p>El cálculo del p-valor se corresponde, con los datos originales, a:</p>
<p><span class="math display">\[
\begin{aligned}
p v &amp; =p\left(\bar{X}_{16} \leq 5.46 / H_{0}\right)+p\left(\bar{X}_{16} \geq 8.54 / H_{0}\right) \\
&amp; =\int_{-\infty}^{5.46} f_{\bar{X}_{16}}(x) d x+\int_{8.54}^{\infty} f_{\bar{X}_{16}}(x) d x \\
&amp; =2 p\left(\bar{X}_{16} \geq 8.54 / H_{0}\right)=.01027
\end{aligned}
\]</span></p>
<p>Así pues, se rechaza <span class="math inline">\(\mathbf{H}_{\mathbf{0}}\)</span>, puesto que:</p>
<p><span class="math display">\[
\alpha=0.05&gt;\mathrm{pv}=0.01027
\]</span></p>
<p>En general, si la distribución del estadístico es continua, como en este caso, se puede calcular fácilmente el p-valor de la prueba bilateral a partir de la unilateral, y viceversa. Así, si designamos con <span class="math inline">\(\mathrm{p}_{uni}\)</span> y <span class="math inline">\(\mathrm{p}_{bil}\)</span>, respectivamente, los p-valores de la prueba unilateral y bilateral, tendremos que:</p>
<ul>
<li>Si <span class="math inline">\(\mathrm{p}_{uni} \leq 0.5\)</span>, entonces <span class="math inline">\(\mathrm{p}_{bil}=2 \mathrm{p}_{uni}\)</span>. Es decir, el p-valor es exactamente el doble que el de la prueba unilateral.</li>
<li>Si <span class="math inline">\(\mathrm{p}_{uni}&gt;0.5\)</span>, entonces <span class="math inline">\(\mathrm{p}_{bil}=2(1-\mathrm{p}_{uni})\)</span>. Es decir, el p-valor es exactamente el doble que el complementario del p-valor de la prueba unilateral.</li>
</ul>
</div>
</div>
<div id="pruebas-exactas-y-pruebas-asintóticas" class="section level2 hasAnchor" number="9.18">
<h2><span class="header-section-number">9.18</span> Pruebas exactas y pruebas asintóticas<a href="pruebas-de-hipótesis.html#pruebas-exactas-y-pruebas-asint%C3%B3ticas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los dos errores ( <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(1-\beta\)</span> ) implicados en cualquier contraste son probabilidades que se basan en hipótesis sobre el parámetro que queremos contrastar. De manera similar a los intervalos de confianza (véase, por ejemplo, los intervalos para una proporción y para la media de una Normal), se pueden clasificar los tests en relación con la distribución empleada.</p>
<p>Si se puede establecer explícitamente para cualquier tamaño de muestra <span class="math inline">\(N\)</span> qué distribución tiene el estadístico de test, y además es factible el cálculo de los errores, se obtendrá una fórmula válida para todo <span class="math inline">\(N\)</span>. Este es el caso de los dos ejemplos seguidos en este capítulo. Un test con estas características se denomina prueba exacta. La prueba t de Student para dos muestras y la prueba F de comparación de varianzas son ejemplos de uso cotidiano en experimentos reales.</p>
<p>En otros casos, cuando existe dificultad para resolver el cálculo de los errores con la verdadera distribución del estadístico, se recurre a las propiedades en el límite de las distribuciones. Un recurso habitual es aplicar el teorema central del límite si la distribución del estadístico tiende a una Normal. En este segundo caso, el test obtenido solo será válido para valores grandes de <span class="math inline">\(N\)</span>, y entonces se denomina prueba asintótica. Los ejemplos más conocidos son las diferentes pruebas de Ji-cuadrado.</p>
<div id="caso-1-test-asintótico" class="section level3 hasAnchor" number="9.18.1">
<h3><span class="header-section-number">9.18.1</span> Caso 1: Test asintótico<a href="pruebas-de-hipótesis.html#caso-1-test-asint%C3%B3tico" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Hasta el momento nos hemos basado para resolver los contrastes en la distribución exacta del estadístico <span class="math inline">\(T=\)</span> número de hembras en diez nidos, que es una Binomial <span class="math inline">\((n, p)\)</span>, con <span class="math inline">\(n=10\)</span> y <span class="math inline">\(p\)</span> desconocida. La distribución exacta de T nos permite calcular p-valores, potencias, etc. para cualquier tamaño de muestra <span class="math inline">\(n\)</span>. No obstante, los cálculos con la distribución Binomial se pueden aproximar mediante la distribución Normal a partir de tamaños de muestra de treinta o mayores. La distribución asintótica de <span class="math inline">\(T\)</span> es:</p>
<p><span class="math display">\[
T \approx N(n p, \sqrt{n p(1-p)})
\]</span></p>
<p>Por ejemplo, si se pretende contrastar:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; H_{0}: p=0.5 \\
&amp; H_{1}: p \neq 0.5
\end{aligned}
\]</span></p>
<p>con <span class="math inline">\(n=36\)</span>, bajo <span class="math inline">\(\mathrm{H}_{0} T\)</span> será aproximadamente <span class="math inline">\(N(18,3)\)</span>. En el documento interactivo se presenta un cuadro donde podemos comprobar las diferencias entre el p-valor exacto y el p-valor según la distribución asintótica para diferentes <span class="math inline">\(n\)</span> y diferentes valores de T. Por ejemplo, para <span class="math inline">\(n=36\)</span> y 28 hembras las diferencias son:</p>
<p><span class="math display">\[
\mathrm{p}_{\mathrm{v}}\text{ exacto }-\mathrm{p}_{\mathrm{v}}\text{ asintótico }=0.00119-0.00085&lt;0.004
\]</span></p>
<p>¿Qué interés tiene entonces la distribución asintótica si conocemos la exacta? La ventaja se sitúa en el terreno del cálculo: la distribución Normal es más fácil de usar computacionalmente tanto si se evalúa mediante tablas (y calculadora) como si se evalúa con el ordenador. En cambio, la fórmula de la densidad Binomial conlleva dificultades operativas con los factoriales cuando <span class="math inline">\(n&gt;30\)</span>.</p>
</div>
<div id="caso-2-test-exacto" class="section level3 hasAnchor" number="9.18.2">
<h3><span class="header-section-number">9.18.2</span> Caso 2: Test exacto<a href="pruebas-de-hipótesis.html#caso-2-test-exacto" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ya se ha analizado anteriormente con detalle la distribución de la media de <span class="math inline">\(n\)</span> atletas cuando la variable observada es una Normal. En resumen, la densidad obtenida es una Normal de parámetros:</p>
<p><span class="math display">\[
\bar{X}_{n} \approx N(\mu, 2.4 / \sqrt{n})
\]</span></p>
<p>Por lo tanto, mediante esta distribución exacta del estadístico para cualquier tamaño de la muestra, se puede plantear sin la necesidad de aproximar a ninguna otra distribución el cálculo del p-valor, de la potencia, etc.</p>
</div>
</div>
<div id="relación-con-los-intervalos-de-confianza" class="section level2 hasAnchor" number="9.19">
<h2><span class="header-section-number">9.19</span> Relación con los intervalos de confianza<a href="pruebas-de-hipótesis.html#relaci%C3%B3n-con-los-intervalos-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los contrastes de hipótesis están muy relacionados con la teoría de los intervalos de confianza. En muchos casos se puede resolver la misma cuestión aplicada formulándola por cualquiera de las dos vías. Por ejemplo, el contraste:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \theta=\theta_{0} \quad \text { contra } \quad \mathrm{H}_{1}: \theta \neq \theta_{0}
\]</span></p>
<p>se puede resolver planteando el intervalo de confianza para <span class="math inline">\(\theta\)</span>, con coeficiente de confianza <span class="math inline">\(1-\alpha\)</span>. Supongamos que el intervalo obtenido es <span class="math inline">\([a ; b]\)</span>. Entonces, si:</p>
<p><span class="math display">\[
\begin{aligned}
&amp; \text { si } \theta_{0} \in[a ; b] \text { aceptar } \mathrm{H}_{0} \\
&amp; \text { si } \theta_{0} \notin[a ; b] \text { aceptar } \mathrm{H}_{1}
\end{aligned}
\]</span></p>
<p>Este contraste tendrá como nivel de significación <span class="math inline">\(\alpha\)</span>. Es posible proporcionar incluso el p-valor si se ajusta la anchura del intervalo para que sea el más amplio posible y a la vez excluya <span class="math inline">\(\theta_{0}\)</span>.</p>
<p>Inversamente, es posible utilizar la región crítica de un contraste para proporcionar una estimación por intervalo del parámetro. Los contrastes bilaterales corresponden a intervalos también bilaterales centrados, mientras que los contrastes unilaterales derechos corresponden a estimaciones unilaterales por exceso y los unilaterales izquierdos, a estimaciones por defecto.</p>
<div id="caso-2-relación-con-los-intervalos-de-confianza" class="section level3 hasAnchor" number="9.19.1">
<h3><span class="header-section-number">9.19.1</span> Caso 2: Relación con los intervalos de confianza<a href="pruebas-de-hipótesis.html#caso-2-relaci%C3%B3n-con-los-intervalos-de-confianza" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el tema anterior se ha estudiado el intervalo de confianza para la media de una distribución Normal. Continuando con las premisas que se han seguido hasta ahora en el caso de la statdrolona, deberemos considerar el intervalo para la medida cuando la varianza es conocida.</p>
<p><span class="math display">\[
\bar{X}_{16}-z_{\alpha / 2} \frac{\sigma}{\sqrt{n}} \leq \mu \leq \bar{X}_{16}+z_{\alpha / 2} \frac{\sigma}{\sqrt{n}}
\]</span></p>
<p>Si tomamos como nivel de confianza <span class="math inline">\(1-\alpha=0.95\)</span>, con los datos obtenidos resulta:</p>
<p><span class="math display">\[
8.54-1.959 \frac{2.4}{\sqrt{16}} \leq \mu \leq 8.54+1.959 \frac{2.4}{\sqrt{16}}
\]</span></p>
<p>Es decir, se obtiene el intervalo <span class="math inline">\([\mathbf{7 , 3 6 4 6};9.7154]\)</span>. Atendiendo a que la media bajo la hipótesis nula es <span class="math inline">\(\mu=7\)</span>, y que no está incluida en el intervalo anterior, se rechaza la hipótesis nula: la media es significativamente diferente de 7. Es la misma conclusión que la que hemos obtenido en el contraste bilateral anterior. Además, dado que se ha calculado un intervalo bilateral, la hipótesis alternativa correspondiente a este intervalo es también bilateral.</p>
</div>
</div>
<div id="tamaños-de-muestra.-diferencia-mínima-significativa" class="section level2 hasAnchor" number="9.20">
<h2><span class="header-section-number">9.20</span> Tamaños de muestra. Diferencia mínima significativa<a href="pruebas-de-hipótesis.html#tama%C3%B1os-de-muestra.-diferencia-m%C3%ADnima-significativa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una de las preguntas más frecuentes en estadística aplicada se refiere a cuál es el tamaño muestral más adecuado. En primer lugar, si la prueba es asintótica, <span class="math inline">\(N\)</span> debe ser suficientemente grande para que la distribución del estadístico bajo la hipótesis nula esté bien aproximada. En el caso de las aproximaciones normales, valores <span class="math inline">\(N \geq 30\)</span> son usualmente aceptados. Esta consideración no se aplica si la prueba es exacta.</p>
<p>El segundo aspecto que hay que considerar se refiere a la potencia deseada en el contraste. Pero la potencia varía en función del parámetro en los contrastes con alternativa compuesta, así que, para formular correctamente el problema, el experimentador debe proporcionar una cantidad adicional: la diferencia mínima significativa <span class="math inline">\(\Delta\)</span>.</p>
<p>Para abreviar, ahora se detalla solo el contraste <span class="math inline">\(\mathrm{H}_{0}: \theta=\theta_{0}\)</span> contra <span class="math inline">\(\mathrm{H}_{0}: \theta \neq \theta_{0}\)</span>, pero la base conceptual es parecida para las alternativas unilaterales.</p>
<p>El significado de <span class="math inline">\(\Delta\)</span> es entonces el siguiente: el experimentador considera que no es importante en la práctica equivocarse aceptando la hipótesis nula (es decir, cometer un error de tipo II) en el rango de alternativas situadas en el intervalo <span class="math inline">\((\theta_{0}-\Delta ; \theta_{0}+\Delta)\)</span>. En cambio, <span class="math inline">\(\theta_{0} \pm \Delta\)</span> son los dos primeros puntos, a medida que <span class="math inline">\(\theta\)</span> se aleja de la hipótesis nula, que el experimentador considera importante diferenciar de <span class="math inline">\(\theta_{0}\)</span>. Es justamente en estos dos puntos donde se ajusta el tamaño de la muestra para garantizar la potencia deseada. Lógicamente, la potencia será todavía más alta si la alternativa finalmente cierta está aún a mayor distancia que <span class="math inline">\(\Delta\)</span>.</p>
<p>La elección concreta del valor de <span class="math inline">\(\Delta\)</span> depende de cada situación aplicada, pero en cualquier caso es una cantidad elegida por el experimentador, no dictada por una regla estadística.</p>
<p>Una vez elegidos <span class="math inline">\(\Delta\)</span> y la potencia deseada en ese punto, es posible indicar cuál es el tamaño mínimo de la muestra para resolver adecuadamente el problema. En algunos casos requerirá un experimento piloto antes de proceder con el experimento definitivo.</p>
<div id="caso-2-cálculo-del-tamaño-de-la-muestra" class="section level3 hasAnchor" number="9.20.1">
<h3><span class="header-section-number">9.20.1</span> Caso 2: Cálculo del tamaño de la muestra<a href="pruebas-de-hipótesis.html#caso-2-c%C3%A1lculo-del-tama%C3%B1o-de-la-muestra" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El estadístico de test de este caso (la media de los atletas) tiene una distribución exacta conocida para todo <span class="math inline">\(n\)</span> que se ha descrito anteriormente. Por lo tanto, aquí el experimentador debe elegir la diferencia mínima significativa (<span class="math inline">\(\boldsymbol{\Delta}\)</span>) y la potencia (<span class="math inline">\(\boldsymbol{\beta}\)</span>) para determinar el tamaño de la muestra adecuado. Supongamos que se quiere hacer el contraste bilateral:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \mu=7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq 7
\]</span></p>
<p>con las condiciones siguientes del experimento fijadas:</p>
<p><span class="math display">\[
\alpha=5 \% \quad \beta=90 \% \quad \Delta=0.8 \mathrm{ng} / \mathrm{ml}
\]</span></p>
<p>Dicho de otro modo, se pretende obtener una potencia del 90% en los puntos:</p>
<p><span class="math display">\[
\mu_{0}-\Delta=6.2 \quad \mu_{0}+\Delta=7.8
\]</span></p>
<p>Estos son los dos primeros valores (menor y mayor que <span class="math inline">\(\mu_{0}=7\)</span>, respectivamente) que el experimentador no quiere que se confundan con <span class="math inline">\(\mathrm{H}_{0}\)</span>, excepto con un error del 10%. Por tanto, se debe aislar el valor de <span class="math inline">\(n\)</span> que cumpla las siguientes condiciones simultáneamente:</p>
<p><span class="math display">\[
\left\{\begin{array}{l}
p\left(\left|\bar{X}_{n}-\mu\right| \sqrt{n} / \sigma \geq z_{\alpha / 2} / \mathrm{H}_{0}\right)=\alpha \\
p\left(\left|\bar{X}_{n}-\mu\right| \sqrt{n} / \sigma \geq z_{\alpha / 2} / \mathrm{H}_{1 \Delta}\right)=\beta
\end{array}\right.
\]</span></p>
<p><span class="math inline">\(\mathrm{H}_{1 \Delta}\)</span> corresponde a la hipótesis simple <span class="math inline">\(\mu=\mu_{0}+\Delta\)</span> (7.8 en el ejemplo). Atendiendo a la distribución de la media de <span class="math inline">\(n\)</span> atletas bajo cada una de las hipótesis, la única incógnita es <span class="math inline">\(n\)</span>. Las constantes <span class="math inline">\(z_{\alpha / 2}\)</span> y <span class="math inline">\(z_{1-\beta}\)</span> corresponden a las colas derechas siguientes de la variable aleatoria Normal tipificada Z:</p>
<p><span class="math display">\[
p\left(Z \geq z_{\alpha / 2}\right)=\alpha / 2 \quad p\left(Z \geq z_{1-\beta}\right)=1-\beta
\]</span></p>
<p>Cuando se resuelve el sistema de ecuaciones anterior se obtiene la fórmula que proporciona el tamaño deseado:</p>
<p><span class="math display">\[
n=\left\{\frac{\sigma\left(z_{1-\beta}+z_{\alpha / 2}\right)}{\Delta}\right\}^{2}
\]</span></p>
<p>Sustituyendo por los valores concretos del ejemplo:</p>
<p><span class="math display">\[
n=\{2.4(1.645+1.960)/0.8\}^{2}=116.964
\]</span></p>
<p>Redondeando, el tamaño debe ser de 117 atletas. En el cuadro siguiente se muestra el tamaño de la muestra en función de la diferencia mínima significativa deseada, junto con otros parámetros que afectan el problema:</p>
<p><img src="images/cap9-SampleSize_i_MDS.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Para los valores extremos de <span class="math inline">\(\alpha(0)\)</span> y de <span class="math inline">\(\beta(1)\)</span>, el valor del tamaño de la muestra se hace infinito y no se puede representar en el cuadro anterior.</p>
</div>
</div>
<div id="esquema-de-un-contraste-correctamente-planteado" class="section level2 hasAnchor" number="9.21">
<h2><span class="header-section-number">9.21</span> Esquema de un contraste correctamente planteado<a href="pruebas-de-hipótesis.html#esquema-de-un-contraste-correctamente-planteado" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los conceptos expuestos hasta aquí son esenciales para entender qué es un contraste estadístico de hipótesis y poder aplicar correctamente los diferentes tests que se detallarán en próximos capítulos. En la práctica, y para la tranquilidad del experimentador, normalmente solo hay que preocuparse de identificar el problema que hay que resolver (contraste sobre una, dos o más poblaciones), la familia de distribución y finalmente aplicar tests ya deducidos, algunos casi centenarios. Ahora bien, el experimentador debe elegir las tres cantidades siguientes:</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">1) nivel de significación <span class="math inline">\(\boldsymbol{\alpha}\)</span></th>
<th align="left">Si no se tiene un criterio definido, se utilizará el estándar <span class="math inline">\(\alpha=\)</span> <br> 0.05.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">2) diferencia mínima <br> significativa <span class="math inline">\(\Delta\)</span></td>
<td align="left">Elegida sobre la base de la experiencia en el campo <br> concreto de aplicación.</td>
</tr>
<tr class="even">
<td align="left">3) potencia deseada en el <br> punto a distancia <span class="math inline">\(\Delta\)</span></td>
<td align="left">Si no se tiene un criterio definido, se tomará <span class="math inline">\(\beta=0.8\)</span> para <br> <span class="math inline">\(\alpha=0.05\)</span>.</td>
</tr>
</tbody>
</table>
<p>Con estas tres cantidades se podrá deducir usualmente el tamaño de muestra necesario, que completará el diseño esencial del test. La información final del resultado del contraste debe indicar estas tres cantidades junto con el p-valor obtenido. Resulta muy aconsejable acompañar el test con el intervalo de confianza equivalente, que puede orientar sobre la significación aplicada (no estadística) del contraste.</p>
</div>
<div id="significación-estadística-y-significación-aplicada" class="section level2 hasAnchor" number="9.22">
<h2><span class="header-section-number">9.22</span> Significación estadística y significación aplicada<a href="pruebas-de-hipótesis.html#significaci%C3%B3n-estad%C3%ADstica-y-significaci%C3%B3n-aplicada" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Al final de este tema resulta conveniente distinguir entre significación estadística y significación aplicada. Cuando se resuelve un contraste de hipótesis se indica que hay significación estadística (S.E.) como sinónimo de aceptación de la hipótesis alternativa. A lo largo de este tema se ha visto, en síntesis, que la S.E. se produce cuando los datos obtenidos en el experimento real y la hipótesis nula presentan una discrepancia que no se atribuye al azar, excepto en el porcentaje de casos marcado por el nivel de significación elegido.</p>
<p>Usualmente, el límite entre la S.E. y la no significación (que técnicamente corresponde a la frontera de la región crítica) depende de la variabilidad del estadístico de test utilizado. Aquí interviene pues de manera directa el tamaño de la muestra <span class="math inline">\(N\)</span> y la varianza del estadístico, como también se ha visto en los dos casos presentados.</p>
<p>En determinadas situaciones, la variabilidad del estadístico es muy pequeña, de modo que el contraste es muy sensible a desviaciones pequeñas de la hipótesis nula. Puede suceder entonces que, cuando se obtienen los datos, el contraste señale que hay S.E., pero que la desviación respecto a la hipótesis nula sea irrelevante desde el punto de vista práctico. La conclusión es que conviene analizar esta significación aplicada (S.A.) cuando se hace un contraste de hipótesis. En muchos casos, la manera más sencilla es obtener el intervalo de confianza adecuado e interpretar la información del contraste junto con la del intervalo.</p>
<p>En resumen, cuando se aplica cualquier contraste no debemos conformarnos con la simple lectura del p-valor y decidir en consecuencia, sino que:</p>
<ul>
<li>si se ha detectado S.E., hay que valorar la S.A., por ejemplo, mediante un intervalo de confianza. Puede haber S.E. pero que no haya S.A.<br />
</li>
<li>si no se ha detectado S.E., hay que valorar si el tamaño de la muestra es suficiente para detectar (estadísticamente) las diferencias deseadas por el experimentador. Puede que no haya S.E. por un tamaño de muestra inadecuado y, por tanto, no se podría concluir sobre la S.A. Si el tamaño de la muestra es suficiente y no hay S.E., entonces tampoco hay S.A.</li>
</ul>
<div id="caso-2-significación-estadística-y-aplicada" class="section level3 hasAnchor" number="9.22.1">
<h3><span class="header-section-number">9.22.1</span> Caso 2: Significación estadística y aplicada<a href="pruebas-de-hipótesis.html#caso-2-significaci%C3%B3n-estad%C3%ADstica-y-aplicada" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Con los datos realmente obtenidos en el estudio, y la hipótesis:</p>
<p><span class="math display">\[
\mathrm{H}_{0}: \mu=7 \quad \text { contra } \quad \mathrm{H}_{1}: \mu \neq 7
\]</span></p>
<p>ya hemos visto que la conclusión, para <span class="math inline">\(\alpha=0.05\)</span>, era indicar que hay significación estadística.</p>
<p>Supongamos que los fisiólogos aceptan que las diferencias en el nivel de la hormona son relevantes cuando hay más de <span class="math inline">\(0.2 \mathrm{ng} / \mathrm{ml}\)</span> de diferencia en la media de la población. El intervalo bilateral en la muestra anterior es:<br />
y permite afirmar que también hay significación aplicada.<br />
Supongamos que la población tuviera una desviación estándar de <span class="math inline">\(0.1 \mathrm{ng} / \mathrm{ml}\)</span> (en lugar de la 2.4 planteada hasta ahora), y se hubiera obtenido una media igual a 7.13. El contraste de hipótesis detectaría entonces igualmente que hay S.E., pero en cambio cuando se observa el intervalo de confianza:</p>
<p>Habría que concluir que no hay S.A. En este segundo caso, la varianza tan pequeña permite que el contraste sea muy sensible a pequeñas variaciones de la media. La S.E. en este último ejemplo no resulta relevante en la práctica.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>La statdrolona no es ninguna hormona, aquí se ha adaptado la información de hormonas reales.<a href="pruebas-de-hipótesis.html#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimación-por-intérvalos.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="construcción-de-contrastes-de-hipótesis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": ["FundamentosInferenciaEstadistica.pdf"],
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "section",
    "scroll_highlight": true
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
